public String [ ] getAllDatabases ( ) throws HttpException , IOException { treturn ( String [ ] ) JSONArray . fromObject ( get ( " _all_dbs " ) ) . toArray ( EMPTY_ARR ) ; } 
public JSONObject getAllDocsBySeq ( final String dbname , final long from , final int limit ) throws HttpException , tIOException { treturn JSONObject . fromObject ( get ( String . format ( " %s/_all_docs_by_seq?startkey=%s&limit=%d&include_docs=true " , tdbname , from , limit ) ) ) ; 
public DbInfo getInfo ( final String dbname ) throws HttpException , IOException { treturn new DbInfo ( JSONObject . fromObject ( get ( dbname ) ) ) ; } 
private String get ( final String path ) throws HttpException , IOException { tfinal GetMethod get = new GetMethod ( url ( path ) ) ; ttry { tCLIENT . executeMethod ( get ) ; 
private String url ( final String path ) { treturn String . format ( " %s/%s " , url , path ) ; } 
private int post ( final String path , final String body ) throws HttpException , IOException { tfinal PostMethod post = new PostMethod ( url ( path ) ) ; tpost . setRequestEntity ( new StringRequestEntity ( body , " application/json " , " UTF-8 " ) ) ; ttry { treturn CLIENT . executeMethod ( post ) ; 
public void run ( ) { tIndexWriter writer = null ; tboolean commit = false ; ttry { tfinal String [ ] dbnames = db . getAllDatabases ( ) ; 
private void updateDocument ( final IndexWriter writer , final String dbname , final JSONObject jsonDoc ) tthrows IOException { tfinal Document doc = new Document ( ) ; } 
private void add ( final Document out , final String key , final Object value , final boolean store ) { if ( value instanceof JSONObject ) { tfinal JSONObject json = ( JSONObject ) value ; 
private Field text ( final String name , final String value , final boolean store ) { treturn new Field ( name , value , store ? Store . YES : Store . NO , Field . Index . ANALYZED ) ; } 
private Field token ( final String name , final String value , final boolean store ) { treturn new Field ( name , value , store ? Store . YES : Store . NO , Field . Index . NOT_ANALYZED_NO_NORMS ) ; } 
public void start ( ) throws IOException { tlog . info ( " couchdb-lucene is starting. " ) ; tthis . reader = IndexReader . open ( dir , true ) ; tthis . searcher = new IndexSearcher ( this . reader ) ; ttimer . schedule ( new IndexUpdateTask ( ) , 0 , Config . REFRESH_INTERVAL ) ; tlog . info ( " couchdb-lucene has started. " ) ; } 
public void stop ( ) throws IOException { tlog . info ( " couchdb-lucene is stopping. " ) ; ttimer . cancel ( ) ; tthis . searcher . close ( ) ; tlog . info ( " couchdb-lucene is stopped. " ) ; } 
public String query ( final String db , final String query , final String sort , final int skip , final int limit ) tthrows IOException , ParseException { if ( log . isDebugEnabled ( ) ) { tfinal String msg = String . format ( " db:%s, query:%s, sort:%s, skip:%,d, limit:%,d " , db , query , sort , skip , tlimit ) ; tlog . debug ( msg ) ; } tfinal BooleanQuery bq = new BooleanQuery ( ) ; tbq . add ( new TermQuery ( new Term ( Config . DB , db ) ) , Occur . MUST ) ; tbq . add ( Config . QP . parse ( query ) , Occur . MUST ) ; tfinal TopDocs td ; if ( sort = = null ) ttd = searcher . search ( bq , null , skip + limit ) ; telse ttd = searcher . search ( bq , null , skip + limit , new Sort ( sort ) ) ; tTopFieldDocs tfd = null ; if ( td instanceof TopFieldDocs ) { ttfd = ( TopFieldDocs ) td ; } tfinal JSONObject json = new JSONObject ( ) ; tjson . element ( " total_rows " , td . totalHits ) ; } 
private IndexWriter newWriter ( ) throws IOException { tfinal IndexWriter result = new IndexWriter ( dir , Config . ANALYZER , MaxFieldLength . UNLIMITED ) ; tresult . setUseCompoundFile ( false ) ; tresult . setRAMBufferSizeMB ( Config . RAM_BUF ) ; treturn result ; } 
public static void main ( final String [ ] args ) throws IOException { tfinal Index index = new Index ( ) ; tindex . start ( ) ; } 
public static JSONObject throwableToJSON ( final Throwable ) { treturn new JSONObject ( ) . element ( " code " , " 500 " ) . element ( " body " , tt . getMessage ( ) = = null ? " Unknown error " : . getMessage ( ) ) ; 
private void updateDocument ( final IndexWriter writer , final String dbname , final JSONObject obj ) tthrows IOException { tfinal Document doc = new Document ( ) ; } 
public void start ( ) throws IOException { tlog . info ( " couchdb-lucene is starting. " ) ; tthis . progress . load ( ) ; tthis . reader = IndexReader . open ( dir , true ) ; tthis . searcher = new IndexSearcher ( this . reader ) ; ttimer . schedule ( new IndexUpdateTask ( ) , 0 , Config . REFRESH_INTERVAL ) ; tlog . info ( " couchdb-lucene has started. " ) ; } 
public void load ( ) throws IOException { tfinal File dest = new File ( dir , " indexing.progress " ) ; if ( dest . exists ( ) = = false ) { tprogress . clear ( ) ; treturn ; } tfinal FileInputStream in = new FileInputStream ( dest ) ; tfinal DataInputStream din = new DataInputStream ( in ) ; ttry { tprogress . clear ( ) ; 
public void save ( ) throws IOException { tfinal File tmp = new File ( dir , " indexing.new " ) ; tfinal File dest = new File ( dir , " indexing.progress " ) ; tfinal FileOutputStream out = new FileOutputStream ( tmp ) ; tfinal DataOutputStream dout = new DataOutputStream ( out ) ; ttry { dout . writeInt ( progress . size ( ) ) ; 
private void updateDocument ( final IndexWriter writer , final String dbname , final JSONObject obj ) tthrows IOException { tfinal Document doc = new Document ( ) ; tfinal JSONObject json = obj . getJSONObject ( " doc " ) ; } 
private void updateDocument ( final IndexWriter writer , final String dbname , final JSONObject obj ) tthrows IOException { tfinal Document doc = new Document ( ) ; tfinal JSONObject json = obj . getJSONObject ( " doc " ) ; } 
public String query ( final String db , final String query , final String sort , final int skip , final int limit ) tthrows IOException , ParseException { tfinal BooleanQuery bq = new BooleanQuery ( ) ; tbq . add ( new TermQuery ( new Term ( Config . DB , db ) ) , Occur . MUST ) ; tbq . add ( Config . QP . parse ( query ) , Occur . MUST ) ; if ( log . isDebugEnabled ( ) ) { tfinal String msg = String . format ( " db:%s, query:%s, sort:%s, skip:%,d, limit:%,d " , db , bq , sort , skip , tlimit ) ; tlog . debug ( msg ) ; } tfinal TopDocs td ; if ( sort = = null ) ttd = searcher . search ( bq , null , skip + limit ) ; telse ttd = searcher . search ( bq , null , skip + limit , new Sort ( sort ) ) ; tTopFieldDocs tfd = null ; if ( td instanceof TopFieldDocs ) { ttfd = ( TopFieldDocs ) td ; } tfinal JSONObject json = new JSONObject ( ) ; tjson . element ( " total_rows " , td . totalHits ) ; } 
public void save ( ) throws IOException { tfinal File tmp = new File ( dir , " indexing.new " ) ; tfinal File dest = new File ( dir , " indexing.progress " ) ; tfinal FileOutputStream out = new FileOutputStream ( tmp ) ; tfinal DataOutputStream dout = new DataOutputStream ( out ) ; ttry { dout . writeUTF ( Integer . toString ( progress . size ( ) ) ) ; 
private void updateDocument ( final IndexWriter writer , final String dbname , final JSONObject obj ) tthrows IOException { tfinal Document doc = new Document ( ) ; tfinal JSONObject json = obj . getJSONObject ( " doc " ) ; } 
public static void main ( final String [ ] args ) throws IOException { tfinal Index index = new Index ( ) ; tindex . start ( ) ; } 
public static void main ( final String [ ] args ) throws IOException { tfinal Index index = new Index ( ) ; tindex . start ( ) ; } 
public void run ( ) { tlog . info ( " couchdb-lucene is starting. " ) ; ttry { tIndex . this . progress . load ( ) ; tIndex . this . reader = IndexReader . open ( dir , true ) ; tIndex . this . searcher = new IndexSearcher ( Index . this . reader ) ; } catch ( IOException e ) { tSystem . out . println ( Utils . throwableToJSON ( e ) ) ; tlog . info ( " couchdb-lucene failed to started. " ) ; treturn ; } tlog . info ( " couchdb-lucene is started. " ) ; } 
public void start ( ) throws IOException { ttimer . schedule ( new IndexStartTask ( ) , 0 ) ; ttimer . schedule ( new IndexUpdateTask ( ) , 0 , Config . REFRESH_INTERVAL ) ; } 
public static String throwableToJSON ( final Throwable ) { treturn error ( . getMessage ( ) = = null ? " Unknown error " : . getMessage ( ) ) ; } 
public static String error ( final String txt ) { treturn new JSONObject ( ) . element ( " code " , " 500 " ) . element ( " body " , txt ) . toString ( ) ; } 
public static void main ( final String [ ] args ) throws IOException { tfinal Index index = new Index ( ) ; tindex . start ( ) ; } 
public void run ( ) { tlog . info ( " couchdb-lucene is starting. " ) ; ttry { if ( IndexWriter . isLocked ( dir ) ) { tlog . warn ( " Forcibly unlocking locked index at startup. " ) ; tIndexWriter . unlock ( dir ) ; } tIndex . this . progress . load ( ) ; tIndex . this . reader = IndexReader . open ( dir , true ) ; tIndex . this . searcher = new IndexSearcher ( Index . this . reader ) ; } catch ( IOException e ) { tSystem . out . println ( Utils . throwableToJSON ( e ) ) ; tlog . info ( " couchdb-lucene failed to started. " ) ; treturn ; } tlog . info ( " couchdb-lucene is started. " ) ; } 
public void run ( ) { tlog . info ( " couchdb-lucene is starting. " ) ; ttry { if ( IndexWriter . isLocked ( dir ) ) { tlog . warn ( " Forcibly unlocking locked index at startup. " ) ; tIndexWriter . unlock ( dir ) ; } tIndex . this . progress . load ( ) ; tIndex . this . reader = IndexReader . open ( dir , true ) ; tIndex . this . searcher = new IndexSearcher ( Index . this . reader ) ; } catch ( IOException e ) { tSystem . out . println ( Utils . throwableToJSON ( e ) ) ; tlog . info ( " couchdb-lucene failed to started. " ) ; treturn ; } tlog . info ( " couchdb-lucene is started. " ) ; } 
public static String throwableToJSON ( final Throwable ) { treturn error ( . getMessage ( ) = = null ? " Unknown error " : String . format ( " %s: %s " , . getClass ( ) , . getMessage ( ) ) ) ; } 
public void run ( ) { tlog . info ( " couchdb-lucene is starting. " ) ; ttry { if ( IndexWriter . isLocked ( dir ) ) { tlog . warn ( " Forcibly unlocking locked index at startup. " ) ; tIndexWriter . unlock ( dir ) ; } tIndex . this . progress . load ( ) ; topenReader ( ) ; } catch ( IOException e ) { tSystem . out . println ( Utils . throwableToJSON ( e ) ) ; tlog . info ( " couchdb-lucene failed to started. " ) ; treturn ; } tlog . info ( " couchdb-lucene is started. " ) ; } 
private void openReader ( ) throws IOException { tfinal IndexReader oldReader ; tsynchronized ( mutex ) { toldReader = this . reader ; } tfinal IndexReader newReader ; if ( oldReader = = null ) { tnewReader = IndexReader . open ( dir , true ) ; } else { tnewReader = oldReader . reopen ( ) ; } if ( oldReader ! = newReader ) { tsynchronized ( mutex ) { 
public void stop ( ) throws IOException { tlog . info ( " couchdb-lucene is stopping. " ) ; ttimer . cancel ( ) ; tthis . reader . close ( ) ; tlog . info ( " couchdb-lucene is stopped. " ) ; } 
public JSONObject getDoc ( final String dbname , final String id , final String rev ) throws HttpException , IOException { treturn JSONObject . fromObject ( get ( String . format ( " %s/%s?rev=%s " , dbname , id , rev ) ) ) ; } 
public static void main ( final String [ ] args ) throws IOException { tfinal Index index = new Index ( ) ; tindex . start ( ) ; } 
public static void main ( final String [ ] args ) throws IOException { tfinal Index index = new Index ( ) ; tindex . start ( ) ; } 
public JSONObject getDocs ( final String dbname , final String . . . ids ) throws HttpException , IOException { tfinal JSONArray keys = new JSONArray ( ) ; tfor ( final String id : ids ) { tkeys . add ( id ) ; } tfinal JSONObject req = new JSONObject ( ) ; treq . element ( " keys " , keys ) ; treturn JSONObject . fromObject ( post ( String . format ( " %s/_all_docs?include_docs=true " , dbname ) , req . toString ( ) ) ) ; } 
private synchronized String get ( final String path ) throws HttpException , IOException { tfinal GetMethod get = new GetMethod ( url ( path ) ) ; ttry { tCLIENT . executeMethod ( get ) ; 
private synchronized String post ( final String path , final String body ) throws HttpException , IOException { tfinal PostMethod post = new PostMethod ( url ( path ) ) ; tpost . setRequestEntity ( new StringRequestEntity ( body , " application/json " , " UTF-8 " ) ) ; ttry { tCLIENT . executeMethod ( post ) ; 
public void start ( ) throws IOException { tlog . info ( " couchdb-lucene is starting. " ) ; if ( IndexWriter . isLocked ( dir ) ) { tlog . warn ( " Forcibly unlocking locked index at startup. " ) ; tIndexWriter . unlock ( dir ) ; } tIndex . this . progress . load ( ) ; topenReader ( ) ; tlog . info ( " couchdb-lucene is started. " ) ; ttimer . schedule ( new IndexUpdateTask ( ) , 0 , Config . REFRESH_INTERVAL ) ; } 
private String get ( final String path ) throws HttpException , IOException { treturn execute ( new GetMethod ( url ( path ) ) ) ; } 
private String post ( final String path , final String body ) throws HttpException , IOException { tfinal PostMethod post = new PostMethod ( url ( path ) ) ; tpost . setRequestEntity ( new StringRequestEntity ( body , " application/json " , " UTF-8 " ) ) ; treturn execute ( post ) ; } 
private synchronized String execute ( final HttpMethodBase method ) throws HttpException , IOException { ttry { tCLIENT . executeMethod ( method ) ; 
private Query parse ( final String query ) throws ParseException { tfinal Query result = Config . QP . parse ( query ) ; } 
private void visit ( final Query result ) { if ( result instanceof BooleanQuery ) { tfinal BooleanQuery bq = ( BooleanQuery ) result ; 
private Query parse ( final String query ) throws ParseException { tfinal Query result = Config . QP . parse ( query ) ; treturn visit ( result ) ; } 
private boolean isNumericOrNull ( final String val ) { if ( val = = null ) treturn true ; ttry { tLong . parseLong ( val ) ; 
private String encodeNumber ( final String num ) { treturn num = = null ? null : NumberTools . longToString ( Long . parseLong ( num ) ) ; } 
public void testSimpleEval ( ) { tfinal String indexing_function = " function(doc) { if (doc.size) { emit_int(doc.size); } } " ; tfinal Rhino rhino = new Rhino ( ) ; tObject obj = rhino . evaluate ( indexing_function ) ; tSystem . err . println ( obj ) ; tfinal Context ctx = new ContextFactory ( ) . enterContext ( ) ; tfinal Scriptable scope = ctx . initStandardObjects ( ) ; tfinal Object [ ] args = new Object [ ] { " a " , " b " , " c " } ; tobj = ctx . evaluateString ( scope , indexing_function , " <fun> " , 0 , null ) ; tSystem . err . println ( obj ) ; } 
public void testSimpleEval ( ) { tfinal String source = " function(doc) { if (doc.size) {return (doc.size); }} " ; tfinal Context ctx = new ContextFactory ( ) . enterContext ( ) ; tfinal Scriptable scope = ctx . initStandardObjects ( ) ; tfinal Function function = ctx . compileFunction ( scope , source , " fun " , 0 , null ) ; tfinal Object [ ] args = new Object [ ] { new Thing ( ) , " b " , " c " } ; tfinal Object obj = function . call ( ctx , scope , null , args ) ; tSystem . err . println ( obj ) ; } 
tString url ( final String path ) { treturn String . format ( " %s/%s " , url , path ) ; } 
public static void main ( final String [ ] args ) throws IOException { tfinal Index index = new Index ( ) ; tindex . start ( ) ; } 
public void parse ( final InputStream in , final String contentType , final Document doc ) { tfinal AutoDetectParser parser = new AutoDetectParser ( ) ; tfinal Metadata md = new Metadata ( ) ; tfinal Reader reader = new ParsingReader ( parser , in , md ) ; tfinal String body ; ttry { ttry { tbody = IOUtils . toString ( reader ) ; } finally { treader . close ( ) ; } } catch ( final IOException e ) { treturn ; } tSystem . err . printf ( " body: %s, md: %s " , body , md ) ; tdoc . add ( text ( Config . BODY , body , false ) ) ; if ( md . get ( Metadata . TITLE ) ! = null ) { tdoc . add ( text ( Config . TITLE , md . get ( Metadata . TITLE ) , true ) ) ; } if ( md . get ( Metadata . AUTHOR ) ! = null ) { tdoc . add ( text ( Config . AUTHOR , md . get ( Metadata . AUTHOR ) , true ) ) ; 
public static Field text ( final String name , final String value , final boolean store ) { treturn new Field ( name , value , store ? Store . YES : Store . NO , Field . Index . ANALYZED ) ; } 
public static Field token ( final String name , final String value , final boolean store ) { treturn new Field ( name , value , store ? Store . YES : Store . NO , Field . Index . NOT_ANALYZED_NO_NORMS ) ; } 
public void parse ( final InputStream in , final String contentType , final Document doc ) { tfinal AutoDetectParser parser = new AutoDetectParser ( ) ; tfinal Metadata md = new Metadata ( ) ; tmd . set ( Metadata . CONTENT_TYPE , contentType ) ; tfinal Reader reader = new ParsingReader ( parser , in , md ) ; tfinal String body ; ttry { ttry { tbody = IOUtils . toString ( reader ) ; } finally { treader . close ( ) ; } } catch ( final IOException e ) { treturn ; } tdoc . add ( text ( Config . BODY , body , false ) ) ; if ( md . get ( Metadata . TITLE ) ! = null ) { tdoc . add ( text ( Config . TITLE , md . get ( Metadata . TITLE ) , true ) ) ; } if ( md . get ( Metadata . AUTHOR ) ! = null ) { tdoc . add ( text ( Config . AUTHOR , md . get ( Metadata . AUTHOR ) , true ) ) ; 
public void parse ( final InputStream in , final String contentType , final Document doc ) { tfinal AutoDetectParser parser = new AutoDetectParser ( ) ; tfinal Metadata md = new Metadata ( ) ; tmd . set ( Metadata . CONTENT_TYPE , contentType ) ; tfinal Reader reader = new ParsingReader ( parser , in , md ) ; tfinal String body ; ttry { ttry { tbody = IOUtils . toString ( reader ) ; } finally { treader . close ( ) ; } } catch ( final IOException e ) { tlog . warn ( " Failed to index an attachment. " , e ) ; treturn ; } tdoc . add ( text ( Config . BODY , body , false ) ) ; if ( md . get ( Metadata . TITLE ) ! = null ) { tdoc . add ( text ( Config . TITLE , md . get ( Metadata . TITLE ) , true ) ) ; } if ( md . get ( Metadata . AUTHOR ) ! = null ) { tdoc . add ( text ( Config . AUTHOR , md . get ( Metadata . AUTHOR ) , true ) ) ; 
tString encode ( final String path ) { ttry { treturn URLEncoder . encode ( path , " UTF-8 " ) ; 
public void testSimpleEval ( ) { tfinal String source = " function(doc) { if (doc.size) {return (doc.size); }} " ; tfinal Context ctx = new ContextFactory ( ) . enterContext ( ) ; tctx . setLanguageVersion ( 170 ) ; tfinal Scriptable scope = ctx . initStandardObjects ( ) ; tfinal Function function = ctx . compileFunction ( scope , source , " fun " , 0 , null ) ; tfinal Object [ ] args = new Object [ ] { new Thing ( ) , " b " , " c " } ; tObject obj = function . call ( ctx , scope , null , args ) ; tSystem . err . println ( obj ) ; tfinal String source2 = " function myobj(arg) {this.size=12} " ; tfinal Object o = Context . jsToJava ( source2 , Object . class ) ; tSystem . err . println ( o ) ; tSystem . err . println ( o . getClass ( ) ) ; tfinal Object o2 = Context . javaToJS ( new Thing ( ) , scope ) ; tSystem . err . println ( o2 ) ; tSystem . err . println ( o2 . getClass ( ) ) ; tobj = ctx . evaluateString ( scope , source2 , " fun2 " , 0 , null ) ; tSystem . err . println ( obj ) ; } 
public void testSimpleEval ( ) { tfinal String source = " function() { var doc = { \" size \" :12}; return doc.size; } " ; tfinal Context ctx = new ContextFactory ( ) . enterContext ( ) ; tctx . setLanguageVersion ( 170 ) ; tfinal Scriptable scope = ctx . initStandardObjects ( ) ; tfinal Function function = ctx . compileFunction ( scope , source , " fun " , 0 , null ) ; tObject obj = function . call ( ctx , scope , null , null ) ; tSystem . err . println ( obj ) ; } 
public String parse ( final String doc ) { treturn function . call ( context , scope , null , new Object [ ] { doc } ) . toString ( ) ; } 
public void testRhino ( ) { tfinal Rhino rhino = new Rhino ( " function(doc){return doc.size} " ) ; tfinal String doc = " { \" size \" :13} " ; tassertThat ( rhino . parse ( doc ) , CoreMatchers . is ( " 13.0 " ) ) ; trhino . close ( ) ; } 
public void emit_text ( final Object key , final String val ) { tSystem . err . printf ( " %s: %s " , key , val ) ; } 
public void emit_int ( final Object key , final Double val ) { tSystem . err . printf ( " %s: %s " , key , val ) ; } 
public void emit_date ( final Object key , final String val ) { tSystem . err . printf ( " %s: %s " , key , val . getClass ( ) ) ; } 
public void test ( ) throws Exception { tfinal QueryParser qp = new QueryParser ( " body " , new StandardAnalyzer ( ) ) ; tfinal Query q = qp . parse ( " field_name: \" -3.2 \" " ) ; tSystem . out . println ( ( ( TermQuery ) q ) . getTerm ( ) . text ( ) ) ; } 
public void testRhino ( ) { tfinal Rhino rhino = new Rhino ( " function(doc) { delete doc.deleteme; return doc.size; } " ) ; tfinal String doc = " { \" deleteme \" : \" true \" , \" size \" :13} " ; tassertThat ( rhino . parse ( doc ) , CoreMatchers . is ( " 13.0 " ) ) ; trhino . close ( ) ; } 
public void testRhinoActual ( ) { tfinal String fn = " function(doc) { " + " out.emit_text( \" body \" , doc.body); " + " out.emit_int( \" size \" , doc.size); " + " out.emit_date( \" start \" , doc.start_date); " + " } " ; tSystem . out . println ( fn ) ; tfinal Rhino rhino = new Rhino ( fn ) ; tfinal String doc = " { \" body \" : \" some text. \" , \" size \" :13, \" start_date \" : \" 2009-05-16 09:14:39 -0000 \" } " ; tassertThat ( rhino . parse ( doc ) , CoreMatchers . is ( " 13.0 " ) ) ; trhino . close ( ) ; } 
public JSONObject getDoc ( final String dbname , final String id , final String rev ) throws HttpException , IOException { if ( rev = = null ) treturn JSONObject . fromObject ( get ( String . format ( " %s/%s " , dbname , id ) ) ) ; 
private synchronized String execute ( final HttpMethodBase method ) throws HttpException , IOException { ttry { tCLIENT . executeMethod ( method ) ; 
public NativeObject parse ( final String doc ) { treturn ( NativeObject ) function . call ( context , scope , null , new Object [ ] { doc } ) ; } 
public void testRhino ( ) { tfinal Rhino rhino = new Rhino ( " function(doc) { delete doc.deleteme; return doc; } " ) ; tfinal String doc = " { \" deleteme \" : \" true \" , \" size \" :13} " ; tassertThat ( ( Double ) rhino . parse ( doc ) . get ( " size " , null ) , CoreMatchers . is ( 13.0 ) ) ; trhino . close ( ) ; } 
public static void main ( final String [ ] args ) throws IOException { tfinal Index index = new Index ( ) ; tfinal Thread startupThread = new Thread ( new Runnable ( ) { public void run ( ) { ttry { tindex . start ( ) ; } catch ( IOException e ) { te . printStackTrace ( ) ; } } } ) ; tstartupThread . start ( ) ; tfinal BufferedReader reader = new BufferedReader ( new InputStreamReader ( System . in , " UTF-8 " ) ) ; tString line = null ; } 
private String loadJSONParser ( ) throws IOException { tfinal InputStream in = Rhino . class . getClassLoader ( ) . getResourceAsStream ( " json2.js " ) ; ttry { treturn IOUtils . toString ( in , " UTF-8 " ) ; 
public String parse ( final String doc ) { treturn ( String ) function . call ( context , scope , null , new Object [ ] { doc } ) ; } 
public void testRhino ( ) throws Exception { tfinal Rhino rhino = new Rhino ( " function(doc) { delete doc.deleteme; return doc; } " ) ; tfinal String doc = " { \" deleteme \" : \" true \" , \" size \" :13} " ; tassertThat ( rhino . parse ( doc ) , CoreMatchers . equalTo ( " { \" size \" :13} " ) ) ; trhino . close ( ) ; } 
public void testRhino ( ) throws Exception { tfinal Rhino rhino = new Rhino ( " function(doc) { delete doc.deleteme; doc.size++; return doc; } " ) ; tfinal String doc = " { \" deleteme \" : \" true \" , \" size \" :13} " ; tassertThat ( rhino . parse ( doc ) , CoreMatchers . equalTo ( " { \" size \" :14} " ) ) ; trhino . close ( ) ; } 
public String parse ( final String doc ) { treturn ( String ) systemFun . call ( context , scope , null , new Object [ ] { doc , userFun } ) ; } 
private Query parse ( final String query ) throws ParseException { treturn Config . QP . parse ( query ) ; } 
public void start ( ) throws Exception { tlog . info ( " couchdb-lucene is starting. " ) ; if ( IndexWriter . isLocked ( dir ) ) { tlog . warn ( " Forcibly unlocking locked index at startup. " ) ; tIndexWriter . unlock ( dir ) ; } tIndex . this . progress . load ( ) ; topenReader ( ) ; } 
public static void main ( final String [ ] args ) throws IOException { tSystem . out . println ( Utils . error ( " couchdb-lucene is unavailable. " ) ) ; tfinal Index index = new Index ( ) ; tfinal Thread startupThread = new Thread ( new Runnable ( ) { public void run ( ) { ttry { tindex . start ( ) ; } catch ( final Exception e ) { te . printStackTrace ( ) ; } } } ) ; tstartupThread . start ( ) ; tfinal BufferedReader reader = new BufferedReader ( new InputStreamReader ( System . in , " UTF-8 " ) ) ; tString line = null ; } 
public static String error ( final String txt ) { treturn new JSONObject ( ) . element ( " code " , 500 ) . element ( " body " , txt ) . toString ( ) ; } 
public static void main ( final String [ ] args ) throws Exception { tfinal Scanner scanner = new Scanner ( System . in ) ; twhile ( scanner . hasNextLine ( ) ) { tfinal String line = scanner . nextLine ( ) ; 
public static void main ( final String [ ] args ) throws Exception { if ( args . length > = 1 & & args [ 0 ] . equals ( " -index " ) ) { tIndex . main ( args ) ; treturn ; } if ( args . length > = 1 & & args [ 0 ] . equals ( " -search " ) ) { tSearch . main ( args ) ; treturn ; } tSystem . out . println ( Utils . error ( " Invoke with -index or -search only. " ) ) ; treturn ; } 
private static void ddd ( ) throws Exception { tSystem . out . println ( Utils . error ( " couchdb-lucene is unavailable. " ) ) ; tfinal Index index = new Index ( ) ; tfinal Thread startupThread = new Thread ( new Runnable ( ) { public void run ( ) { ttry { tindex . start ( ) ; } catch ( final Exception e ) { te . printStackTrace ( ) ; } } } ) ; tstartupThread . start ( ) ; tfinal BufferedReader reader = new BufferedReader ( new InputStreamReader ( System . in , " UTF-8 " ) ) ; tString line = null ; } 
public static void main ( final String [ ] args ) throws Exception { tIndexSearcher searcher = null ; tfinal Scanner scanner = new Scanner ( System . in ) ; twhile ( scanner . hasNextLine ( ) ) { if ( searcher = = null & & IndexReader . indexExists ( Config . INDEX_DIR ) ) { 
public void start ( ) throws Exception { tlog . info ( " couchdb-lucene is starting. " ) ; if ( IndexWriter . isLocked ( dir ) ) { tlog . warn ( " Forcibly unlocking locked index at startup. " ) ; tIndexWriter . unlock ( dir ) ; } tSearch . this . progress . load ( ) ; topenReader ( ) ; } 
public String execute ( final IndexSearcher searcher ) throws IOException { tfinal TopDocs td ; if ( sort = = null ) { ttd = searcher . search ( q , null , skip + limit ) ; } else { ttd = searcher . search ( q , null , skip + limit , sort ) ; } tfinal JSONObject result = new JSONObject ( ) ; tresult . element ( " code " , 200 ) ; tfinal JSONObject json = new JSONObject ( ) ; tjson . element ( " total_rows " , td . totalHits ) ; tresult . put ( " json " , json ) ; treturn result . toString ( ) ; } 
public static void log ( final String fmt , final Object . . . args ) { tfinal String msg = String . format ( fmt , args ) ; tSystem . out . printf ( " { \" log \" : \" %s \" } " , msg ) ; } 
public static void main ( final String [ ] args ) throws Exception { tIndexReader reader = null ; tIndexSearcher searcher = null ; tfinal Scanner scanner = new Scanner ( System . in ) ; twhile ( scanner . hasNextLine ( ) ) { if ( reader = = null ) { 
public static void main ( final String [ ] args ) throws Exception { tIndexReader reader = null ; tIndexSearcher searcher = null ; tfinal Scanner scanner = new Scanner ( System . in ) ; twhile ( scanner . hasNextLine ( ) ) { if ( reader = = null ) { reader.close(); 
public String execute ( final IndexSearcher searcher ) throws IOException { tfinal TopDocs td ; tfinal StopWatch stopWatch = new StopWatch ( ) ; } 
public void lap ( final String name ) { tfinal long now = System . nanoTime ( ) ; telapsed . put ( name , now - start ) ; tstart = now ; } 
public static void main ( final String [ ] args ) throws Exception { tIndexReader reader = null ; tIndexSearcher searcher = null ; tfinal Scanner scanner = new Scanner ( System . in ) ; twhile ( scanner . hasNextLine ( ) ) { if ( reader = = null ) { reader.close(); 
public String execute ( final IndexSearcher searcher ) throws IOException { tfinal TopDocs td ; tfinal StopWatch stopWatch = new StopWatch ( ) ; } 
public String execute ( final IndexSearcher searcher ) throws IOException { tfinal TopDocs td ; tfinal StopWatch stopWatch = new StopWatch ( ) ; } 
public String execute ( final IndexSearcher searcher ) throws IOException { tfinal TopDocs td ; tfinal StopWatch stopWatch = new StopWatch ( ) ; } 
public static void main ( final String [ ] args ) throws Exception { tIndexReader reader = null ; tIndexSearcher searcher = null ; tfinal Scanner scanner = new Scanner ( System . in ) ; twhile ( scanner . hasNextLine ( ) ) { if ( reader = = null ) { reader.close(); 
public static void main ( final String [ ] args ) throws Exception { tfinal Runnable indexer = new Indexer ( ) ; tfinal Thread indexerThread = new Thread ( indexer , " indexer " ) ; tindexerThread . setDaemon ( true ) ; tindexerThread . start ( ) ; tfinal Scanner scanner = new Scanner ( System . in ) ; twhile ( scanner . hasNextLine ( ) ) { tfinal String line = scanner . nextLine ( ) ; 
public static void main ( final String [ ] args ) throws Exception { tIndexReader reader = null ; tIndexSearcher searcher = null ; tfinal Scanner scanner = new Scanner ( System . in ) ; twhile ( scanner . hasNextLine ( ) ) { if ( reader = = null ) { reader.close(); 
public String execute ( final IndexSearcher searcher ) throws IOException { } 
public void run ( ) { ttry { tthis . dir = FSDirectory . getDirectory ( Config . INDEX_DIR ) ; 
private void updateIndex ( ) throws IOException { if ( IndexWriter . isLocked ( dir ) ) { tLog . log ( " Forcibly unlocking locked index at startup. " ) ; tIndexWriter . unlock ( dir ) ; } tfinal String [ ] dbnames = DB . getAllDatabases ( ) ; tRhino rhino = null ; tboolean commit = false ; tfinal IndexWriter writer = newWriter ( ) ; tProgress progress = null ; ttry { tprogress = new Progress ( dir ) ; 
private void waitForUpdateNotification ( ) { tsynchronized ( MUTEX ) { ttry { 
private IndexWriter newWriter ( ) throws IOException { tfinal IndexWriter result = new IndexWriter ( dir , Config . ANALYZER , MaxFieldLength . UNLIMITED ) ; tresult . setUseCompoundFile ( false ) ; tresult . setRAMBufferSizeMB ( Config . RAM_BUF ) ; treturn result ; } 
public static void log ( final String fmt , final Object . . . args ) { tSystem . out . print ( " log, " ) ; tSystem . out . printf ( fmt , args ) ; tSystem . out . println ( ) ; } 
public void load ( ) throws IOException { if ( dir . fileExists ( FILENAME ) = = false ) { tprogress . clear ( ) ; treturn ; } tfinal IndexInput in = dir . openInput ( FILENAME ) ; ttry { tprogress . clear ( ) ; 
public void save ( ) throws IOException { tfinal String tmp = " couchdb.new " ; tfinal IndexOutput out = dir . createOutput ( tmp ) ; ttry { out . writeVInt ( progress . size ( ) ) ; 
public String execute ( final IndexSearcher searcher ) throws IOException { } 
public String execute ( final IndexSearcher searcher ) throws IOException { } 
private String toString ( final Sort sort ) { treturn toString ( sort . getSort ( ) ) ; } 
public static void main ( final String [ ] args ) { tfinal Runnable indexer = new Indexer ( ) ; tfinal Thread indexerThread = new Thread ( indexer , " indexer " ) ; tindexerThread . setDaemon ( true ) ; tindexerThread . start ( ) ; tfinal Scanner scanner = new Scanner ( System . in ) ; twhile ( scanner . hasNextLine ( ) ) { tfinal String line = scanner . nextLine ( ) ; 
public static void main ( final String [ ] args ) throws Exception { tIndexReader reader = null ; tIndexSearcher searcher = null ; tfinal Scanner scanner = new Scanner ( System . in ) ; twhile ( scanner . hasNextLine ( ) ) { if ( reader = = null ) { reader.close(); 
private void updateIndex ( ) throws IOException { if ( IndexWriter . isLocked ( dir ) ) { tLog . errlog ( " Forcibly unlocking locked index at startup. " ) ; tIndexWriter . unlock ( dir ) ; } tfinal String [ ] dbnames = DB . getAllDatabases ( ) ; tRhino rhino = null ; tboolean commit = false ; tfinal IndexWriter writer = newWriter ( ) ; tProgress progress = null ; ttry { tprogress = new Progress ( dir ) ; 
public static void outlog ( final String fmt , final Object . . . args ) { tSystem . out . print ( " { \" log \" : \" " ) ; tSystem . out . printf ( fmt , args ) ; tSystem . out . println ( " \" } " ) ; } 
public static void errlog ( final String fmt , final Object . . . args ) { tSystem . err . printf ( fmt , args ) ; tSystem . err . println ( ) ; } 
public static void outlog ( final Exception e ) { outlog ( " %s " , e . getMessage ( ) ) ; } 
public static void errlog ( final Exception e ) { terrlog ( " %s " , e . getMessage ( ) ) ; } 
public static void main ( final String [ ] args ) throws Exception { tIndexReader reader = null ; tIndexSearcher searcher = null ; tfinal Scanner scanner = new Scanner ( System . in ) ; twhile ( scanner . hasNextLine ( ) ) { if ( reader = = null ) { reader.close(); 
private void optimizeIndex ( ) throws IOException { tfinal IndexWriter writer = newWriter ( ) ; ttry { twriter . optimize ( ) ; 
public JSONObject getInfo ( final String dbname ) throws HttpException , IOException { treturn JSONObject . fromObject ( get ( dbname ) ) ; } 
private void updateIndex ( ) throws IOException { if ( IndexWriter . isLocked ( dir ) ) { tLog . errlog ( " Forcibly unlocking locked index at startup. " ) ; tIndexWriter . unlock ( dir ) ; } tfinal String [ ] dbnames = DB . getAllDatabases ( ) ; tArrays . sort ( dbnames ) ; tRhino rhino = null ; tboolean commit = false ; tboolean expunge = false ; tfinal IndexWriter writer = newWriter ( ) ; tProgress progress = null ; ttry { Delete all documents in non-extant databases. 
private IndexWriter newWriter ( ) throws IOException { tfinal IndexWriter result = new IndexWriter ( dir , Config . ANALYZER , MaxFieldLength . UNLIMITED ) ; tresult . setUseCompoundFile ( false ) ; tresult . setRAMBufferSizeMB ( Config . RAM_BUF ) ; tresult . setMergeFactor ( 5 ) ; treturn result ; } 
private boolean updateDatabase ( final IndexWriter writer , final String dbname , final Progress progress , tfinal Rhino rhino ) throws HttpException , IOException { tfinal JSONObject info = DB . getInfo ( dbname ) ; tfinal long update_seq = info . getLong ( " update_seq " ) ; tlong from = progress . getProgress ( dbname ) ; tlong start = from ; if ( from > update_seq ) { tstart = from = - 1 ; tprogress . setProgress ( dbname , - 1 ) ; } if ( from = = - 1 ) { tLog . errlog ( " Indexing '%s' from scratch. " , dbname ) ; tdelete ( writer , dbname ) ; } tboolean changed = false ; twhile ( from < update_seq ) { tfinal JSONObject obj = DB . getAllDocsBySeq ( dbname , from , Config . BATCH_SIZE ) ; if ( ! obj . has ( " rows " ) ) { tLog . errlog ( " no rows found (%s). " , obj ) ; treturn false ; } tfinal JSONArray rows = obj . getJSONArray ( " rows " ) ; tfor ( int i = 0 , max = rows . size ( ) ; i < max ; i + + ) { tfinal JSONObject row = rows . getJSONObject ( i ) ; tfinal JSONObject value = row . optJSONObject ( " value " ) ; tfinal JSONObject doc = row . optJSONObject ( " doc " ) ; if ( doc ! = null ) { tupdateDocument ( writer , dbname , rows . getJSONObject ( i ) , rhino ) ; tchanged = true ; } if ( value ! = null & & value . optBoolean ( " deleted " ) ) { twriter . deleteDocuments ( new Term ( Config . ID , row . getString ( " id " ) ) ) ; tchanged = true ; } } tfrom + = Config . BATCH_SIZE ; } tprogress . setProgress ( dbname , update_seq ) ; if ( changed ) { tsynchronized ( MUTEX ) { tupdates . remove ( dbname ) ; } tLog . errlog ( " %s: index caught up from %,d to %,d. " , dbname , start , update_seq ) ; } treturn changed ; } 
private void delete ( final IndexWriter writer , final String dbname ) throws IOException { twriter . deleteDocuments ( new Term ( Config . DB , dbname ) ) ; } 
public void testPDF ( ) throws IOException { tparse ( " paxos-simple.pdf " , " application/pdf " ) ; tassertThat ( doc . getField ( Config . BODY ) , not ( nullValue ( ) ) ) ; } 
public void testXML ( ) throws IOException { tparse ( " example.xml " , " text/xml " ) ; tassertThat ( doc . getField ( Config . BODY ) , not ( nullValue ( ) ) ) ; } 
private void parse ( final String resource , final String type ) throws IOException { tfinal InputStream in = getClass ( ) . getClassLoader ( ) . getResourceAsStream ( resource ) ; ttry { ttika . parse ( in , type , doc ) ; 
public void parse ( final InputStream in , final String contentType , final Document doc ) { tfinal AutoDetectParser parser = new AutoDetectParser ( ) ; tfinal Metadata md = new Metadata ( ) ; tmd . set ( Metadata . CONTENT_TYPE , contentType ) ; tfinal Reader reader = new ParsingReader ( parser , in , md ) ; tfinal String body ; ttry { ttry { tbody = IOUtils . toString ( reader ) ; } finally { treader . close ( ) ; } } catch ( final IOException e ) { tlog . warn ( " Failed to index an attachment. " , e ) ; treturn ; } } 
private void addDublinCoreAttributes ( final Metadata md , final Document doc ) { taddAttribute ( DC , DublinCore . CONTRIBUTOR , md , doc ) ; taddAttribute ( DC , DublinCore . COVERAGE , md , doc ) ; taddAttribute ( DC , DublinCore . CREATOR , md , doc ) ; taddAttribute ( DC , DublinCore . DATE , md , doc ) ; taddAttribute ( DC , DublinCore . DESCRIPTION , md , doc ) ; taddAttribute ( DC , DublinCore . FORMAT , md , doc ) ; taddAttribute ( DC , DublinCore . IDENTIFIER , md , doc ) ; taddAttribute ( DC , DublinCore . LANGUAGE , md , doc ) ; taddAttribute ( DC , DublinCore . MODIFIED , md , doc ) ; taddAttribute ( DC , DublinCore . PUBLISHER , md , doc ) ; taddAttribute ( DC , DublinCore . RELATION , md , doc ) ; taddAttribute ( DC , DublinCore . RIGHTS , md , doc ) ; taddAttribute ( DC , DublinCore . SOURCE , md , doc ) ; taddAttribute ( DC , DublinCore . SUBJECT , md , doc ) ; taddAttribute ( DC , DublinCore . TITLE , md , doc ) ; taddAttribute ( DC , DublinCore . TYPE , md , doc ) ; } 
private void addAttribute ( final String namespace , final String attributeName , final Metadata md , final Document doc ) { if ( md . get ( attributeName ) ! = null ) { tdoc . add ( token ( namespace + attributeName , md . get ( attributeName ) , true ) ) ; 
public void parse ( final InputStream in , final String contentType , final Document doc ) { tfinal AutoDetectParser parser = new AutoDetectParser ( ) ; tfinal Metadata md = new Metadata ( ) ; tmd . set ( Metadata . CONTENT_TYPE , contentType ) ; tfinal Reader reader = new ParsingReader ( parser , in , md ) ; tfinal String body ; ttry { ttry { tbody = IOUtils . toString ( reader ) ; } finally { treader . close ( ) ; } } catch ( final IOException e ) { tlog . warn ( " Failed to index an attachment. " , e ) ; treturn ; } } 
private void addAttribute ( final String namespace , final String attributeName , final Metadata md , final Document doc ) { if ( md . get ( attributeName ) ! = null ) { tdoc . add ( token ( namespace + attributeName , md . get ( attributeName ) , false ) ) ; 
private void addAttribute ( final String namespace , final String attributeName , final Metadata md , final Document doc ) { if ( md . get ( attributeName ) ! = null ) { tdoc . add ( text ( namespace + attributeName , md . get ( attributeName ) , false ) ) ; 
public JSONObject getAllDocsBySeq ( final String dbname , final long from , final int limit ) throws HttpException , tIOException { treturn JSONObject . fromObject ( get ( String . format ( " %s/_all_docs_by_seq?startkey=%s&limit=%d&include_docs=true " , tencode ( dbname ) , from , limit ) ) ) ; 
public JSONObject getDoc ( final String dbname , final String id , final String rev ) throws HttpException , IOException { if ( rev = = null ) treturn JSONObject . fromObject ( get ( String . format ( " %s/%s " , encode ( dbname ) , id ) ) ) ; 
public JSONObject getDocs ( final String dbname , final String . . . ids ) throws HttpException , IOException { tfinal JSONArray keys = new JSONArray ( ) ; tfor ( final String id : ids ) { tkeys . add ( id ) ; } tfinal JSONObject req = new JSONObject ( ) ; treq . element ( " keys " , keys ) ; treturn JSONObject . fromObject ( post ( String . format ( " %s/_all_docs?include_docs=true " , encode ( dbname ) ) , req . toString ( ) ) ) ; } 
public JSONObject getInfo ( final String dbname ) throws HttpException , IOException { treturn JSONObject . fromObject ( get ( encode ( dbname ) ) ) ; } 
private IndexWriter newWriter ( ) throws IOException { tfinal IndexWriter result = new IndexWriter ( dir , Config . ANALYZER , MaxFieldLength . UNLIMITED ) ; tresult . setUseCompoundFile ( false ) ; tresult . setRAMBufferSizeMB ( Config . RAM_BUF ) ; tresult . setMergeFactor ( 5 ) ; tresult . setMaxMergeDocs ( 1 * 1000 * 1000 ) ; treturn result ; } 
public static void main ( final String [ ] args ) throws Exception { tIndexReader reader = null ; tIndexSearcher searcher = null ; tfinal Scanner scanner = new Scanner ( System . in ) ; twhile ( scanner . hasNextLine ( ) ) { if ( reader = = null ) { reader.close(); 
public static String error ( final int code , final String txt ) { treturn new JSONObject ( ) . element ( " code " , code ) . element ( " body " , StringEscapeUtils . escapeHtml ( txt ) ) . toString ( ) ; } 
public static void main ( final String [ ] args ) throws Exception { tIndexReader reader = null ; tIndexSearcher searcher = null ; tfinal Scanner scanner = new Scanner ( System . in ) ; twhile ( scanner . hasNextLine ( ) ) { if ( reader = = null ) { reader.close(); 
private static long size ( final Directory dir ) throws IOException { tlong result = 0 ; tfor ( final String name : dir . list ( ) ) { tresult + = dir . fileLength ( name ) ; } treturn result ; } 
public static void main ( final String [ ] args ) { ttry { tIndexReader reader = null ; 
public JSONObject getDoc ( final String dbname , final String id ) throws HttpException , IOException { treturn JSONObject . fromObject ( get ( String . format ( " %s/%s " , encode ( dbname ) , id ) ) ) ; } 
public String execute ( final IndexSearcher searcher ) throws IOException { } 
public String execute ( final IndexSearcher searcher ) throws IOException { } 
public String execute ( final IndexSearcher searcher ) throws IOException { } 
public JSONObject getAllDocsBySeq ( final String dbname , final long startkey ) throws HttpException , IOException { treturn JSONObject . fromObject ( get ( String . format ( " %s/_all_docs_by_seq?startkey=%s&include_docs=true " , tencode ( dbname ) , startkey ) ) ) ; 
public JSONObject getDoc ( final String dbname , final String id ) throws HttpException , IOException { treturn JSONObject . fromObject ( get ( String . format ( " %s/%s " , encode ( dbname ) , id ) ) ) ; } 
public JSONObject getDocs ( final String dbname , final String . . . ids ) throws HttpException , IOException { tfinal JSONArray keys = new JSONArray ( ) ; tfor ( final String id : ids ) { tkeys . add ( id ) ; } tfinal JSONObject req = new JSONObject ( ) ; treq . element ( " keys " , keys ) ; treturn JSONObject . fromObject ( post ( String . format ( " %s/_all_docs?include_docs=true " , encode ( dbname ) ) , req . toString ( ) ) ) ; 
private IndexWriter newWriter ( ) throws IOException { tfinal IndexWriter result = new IndexWriter ( dir , Config . ANALYZER , MaxFieldLength . UNLIMITED ) ; } 
private boolean updateDatabase ( final IndexWriter writer , final String dbname , final Progress progress , tfinal Rhino rhino ) throws HttpException , IOException { tfinal JSONObject obj = DB . getAllDocsBySeq ( dbname , progress . getProgress ( dbname ) ) ; if ( ! obj . has ( " rows " ) ) { tLog . errlog ( " no rows found (%s). " , obj ) ; treturn false ; } } 
private void updateIndex ( ) throws IOException { if ( IndexWriter . isLocked ( dir ) ) { tLog . errlog ( " Forcibly unlocking locked index at startup. " ) ; tIndexWriter . unlock ( dir ) ; } tfinal String [ ] dbnames = DB . getAllDatabases ( ) ; tArrays . sort ( dbnames ) ; tRhino rhino = null ; tboolean commit = false ; tfinal IndexWriter writer = newWriter ( ) ; tfinal Progress progress = new Progress ( ) ; ttry { tfinal IndexReader reader = IndexReader . open ( dir ) ; 
private boolean updateDatabase ( final IndexWriter writer , final String dbname , final Progress progress , tfinal Rhino rhino ) throws HttpException , IOException { tfinal String cur_sig = progress . getSignature ( dbname ) ; tfinal String new_sig = rhino = = null ? Progress . NO_SIGNATURE : rhino . getSignature ( ) ; } 
private void delete ( final String dbname , final IndexWriter writer ) throws IOException { twriter . deleteDocuments ( new Term ( Config . DB , dbname ) ) ; } 
public void load ( final IndexReader reader ) throws IOException { tfinal TermDocs termDocs = reader . termDocs ( PROGRESS_TERM ) ; ttry { tprogress = termDocs . next ( ) ? reader . document ( termDocs . doc ( ) ) : newDocument ( ) ; 
public void save ( final IndexWriter writer ) throws IOException { twriter . updateDocument ( PROGRESS_TERM , progress ) ; } 
public void update ( final String dbname , final String sig , final long seq ) { } 
private Document newDocument ( ) { tfinal Document result = new Document ( ) ; } 
public static String digest ( final String data ) { treturn DigestUtils . md5Hex ( data ) ; } 
public static void outlog ( final Exception e ) { outlog ( " %s " , e . getMessage ( ) ) ; te . printStackTrace ( System . out ) ; } 
public static void errlog ( final Exception e ) { terrlog ( " %s " , e . getMessage ( ) ) ; te . printStackTrace ( ) ; } 
private void updateIndex ( ) throws IOException { if ( IndexWriter . isLocked ( dir ) ) { tLog . errlog ( " Forcibly unlocking locked index at startup. " ) ; tIndexWriter . unlock ( dir ) ; } tfinal String [ ] dbnames = DB . getAllDatabases ( ) ; tArrays . sort ( dbnames ) ; tRhino rhino = null ; tboolean commit = true ; tfinal IndexWriter writer = newWriter ( ) ; tfinal Progress progress = new Progress ( ) ; ttry { tfinal IndexReader reader = IndexReader . open ( dir ) ; 
public void load ( final IndexReader reader ) throws IOException { tprogress = newDocument ( ) ; tfinal TermDocs termDocs = reader . termDocs ( PROGRESS_TERM ) ; ttry { twhile ( termDocs . next ( ) ) { 
private Document newDocument ( ) { tfinal Document result = new Document ( ) ; } 
public String execute ( final IndexSearcher searcher ) throws IOException { } 
public JSONObject getAllDocsBySeq ( final String dbname , final long startkey , final int limit ) throws HttpException , IOException { treturn JSONObject . fromObject ( get ( String . format ( " %s/_all_docs_by_seq?startkey=%d&limit=%d&include_docs=true " , tencode ( dbname ) , startkey , limit ) ) ) ; 
private synchronized void updateIndex ( ) throws IOException { if ( IndexWriter . isLocked ( dir ) ) { tLog . errlog ( " Forcibly unlocking locked index at startup. " ) ; tIndexWriter . unlock ( dir ) ; } tfinal String [ ] dbnames = DB . getAllDatabases ( ) ; tArrays . sort ( dbnames ) ; tRhino rhino = null ; tboolean commit = false ; tfinal IndexWriter writer = newWriter ( ) ; tfinal Progress progress = new Progress ( ) ; ttry { tfinal IndexReader reader = IndexReader . open ( dir ) ; 
public static void main ( final String [ ] args ) { tstart ( " indexer " , new Indexer ( ) ) ; tTIMER . schedule ( new CheckpointTask ( ) , Config . TIME_THRESHOLD * 1000 , Config . TIME_THRESHOLD * 1000 ) ; tfinal Scanner scanner = new Scanner ( System . in ) ; twhile ( scanner . hasNextLine ( ) ) { tfinal String line = scanner . nextLine ( ) ; 
private static void wakeupIndexer ( ) { tsynchronized ( MUTEX ) { tMUTEX . notify ( ) ; 
private static void start ( final String name , final Runnable runnable ) { tfinal Thread thread = new Thread ( runnable , name ) ; tthread . setDaemon ( true ) ; tthread . start ( ) ; } 
public JSONObject getAllDocsBySeq ( final String dbname , final long startkey , final int limit ) throws HttpException , tIOException { treturn JSONObject . fromObject ( get ( String . format ( " %s/_all_docs_by_seq?startkey=%d&limit=%d&include_docs=true " , tencode ( dbname ) , startkey , limit ) ) ) ; 
private synchronized String execute ( final HttpMethodBase method ) throws HttpException , IOException { ttry { 
public String execute ( final IndexSearcher searcher ) throws IOException { } 
private synchronized void updateIndex ( ) throws IOException { if ( IndexWriter . isLocked ( dir ) ) { tLog . errlog ( " Forcibly unlocking locked index at startup. " ) ; tIndexWriter . unlock ( dir ) ; } tfinal String [ ] dbnames = DB . getAllDatabases ( ) ; tArrays . sort ( dbnames ) ; tRhino rhino = null ; tboolean commit = false ; tboolean expunge = false ; tfinal IndexWriter writer = newWriter ( ) ; tfinal Progress progress = new Progress ( ) ; ttry { tfinal IndexReader reader = IndexReader . open ( dir ) ; 
private void delete ( final String dbname , final Progress progress , final IndexWriter writer ) throws IOException { twriter . deleteDocuments ( new Term ( Config . DB , dbname ) ) ; tprogress . remove ( dbname ) ; } 
public void remove ( final String dbname ) { tprogress . removeFields ( seqField ( dbname ) ) ; tprogress . removeFields ( sigField ( dbname ) ) ; } 
public String execute ( final IndexSearcher searcher ) throws IOException { } 
public String execute ( final IndexSearcher searcher ) throws IOException { } 
public void parse ( final InputStream in , final String contentType , final Document doc ) throws IOException { tfinal AutoDetectParser parser = new AutoDetectParser ( ) ; tfinal Metadata md = new Metadata ( ) ; tmd . set ( Metadata . CONTENT_TYPE , contentType ) ; tfinal Reader reader = new ParsingReader ( parser , in , md ) ; tfinal String body ; ttry { ttry { tbody = IOUtils . toString ( reader ) ; } finally { treader . close ( ) ; } } catch ( final IOException e ) { tlog . warn ( " Failed to index an attachment. " , e ) ; treturn ; } } 
public static String error ( final int code , final Throwable ) { tfinal StringWriter writer = new StringWriter ( ) ; tfinal PrintWriter printWriter = new PrintWriter ( writer ) ; if ( . getMessage ( ) ! = null ) tprintWriter . append ( . getMessage ( ) ) ; tt . printStackTrace ( printWriter ) ; treturn new JSONObject ( ) . element ( " code " , code ) . element ( " body " , writer . toString ( ) ) . toString ( ) ; } 
public String execute ( final IndexSearcher searcher ) throws IOException { } 
public void testEnglish ( ) throws IOException { ttika . parse ( new ByteArrayInputStream ( " english text goes here " . getBytes ( ) ) , " text/plain " , doc ) ; tassertThat ( doc . getField ( " dc.language " ) . stringValue ( ) , is ( " en " ) ) ; } 
public void testGerman ( ) throws IOException { ttika . parse ( new ByteArrayInputStream ( " Alle Menschen sind frei und gleich " . getBytes ( ) ) , " text/plain " , doc ) ; tassertThat ( doc . getField ( " dc.language " ) . stringValue ( ) , is ( " de " ) ) ; } 
public void testFrench ( ) throws IOException { ttika . parse ( new ByteArrayInputStream ( " Me permettez-vous, dans ma gratitude " . getBytes ( ) ) , " text/plain " , doc ) ; tassertThat ( doc . getField ( " dc.language " ) . stringValue ( ) , is ( " fr " ) ) ; } 
public void testEnglish ( ) throws IOException { tassertThat ( detectLanguage ( " english " ) , is ( nullValue ( ) ) ) ; tassertThat ( detectLanguage ( " english text here " ) , is ( " en " ) ) ; } 
public void testGerman ( ) throws IOException { tassertThat ( detectLanguage ( " Alle Menschen sind frei und gleich " ) , is ( " de " ) ) ; } 
public void testFrench ( ) throws IOException { tassertThat ( detectLanguage ( " Me permettez-vous, dans ma gratitude " ) , is ( " fr " ) ) ; } 
public String identify ( String content ) { return identify ( new StringBuffer ( content ) ) ; } 
public String identify ( StringBuffer content ) { StringBuffer text = content ; if ( ( analyzeLength > 0 ) & & ( content . length ( ) > analyzeLength ) ) { text = new StringBuffer ( ) . append ( content ) ; text . setLength ( analyzeLength ) ; } suspect . analyze ( text ) ; Iterator iter = suspect . getSorted ( ) . iterator ( ) ; float topscore = Float . MIN_VALUE ; String lang = " " ; HashMap scores = new HashMap ( ) ; NGramEntry searched = null ; while ( iter . hasNext ( ) ) { searched = ( NGramEntry ) iter . next ( ) ; NGramEntry [ ] ngrams = ( NGramEntry [ ] ) ngramsIdx . get ( searched . getSeq ( ) ) ; if ( ngrams ! = null ) { for ( int j = 0 ; j < ngrams . length ; j + + ) { NGramProfile profile = ngrams [ j ] . getProfile ( ) ; Float pScore = ( Float ) scores . get ( profile ) ; if ( pScore = = null ) { pScore = new Float ( 0 ) ; } float plScore = pScore . floatValue ( ) ; plScore + = ngrams [ j ] . getFrequency ( ) + searched . getFrequency ( ) ; scores . put ( profile , new Float ( plScore ) ) ; if ( plScore > topscore ) { topscore = plScore ; lang = profile . getName ( ) ; } } } } return lang ; } 
public String identify ( InputStream is ) throws IOException { return identify ( is , null ) ; } 
public String identify ( InputStream is , String charset ) throws IOException { ByteArrayOutputStream out = new ByteArrayOutputStream ( ) ; byte [ ] buffer = new byte [ 2048 ] ; int len = 0 ; while ( ( ( len = is . read ( buffer ) ) ! = - 1 ) & & ( ( analyzeLength = = 0 ) | | ( out . size ( ) < analyzeLength ) ) ) { if ( analyzeLength ! = 0 ) { len = Math . min ( len , analyzeLength - out . size ( ) ) ; } out . write ( buffer , 0 , len ) ; } return identify ( ( charset = = null ) ? out . toString ( ) : out . toString ( charset ) ) ; 
public void add ( Token ) { add ( new StringBuffer ( ) . append ( SEPARATOR ) . append ( . termText ( ) ) 
public void add ( StringBuffer word ) { for ( int i = minLength ; ( i < = maxLength ) & & ( i < word . length ( ) ) ; i + + ) { add ( word , i ) ; 
private void add ( QuickStringBuffer word ) { int wlen = word . length ( ) ; if ( wlen > = minLength ) { int max = Math . min ( maxLength , wlen ) ; 
private void add ( CharSequence cs ) { if ( cs . equals ( SEP_CHARSEQ ) ) { return ; } NGramEntry nge = ( NGramEntry ) ngrams . get ( cs ) ; if ( nge = = null ) { nge = new NGramEntry ( cs ) ; ngrams . put ( cs , nge ) ; } nge . inc ( ) ; } 
public void analyze ( StringBuffer text ) { if ( ngrams ! = null ) { ngrams . clear ( ) ; sorted = null ; ngramcounts = null ; } word . clear ( ) . append ( SEPARATOR ) ; for ( int i = 0 ; i < text . length ( ) ; i + + ) { char c = Character . toLowerCase ( text . charAt ( i ) ) ; if ( Character . isLetter ( c ) ) { add ( word . append ( c ) ) ; } else { found word boundary if (word.length() > 1) { we have a word! add(word.append(SEPARATOR)); word.clear().append(SEPARATOR); } } } if (word.length() > 1) { we have a word! add(word.append(SEPARATOR)); } normalize(); } 
private void add ( StringBuffer word , int ) { for ( int i = 0 ; i < = word . length ( ) - ; i + + ) { add ( word . subSequence ( i , i + ) ) ; 
protected void normalize ( ) { NGramEntry e = null ; List sorted = getSorted(); Iterator i = ngrams.values().iterator(); Calculate ngramcount if not already done if (ngramcounts == null) { ngramcounts = new int[maxLength+1]; while (i.hasNext()) { e = (NGramEntry) i.next(); ngramcounts[e.size()] += e.count; } } i = ngrams.values().iterator(); while (i.hasNext()) { e = (NGramEntry) i.next(); 
public String toString ( ) { StringBuffer s = new StringBuffer ( ) . append ( " NGramProfile: " ) . append ( name ) . append ( " " ) ; Iterator i = getSorted ( ) . iterator ( ) ; while ( i . hasNext ( ) ) { NGramEntry entry = ( NGramEntry ) i . next ( ) ; s . append ( " [ " ) . append ( entry . seq ) . append ( " / " ) . append ( entry . count ) . append ( " / " ) . append ( entry . frequency ) . append ( " ] " ) ; } return s . toString ( ) ; } 
public void load ( InputStream is ) throws IOException { ngrams . clear ( ) ; ngramcounts = new int [ maxLength + 1 ] ; BufferedReader reader = new BufferedReader ( new InputStreamReader ( is , " UTF-8 " ) ) ; String line = null ; while ( ( line = reader . readLine ( ) ) ! = null ) { # starts a comment line if (line.charAt(0) != '#') { int spacepos = line.indexOf(' '); String ngramsequence = line.substring(0, spacepos).trim(); int len = ngramsequence.length(); if ((len >= minLength) && (len <= maxLength)) { int ngramcount = Integer.parseInt(line.substring(spacepos + 1)); NGramEntry en = new NGramEntry(ngramsequence, ngramcount); ngrams.put(en.getSeq(), en); ngramcounts[len] += ngramcount; } } } normalize(); } 
public static NGramProfile create ( String name , InputStream is , String encoding ) { NGramProfile newProfile = new NGramProfile ( name , ABSOLUTE_MIN_NGRAM_LENGTH , ABSOLUTE_MAX_NGRAM_LENGTH ) ; BufferedInputStream bis = new BufferedInputStream ( is ) ; byte buffer [ ] = new byte [ 4096 ] ; StringBuffer text = new StringBuffer ( ) ; int len ; try { while ( ( len = bis . read ( buffer ) ) ! = - 1 ) { text . append ( new String ( buffer , 0 , len , encoding ) ) ; } } catch ( IOException e ) { tLog . errlog ( e ) ; } newProfile . analyze ( text ) ; return newProfile ; } 
public static void main ( String args [ ] ) { String usage = " Usage: NGramProfile " + " [-create profilename filename encoding] " + " [-similarity file1 file2] " + " [-score profile-name filename encoding] " ; int command = 0 ; final int CREATE = 1 ; final int SIMILARITY = 2 ; final int SCORE = 3 ; String profilename = " " ; String filename = " " ; String filename2 = " " ; String encoding = " " ; if ( args . length = = 0 ) { System . err . println ( usage ) ; System . exit ( - 1 ) ; } for ( int i = 0 ; i < args . length ; i + + ) { parse command line if (args[i].equals("-create")) { found -create option command = CREATE; profilename = args[++i]; filename = args[++i]; encoding = args[++i]; } if (args[i].equals("-similarity")) { found -similarity option command = SIMILARITY; filename = args[++i]; filename2 = args[++i]; encoding = args[++i]; } if (args[i].equals("-score")) { found -Score option command = SCORE; profilename = args[++i]; filename = args[++i]; encoding = args[++i]; } } try { 
public int compareTo ( Object o ) { NGramEntry ngram = ( NGramEntry ) o ; int diff = Float . compare ( ngram . getFrequency ( ) , frequency ) ; if ( diff ! = 0 ) { return diff ; 
public boolean equals ( Object obj ) { NGramEntry ngram = null ; try { ngram = ( NGramEntry ) obj ; 
private void expandCapacity ( int minimumCapacity ) { int newCapacity = ( value . length + 1 ) * 2 ; if ( newCapacity < 0 ) { newCapacity = Integer . MAX_VALUE ; } else if ( minimumCapacity > newCapacity ) { newCapacity = minimumCapacity ; } char newValue [ ] = new char [ newCapacity ] ; System . arraycopy ( value , 0 , newValue , 0 , count ) ; value = newValue ; } 
QuickStringBuffer append ( String str ) { if ( str = = null ) { str = String . valueOf ( str ) ; } int len = str . length ( ) ; int newcount = count + len ; if ( newcount > value . length ) { expandCapacity ( newcount ) ; } str . getChars ( 0 , len , value , count ) ; count = newcount ; return this ; } 
QuickStringBuffer append ( char c ) { int newcount = count + 1 ; if ( newcount > value . length ) { expandCapacity ( newcount ) ; } value [ count + + ] = c ; return this ; } 
public CharSequence subSequence ( int start , int end ) { return new String ( value , start , end - start ) ; } 
public void tff ( ) throws Exception { tfinal QueryParser qp = new QueryParser ( " body " , new StandardAnalyzer ( ) ) ; tfinal Query q = qp . parse ( " \" hello whups thin* \" " ) ; tSystem . out . println ( q ) ; } 
public void testEnglish ( ) throws IOException { tassertThat ( detectLanguage ( " english here " ) , is ( " en " ) ) ; tassertThat ( detectLanguage ( " english text here " ) , is ( " en " ) ) ; } 
private String detectLanguage ( final String text ) { tfinal LanguageIdentifier identifier = new LanguageIdentifier ( ) ; treturn identifier . identify ( text ) ; } 
public void parse ( final InputStream in , final String contentType , final Document doc ) throws IOException { tfinal AutoDetectParser parser = new AutoDetectParser ( ) ; tfinal Metadata md = new Metadata ( ) ; tmd . set ( Metadata . CONTENT_TYPE , contentType ) ; tfinal Reader reader = new ParsingReader ( parser , in , md ) ; tfinal String body ; ttry { ttry { tbody = IOUtils . toString ( reader ) ; } finally { treader . close ( ) ; } } catch ( final IOException e ) { tlog . warn ( " Failed to index an attachment. " , e ) ; treturn ; } } 
private void addDublinCoreAttributes ( final Metadata md , final Document doc ) { taddAttribute ( DC , DublinCore . CONTRIBUTOR , md , doc ) ; taddAttribute ( DC , DublinCore . COVERAGE , md , doc ) ; taddAttribute ( DC , DublinCore . CREATOR , md , doc ) ; taddAttribute ( DC , DublinCore . DATE , md , doc ) ; taddAttribute ( DC , DublinCore . DESCRIPTION , md , doc ) ; taddAttribute ( DC , DublinCore . FORMAT , md , doc ) ; taddAttribute ( DC , DublinCore . IDENTIFIER , md , doc ) ; } 
private IndexWriter newWriter ( ) throws IOException { tfinal IndexWriter result = new IndexWriter ( dir , Utils . DEFAULT_ANALYZER , MaxFieldLength . UNLIMITED ) ; } 
public void testEnglish ( ) throws IOException { tassertThat ( detectLanguage ( " my head hurts " ) , is ( " en " ) ) ; tassertThat ( detectLanguage ( " english text here " ) , is ( " en " ) ) ; } 
public void parse ( final InputStream in , final String contentType , final Document doc ) throws IOException { tfinal AutoDetectParser parser = new AutoDetectParser ( ) ; tfinal Metadata md = new Metadata ( ) ; tmd . set ( Metadata . CONTENT_TYPE , contentType ) ; tfinal Reader reader = new ParsingReader ( parser , in , md ) ; tfinal String body ; ttry { ttry { tbody = IOUtils . toString ( reader ) ; } finally { treader . close ( ) ; } } catch ( final IOException e ) { tlog . warn ( " Failed to index an attachment. " , e ) ; treturn ; } } 
private void add ( final String prefix , final Document out , final String key , final Object value , tfinal boolean store ) { tfinal String prefixed_key = prefix ! = null ? prefix + " . " + key : key ; if ( value instanceof JSONObject ) { tfinal JSONObject json = ( JSONObject ) value ; 
public boolean visibleToScripts ( final String fullClassName ) { treturn false ; } 
public void run ( ) { twhile ( true ) { tfinal long commitAt = System . nanoTime ( ) + Config . COMMIT_MAX * 1000000 ; 
private IndexWriter newWriter ( ) throws IOException { tfinal IndexWriter result = new IndexWriter ( Config . INDEX_DIR , Config . ANALYZER , MaxFieldLength . UNLIMITED ) ; } 
public static void main ( String [ ] args ) throws Exception { tfinal Indexer indexer = new Indexer ( FSDirectory . getDirectory ( Config . INDEX_DIR ) ) ; tfinal Thread thread = new Thread ( indexer , " index " ) ; tthread . start ( ) ; tfinal Scanner scanner = new Scanner ( System . in ) ; twhile ( scanner . hasNextLine ( ) ) { tfinal String line = scanner . nextLine ( ) ; 
public static void main ( String [ ] args ) throws Exception { tfinal Indexer indexer = new Indexer ( FSDirectory . getDirectory ( Config . INDEX_DIR ) ) ; tfinal Thread thread = new Thread ( indexer , " index " ) ; tthread . setDaemon ( true ) ; tthread . start ( ) ; tfinal Scanner scanner = new Scanner ( System . in ) ; twhile ( scanner . hasNextLine ( ) ) { tfinal String line = scanner . nextLine ( ) ; 
public String execute ( final IndexSearcher searcher ) throws IOException { } 
public void parse ( final InputStream in , final String contentType , final Document doc ) throws IOException { tfinal AutoDetectParser parser = new AutoDetectParser ( ) ; tfinal Metadata md = new Metadata ( ) ; tmd . set ( Metadata . CONTENT_TYPE , contentType ) ; tfinal Reader reader = new ParsingReader ( parser , in , md ) ; tfinal String body ; ttry { ttry { tbody = IOUtils . toString ( reader ) ; } finally { treader . close ( ) ; } } catch ( final IOException e ) { tlog . warn ( " Failed to index an attachment. " , e ) ; treturn ; } doc.add(text(DC + DublinCore.LANGUAGE, language, false)); 
public static String identifyLanguage ( final String txt ) { treturn INSTANCE . identify ( txt ) ; } 
public String identify ( String content ) { treturn identify ( new StringBuffer ( content ) ) ; } 
public String identify ( StringBuffer content ) { tStringBuffer text = content ; if ( ( analyzeLength > 0 ) & & ( content . length ( ) > analyzeLength ) ) { ttext = new StringBuffer ( ) . append ( content ) ; ttext . setLength ( analyzeLength ) ; } tsuspect . analyze ( text ) ; tIterator iter = suspect . getSorted ( ) . iterator ( ) ; tfloat topscore = Float . MIN_VALUE ; tString lang = " " ; tHashMap scores = new HashMap ( ) ; tNGramEntry searched = null ; twhile ( iter . hasNext ( ) ) { tsearched = ( NGramEntry ) iter . next ( ) ; tNGramEntry [ ] ngrams = ( NGramEntry [ ] ) ngramsIdx . get ( searched . getSeq ( ) ) ; if ( ngrams ! = null ) { tfor ( int j = 0 ; j < ngrams . length ; j + + ) { tNGramProfile profile = ngrams [ j ] . getProfile ( ) ; tFloat pScore = ( Float ) scores . get ( profile ) ; if ( pScore = = null ) { tpScore = new Float ( 0 ) ; } tfloat plScore = pScore . floatValue ( ) ; tplScore + = ngrams [ j ] . getFrequency ( ) + searched . getFrequency ( ) ; tscores . put ( profile , new Float ( plScore ) ) ; if ( plScore > topscore ) { ttopscore = plScore ; tlang = profile . getName ( ) ; } } } } treturn lang ; } 
public String identify ( InputStream is ) throws IOException { treturn identify ( is , null ) ; } 
public String identify ( InputStream is , String charset ) throws IOException { tByteArrayOutputStream out = new ByteArrayOutputStream ( ) ; tbyte [ ] buffer = new byte [ 2048 ] ; tint len = 0 ; twhile ( ( ( len = is . read ( buffer ) ) ! = - 1 ) & & ( ( analyzeLength = = 0 ) | | ( out . size ( ) < analyzeLength ) ) ) { if ( analyzeLength ! = 0 ) { tlen = Math . min ( len , analyzeLength - out . size ( ) ) ; } out . write ( buffer , 0 , len ) ; } treturn identify ( ( charset = = null ) ? out . toString ( ) : out . toString ( charset ) ) ; } 
public void testEnglish ( ) throws Exception { tassertLanguage ( " i18n/en/ep-97-05-15.txt " , " en " ) ; } 
public void testDanish ( ) throws Exception { tassertLanguage ( " i18n/da/ep-04-09-16.txt " , " da " ) ; } 
public void testGerman ( ) throws Exception { tassertLanguage ( " i18n/de/ep-00-02-02.txt " , " de " ) ; } 
public void testSpanish ( ) throws Exception { tassertLanguage ( " i18n/es/ep-03-10-08.txt " , " es " ) ; } 
public void testGreek ( ) throws Exception { tassertLanguage ( " i18n/el/ep-04-05-03.txt " , " el " ) ; } 
public void testFinnish ( ) throws Exception { tassertLanguage ( " i18n/fi/ep-99-03-09.txt " , " fi " ) ; 
public void testItalian ( ) throws Exception { tassertLanguage ( " i18n/it/ep-98-09-16.txt " , " it " ) ; } 
public void testFrench ( ) throws Exception { tassertLanguage ( " i18n/fr/ep-96-09-18.txt " , " fr " ) ; } 
public void testDutch ( ) throws Exception { tassertLanguage ( " i18n/nl/ep-98-09-18.txt " , " nl " ) ; } 
public void testPortugese ( ) throws Exception { tassertLanguage ( " i18n/pt/ep-98-09-17.txt " , " pt " ) ; } 
public void testSwedish ( ) throws Exception { tassertLanguage ( " i18n/sv/ep-98-09-17.txt " , " sv " ) ; } 
public void testPerformance ( ) throws Exception { tfinal long start = System . currentTimeMillis ( ) ; tfinal int max = 200 ; tfor ( int i = 0 ; i < max ; i + + ) { tassertLanguage ( " i18n/sv/ep-98-09-17.txt " , " sv " ) ; tassertLanguage ( " i18n/nl/ep-98-09-18.txt " , " nl " ) ; } tSystem . out . println ( ( System . currentTimeMillis ( ) - start ) / max ) ; } 
private void assertLanguage ( final String file , final String expectedLanguage ) throws Exception { tfinal InputStream in = LanguageIdentifier . class . getClassLoader ( ) . getResourceAsStream ( file ) ; tfinal String txt = IOUtils . toString ( in ) ; tin . close ( ) ; tassertThat ( LanguageIdentifier . identifyLanguage ( txt ) , is ( expectedLanguage ) ) ; } 
public static Field uniqueField ( final String dbname , final String id ) { treturn token ( Config . UID , qualify ( dbname , id ) , false ) ; } 
public static Term uniqueTerm ( final String dbname , final String id ) { treturn new Term ( Config . UID , qualify ( dbname , id ) ) ; } 
private static String qualify ( final String dbname , final String id ) { treturn String . format ( " %s-%s " , dbname , id ) ; } 
public static Query docQuery ( final String dbname , final String id ) { BooleanQuery q = new BooleanQuery ( ) ; q . add ( new TermQuery ( new Term ( Config . DB , dbname ) ) , Occur . MUST ) ; q . add ( new TermQuery ( new Term ( Config . ID , id ) ) , Occur . MUST ) ; return q ; } 
private void assertLanguage ( final String file , final String expectedLanguage ) throws Exception { tfinal InputStream in = LanguageIdentifier . class . getClassLoader ( ) . getResourceAsStream ( file ) ; tfinal String txt = IOUtils . toString ( in , " UTF-8 " ) ; tin . close ( ) ; tassertThat ( LanguageIdentifier . identifyLanguage ( txt ) , is ( expectedLanguage ) ) ; } 
private static Date parseDate ( final String str ) { tfor ( final DateFormat df : DATE_FORMATS ) { ttry { treturn df . parse ( str ) ; } catch ( final ParseException e ) { tcontinue ; } } treturn null ; } 
private synchronized void updateIndex ( ) throws IOException { if ( IndexWriter . isLocked ( dir ) ) { tLog . errlog ( " Forcibly unlocking locked index at startup. " ) ; tIndexWriter . unlock ( dir ) ; } tfinal String [ ] dbnames = DB . getAllDatabases ( ) ; tArrays . sort ( dbnames ) ; tboolean commit = false ; tboolean expunge = false ; tfinal IndexWriter writer = newWriter ( ) ; tfinal Progress progress = new Progress ( ) ; ttry { tfinal IndexReader reader = IndexReader . open ( dir ) ; 
public boolean visibleToScripts ( String fullClassName ) { treturn false ; } 
public static Query docQuery ( final String dbname , final String id ) { tBooleanQuery q = new BooleanQuery ( ) ; tq . add ( new TermQuery ( new Term ( Config . DB , dbname ) ) , Occur . MUST ) ; tq . add ( new TermQuery ( new Term ( Config . ID , id ) ) , Occur . MUST ) ; treturn q ; } 
public Document [ ] map ( final String doc ) { return this . map ( " " , doc ) ; } 
public static Scriptable jsConstructor ( Context cx , Object [ ] args , Function ctorObj , boolean inNewExpr ) { RhinoDocument doc = new RhinoDocument ( ) ; if ( args . length > = 2 ) jsFunction_field ( cx , doc , args , ctorObj ) ; return doc ; } 
public static void jsFunction_field ( final Context cx , final Scriptable thisObj , final Object [ ] args , final Function funObj ) { final RhinoDocument doc = checkInstance ( thisObj ) ; if ( args . length < 2 ) { throw Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } Field . Store str = null ; Field . Index idx = null ; Field . TermVector tv = null ; if ( args . length > = 3 ) { str = ( Field . Store ) Store . get ( args [ 2 ] . toString ( ) . toUpperCase ( ) ) ; } if ( str = = null ) str = Field . Store . NO ; if ( args . length > = 4 ) { idx = ( Field . Index ) Index . get ( args [ 3 ] . toString ( ) . toUpperCase ( ) ) ; } if ( idx = = null ) idx = Field . Index . ANALYZED ; if ( args . length > = 5 ) { tv = ( Field . TermVector ) TermVector . get ( args [ 4 ] . toString ( ) . toUpperCase ( ) ) ; } if ( tv = = null ) tv = Field . TermVector . NO ; doc . doc . add ( new Field ( args [ 0 ] . toString ( ) , args [ 1 ] . toString ( ) , str , idx , tv ) ) ; } 
public static void jsFunction_attachment ( final Context cx , final Scriptable thisObj , final Object [ ] args , final Function funObj ) throws IOException { final RhinoDocument doc = checkInstance ( thisObj ) ; if ( args . length < 2 ) { throw Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } final String dbname = ( String ) cx . getThreadLocal ( " dbname " ) ; final String docid = ( String ) cx . getThreadLocal ( " docid " ) ; final String field = args [ 0 ] . toString ( ) ; final String attname = args [ 1 ] . toString ( ) ; final String url = DB . url ( String . format ( " %s/%s/%s " , dbname , DB . encode ( docid ) , DB . encode ( attname ) ) ) ; System . err . println ( " ATTACHMENT: " + url ) ; final GetMethod get = new GetMethod ( url ) ; try { final int sc = Database . CLIENT . executeMethod ( get ) ; 
public static void jsFunction_date ( final Context cx , final Scriptable thisObj , final Object [ ] args , final Function funObj ) throws IOException { final RhinoDocument doc = checkInstance ( thisObj ) ; if ( args . length < 2 ) { throw Context . reportRuntimeError ( " field name and value required. " ) ; } final String field = args [ 0 ] . toString ( ) ; final String value = args [ 1 ] . toString ( ) ; final Field . Store str ; if ( args . length > 2 ) { final String strtype = args [ 2 ] . toString ( ) . toUpperCase ( ) ; str = Store . get ( strtype ) = = null ? Field . Store . NO : ( Field . Store ) Store . get ( strtype ) ; } else { str = Field . Store . NO ; } final DateFormat [ ] formats ; if ( args . length > 3 ) { formats = new DateFormat [ ] { new SimpleDateFormat ( args [ 3 ] . toString ( ) ) } ; } else { formats = DATE_FORMATS ; } final Date parsed = parse_date ( formats , value ) ; if ( parsed = = null ) { throw Context . reportRuntimeError ( " failed to parse date value: " + value ) ; } doc . doc . add ( new Field ( field , Long . toString ( parsed . getTime ( ) ) , str , Field . Index . NOT_ANALYZED_NO_NORMS ) ) ; } 
private static Date parse_date ( final DateFormat [ ] formats , final String value ) { for ( final DateFormat fmt : formats ) { try { return fmt . parse ( value ) ; } catch ( final ParseException e ) { continue ; } } return null ; } 
private static RhinoDocument checkInstance ( Scriptable obj ) { if ( obj = = null | | ! ( obj instanceof RhinoDocument ) ) { throw Context . reportRuntimeError ( " called on incompatible object. " ) ; } return ( RhinoDocument ) obj ; } 
public void parse ( final InputStream in , final String contentType , final String fieldName , final Document doc ) throws IOException { tfinal AutoDetectParser parser = new AutoDetectParser ( ) ; tfinal Metadata md = new Metadata ( ) ; tmd . set ( Metadata . CONTENT_TYPE , contentType ) ; tfinal Reader reader = new ParsingReader ( parser , in , md ) ; tfinal String body ; ttry { ttry { tbody = IOUtils . toString ( reader ) ; } finally { treader . close ( ) ; } } catch ( final IOException e ) { tlog . warn ( " Failed to index an attachment. " , e ) ; treturn ; } doc.add(text(DC + DublinCore.LANGUAGE, language, false)); 
private void addAttribute ( final String namespace , final String attributeName , final Metadata md , final Document doc ) { if ( md . get ( attributeName ) ! = null ) { tdoc . add ( text ( namespace + attributeName , md . get ( attributeName ) , false ) ) ; 
public void testRhino ( ) throws Exception { tfinal Rhino rhino = new Rhino ( " function(doc) { var ret = new Document(); " + " ret.field( \" foo \" , doc.size); return ret } " ) ; tfinal String doc = " { \" deleteme \" : \" true \" , \" size \" :13} " ; Document [ ] ret = rhino . map ( doc ) ; assertThat ( ret . length , CoreMatchers . equalTo ( 1 ) ) ; assertThat ( ret [ 0 ] . getField ( " foo " ) , CoreMatchers . notNullValue ( ) ) ; trhino . close ( ) ; } 
public void testNoReturn ( ) throws Exception { final Rhino rhino = new Rhino ( " function(doc) {} " ) ; Document [ ] ret = rhino . map ( " {} " ) ; assertThat ( ret . length , CoreMatchers . equalTo ( 0 ) ) ; rhino . close ( ) ; } 
public void testBadReturn ( ) throws Exception { final Rhino rhino = new Rhino ( " function(doc) {return 1;} " ) ; rhino . map ( " {} " ) ; rhino . close ( ) ; } 
public void testCtor ( ) throws Exception { final Rhino rhino = new Rhino ( " function(doc) { return new Document( \" foo \" , 1); } " ) ; Document [ ] ret = rhino . map ( " {} " ) ; assertThat ( ret . length , CoreMatchers . equalTo ( 1 ) ) ; assertThat ( ret [ 0 ] . getField ( " foo " ) , CoreMatchers . notNullValue ( ) ) ; rhino . close ( ) ; } 
public void testMultipleReturn ( ) throws Exception { final Rhino rhino = new Rhino ( " function(doc) { " + " var ret = []; " + " for(var v in doc) {var d = new Document(); d.field(v, doc[v]); ret.push(d)} " + " return ret; " + " } " ) ; Document [ ] ret = rhino . map ( " { \" foo \" : 1, \" bar \" : 2} " ) ; assertThat ( ret . length , CoreMatchers . equalTo ( 2 ) ) ; rhino . close ( ) ; } 
public void testDate ( ) throws Exception { final Rhino rhino = new Rhino ( " function(doc) { var ret = new Document(); " + " ret.date( \" bar \" , \" 2009-01-0T00:00:00Z \" ); return ret;} " ) ; Document [ ] ret = rhino . map ( " { \" foo \" : 1, \" bar \" : 2} " ) ; assertThat ( ret . length , CoreMatchers . equalTo ( 1 ) ) ; assertThat ( ret [ 0 ] . getField ( " bar " ) , CoreMatchers . notNullValue ( ) ) ; rhino . close ( ) ; } 
public void testPDF ( ) throws IOException { tparse ( " paxos-simple.pdf " , " application/pdf " , " foo " ) ; tassertThat ( doc . getField ( " foo " ) , not ( nullValue ( ) ) ) ; } 
public void testXML ( ) throws IOException { tparse ( " example.xml " , " text/xml " , " bar " ) ; tassertThat ( doc . getField ( " bar " ) , not ( nullValue ( ) ) ) ; } 
private void parse ( final String resource , final String type , final String field ) throws IOException { tfinal InputStream in = getClass ( ) . getClassLoader ( ) . getResourceAsStream ( resource ) ; ttry { ttika . parse ( in , type , field , doc ) ; 
public String [ ] getAllDatabases ( ) throws HttpException , IOException { return ( String [ ] ) JSONArray . fromObject ( get ( " _all_dbs " ) ) . toArray ( EMPTY_ARR ) ; } 
public JSONObject getAllDocsBySeq ( final String dbname , final long startkey ) throws HttpException , IOException { return JSONObject . fromObject ( get ( String . format ( " %s/_all_docs_by_seq?startkey=%s&include_docs=true " , encode ( dbname ) , startkey ) ) ) ; 
public JSONObject getAllDocsBySeq ( final String dbname , final long startkey , final int limit ) throws HttpException , IOException { return JSONObject . fromObject ( get ( String . format ( " %s/_all_docs_by_seq?startkey=%d&limit=%d&include_docs=true " , encode ( dbname ) , startkey , limit ) ) ) ; 
public JSONObject getDoc ( final String dbname , final String id ) throws HttpException , IOException { return JSONObject . fromObject ( get ( String . format ( " %s/%s " , encode ( dbname ) , id ) ) ) ; } 
public JSONObject getDocs ( final String dbname , final String . . . ids ) throws HttpException , IOException { final JSONArray keys = new JSONArray ( ) ; for ( final String id : ids ) { keys . add ( id ) ; } final JSONObject req = new JSONObject ( ) ; req . element ( " keys " , keys ) ; return JSONObject . fromObject ( post ( String . format ( " %s/_all_docs?include_docs=true " , encode ( dbname ) ) , req . toString ( ) ) ) ; 
public JSONObject getInfo ( final String dbname ) throws HttpException , IOException { return JSONObject . fromObject ( get ( encode ( dbname ) ) ) ; } 
private String get ( final String path ) throws HttpException , IOException { return execute ( new GetMethod ( url ( path ) ) ) ; } 
String url ( final String path ) { return String . format ( " %s/%s " , url , path ) ; } 
String encode ( final String path ) { try { return URLEncoder . encode ( path , " UTF-8 " ) ; 
private String post ( final String path , final String body ) throws HttpException , IOException { final PostMethod post = new PostMethod ( url ( path ) ) ; post . setRequestEntity ( new StringRequestEntity ( body , " application/json " , " UTF-8 " ) ) ; return execute ( post ) ; } 
private synchronized String execute ( final HttpMethodBase method ) throws HttpException , IOException { try { 
public synchronized boolean isStale ( ) { return isStale ; } 
public void run ( ) { while ( true ) { if ( ! isStale ( ) ) { 
private void sleep ( ) { try { Thread . sleep ( Config . COMMIT_MIN ) ; 
private IndexWriter newWriter ( ) throws IOException { final IndexWriter result = new IndexWriter ( Config . INDEX_DIR , Config . ANALYZER , MaxFieldLength . UNLIMITED ) ; Customize merge policy. final LogByteSizeMergePolicy mp = new LogByteSizeMergePolicy(); mp.setMergeFactor(5); mp.setMaxMergeMB(1000); result.setMergePolicy(mp); Customize other settings. result.setUseCompoundFile(false); result.setRAMBufferSizeMB(Config.RAM_BUF); return result; } 
private synchronized void updateIndex ( ) throws IOException { if ( IndexWriter . isLocked ( dir ) ) { Log . errlog ( " Forcibly unlocking locked index at startup. " ) ; IndexWriter . unlock ( dir ) ; } final String [ ] dbnames = DB . getAllDatabases ( ) ; Arrays . sort ( dbnames ) ; boolean commit = false ; boolean expunge = false ; final IndexWriter writer = newWriter ( ) ; final Progress progress = new Progress ( ) ; try { final IndexReader reader = IndexReader . open ( dir ) ; 
private void delete ( final String dbname , final Progress progress , final IndexWriter writer ) throws IOException { writer . deleteDocuments ( new Term ( Config . DB , dbname ) ) ; progress . remove ( dbname ) ; } 
public static void main ( String [ ] args ) throws Exception { final Indexer indexer = new Indexer ( FSDirectory . getDirectory ( Config . INDEX_DIR ) ) ; final Thread thread = new Thread ( indexer , " index " ) ; thread . setDaemon ( true ) ; thread . start ( ) ; final Scanner scanner = new Scanner ( System . in ) ; while ( scanner . hasNextLine ( ) ) { final String line = scanner . nextLine ( ) ; 
public static void outlog ( final String fmt , final Object . . . args ) { System . out . print ( " { \" log \" : \" " ) ; System . out . printf ( fmt , args ) ; System . out . println ( " \" } " ) ; } 
public static void errlog ( final String fmt , final Object . . . args ) { System . err . printf ( fmt , args ) ; System . err . println ( ) ; } 
public static void outlog ( final Exception e ) { outlog ( " %s " , e . getMessage ( ) ) ; e . printStackTrace ( System . out ) ; } 
public static void errlog ( final Exception e ) { errlog ( " %s " , e . getMessage ( ) ) ; e . printStackTrace ( ) ; } 
public static void main ( final String [ ] args ) throws Exception { if ( args . length > = 1 & & args [ 0 ] . equals ( " -index " ) ) { Index . main ( args ) ; return ; } if ( args . length > = 1 & & args [ 0 ] . equals ( " -search " ) ) { Search . main ( args ) ; return ; } System . out . println ( Utils . error ( " Invoke with -index or -search only. " ) ) ; return ; } 
public void load ( final IndexReader reader ) throws IOException { progress = newDocument ( ) ; final TermDocs termDocs = reader . termDocs ( PROGRESS_TERM ) ; try { while ( termDocs . next ( ) ) { 
public void save ( final IndexWriter writer ) throws IOException { writer . updateDocument ( PROGRESS_TERM , progress ) ; } 
public void remove ( final String dbname ) { progress . removeFields ( seqField ( dbname ) ) ; progress . removeFields ( sigField ( dbname ) ) ; } 
public void update ( final String dbname , final String sig , final long seq ) { Update seq. progress.removeFields(seqField(dbname)); progress.add(new Field(seqField(dbname), Long.toString(seq), Store.YES, Field.Index.NO)); Update sig. progress.removeFields(sigField(dbname)); progress.add(new Field(sigField(dbname), sig, Store.YES, Field.Index.NO)); } 
private Document newDocument ( ) { final Document result = new Document ( ) ; Add unique identifier. result.add(new Field(PROGRESS_KEY, PROGRESS_VALUE, Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS)); return result; } 
private String seqField ( final String dbname ) { return dbname + " -seq " ; } 
private String sigField ( final String dbname ) { return dbname + " -sig " ; } 
public boolean visibleToScripts ( String fullClassName ) { return false ; } 
private String loadJSONParser ( ) throws IOException { final InputStream in = Rhino . class . getClassLoader ( ) . getResourceAsStream ( " json2.js " ) ; try { return IOUtils . toString ( in , " UTF-8 " ) ; 
public static Scriptable jsConstructor ( Context cx , Object [ ] args , Function ctorObj , boolean inNewExpr ) { RhinoDocument doc = new RhinoDocument ( ) ; if ( args . length > = 2 ) jsFunction_field ( cx , doc , args , ctorObj ) ; return doc ; } 
public static void jsFunction_field ( final Context cx , final Scriptable thisObj , final Object [ ] args , final Function funObj ) { final RhinoDocument doc = checkInstance ( thisObj ) ; if ( args . length < 2 ) { throw Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } Field . Store str = null ; Field . Index idx = null ; Field . TermVector tv = null ; if ( args . length > = 3 ) { str = ( Field . Store ) Store . get ( args [ 2 ] . toString ( ) . toUpperCase ( ) ) ; } if ( str = = null ) str = Field . Store . NO ; if ( args . length > = 4 ) { idx = ( Field . Index ) Index . get ( args [ 3 ] . toString ( ) . toUpperCase ( ) ) ; } if ( idx = = null ) idx = Field . Index . ANALYZED ; if ( args . length > = 5 ) { tv = ( Field . TermVector ) TermVector . get ( args [ 4 ] . toString ( ) . toUpperCase ( ) ) ; } if ( tv = = null ) tv = Field . TermVector . NO ; doc . doc . add ( new Field ( args [ 0 ] . toString ( ) , args [ 1 ] . toString ( ) , str , idx , tv ) ) ; } 
public static void jsFunction_attachment ( final Context cx , final Scriptable thisObj , final Object [ ] args , final Function funObj ) throws IOException { final RhinoDocument doc = checkInstance ( thisObj ) ; if ( args . length < 2 ) { throw Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } final String dbname = ( String ) cx . getThreadLocal ( " dbname " ) ; final String docid = ( String ) cx . getThreadLocal ( " docid " ) ; final String field = args [ 0 ] . toString ( ) ; final String attname = args [ 1 ] . toString ( ) ; final String url = DB . url ( String . format ( " %s/%s/%s " , dbname , DB . encode ( docid ) , DB . encode ( attname ) ) ) ; System . err . println ( " ATTACHMENT: " + url ) ; final GetMethod get = new GetMethod ( url ) ; try { final int sc = Database . CLIENT . executeMethod ( get ) ; 
public static void jsFunction_date ( final Context cx , final Scriptable thisObj , final Object [ ] args , final Function funObj ) throws IOException { final RhinoDocument doc = checkInstance ( thisObj ) ; if ( args . length < 2 ) { throw Context . reportRuntimeError ( " field name and value required. " ) ; } final String field = args [ 0 ] . toString ( ) ; final String value = args [ 1 ] . toString ( ) ; final Field . Store str ; if ( args . length > 2 ) { final String strtype = args [ 2 ] . toString ( ) . toUpperCase ( ) ; str = Store . get ( strtype ) = = null ? Field . Store . NO : ( Field . Store ) Store . get ( strtype ) ; } else { str = Field . Store . NO ; } final DateFormat [ ] formats ; if ( args . length > 3 ) { formats = new DateFormat [ ] { new SimpleDateFormat ( args [ 3 ] . toString ( ) ) } ; } else { formats = DATE_FORMATS ; } final Date parsed = parse_date ( formats , value ) ; if ( parsed = = null ) { throw Context . reportRuntimeError ( " failed to parse date value: " + value ) ; } doc . doc . add ( new Field ( field , Long . toString ( parsed . getTime ( ) ) , str , Field . Index . NOT_ANALYZED_NO_NORMS ) ) ; } 
private static RhinoDocument checkInstance ( Scriptable obj ) { if ( obj = = null | | ! ( obj instanceof RhinoDocument ) ) { throw Context . reportRuntimeError ( " called on incompatible object. " ) ; } return ( RhinoDocument ) obj ; } 
public static void main ( final String [ ] args ) { try { IndexReader reader = null ; 
private static long size ( final Directory dir ) throws IOException { long result = 0 ; for ( final String name : dir . list ( ) ) { result + = dir . fileLength ( name ) ; } return result ; } 
public void lap ( final String name ) { final long now = System . nanoTime ( ) ; elapsed . put ( name , now - start ) ; start = now ; } 
public void parse ( final InputStream in , final String contentType , final String fieldName , final Document doc ) throws IOException { final AutoDetectParser parser = new AutoDetectParser ( ) ; final Metadata md = new Metadata ( ) ; md . set ( Metadata . CONTENT_TYPE , contentType ) ; final Reader reader = new ParsingReader ( parser , in , md ) ; final String body ; try { try { body = IOUtils . toString ( reader ) ; } finally { reader . close ( ) ; } } catch ( final IOException e ) { log . warn ( " Failed to index an attachment. " , e ) ; return ; } Add body text. doc.add(text(fieldName, body, false)); Add DC attributes. addDublinCoreAttributes(md, doc); Detect language. final String language = LanguageIdentifier.identifyLanguage(body); if (language != null && language.length() > 0) doc.add(text(DC + DublinCore.LANGUAGE, language, false)); 
private void addDublinCoreAttributes ( final Metadata md , final Document doc ) { addAttribute ( DC , DublinCore . CONTRIBUTOR , md , doc ) ; addAttribute ( DC , DublinCore . COVERAGE , md , doc ) ; addAttribute ( DC , DublinCore . CREATOR , md , doc ) ; addAttribute ( DC , DublinCore . DATE , md , doc ) ; addAttribute ( DC , DublinCore . DESCRIPTION , md , doc ) ; addAttribute ( DC , DublinCore . FORMAT , md , doc ) ; addAttribute ( DC , DublinCore . IDENTIFIER , md , doc ) ; addAttribute ( DC , DublinCore . LANGUAGE , md , doc ) ; addAttribute ( DC , DublinCore . MODIFIED , md , doc ) ; addAttribute ( DC , DublinCore . PUBLISHER , md , doc ) ; addAttribute ( DC , DublinCore . RELATION , md , doc ) ; addAttribute ( DC , DublinCore . RIGHTS , md , doc ) ; addAttribute ( DC , DublinCore . SOURCE , md , doc ) ; addAttribute ( DC , DublinCore . SUBJECT , md , doc ) ; addAttribute ( DC , DublinCore . TITLE , md , doc ) ; addAttribute ( DC , DublinCore . TYPE , md , doc ) ; } 
private void addAttribute ( final String namespace , final String attributeName , final Metadata md , final Document doc ) { if ( md . get ( attributeName ) ! = null ) { doc . add ( text ( namespace + attributeName , md . get ( attributeName ) , false ) ) ; 
public static void log ( final String fmt , final Object . . . args ) { final String msg = String . format ( fmt , args ) ; System . out . printf ( " { \" log \" : \" %s \" } " , msg ) ; } 
public static String throwableToJSON ( final Throwable ) { return error ( . getMessage ( ) = = null ? " Unknown error " : String . format ( " %s: %s " , . getClass ( ) , . getMessage ( ) ) ) ; } 
public static String error ( final String txt ) { return error ( 500 , txt ) ; } 
public static String digest ( final String data ) { return DigestUtils . md5Hex ( data ) ; } 
public static String error ( final int code , final Throwable ) { final StringWriter writer = new StringWriter ( ) ; final PrintWriter printWriter = new PrintWriter ( writer ) ; if ( . getMessage ( ) ! = null ) printWriter . append ( . getMessage ( ) ) ; . printStackTrace ( printWriter ) ; return new JSONObject ( ) . element ( " code " , code ) . element ( " body " , writer . toString ( ) ) . toString ( ) ; } 
public static String error ( final int code , final String txt ) { return new JSONObject ( ) . element ( " code " , code ) . element ( " body " , StringEscapeUtils . escapeHtml ( txt ) ) . toString ( ) ; } 
public static Field text ( final String name , final String value , final boolean store ) { return new Field ( name , value , store ? Store . YES : Store . NO , Field . Index . ANALYZED ) ; } 
public static Field token ( final String name , final String value , final boolean store ) { return new Field ( name , value , store ? Store . YES : Store . NO , Field . Index . NOT_ANALYZED_NO_NORMS ) ; } 
public static String identifyLanguage ( final String txt ) { return INSTANCE . identify ( txt ) ; } 
public String identify ( String content ) { return identify ( new StringBuffer ( content ) ) ; } 
public String identify ( StringBuffer content ) { StringBuffer text = content ; if ( ( analyzeLength > 0 ) & & ( content . length ( ) > analyzeLength ) ) { text = new StringBuffer ( ) . append ( content ) ; text . setLength ( analyzeLength ) ; } suspect . analyze ( text ) ; Iterator iter = suspect . getSorted ( ) . iterator ( ) ; float topscore = Float . MIN_VALUE ; String lang = " " ; HashMap scores = new HashMap ( ) ; NGramEntry searched = null ; while ( iter . hasNext ( ) ) { searched = ( NGramEntry ) iter . next ( ) ; NGramEntry [ ] ngrams = ( NGramEntry [ ] ) ngramsIdx . get ( searched . getSeq ( ) ) ; if ( ngrams ! = null ) { for ( int j = 0 ; j < ngrams . length ; j + + ) { NGramProfile profile = ngrams [ j ] . getProfile ( ) ; Float pScore = ( Float ) scores . get ( profile ) ; if ( pScore = = null ) { pScore = new Float ( 0 ) ; } float plScore = pScore . floatValue ( ) ; plScore + = ngrams [ j ] . getFrequency ( ) + searched . getFrequency ( ) ; scores . put ( profile , new Float ( plScore ) ) ; if ( plScore > topscore ) { topscore = plScore ; lang = profile . getName ( ) ; } } } } return lang ; } 
public String identify ( InputStream is ) throws IOException { return identify ( is , null ) ; } 
public String identify ( InputStream is , String charset ) throws IOException { ByteArrayOutputStream out = new ByteArrayOutputStream ( ) ; byte [ ] buffer = new byte [ 2048 ] ; int len = 0 ; while ( ( ( len = is . read ( buffer ) ) ! = - 1 ) & & ( ( analyzeLength = = 0 ) | | ( out . size ( ) < analyzeLength ) ) ) { if ( analyzeLength ! = 0 ) { len = Math . min ( len , analyzeLength - out . size ( ) ) ; } out . write ( buffer , 0 , len ) ; } return identify ( ( charset = = null ) ? out . toString ( ) : out . toString ( charset ) ) ; } 
public void add ( Token ) { add ( new StringBuffer ( ) . append ( SEPARATOR ) . append ( . termText ( ) ) . append ( SEPARATOR ) ) ; } 
public void add ( StringBuffer word ) { for ( int i = minLength ; ( i < = maxLength ) & & ( i < word . length ( ) ) ; i + + ) { add ( word , i ) ; 
private void add ( QuickStringBuffer word ) { int wlen = word . length ( ) ; if ( wlen > = minLength ) { int max = Math . min ( maxLength , wlen ) ; 
private void add ( CharSequence cs ) { if ( cs . equals ( SEP_CHARSEQ ) ) { return ; } NGramEntry nge = ( NGramEntry ) ngrams . get ( cs ) ; if ( nge = = null ) { nge = new NGramEntry ( cs ) ; ngrams . put ( cs , nge ) ; } nge . inc ( ) ; } 
public void analyze ( StringBuffer text ) { if ( ngrams ! = null ) { ngrams . clear ( ) ; sorted = null ; ngramcounts = null ; } word . clear ( ) . append ( SEPARATOR ) ; for ( int i = 0 ; i < text . length ( ) ; i + + ) { char c = Character . toLowerCase ( text . charAt ( i ) ) ; if ( Character . isLetter ( c ) ) { add ( word . append ( c ) ) ; } else { found word boundary if (word.length() > 1) { we have a word! add(word.append(SEPARATOR)); word.clear().append(SEPARATOR); } } } if (word.length() > 1) { we have a word! add(word.append(SEPARATOR)); } normalize(); } 
private void add ( StringBuffer word , int ) { for ( int i = 0 ; i < = word . length ( ) - ; i + + ) { add ( word . subSequence ( i , i + ) ) ; 
protected void normalize ( ) { NGramEntry e = null ; List sorted = getSorted(); Iterator i = ngrams.values().iterator(); Calculate ngramcount if not already done if (ngramcounts == null) { ngramcounts = new int[maxLength + 1]; while (i.hasNext()) { e = (NGramEntry) i.next(); ngramcounts[e.size()] += e.count; } } i = ngrams.values().iterator(); while (i.hasNext()) { e = (NGramEntry) i.next(); 
public String toString ( ) { StringBuffer s = new StringBuffer ( ) . append ( " NGramProfile: " ) . append ( name ) . append ( " " ) ; Iterator i = getSorted ( ) . iterator ( ) ; while ( i . hasNext ( ) ) { NGramEntry entry = ( NGramEntry ) i . next ( ) ; s . append ( " [ " ) . append ( entry . seq ) . append ( " / " ) . append ( entry . count ) . append ( " / " ) . append ( entry . frequency ) . append ( " ] " ) ; } return s . toString ( ) ; } 
public void load ( InputStream is ) throws IOException { ngrams . clear ( ) ; ngramcounts = new int [ maxLength + 1 ] ; BufferedReader reader = new BufferedReader ( new InputStreamReader ( is , " UTF-8 " ) ) ; String line = null ; while ( ( line = reader . readLine ( ) ) ! = null ) { # starts a comment line if (line.charAt(0) != '#') { int spacepos = line.indexOf(' '); String ngramsequence = line.substring(0, spacepos).trim(); int len = ngramsequence.length(); if ((len >= minLength) && (len <= maxLength)) { int ngramcount = Integer.parseInt(line.substring(spacepos + 1)); NGramEntry en = new NGramEntry(ngramsequence, ngramcount); ngrams.put(en.getSeq(), en); ngramcounts[len] += ngramcount; } } } normalize(); } 
public static NGramProfile create ( String name , InputStream is , String encoding ) { NGramProfile newProfile = new NGramProfile ( name , ABSOLUTE_MIN_NGRAM_LENGTH , ABSOLUTE_MAX_NGRAM_LENGTH ) ; BufferedInputStream bis = new BufferedInputStream ( is ) ; byte buffer [ ] = new byte [ 4096 ] ; StringBuffer text = new StringBuffer ( ) ; int len ; try { while ( ( len = bis . read ( buffer ) ) ! = - 1 ) { text . append ( new String ( buffer , 0 , len , encoding ) ) ; } } catch ( IOException e ) { Log . errlog ( e ) ; } newProfile . analyze ( text ) ; return newProfile ; } 
public static void main ( String args [ ] ) { String usage = " Usage: NGramProfile " + " [-create profilename filename encoding] " + " [-similarity file1 file2] " + " [-score profile-name filename encoding] " ; int command = 0 ; final int CREATE = 1 ; final int SIMILARITY = 2 ; final int SCORE = 3 ; String profilename = " " ; String filename = " " ; String filename2 = " " ; String encoding = " " ; if ( args . length = = 0 ) { System . err . println ( usage ) ; System . exit ( - 1 ) ; } for ( int i = 0 ; i < args . length ; i + + ) { parse command line if (args[i].equals("-create")) { found -create option command = CREATE; profilename = args[++i]; filename = args[++i]; encoding = args[++i]; } if (args[i].equals("-similarity")) { found -similarity option command = SIMILARITY; filename = args[++i]; filename2 = args[++i]; encoding = args[++i]; } if (args[i].equals("-score")) { found -Score option command = SCORE; profilename = args[++i]; filename = args[++i]; encoding = args[++i]; } } try { 
public int compareTo ( Object o ) { NGramEntry ngram = ( NGramEntry ) o ; int diff = Float . compare ( ngram . getFrequency ( ) , frequency ) ; if ( diff ! = 0 ) { return diff ; 
public String toString ( ) { return seq . toString ( ) ; } 
public boolean equals ( Object obj ) { NGramEntry ngram = null ; try { ngram = ( NGramEntry ) obj ; 
private void expandCapacity ( int minimumCapacity ) { int newCapacity = ( value . length + 1 ) * 2 ; if ( newCapacity < 0 ) { newCapacity = Integer . MAX_VALUE ; } else if ( minimumCapacity > newCapacity ) { newCapacity = minimumCapacity ; } char newValue [ ] = new char [ newCapacity ] ; System . arraycopy ( value , 0 , newValue , 0 , count ) ; value = newValue ; } 
QuickStringBuffer clear ( ) { count = 0 ; return this ; } 
public char charAt ( int index ) { return value [ index ] ; } 
QuickStringBuffer append ( String str ) { if ( str = = null ) { str = String . valueOf ( str ) ; } int len = str . length ( ) ; int newcount = count + len ; if ( newcount > value . length ) { expandCapacity ( newcount ) ; } str . getChars ( 0 , len , value , count ) ; count = newcount ; return this ; } 
QuickStringBuffer append ( char c ) { int newcount = count + 1 ; if ( newcount > value . length ) { expandCapacity ( newcount ) ; } value [ count + + ] = c ; return this ; } 
public CharSequence subSequence ( int start , int end ) { return new String ( value , start , end - start ) ; } 
public String toString ( ) { return new String ( this . value ) ; } 
public void testEnglish ( ) throws Exception { assertLanguage ( " i18n/en/ep-97-05-15.txt " , " en " ) ; } 
public void testDanish ( ) throws Exception { assertLanguage ( " i18n/da/ep-04-09-16.txt " , " da " ) ; } 
public void testGerman ( ) throws Exception { assertLanguage ( " i18n/de/ep-00-02-02.txt " , " de " ) ; } 
public void testSpanish ( ) throws Exception { assertLanguage ( " i18n/es/ep-03-10-08.txt " , " es " ) ; } 
public void testGreek ( ) throws Exception { assertLanguage ( " i18n/el/ep-04-05-03.txt " , " el " ) ; } 
public void testFinnish ( ) throws Exception { assertLanguage ( " i18n/fi/ep-99-03-09.txt " , " fi " ) ; 
public void testItalian ( ) throws Exception { assertLanguage ( " i18n/it/ep-98-09-16.txt " , " it " ) ; } 
public void testFrench ( ) throws Exception { assertLanguage ( " i18n/fr/ep-96-09-18.txt " , " fr " ) ; } 
public void testDutch ( ) throws Exception { assertLanguage ( " i18n/nl/ep-98-09-18.txt " , " nl " ) ; } 
public void testPortugese ( ) throws Exception { assertLanguage ( " i18n/pt/ep-98-09-17.txt " , " pt " ) ; } 
public void testSwedish ( ) throws Exception { assertLanguage ( " i18n/sv/ep-98-09-17.txt " , " sv " ) ; } 
public void testPerformance ( ) throws Exception { final long start = System . currentTimeMillis ( ) ; final int max = 200 ; for ( int i = 0 ; i < max ; i + + ) { assertLanguage ( " i18n/sv/ep-98-09-17.txt " , " sv " ) ; assertLanguage ( " i18n/nl/ep-98-09-18.txt " , " nl " ) ; } System . out . println ( ( System . currentTimeMillis ( ) - start ) / max ) ; } 
private void assertLanguage ( final String file , final String expectedLanguage ) throws Exception { final InputStream in = LanguageIdentifier . class . getClassLoader ( ) . getResourceAsStream ( file ) ; final String txt = IOUtils . toString ( in , " UTF-8 " ) ; in . close ( ) ; assertThat ( LanguageIdentifier . identifyLanguage ( txt ) , is ( expectedLanguage ) ) ; } 
public void testRhino ( ) throws Exception { final Rhino rhino = new Rhino ( " function(doc) { var ret = new Document(); " + " ret.field( \" foo \" , doc.size); return ret } " ) ; final String doc = " { \" deleteme \" : \" true \" , \" size \" :13} " ; Document [ ] ret = rhino . map ( doc ) ; assertThat ( ret . length , CoreMatchers . equalTo ( 1 ) ) ; assertThat ( ret [ 0 ] . getField ( " foo " ) , CoreMatchers . notNullValue ( ) ) ; rhino . close ( ) ; } 
public void testMultipleReturn ( ) throws Exception { final Rhino rhino = new Rhino ( " function(doc) { " + " var ret = []; " + " for(var v in doc) {var d = new Document(); d.field(v, doc[v]); ret.push(d)} " + " return ret; " + " } " ) ; Document [ ] ret = rhino . map ( " { \" foo \" : 1, \" bar \" : 2} " ) ; assertThat ( ret . length , CoreMatchers . equalTo ( 2 ) ) ; rhino . close ( ) ; } 
public void setup ( ) { tika = new Tika ( ) ; doc = new Document ( ) ; } 
public void testPDF ( ) throws IOException { parse ( " paxos-simple.pdf " , " application/pdf " , " foo " ) ; assertThat ( doc . getField ( " foo " ) , not ( nullValue ( ) ) ) ; } 
public void testXML ( ) throws IOException { parse ( " example.xml " , " text/xml " , " bar " ) ; assertThat ( doc . getField ( " bar " ) , not ( nullValue ( ) ) ) ; } 
private void parse ( final String resource , final String type , final String field ) throws IOException { final InputStream in = getClass ( ) . getClassLoader ( ) . getResourceAsStream ( resource ) ; try { tika . parse ( in , type , field , doc ) ; 
public void testEnglish ( ) throws IOException { assertThat ( detectLanguage ( " my head hurts " ) , is ( " en " ) ) ; assertThat ( detectLanguage ( " english text here " ) , is ( " en " ) ) ; } 
public void testGerman ( ) throws IOException { assertThat ( detectLanguage ( " Alle Menschen sind frei und gleich " ) , is ( " de " ) ) ; } 
public void testFrench ( ) throws IOException { assertThat ( detectLanguage ( " Me permettez-vous, dans ma gratitude " ) , is ( " fr " ) ) ; } 
private String detectLanguage ( final String text ) { final LanguageIdentifier identifier = new LanguageIdentifier ( ) ; return identifier . identify ( text ) ; } 
public static void jsFunction_attachment ( final Context cx , final Scriptable thisObj , final Object [ ] args , final Function funObj ) throws IOException { final RhinoDocument doc = checkInstance ( thisObj ) ; if ( args . length < 2 ) { throw Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } final String dbname = ( String ) cx . getThreadLocal ( " dbname " ) ; final String docid = ( String ) cx . getThreadLocal ( " docid " ) ; final String field = args [ 0 ] . toString ( ) ; final String attname = args [ 1 ] . toString ( ) ; final String url = DB . url ( String . format ( " %s/%s/%s " , dbname , DB . encode ( docid ) , DB . encode ( attname ) ) ) ; final GetMethod get = new GetMethod ( url ) ; try { final int sc = Database . CLIENT . executeMethod ( get ) ; 
public void cleanup ( ) { if ( rhino ! = null ) rhino . close ( ) ; 
public void testRhino ( ) throws Exception { rhino = new Rhino ( " db, " , " function(doc) { var ret = new Document(); " + " ret.field( \" foo \" , doc.size); return ret } " ) ; final String doc = " { \" deleteme \" : \" true \" , \" size \" :13} " ; Document [ ] ret = rhino . map ( " doc " , doc ) ; assertThat ( ret . length , CoreMatchers . equalTo ( 1 ) ) ; assertThat ( ret [ 0 ] . getField ( " foo " ) , CoreMatchers . notNullValue ( ) ) ; } 
public void testNoReturn ( ) throws Exception { rhino = new Rhino ( " db " , " function(doc) {} " ) ; Document [ ] ret = rhino . map ( " doc " , " {} " ) ; assertThat ( ret . length , CoreMatchers . equalTo ( 0 ) ) ; } 
public void testBadReturn ( ) throws Exception { rhino = new Rhino ( " db " , " function(doc) {return 1;} " ) ; rhino . map ( " doc " , " {} " ) ; } 
public void testCtor ( ) throws Exception { rhino = new Rhino ( " db " , " function(doc) { return new Document( \" foo \" , 1); } " ) ; Document [ ] ret = rhino . map ( " doc " , " {} " ) ; assertThat ( ret . length , CoreMatchers . equalTo ( 1 ) ) ; assertThat ( ret [ 0 ] . getField ( " foo " ) , CoreMatchers . notNullValue ( ) ) ; } 
public void testMultipleReturn ( ) throws Exception { rhino = new Rhino ( " db " , " function(doc) { " + " var ret = []; " + " for(var v in doc) {var d = new Document(); d.field(v, doc[v]); ret.push(d)} " + " return ret; " + " } " ) ; Document [ ] ret = rhino . map ( " doc " , " { \" foo \" : 1, \" bar \" : 2} " ) ; assertThat ( ret . length , CoreMatchers . equalTo ( 2 ) ) ; } 
public void testDate ( ) throws Exception { rhino = new Rhino ( " db " , " function(doc) { var ret = new Document(); " + " ret.date( \" bar \" , \" 2009-01-0T00:00:00Z \" ); return ret;} " ) ; Document [ ] ret = rhino . map ( " doc " , " { \" foo \" : 1, \" bar \" : 2} " ) ; assertThat ( ret . length , CoreMatchers . equalTo ( 1 ) ) ; assertThat ( ret [ 0 ] . getField ( " bar " ) , CoreMatchers . notNullValue ( ) ) ; } 
public static void jsFunction_date ( final Context cx , final Scriptable thisObj , final Object [ ] args , final Function funObj ) throws IOException { final RhinoDocument doc = checkInstance ( thisObj ) ; if ( args . length < 2 ) { throw Context . reportRuntimeError ( " field name and value required. " ) ; } final String field = args [ 0 ] . toString ( ) ; final Field . Store str ; if ( args . length > 2 ) { final String strtype = args [ 2 ] . toString ( ) . toUpperCase ( ) ; str = Store . get ( strtype ) = = null ? Field . Store . NO : ( Field . Store ) Store . get ( strtype ) ; } else { str = Field . Store . NO ; } Is it a native date? try { final Date date = (Date) Context.jsToJava(args[1], Date.class); doc.doc.add(new Field(field, Long.toString(date.getTime()), str, Field.Index.NOT_ANALYZED_NO_NORMS)); return; } catch (final EvaluatorException e) { Ignore. } Try to parse it as a string. final String value= Context.toString(args[1]); final DateFormat[] formats; if (args.length > 3) { formats = new DateFormat[] { new SimpleDateFormat(args[3].toString()) }; } else { formats = DATE_FORMATS; } final Date parsed = parse_date(formats, value); if (parsed == null) { throw Context.reportRuntimeError("failed to parse date value: " + value); } doc.doc.add(new Field(field, Long.toString(parsed.getTime()), str, Field.Index.NOT_ANALYZED_NO_NORMS)); } 
public void cleanup ( ) { if ( rhino ! = null ) { rhino . close ( ) ; 
public void testBadCode ( ) throws Exception { rhino = new Rhino ( " db " , " function(doc) {no_such_function(); } " ) ; rhino . map ( " doc " , " {} " ) ; } 
public void testBadCodeRecovers ( ) throws Exception { try { testBadCode ( ) ; } catch ( EcmaError e ) { Ignored. } testRhino(); } 
private IndexWriter newWriter ( ) throws IOException { final IndexWriter result = new IndexWriter ( Config . INDEX_DIR , Config . ANALYZER , MaxFieldLength . UNLIMITED ) ; Customize merge policy. final LogByteSizeMergePolicy mp = new LogByteSizeMergePolicy(); mp.setMergeFactor(5); mp.setMaxMergeMB(1000); mp.setUseCompoundFile(false); result.setMergePolicy(mp); Customize other settings. result.setRAMBufferSizeMB(Config.RAM_BUF); return result; } 
private synchronized void updateIndex ( ) throws IOException { if ( IndexWriter . isLocked ( dir ) ) { Log . log ( " Forcibly unlocking locked index at startup. " ) ; IndexWriter . unlock ( dir ) ; } final String [ ] dbnames = DB . getAllDatabases ( ) ; Arrays . sort ( dbnames ) ; boolean commit = false ; boolean expunge = false ; final IndexWriter writer = newWriter ( ) ; final Progress progress = new Progress ( ) ; try { final IndexReader reader = IndexReader . open ( dir ) ; 
public static void log ( final String fmt , final Object . . . args ) { if ( LOG . isInfoEnabled ( ) ) { LOG . info ( String . format ( fmt , args ) ) ; 
public static void log ( final Exception e ) { LOG . warn ( e . getMessage ( ) , e ) ; } 
public static NGramProfile create ( String name , InputStream is , String encoding ) { NGramProfile newProfile = new NGramProfile ( name , ABSOLUTE_MIN_NGRAM_LENGTH , ABSOLUTE_MAX_NGRAM_LENGTH ) ; BufferedInputStream bis = new BufferedInputStream ( is ) ; byte buffer [ ] = new byte [ 4096 ] ; StringBuffer text = new StringBuffer ( ) ; int len ; try { while ( ( len = bis . read ( buffer ) ) ! = - 1 ) { text . append ( new String ( buffer , 0 , len , encoding ) ) ; } } catch ( IOException e ) { Log . log ( e ) ; } newProfile . analyze ( text ) ; return newProfile ; } 
public static void jsFunction_field ( final Context cx , final Scriptable thisObj , final Object [ ] args , final Function funObj ) { final RhinoDocument doc = checkInstance ( thisObj ) ; if ( args . length < 2 ) { throw Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } Field . Store str = null ; Field . Index idx = null ; Field . TermVector tv = null ; if ( args . length > = 3 ) { str = ( Field . Store ) Store . get ( args [ 2 ] . toString ( ) . toUpperCase ( ) ) ; } if ( str = = null ) str = Field . Store . NO ; if ( args . length > = 4 ) { idx = ( Field . Index ) Index . get ( args [ 3 ] . toString ( ) . toUpperCase ( ) ) ; } if ( idx = = null ) idx = Field . Index . ANALYZED ; if ( args . length > = 5 ) { tv = ( Field . TermVector ) TermVector . get ( args [ 4 ] . toString ( ) . toUpperCase ( ) ) ; } if ( tv = = null ) tv = Field . TermVector . NO ; if ( args [ 0 ] = = null ) { Log . log ( " null key passed to field(). " ) ; return ; } if ( args [ 1 ] = = null ) { Log . log ( " null value passed to field(). " ) ; return ; } doc . doc . add ( new Field ( args [ 0 ] . toString ( ) , args [ 1 ] . toString ( ) , str , idx , tv ) ) ; } 
private synchronized void updateIndex ( ) throws IOException { if ( IndexWriter . isLocked ( dir ) ) { Utils . LOG . warn ( " Forcibly unlocking locked index at startup. " ) ; IndexWriter . unlock ( dir ) ; } final String [ ] dbnames = DB . getAllDatabases ( ) ; Arrays . sort ( dbnames ) ; boolean commit = false ; boolean expunge = false ; final IndexWriter writer = newWriter ( ) ; final Progress progress = new Progress ( ) ; try { final IndexReader reader = IndexReader . open ( dir ) ; 
public static void jsFunction_field ( final Context cx , final Scriptable thisObj , final Object [ ] args , final Function funObj ) { final RhinoDocument doc = checkInstance ( thisObj ) ; if ( args . length < 2 ) { throw Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } Field . Store str = null ; Field . Index idx = null ; Field . TermVector tv = null ; if ( args . length > = 3 ) { str = ( Field . Store ) Store . get ( args [ 2 ] . toString ( ) . toUpperCase ( ) ) ; } if ( str = = null ) str = Field . Store . NO ; if ( args . length > = 4 ) { idx = ( Field . Index ) Index . get ( args [ 3 ] . toString ( ) . toUpperCase ( ) ) ; } if ( idx = = null ) idx = Field . Index . ANALYZED ; if ( args . length > = 5 ) { tv = ( Field . TermVector ) TermVector . get ( args [ 4 ] . toString ( ) . toUpperCase ( ) ) ; } if ( tv = = null ) tv = Field . TermVector . NO ; if ( args [ 0 ] = = null ) { Utils . LOG . warn ( " null key passed to field(). " ) ; return ; } if ( args [ 1 ] = = null ) { Utils . LOG . warn ( " null value passed to field(). " ) ; return ; } doc . doc . add ( new Field ( args [ 0 ] . toString ( ) , args [ 1 ] . toString ( ) , str , idx , tv ) ) ; } 
public static NGramProfile create ( String name , InputStream is , String encoding ) { NGramProfile newProfile = new NGramProfile ( name , ABSOLUTE_MIN_NGRAM_LENGTH , ABSOLUTE_MAX_NGRAM_LENGTH ) ; BufferedInputStream bis = new BufferedInputStream ( is ) ; byte buffer [ ] = new byte [ 4096 ] ; StringBuffer text = new StringBuffer ( ) ; int len ; try { while ( ( len = bis . read ( buffer ) ) ! = - 1 ) { text . append ( new String ( buffer , 0 , len , encoding ) ) ; } } catch ( final IOException e ) { LOGGER . warn ( " Exception raised while creating profile. " , e ) ; } newProfile . analyze ( text ) ; return newProfile ; } 
public static void main ( String args [ ] ) throws Exception { String usage = " Usage: NGramProfile " + " [-create profilename filename encoding] " + " [-similarity file1 file2] " + " [-score profile-name filename encoding] " ; int command = 0 ; final int CREATE = 1 ; final int SIMILARITY = 2 ; final int SCORE = 3 ; String profilename = " " ; String filename = " " ; String filename2 = " " ; String encoding = " " ; if ( args . length = = 0 ) { System . err . println ( usage ) ; System . exit ( - 1 ) ; } for ( int i = 0 ; i < args . length ; i + + ) { parse command line if (args[i].equals("-create")) { found -create option command = CREATE; profilename = args[++i]; filename = args[++i]; encoding = args[++i]; } if (args[i].equals("-similarity")) { found -similarity option command = SIMILARITY; filename = args[++i]; filename2 = args[++i]; encoding = args[++i]; } if (args[i].equals("-score")) { found -Score option command = SCORE; profilename = args[++i]; filename = args[++i]; encoding = args[++i]; } } switch (command) { 
public static void main ( String [ ] args ) throws Exception { Utils . LOG . info ( " indexer started. " ) ; final Indexer indexer = new Indexer ( FSDirectory . getDirectory ( Config . INDEX_DIR ) ) ; final Thread thread = new Thread ( indexer , " index " ) ; thread . setDaemon ( true ) ; thread . start ( ) ; final Scanner scanner = new Scanner ( System . in ) ; while ( scanner . hasNextLine ( ) ) { final String line = scanner . nextLine ( ) ; final JSONObject obj = JSONObject . fromObject ( line ) ; if ( obj . has ( " type " ) & & obj . has ( " db " ) ) { indexer . setStale ( true ) ; } } Utils . LOG . info ( " indexer stopped. " ) ; } 
public static Scriptable jsConstructor ( Context cx , Object [ ] args , Function ctorObj , boolean inNewExpr ) { RhinoDocument doc = new RhinoDocument ( ) ; if ( args . length > = 2 ) jsFunction_add ( cx , doc , args , ctorObj ) ; return doc ; } 
public static void jsFunction_add ( final Context cx , final Scriptable thisObj , final Object [ ] args , final Function funObj ) { final RhinoDocument doc = checkInstance ( thisObj ) ; if ( args . length < 1 | | args . length > 2 ) { throw Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } if ( args [ 0 ] = = null ) { throw Context . reportRuntimeError ( " first argument must be non-null. " ) ; } if ( args . length = = 2 & & ( args [ 1 ] = = null | | args [ 1 ] instanceof NativeObject = = false ) ) { throw Context . reportRuntimeError ( " second argument must be an object. " ) ; } defaults. String field = Config.DEFAULT_FIELD; Field.Store store = Field.Store.NO; Field.Index index = Field.Index.ANALYZED; Field.TermVector tv = Field.TermVector.NO; Check for overrides. if (args.length == 2) { final NativeObject obj = (NativeObject) args[1]; Change the field name. if (obj.has("field", null)) { field = (String) obj.get("field", null); } Change the stored flag. if (obj.has("store", null)) { store = Store.get(obj.get("store", null)); } Change the indexed flag. if (obj.has("index", null)) { index = Index.get(obj.get("index", null)); } } doc.add(new Field(field, args[0].toString(), store, index, tv)); } 
public static void jsFunction_date ( final Context cx , final Scriptable thisObj , final Object [ ] args , final Function funObj ) throws IOException { final RhinoDocument doc = checkInstance ( thisObj ) ; if ( args . length < 2 ) { throw Context . reportRuntimeError ( " field name and value required. " ) ; } final String field = args [ 0 ] . toString ( ) ; final Field . Store str ; if ( args . length > 2 ) { final String strtype = args [ 2 ] . toString ( ) . toUpperCase ( ) ; str = Store . get ( strtype ) = = null ? Field . Store . NO : ( Field . Store ) Store . get ( strtype ) ; } else { str = Field . Store . NO ; } Is it a native date? try { final Date date = (Date) Context.jsToJava(args[1], Date.class); doc.doc.add(new Field(field, Long.toString(date.getTime()), str, Field.Index.NOT_ANALYZED_NO_NORMS)); return; } catch (final EvaluatorException e) { Ignore. } Try to parse it as a string. final String value = Context.toString(args[1]); final DateFormat[] formats; if (args.length > 3) { formats = new DateFormat[] { new SimpleDateFormat(args[3].toString()) }; } else { formats = DATE_FORMATS; } final Date parsed = parse_date(formats, value); if (parsed == null) { throw Context.reportRuntimeError("failed to parse date value: " + value); } doc.doc.add(new Field(field, Long.toString(parsed.getTime()), str, Field.Index.NOT_ANALYZED_NO_NORMS)); } 
public JSONObject getAllDocs ( final String dbname , final String startkey , final String endkey ) throws HttpException , IOException { return JSONObject . fromObject ( get ( String . format ( " %s/_all_docs?startkey=%%22%s%%22&endkey=%%22%s%%22&include_docs=true " , encode ( dbname ) , encode ( startkey ) , encode ( endkey ) ) ) ) ; 
public void addAnalyzer ( final String prefix , final Analyzer analyzer ) { map . put ( prefix , analyzer ) ; } 
public TokenStream reusableTokenStream ( final String fieldName , final Reader reader ) throws IOException { return analyzer ( fieldName ) . reusableTokenStream ( removePrefix ( fieldName ) , reader ) ; } 
public TokenStream tokenStream ( final String fieldName , final Reader reader ) { return analyzer ( fieldName ) . tokenStream ( removePrefix ( fieldName ) , reader ) ; } 
private Analyzer analyzer ( final String fieldName ) { final int idx = fieldName . indexOf ( prefixTerminator ) ; if ( idx = = - 1 ) { return defaultAnalyzer ; } final Analyzer result = map . get ( fieldName . substring ( 0 , idx ) ) ; return result ! = null ? result : defaultAnalyzer ; } 
private String removePrefix ( final String fieldName ) { final int idx = fieldName . indexOf ( prefixTerminator ) ; if ( idx = = - 1 ) return fieldName ; return fieldName . substring ( idx ) ; } 
private void deleteView ( final String viewname , final Progress progress , final IndexWriter writer ) throws IOException { writer . deleteDocuments ( new Term ( Config . VIEW , viewname ) ) ; progress . remove ( viewname ) ; } 
private void deleteDatabase ( final String dbname , final Progress progress , final IndexWriter writer ) throws IOException { writer . deleteDocuments ( new Term ( Config . DB , dbname ) ) ; TODO remove all entries prefixed with dbname/ 
public void remove ( final String view_name ) { progress . removeFields ( seqField ( view_name ) ) ; progress . removeFields ( sigField ( view_name ) ) ; } 
public void update ( final String view_name , final String sig , final long seq ) { Update seq. progress.removeFields(seqField(view_name)); progress.add(new Field(seqField(view_name), Long.toString(seq), Store.YES, Field.Index.NO)); Update sig. progress.removeFields(sigField(view_name)); progress.add(new Field(sigField(view_name), sig, Store.YES, Field.Index.NO)); } 
private String seqField ( final String view_name ) { return view_name + " -seq " ; } 
private String sigField ( final String view_name ) { return view_name + " -sig " ; } 
public static void jsFunction_add ( final Context cx , final Scriptable thisObj , final Object [ ] args , final Function funObj ) { final RhinoDocument doc = checkInstance ( thisObj ) ; if ( args . length < 1 | | args . length > 2 ) { throw Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } if ( args [ 0 ] = = null ) { throw Context . reportRuntimeError ( " first argument must be non-null. " ) ; } if ( args . length = = 2 & & ( args [ 1 ] = = null | | args [ 1 ] instanceof NativeObject = = false ) ) { throw Context . reportRuntimeError ( " second argument must be an object. " ) ; } defaults. String field = Config.DEFAULT_FIELD; String language = "en"; Field.Store store = Field.Store.NO; Field.Index index = Field.Index.ANALYZED; Field.TermVector tv = Field.TermVector.NO; Check for overrides. if (args.length == 2) { final NativeObject obj = (NativeObject) args[1]; Change the field name. if (obj.has("field", null)) { field = (String) obj.get("field", null); } Change the stored flag. if (obj.has("store", null)) { store = Store.get(obj.get("store", null)); } Change the indexed flag. if (obj.has("index", null)) { index = Index.get(obj.get("index", null)); } Change the language. if (obj.has("language", null)) { language = (String) obj.get("language", null); } } doc.add(new Field(field, args[0].toString(), store, index, tv)); } 
public void testConfigurableAnalyzer ( ) throws Exception { final ConfigurableAnalyzer analyzer = new ConfigurableAnalyzer ( ':' , new StandardAnalyzer ( ) ) ; analyzer . addAnalyzer ( " fr " , new FrenchAnalyzer ( ) ) ; analyzer . addAnalyzer ( " de " , new GermanAnalyzer ( ) ) ; final Reader reader = new StringReader ( " hello " ) ; assertThat ( analyzer . tokenStream ( " de:hello " , reader ) , instanceOf ( GermanStemFilter . class ) ) ; assertThat ( analyzer . tokenStream ( " hello " , reader ) , instanceOf ( StopFilter . class ) ) ; assertThat ( analyzer . tokenStream ( " fr:hello " , reader ) , instanceOf ( LowerCaseFilter . class ) ) ; } 
private void deleteView ( final String viewname , final Progress progress , final IndexWriter writer ) throws IOException { writer . deleteDocuments ( new Term ( Config . VIEW , viewname ) ) ; progress . removeView ( viewname ) ; } 
private void deleteDatabase ( final String dbname , final Progress progress , final IndexWriter writer ) throws IOException { writer . deleteDocuments ( new Term ( Config . DB , dbname ) ) ; progress . removeDatabase ( dbname ) ; } 
public void removeView ( final String view_name ) { progress . removeFields ( seqField ( view_name ) ) ; progress . removeFields ( sigField ( view_name ) ) ; } 
public static void jsFunction_add ( final Context cx , final Scriptable thisObj , final Object [ ] args , final Function funObj ) { final RhinoDocument doc = checkInstance ( thisObj ) ; if ( args . length < 1 | | args . length > 2 ) { throw Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } if ( args [ 0 ] = = null ) { throw Context . reportRuntimeError ( " first argument must be non-null. " ) ; } if ( args . length = = 2 & & ( args [ 1 ] = = null | | args [ 1 ] instanceof NativeObject = = false ) ) { throw Context . reportRuntimeError ( " second argument must be an object. " ) ; } defaults. String field = Config.DEFAULT_FIELD; String language = "en"; Field.Store store = Field.Store.NO; Field.Index index = Field.Index.ANALYZED; Field.TermVector tv = Field.TermVector.NO; Check for overrides. if (args.length == 2) { final NativeObject obj = (NativeObject) args[1]; Change the field name. if (obj.has("field", null)) { field = (String) obj.get("field", null); } Change the stored flag. if (obj.has("store", null)) { store = Store.get(obj.get("store", null)); } Change the indexed flag. if (obj.has("index", null)) { index = Index.get(obj.get("index", null)); } Change the language. if (obj.has("language", null)) { language = (String) obj.get("language", null); } } if (args[0] instanceof String) { doc.add(new Field(field, (String) args[0], store, index, tv)); 
public static void jsFunction_add ( final Context cx , final Scriptable thisObj , final Object [ ] args , final Function funObj ) { final RhinoDocument doc = checkInstance ( thisObj ) ; if ( args . length < 1 | | args . length > 2 ) { throw Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } if ( args [ 0 ] = = null ) { throw Context . reportRuntimeError ( " first argument must be non-null. " ) ; } if ( args . length = = 2 & & ( args [ 1 ] = = null | | args [ 1 ] instanceof NativeObject = = false ) ) { throw Context . reportRuntimeError ( " second argument must be an object. " ) ; } defaults. String field = Config.DEFAULT_FIELD; String language = "en"; Field.Store store = Field.Store.NO; Field.Index index = Field.Index.ANALYZED; Field.TermVector tv = Field.TermVector.NO; Check for overrides. if (args.length == 2) { final NativeObject obj = (NativeObject) args[1]; Change the field name. if (obj.has("field", null)) { field = (String) obj.get("field", null); } Change the stored flag. if (obj.has("store", null)) { store = Store.get(obj.get("store", null)); } Change the indexed flag. if (obj.has("index", null)) { index = Index.get(obj.get("index", null)); } Change the language. if (obj.has("language", null)) { language = (String) obj.get("language", null); } } if (args[0] instanceof String || args[0] instanceof Integer || args[0] instanceof Double || args[0] instanceof Boolean) { 
public void testRhino ( ) throws Exception { rhino = new Rhino ( " db, " , " function(doc) { var ret = new Document(); " + " ret.add(doc.size, { \" field \" : \" foo \" }); return ret; } " ) ; final String doc = " { \" deleteme \" : \" true \" , \" size \" :13} " ; Document [ ] ret = rhino . map ( " doc " , doc ) ; assertThat ( ret . length , CoreMatchers . equalTo ( 1 ) ) ; assertThat ( ret [ 0 ] . getField ( " foo " ) , CoreMatchers . notNullValue ( ) ) ; } 
public void testCtor ( ) throws Exception { rhino = new Rhino ( " db " , " function(doc) { return new Document(1, { \" field \" : \" foo \" }); } " ) ; Document [ ] ret = rhino . map ( " doc " , " {} " ) ; assertThat ( ret . length , CoreMatchers . equalTo ( 1 ) ) ; assertThat ( ret [ 0 ] . getField ( " foo " ) , CoreMatchers . notNullValue ( ) ) ; } 
public void testMultipleReturn ( ) throws Exception { rhino = new Rhino ( " db " , " function(doc) { " + " var ret = []; " + " for(var v in doc) {var d = new Document(); d.add(doc[v], { \" field \" : v}); ret.push(d)} " + " return ret; " + " } " ) ; Document [ ] ret = rhino . map ( " doc " , " { \" foo \" : 1, \" bar \" : 2} " ) ; assertThat ( ret . length , CoreMatchers . equalTo ( 2 ) ) ; } 
public void testDate ( ) throws Exception { rhino = new Rhino ( " db " , " function(doc) { var ret = new Document(); " + " ret.add(new Date(), { \" field \" : \" bar \" }); return ret;} " ) ; Document [ ] ret = rhino . map ( " doc " , " { \" foo \" : 1, \" bar \" : 2} " ) ; assertThat ( ret . length , CoreMatchers . equalTo ( 1 ) ) ; assertThat ( ret [ 0 ] . getField ( " bar " ) , CoreMatchers . notNullValue ( ) ) ; } 
private static String loadResource ( final String name ) throws IOException { final InputStream in = Rhino . class . getClassLoader ( ) . getResourceAsStream ( name ) ; try { return IOUtils . toString ( in , " UTF-8 " ) ; 
public static void jsFunction_add ( final Context cx , final Scriptable thisObj , final Object [ ] args , final Function funObj ) { final RhinoDocument doc = checkInstance ( thisObj ) ; if ( args . length < 1 | | args . length > 2 ) { throw Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } if ( args [ 0 ] = = null ) { throw Context . reportRuntimeError ( " first argument must be non-null. " ) ; } if ( args . length = = 2 & & ( args [ 1 ] = = null | | args [ 1 ] instanceof NativeObject = = false ) ) { throw Context . reportRuntimeError ( " second argument must be an object. " ) ; } final JSONObject defaults = JSONObject . fromObject ( ( String ) cx . getThreadLocal ( " defaults " ) ) ; String language = defaults . optString ( " language " , " en " ) ; String field = defaults . optString ( " field " , Config . DEFAULT_FIELD ) ; String store = defaults . optString ( " store " , " no " ) ; String index = defaults . optString ( " index " , " analyzed " ) ; Check for local override. if (args.length == 2) { final NativeObject obj = (NativeObject) args[1]; language = optString(obj, "language", language); field = optString(obj, "field", field); store = optString(obj, "store", store); index = optString(obj, "index", index); } if (args[0] instanceof String || args[0] instanceof Integer || args[0] instanceof Double || args[0] instanceof Boolean) { 
private static String optString ( final NativeObject obj , final String key , final String defaultValue ) { if ( obj . has ( key , null ) ) return ( String ) obj . get ( " key " , null ) ; return defaultValue ; } 
public static Query docQuery ( final String viewname , final String id ) { BooleanQuery q = new BooleanQuery ( ) ; q . add ( new TermQuery ( new Term ( Config . VIEW , viewname ) ) , Occur . MUST ) ; q . add ( new TermQuery ( new Term ( Config . ID , id ) ) , Occur . MUST ) ; return q ; } 
private static String optString ( final NativeObject obj , final String key , final String defaultValue ) { if ( obj . has ( key , null ) ) { final Object value = obj . get ( key , null ) ; return value instanceof String ? ( String ) value : defaultValue ; } return defaultValue ; } 
private IndexWriter newWriter ( ) throws IOException { final IndexWriter result = new IndexWriter ( Config . INDEX_DIR , Config . ANALYZER , MaxFieldLength . UNLIMITED ) ; Customize merge policy. final LogByteSizeMergePolicy mp = new LogByteSizeMergePolicy(); mp.setMergeFactor(5); mp.setMaxMergeMB(1000); mp.setUseCompoundFile(false); result.setMergePolicy(mp); Customize other settings. result.setRAMBufferSizeMB(Config.RAM_BUF); if (Config.LUCENE_DEBUG) { result.setInfoStream(System.err); } return result; } 
public static Filter get ( final Object key , final Filter value ) { CachingWrapperFilter filter ; Get cached filter. synchronized (CACHE) { filter = (CachingWrapperFilter) CACHE.get(key); } Return cached filter, if possible. if (filter != null) { return filter; } Cache miss. filter = new CachingWrapperFilter(value); synchronized (CACHE) { CACHE.put(key, filter); } return filter; } 
private static void getValidViews ( final IndexReader reader , final Set < String > out ) throws IOException { out . clear ( ) ; final TermEnum terms = reader . terms ( new Term ( Config . VIEW ) ) ; try { do { 
public static String viewname ( final JSONArray path ) { return String . format ( " %s/%s/%s " , path . getString ( 0 ) , path . getString ( 2 ) , path . getString ( 3 ) ) ; } 
private IndexWriter newWriter ( ) throws IOException { final IndexWriter result = new IndexWriter ( Config . INDEX_DIR , Config . ANALYZER , MaxFieldLength . UNLIMITED ) ; Customize merge policy. final LogByteSizeMergePolicy mp = new LogByteSizeMergePolicy(); mp.setMaxMergeMB(1000); mp.setUseCompoundFile(false); result.setMergePolicy(mp); result.setRAMBufferSizeMB(Config.RAM_BUF); if (Config.LUCENE_DEBUG) { result.setInfoStream(System.err); } return result; } 
private IndexWriter newWriter ( ) throws IOException { final IndexWriter result = new IndexWriter ( Config . INDEX_DIR , Config . ANALYZER , MaxFieldLength . UNLIMITED ) ; Customize merge policy. final LogByteSizeMergePolicy mp = new LogByteSizeMergePolicy(); mp.setMergeFactor(5); mp.setMaxMergeMB(1000); mp.setUseCompoundFile(false); result.setMergePolicy(mp); result.setRAMBufferSizeMB(Config.RAM_BUF); if (Config.LUCENE_DEBUG) { result.setInfoStream(System.err); } return result; } 
public static void main ( final String [ ] args ) throws Exception { final File dir = new File ( Config . INDEX_DIR ) ; Create index directory if missing. if (!dir.exists()) { if (!dir.mkdir()) { Utils.LOG.fatal("Unable to create index dir " + dir.getAbsolutePath()); System.exit(1); } } Verify index directory is writable. final File canWrite = new File(dir, ".writable"); canWrite.delete(); delete stale copy. try { canWrite.createNewFile(); } catch (final IOException e) { Utils.LOG.fatal(dir.getAbsolutePath() + " is not writable."); System.exit(1); } finally { canWrite.delete(); } Utils.LOG.info("indexer started."); final Indexer indexer = new Indexer(FSDirectory.getDirectory(dir)); final Thread thread = new Thread(indexer, "index"); thread.setDaemon(true); thread.start(); final Scanner scanner = new Scanner(System.in); while (scanner.hasNextLine()) { final String line = scanner.nextLine(); final JSONObject obj = JSONObject.fromObject(line); if (obj.has("type") && obj.has("db")) { indexer.setStale(true); } } Utils.LOG.info("indexer stopped."); } 
public static void main ( final String [ ] args ) throws Exception { final File dir = new File ( Config . INDEX_DIR ) ; Create index directory if missing. if (!dir.exists()) { if (!dir.mkdir()) { Utils.LOG.fatal("Unable to create index dir " + dir.getAbsolutePath()); System.exit(1); } } Verify index directory is writable. final File canWrite = new File(dir, ".writable"); canWrite.delete(); delete stale copy. try { canWrite.createNewFile(); } catch (final IOException e) { Utils.LOG.fatal(dir.getAbsolutePath() + " is not writable."); System.exit(1); } finally { canWrite.delete(); } Check index prior to startup if it exists. final Directory d = FSDirectory.getDirectory(dir); if (IndexReader.indexExists(d)) { final CheckIndex check = new CheckIndex(d); final Status status = check.checkIndex(); if (status.clean) Utils.LOG.info("Index is clean."); else Utils.LOG.warn("Index is not clean."); } Utils.LOG.info("indexer started."); final Indexer indexer = new Indexer(d); final Thread thread = new Thread(indexer, "index"); thread.setDaemon(true); thread.start(); final Scanner scanner = new Scanner(System.in); while (scanner.hasNextLine()) { final String line = scanner.nextLine(); final JSONObject obj = JSONObject.fromObject(line); if (obj.has("type") && obj.has("db")) { indexer.setStale(true); } } Utils.LOG.info("indexer stopped."); } 
private static void onNewReader ( final IndexReader reader ) throws IOException { Remember list of valid views. getValidViews(reader, validViews); Remember signatures of views. progress.load(reader); } 
private String escape ( final String str ) { final StringBuilder builder = new StringBuilder ( str . length ( ) + 10 ) ; builder . append ( DOUBLE_QUOTE ) ; for ( int i = 0 ; i < str . length ( ) ; i + + ) { final char c = str . charAt ( i ) ; if ( c = = DOUBLE_QUOTE ) builder . append ( " \" " ) ; else builder . append ( c ) ; } builder . append ( DOUBLE_QUOTE ) ; return builder . toString ( ) ; } 
public Analyzer newAnalyzer ( ) { return new BrazilianAnalyzer ( ) ; } 
public Analyzer newAnalyzer ( ) { return new ChineseAnalyzer ( ) ; } 
public Analyzer newAnalyzer ( ) { return new CJKAnalyzer ( ) ; } 
public Analyzer newAnalyzer ( ) { return new CzechAnalyzer ( ) ; } 
public Analyzer newAnalyzer ( ) { return new DutchAnalyzer ( ) ; } 
public Analyzer newAnalyzer ( ) { return new StandardAnalyzer ( ) ; } 
public Analyzer newAnalyzer ( ) { return new FrenchAnalyzer ( ) ; } 
public Analyzer newAnalyzer ( ) { return new GermanAnalyzer ( ) ; } 
public Analyzer newAnalyzer ( ) { return new KeywordAnalyzer ( ) ; } 
public Analyzer newAnalyzer ( ) { return new PorterStemAnalyzer ( ) ; } 
public Analyzer newAnalyzer ( ) { return new RussianAnalyzer ( ) ; } 
public Analyzer newAnalyzer ( ) { return new SimpleAnalyzer ( ) ; } 
public Analyzer newAnalyzer ( ) { return new ThaiAnalyzer ( ) ; } 
public TokenStream tokenStream ( final String fieldName , final Reader reader ) { return new PorterStemFilter ( new LowerCaseTokenizer ( reader ) ) ; } 
public static void jsFunction_add ( final Context cx , final Scriptable thisObj , final Object [ ] args , final Function funObj ) { final RhinoDocument doc = checkInstance ( thisObj ) ; if ( args . length < 1 | | args . length > 2 ) { throw Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } if ( args [ 0 ] = = null ) { throw Context . reportRuntimeError ( " first argument must be non-null. " ) ; } if ( args . length = = 2 & & ( args [ 1 ] = = null | | args [ 1 ] instanceof NativeObject = = false ) ) { throw Context . reportRuntimeError ( " second argument must be an object. " ) ; } final JSONObject defaults = JSONObject . fromObject ( ( String ) cx . getThreadLocal ( " defaults " ) ) ; String language = defaults . optString ( " language " , " en " ) ; String field = defaults . optString ( " field " , Config . DEFAULT_FIELD ) ; String store = defaults . optString ( " store " , " no " ) ; String index = defaults . optString ( " index " , " analyzed " ) ; Check for local override. if (args.length == 2) { final NativeObject obj = (NativeObject) args[1]; language = optString(obj, "language", language); field = optString(obj, "field", field); store = optString(obj, "store", store); index = optString(obj, "index", index); } A standard field? if (args[0] instanceof String || args[0] instanceof Integer || args[0] instanceof Double || args[0] instanceof Boolean) { doc.add(new Field(field, args[0].toString(), Store.get(store), Index.get(index))); return; } Is it a date? try { final Date date = (Date) Context.jsToJava(args[0], Date.class); 
public void testBadCode ( ) throws Exception { rhino = new Rhino ( " db " , " function(doc) {no_such_function(); } " ) ; Document [ ] ret = rhino . map ( " doc " , " {} " ) ; assertThat ( ret . length , CoreMatchers . equalTo ( 0 ) ) ; } 
public static void main ( final String [ ] args ) throws Exception { final File dir = new File ( Config . INDEX_DIR ) ; Create index directory if missing. if (!dir.exists()) { if (!dir.mkdir()) { Utils.LOG.fatal("Unable to create index dir " + dir.getAbsolutePath()); System.exit(1); } } Verify index directory is writable. final File canWrite = new File(dir, ".writable"); canWrite.delete(); delete stale copy. try { canWrite.createNewFile(); } catch (final IOException e) { Utils.LOG.fatal(dir.getAbsolutePath() + " is not writable."); System.exit(1); } finally { canWrite.delete(); } Check index prior to startup if it exists. final Directory d = FSDirectory.getDirectory(dir); if (IndexReader.indexExists(d)) { final CheckIndex check = new CheckIndex(d); final Status status = check.checkIndex(); if (status.clean) Utils.LOG.info("Index is clean."); else Utils.LOG.warn("Index is not clean."); } Utils.LOG.info("indexer started."); final Indexer indexer = new Indexer(d); final Thread thread = new Thread(indexer, "index"); thread.setDaemon(true); thread.start(); final Scanner scanner = new Scanner(System.in, "UTF-8"); while (scanner.hasNextLine()) { final String line = scanner.nextLine(); final JSONObject obj = JSONObject.fromObject(line); if (obj.has("type") && obj.has("db")) { indexer.setStale(true); } } Utils.LOG.info("indexer stopped."); } 
public static void out ( final Object obj ) { if ( OUT = = null ) { try { OUT = new PrintWriter ( new OutputStreamWriter ( System . out , " UTF-8 " ) ) ; } catch ( final UnsupportedEncodingException e ) { throw new Error ( " UTF-8 support is missing from your JVM. " ) ; } } OUT . println ( obj . toString ( ) ) ; OUT . flush ( ) ; } 
private static void onNewReader ( final IndexReader reader ) throws IOException { progress . load ( reader ) ; } 
static Object convert ( final Object obj ) { if ( obj instanceof NativeObject ) return convertObject ( ( NativeObject ) obj ) ; else if ( obj instanceof NativeArray ) return convertArray ( ( NativeArray ) obj ) ; try { return Context . jsToJava ( obj , Date . class ) ; } catch ( final EvaluatorException e ) { not a date (this sucks). } return obj; } 
private static Object convertArray ( final NativeArray arr ) { final int len = ( int ) arr . getLength ( ) ; final JSONArray result = new JSONArray ( ) ; for ( int i = 0 ; i < len ; i + + ) { Object value = arr . get ( i , null ) ; if ( value instanceof NativeObject ) value = convertObject ( ( NativeObject ) value ) ; if ( value instanceof NativeArray ) value = convertArray ( ( NativeArray ) value ) ; result . add ( value ) ; } return result ; } 
public static void jsFunction_add ( final Context cx , final Scriptable thisObj , final Object [ ] args , final Function funObj ) { final RhinoDocument doc = checkInstance ( thisObj ) ; if ( args . length < 1 | | args . length > 2 ) { throw Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } if ( args [ 0 ] = = null ) { throw Context . reportRuntimeError ( " first argument must be non-null. " ) ; } if ( args . length = = 2 & & ( args [ 1 ] = = null | | args [ 1 ] instanceof NativeObject = = false ) ) { throw Context . reportRuntimeError ( " second argument must be an object. " ) ; } final JSONObject defaults = JSONObject . fromObject ( ( String ) cx . getThreadLocal ( " defaults " ) ) ; String language = defaults . optString ( " language " , " en " ) ; String field = defaults . optString ( " field " , Config . DEFAULT_FIELD ) ; String store = defaults . optString ( " store " , " no " ) ; String index = defaults . optString ( " index " , " analyzed " ) ; Check for local override. if (args.length == 2) { final NativeObject obj = (NativeObject) args[1]; language = optString(obj, "language", language); field = optString(obj, "field", field); store = optString(obj, "store", store); index = optString(obj, "index", index); } final Object obj = Conversion.convert(args[0]); if (obj instanceof Date) { Special indexed form. 
public synchronized boolean isStale ( ) { return staleAt > = freshAt ; } 
private long leniency ( ) { return MILLISECONDS . toNanos ( Config . COMMIT_MIN ) ; } 
public void run ( ) { while ( true ) { if ( isStale ( ) ) { 
private synchronized void updateIndex ( ) throws IOException { if ( IndexWriter . isLocked ( dir ) ) { Utils . LOG . warn ( " Forcibly unlocking locked index at startup. " ) ; IndexWriter . unlock ( dir ) ; } final String [ ] dbnames = DB . getAllDatabases ( ) ; Arrays . sort ( dbnames ) ; boolean expunge = false ; final IndexWriter writer = newWriter ( ) ; final Progress progress = new Progress ( ) ; try { final IndexReader reader = IndexReader . open ( dir ) ; 
public static void main ( final String [ ] args ) throws Exception { final File dir = new File ( Config . INDEX_DIR ) ; Create index directory if missing. if (!dir.exists()) { if (!dir.mkdir()) { Utils.LOG.fatal("Unable to create index dir " + dir.getAbsolutePath()); System.exit(1); } } Verify index directory is writable. final File canWrite = new File(dir, ".writable"); canWrite.delete(); delete stale copy. try { canWrite.createNewFile(); } catch (final IOException e) { Utils.LOG.fatal(dir.getAbsolutePath() + " is not writable."); System.exit(1); } finally { canWrite.delete(); } Check index prior to startup if it exists. final Directory d = FSDirectory.getDirectory(dir); if (IndexReader.indexExists(d)) { final CheckIndex check = new CheckIndex(d); final Status status = check.checkIndex(); if (status.clean) Utils.LOG.info("Index is clean."); else Utils.LOG.warn("Index is not clean."); } Utils.LOG.info("indexer started."); final Indexer indexer = new Indexer(d); indexer.updateIndex(); final Thread thread = new Thread(indexer, "index"); thread.setDaemon(true); thread.start(); final Scanner scanner = new Scanner(System.in, "UTF-8"); while (scanner.hasNextLine()) { final String line = scanner.nextLine(); final JSONObject obj = JSONObject.fromObject(line); if (obj.has("type") && obj.has("db")) { indexer.setStale(); } } Utils.LOG.info("indexer stopped."); } 
public JSONObject getAllDocsBySeq ( final String dbname , final long startkey ) throws IOException { return JSONObject . fromObject ( get ( String . format ( " %s/_all_docs_by_seq?startkey=%s&include_docs=true " , encode ( dbname ) , startkey ) ) ) ; 
public boolean createDatabase ( final String dbname ) throws IOException { return put ( encode ( dbname ) , null ) = = 201 ; } 
public boolean deleteDatabase ( final String dbname ) throws IOException { return delete ( encode ( dbname ) ) = = 201 ; } 
public boolean saveDocument ( final String dbname , final String id , final String body ) throws IOException { return put ( String . format ( " %s/%s " , encode ( dbname ) , id ) , body ) = = 201 ; } 
public JSONObject getAllDocs ( final String dbname , final String startkey , final String endkey ) throws IOException { return JSONObject . fromObject ( get ( String . format ( " %s/_all_docs?startkey=%%22%s%%22&endkey=%%22%s%%22&include_docs=true " , encode ( dbname ) , 
public JSONObject getAllDocsBySeq ( final String dbname , final long startkey , final int limit ) throws IOException { return JSONObject . fromObject ( get ( String . format ( " %s/_all_docs_by_seq?startkey=%d&limit=%d&include_docs=true " , encode ( dbname ) , startkey , limit ) ) ) ; 
public JSONObject getDoc ( final String dbname , final String id ) throws IOException { return JSONObject . fromObject ( get ( String . format ( " %s/%s " , encode ( dbname ) , id ) ) ) ; } 
public JSONObject getDocs ( final String dbname , final String . . . ids ) throws IOException { final JSONArray keys = new JSONArray ( ) ; for ( final String id : ids ) { keys . add ( id ) ; } final JSONObject req = new JSONObject ( ) ; req . element ( " keys " , keys ) ; return JSONObject . fromObject ( post ( String . format ( " %s/_all_docs?include_docs=true " , encode ( dbname ) ) , req . toString ( ) ) ) ; 
public JSONObject getInfo ( final String dbname ) throws IOException { return JSONObject . fromObject ( get ( encode ( dbname ) ) ) ; } 
private String get ( final String path ) throws IOException { return execute ( new GetMethod ( url ( path ) ) ) ; } 
private String post ( final String path , final String body ) throws IOException { final PostMethod post = new PostMethod ( url ( path ) ) ; post . setRequestEntity ( new StringRequestEntity ( body , " application/json " , " UTF-8 " ) ) ; return execute ( post ) ; } 
private int put ( final String path , final String body ) throws IOException { final PutMethod method = new PutMethod ( url ( path ) ) ; if ( body ! = null ) { method . setRequestEntity ( new StringRequestEntity ( body , " application/json " , " UTF-8 " ) ) ; } try { return CLIENT . executeMethod ( method ) ; 
private int delete ( final String path ) throws IOException { final DeleteMethod method = new DeleteMethod ( url ( path ) ) ; try { return CLIENT . executeMethod ( method ) ; 
private String execute ( final HttpMethodBase method ) throws IOException { try { final int sc = CLIENT . executeMethod ( method ) ; 
public void setup ( ) throws IOException , InterruptedException { final File dir = new File ( " arget/output " ) ; FileUtils . cleanDirectory ( dir ) ; System . setProperty ( " couchdb.lucene.dir " , dir . getAbsolutePath ( ) ) ; db = new Database ( base ) ; try { db . deleteDatabase ( dbname ) ; 
public void teardown ( ) throws IOException { db.deleteDatabase(dbname); } @Test public void index() throws IOException, InterruptedException { final String ddoc = "{\"fulltext\": {\"idx\": {\"index\":\"function(doc) {var ret=new Document(); ret.add(doc.content); return ret;}\"}}}"; assertThat(db.saveDocument(dbname, "_design/lucene", ddoc), is(true)); for (int i = 0; i < 50; i++) { assertThat(db.saveDocument(dbname, "doc-" + i, "{\"content\":\"hello\"}"), is(true)); } SECONDS.sleep(5); final JSONObject indexState = db.getDoc(dbname, "_fti"); assertThat(indexState.getInt("doc_count"), is(51)); }} 
public void index ( ) throws IOException , InterruptedException { final String ddoc = " { \" fulltext \" : { \" idx \" : { \" index \" : \" function(doc) {var ret=new Document(); ret.add(doc.content); return ret;} \" }}} " ; assertThat ( db . saveDocument ( dbname , " _design/lucene " , ddoc ) , is ( true ) ) ; for ( int i = 0 ; i < 50 ; i + + ) { assertThat ( db . saveDocument ( dbname , " doc- " + i , " { \" content \" : \" hello \" } " ) , is ( true ) ) ; } SECONDS . sleep ( 5 ) ; final JSONObject indexState = db . getDoc ( dbname , " _fti " ) ; assertThat ( indexState . getInt ( " doc_count " ) , is ( 51 ) ) ; } 
public void setup ( ) throws IOException , InterruptedException { db = new Database ( base ) ; try { db . deleteDatabase ( dbname ) ; 
public void teardown ( ) throws IOException { db . deleteDatabase ( dbname ) ; } 
public void index ( ) throws IOException , InterruptedException { final String ddoc = " { \" fulltext \" : { \" idx \" : { \" index \" : \" function(doc) {var ret=new Document(); ret.add(doc.content); return ret;} \" }}} " ; assertThat ( db . saveDocument ( dbname , " _design/lucene " , ddoc ) , is ( true ) ) ; for ( int i = 0 ; i < 50 ; i + + ) { assertThat ( db . saveDocument ( dbname , " doc- " + i , " { \" content \" : \" hello \" } " ) , is ( true ) ) ; } SECONDS . sleep ( 6 ) ; final JSONObject indexState = db . getDoc ( dbname , " _fti " ) ; assertThat ( indexState . getInt ( " doc_count " ) , is ( 51 ) ) ; final JSONObject queryResult = db . getDoc ( dbname , " /_fti/lucene/idx?q=hello " ) ; assertThat ( queryResult . getInt ( " total_rows " ) , is ( 50 ) ) ; } 
public void setup ( ) throws IOException , InterruptedException { db = new Database ( base ) ; try { db . deleteDatabase ( dbname ) ; SECONDS . sleep ( 6 ) ; db . createDatabase ( dbname ) ; } catch ( final IOException e ) { Bail here if couch isn't running. assumeTrue(false); } final String ddoc = "{\"fulltext\": {\"idx\": {\"index\":\"function(doc) {var ret=new Document(); ret.add(doc.content); return ret;}\"}}}"; assertThat(db.saveDocument(dbname, "_design/lucene", ddoc), is(true)); } 
public void index ( ) throws IOException , InterruptedException { for ( int i = 0 ; i < 50 ; i + + ) { assertThat ( db . saveDocument ( dbname , " doc- " + i , " { \" content \" : \" hello \" } " ) , is ( true ) ) ; } SECONDS . sleep ( 6 ) ; final JSONObject indexState = db . getDoc ( dbname , " _fti " ) ; assertThat ( indexState . getInt ( " doc_count " ) , is ( 51 ) ) ; final JSONObject queryResult = db . getDoc ( dbname , " /_fti/lucene/idx?q=hello " ) ; assertThat ( queryResult . getInt ( " total_rows " ) , is ( 50 ) ) ; } 
public void longIndex ( ) throws IOException , InterruptedException { for ( int i = 0 ; i < 20 ; i + + ) { assertThat ( db . saveDocument ( dbname , " doc- " + i , " { \" content \" : \" hello \" } " ) , is ( true ) ) ; MILLISECONDS . sleep ( 500 ) ; } SECONDS . sleep ( 6 ) ; final JSONObject indexState = db . getDoc ( dbname , " _fti " ) ; assertThat ( indexState . getInt ( " doc_count " ) , is ( 21 ) ) ; final JSONObject queryResult = db . getDoc ( dbname , " /_fti/lucene/idx?q=hello " ) ; assertThat ( queryResult . getInt ( " total_rows " ) , is ( 20 ) ) ; } 
public void setup ( ) throws IOException , InterruptedException { if ( ! enabled ) return ; SECONDS . sleep ( 6 ) ; db . createDatabase ( dbname ) ; final String ddoc = " { \" fulltext \" : { \" idx \" : { \" index \" : \" function(doc) {var ret=new Document(); ret.add(doc.content); return ret;} \" }}} " ; assertThat ( db . saveDocument ( dbname , " _design/lucene " , ddoc ) , is ( true ) ) ; } 
public void teardown ( ) throws IOException { if ( ! enabled ) return ; db . deleteDatabase ( dbname ) ; } 
public void index ( ) throws IOException , InterruptedException { if ( ! enabled ) return ; for ( int i = 0 ; i < 50 ; i + + ) { assertThat ( db . saveDocument ( dbname , " doc- " + i , " { \" content \" : \" hello \" } " ) , is ( true ) ) ; } SECONDS . sleep ( 10 ) ; final JSONObject indexState = db . getDoc ( dbname , " _fti " ) ; assertThat ( indexState . getInt ( " doc_count " ) , is ( 51 ) ) ; final JSONObject queryResult = db . getDoc ( dbname , " /_fti/lucene/idx?q=hello " ) ; assertThat ( queryResult . getInt ( " total_rows " ) , is ( 50 ) ) ; } 
public void longIndex ( ) throws IOException , InterruptedException { if ( ! enabled ) return ; for ( int i = 0 ; i < 20 ; i + + ) { assertThat ( db . saveDocument ( dbname , " doc- " + i , " { \" content \" : \" hello \" } " ) , is ( true ) ) ; MILLISECONDS . sleep ( 500 ) ; } SECONDS . sleep ( 6 ) ; final JSONObject indexState = db . getDoc ( dbname , " _fti " ) ; assertThat ( indexState . getInt ( " doc_count " ) , is ( 21 ) ) ; final JSONObject queryResult = db . getDoc ( dbname , " /_fti/lucene/idx?q=hello " ) ; assertThat ( queryResult . getInt ( " total_rows " ) , is ( 20 ) ) ; } 
private IndexWriter newWriter ( ) throws IOException { final IndexWriter result = new IndexWriter ( Config . INDEX_DIR , Config . ANALYZER , MaxFieldLength . UNLIMITED ) ; Customize merge policy. final LogByteSizeMergePolicy mp = new LogByteSizeMergePolicy(result); mp.setMergeFactor(5); mp.setMaxMergeMB(1000); mp.setUseCompoundFile(false); result.setMergePolicy(mp); result.setRAMBufferSizeMB(Config.RAM_BUF); if (Config.LUCENE_DEBUG) { result.setInfoStream(System.err); } return result; } 
public static void jsFunction_add ( final Context cx , final Scriptable thisObj , final Object [ ] args , final Function funObj ) { final RhinoDocument doc = checkInstance ( thisObj ) ; if ( args . length < 1 | | args . length > 2 ) { throw Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } if ( args [ 0 ] = = null ) { throw Context . reportRuntimeError ( " first argument must be non-null. " ) ; } if ( args . length = = 2 & & ( args [ 1 ] = = null | | args [ 1 ] instanceof NativeObject = = false ) ) { throw Context . reportRuntimeError ( " second argument must be an object. " ) ; } final JSONObject defaults = JSONObject . fromObject ( ( String ) cx . getThreadLocal ( " defaults " ) ) ; String language = defaults . optString ( " language " , " en " ) ; String field = defaults . optString ( " field " , Config . DEFAULT_FIELD ) ; String store = defaults . optString ( " store " , " no " ) ; String index = defaults . optString ( " index " , " analyzed " ) ; Check for local override. if (args.length == 2) { final NativeObject obj = (NativeObject) args[1]; language = optString(obj, "language", language); field = optString(obj, "field", field); store = optString(obj, "store", store); index = optString(obj, "index", index); } final Object obj = Conversion.convert(args[0]); System.err.println(obj.getClass()); if (obj instanceof Date) { Special indexed form. 
static Object convert ( final Object obj ) { if ( obj instanceof NativeObject ) return convertObject ( ( NativeObject ) obj ) ; else if ( obj instanceof NativeArray ) return convertArray ( ( NativeArray ) obj ) ; return obj ; } 
static < T > T convert ( final Object obj , final Class < T > clazz ) { return ( T ) Context . jsToJava ( obj , clazz ) ; } 
public static void jsFunction_add ( final Context cx , final Scriptable thisObj , final Object [ ] args , final Function funObj ) { final RhinoDocument doc = checkInstance ( thisObj ) ; if ( args . length < 1 | | args . length > 2 ) { throw Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } if ( args [ 0 ] = = null ) { throw Context . reportRuntimeError ( " first argument must be non-null. " ) ; } if ( args . length = = 2 & & ( args [ 1 ] = = null | | args [ 1 ] instanceof NativeObject = = false ) ) { throw Context . reportRuntimeError ( " second argument must be an object. " ) ; } final JSONObject defaults = JSONObject . fromObject ( ( String ) cx . getThreadLocal ( " defaults " ) ) ; String language = defaults . optString ( " language " , " en " ) ; String field = defaults . optString ( " field " , Config . DEFAULT_FIELD ) ; String store = defaults . optString ( " store " , " no " ) ; String index = defaults . optString ( " index " , " analyzed " ) ; String type = defaults . optString ( " type " , " string " ) ; Check for local override. if (args.length == 2) { final NativeObject obj = (NativeObject) args[1]; language = optString(obj, "language", language); field = optString(obj, "field", field); store = optString(obj, "store", store); index = optString(obj, "index", index); type = optString(obj, "type", type); } final Field.Store storeObj = Store.get(store); Fieldable fieldObj = null; if ("integer".equals(type)) { fieldObj = new NumericField(field, storeObj, true).setIntValue(Conversion.convert(args[0], Integer.class)); } else if ("float".equals(type)) { fieldObj = new NumericField(field, storeObj, true).setFloatValue(Conversion.convert(args[0], Float.class)); } else if ("double".equals(type)) { fieldObj = new NumericField(field, storeObj, true) .setDoubleValue(Conversion.convert(args[0], Double.class)); } else if ("long".equals(type)) { fieldObj = new NumericField(field, storeObj, true).setLongValue(Conversion.convert(args[0], Long.class)); } else if ("date".equals(type)) { fieldObj = new NumericField(field, storeObj, true).setLongValue(Conversion.convert(args[0], Date.class) .getTime()); } else if ("string".equals(type)) { fieldObj = new Field(field, Conversion.convert(args[0]).toString(), storeObj, Index.get(index)); } else { Ignore. } if (fieldObj != null) doc.add(fieldObj); 
public void testNumerics ( ) throws Exception { final Directory dir = new RAMDirectory ( ) ; final IndexWriter writer = new IndexWriter ( dir , new StandardAnalyzer ( Version . LUCENE_CURRENT ) , true , MaxFieldLength . UNLIMITED ) ; add ( writer , 1 ) ; add ( writer , 2 ) ; add ( writer , 10 ) ; add ( writer , 100 ) ; writer . close ( ) ; final IndexReader reader = IndexReader . open ( dir , true ) ; final IndexSearcher searcher = new IndexSearcher ( reader ) ; final TopDocs td = searcher . search ( NumericRangeQuery . newIntRange ( " int " , 2 , 10 , true , true ) , 10 ) ; assertThat ( td . totalHits , is ( 2 ) ) ; final TopFieldDocs tfd = searcher . search ( NumericRangeQuery . newIntRange ( " int " , 0 , 5 , true , true ) , null , 10 , new Sort ( new SortField ( " int " , SortField . INT ) ) ) ; assertThat ( tfd . totalHits , is ( 2 ) ) ; reader . close ( ) ; } 
private void add ( final IndexWriter writer , final int value ) throws IOException { final Document doc = new Document ( ) ; doc . add ( new NumericField ( " int " ) . setIntValue ( value ) ) ; writer . addDocument ( doc ) ; } 
public static void jsFunction_add ( final Context cx , final Scriptable thisObj , final Object [ ] args , final Function funObj ) { final RhinoDocument doc = checkInstance ( thisObj ) ; if ( args . length < 1 | | args . length > 2 ) { throw Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } if ( args [ 0 ] = = null ) { throw Context . reportRuntimeError ( " first argument must be non-null. " ) ; } if ( args . length = = 2 & & ( args [ 1 ] = = null | | args [ 1 ] instanceof NativeObject = = false ) ) { throw Context . reportRuntimeError ( " second argument must be an object. " ) ; } final JSONObject defaults = JSONObject . fromObject ( ( String ) cx . getThreadLocal ( " defaults " ) ) ; String language = defaults . optString ( " language " , " en " ) ; String field = defaults . optString ( " field " , Config . DEFAULT_FIELD ) ; String store = defaults . optString ( " store " , " no " ) ; String index = defaults . optString ( " index " , " analyzed " ) ; String type = defaults . optString ( " type " , " string " ) ; Check for local override. if (args.length == 2) { final NativeObject obj = (NativeObject) args[1]; language = optString(obj, "language", language); field = optString(obj, "field", field); store = optString(obj, "store", store); index = optString(obj, "index", index); type = optString(obj, "type", type); } final Field.Store storeObj = Store.get(store); Fieldable fieldObj = null; if ("int".equals(type)) { fieldObj = new NumericField(field, storeObj, true).setIntValue(Conversion.convert(args[0], Integer.class)); } else if ("float".equals(type)) { fieldObj = new NumericField(field, storeObj, true).setFloatValue(Conversion.convert(args[0], Float.class)); } else if ("double".equals(type)) { fieldObj = new NumericField(field, storeObj, true) .setDoubleValue(Conversion.convert(args[0], Double.class)); } else if ("long".equals(type)) { fieldObj = new NumericField(field, storeObj, true).setLongValue(Conversion.convert(args[0], Long.class)); } else if ("date".equals(type)) { fieldObj = new NumericField(field, storeObj, true).setLongValue(Conversion.convert(args[0], Date.class) .getTime()); } else if ("string".equals(type)) { fieldObj = new Field(field, Conversion.convert(args[0]).toString(), storeObj, Index.get(index)); } else { Ignore. } if (fieldObj != null) doc.add(fieldObj); 
public Analyzer newAnalyzer ( ) { return new StandardAnalyzer ( Version . LUCENE_CURRENT ) ; } 
protected void doGet ( final HttpServletRequest req , final HttpServletResponse resp ) tthrows ServletException , IOException { tsuper . doGet ( req , resp ) ; } 
public Integer handleResponse ( final HttpResponse response ) throws ClientProtocolException , IOException { return response . getStatusLine ( ) . getStatusCode ( ) ; } 
private String get ( final String path ) throws IOException { return execute ( new HttpGet ( url ( path ) ) ) ; } 
private String post ( final String path , final String body ) throws IOException { final HttpPost post = new HttpPost ( url ( path ) ) ; post . setEntity ( new StringEntity ( body ) ) ; return execute ( post ) ; } 
private int put ( final String path , final String body ) throws IOException { final HttpPut put = new HttpPut ( url ( path ) ) ; if ( body ! = null ) { put . setHeader ( " Content-Type " , " application/json " ) ; put . setEntity ( new StringEntity ( body ) ) ; } return httpClient . execute ( put , STATUS_CODE_HANDLER ) ; } 
private int delete ( final String path ) throws IOException { final HttpDelete delete = new HttpDelete ( url ( path ) ) ; return httpClient . execute ( delete , STATUS_CODE_HANDLER ) ; } 
private String execute ( final HttpUriRequest request ) throws IOException { return httpClient . execute ( request , RESPONSE_BODY_HANDLER ) ; } 
public static void main ( final String [ ] args ) throws Exception { System . err . println ( " This entrypoint is deprecated. Please read the 0.4 to 0.5 upgrade notes. " ) ; while ( System . in . read ( ) ! = - 1 ) ; 
public Analyzer newAnalyzer ( ) { return new BrazilianAnalyzer ( ) ; } 
public Analyzer newAnalyzer ( ) { return new ChineseAnalyzer ( ) ; } 
public Analyzer newAnalyzer ( ) { return new CJKAnalyzer ( ) ; } 
public Analyzer newAnalyzer ( ) { return new CzechAnalyzer ( ) ; } 
public Analyzer newAnalyzer ( ) { return new DutchAnalyzer ( ) ; } 
public Analyzer newAnalyzer ( ) { return new StandardAnalyzer ( Version . LUCENE_CURRENT ) ; } 
public Analyzer newAnalyzer ( ) { return new FrenchAnalyzer ( ) ; } 
public Analyzer newAnalyzer ( ) { return new GermanAnalyzer ( ) ; } 
public Analyzer newAnalyzer ( ) { return new KeywordAnalyzer ( ) ; } 
public Analyzer newAnalyzer ( ) { return new PorterStemAnalyzer ( ) ; } 
public Analyzer newAnalyzer ( ) { return new RussianAnalyzer ( ) ; } 
public Analyzer newAnalyzer ( ) { return new SimpleAnalyzer ( ) ; } 
public Analyzer newAnalyzer ( ) { return new ThaiAnalyzer ( ) ; } 
public TokenStream tokenStream ( final String fieldName , final Reader reader ) { return new PorterStemFilter ( new LowerCaseTokenizer ( reader ) ) ; } 
public static Object convert ( final Object obj ) { if ( obj instanceof NativeObject ) return convertObject ( ( NativeObject ) obj ) ; else if ( obj instanceof NativeArray ) return convertArray ( ( NativeArray ) obj ) ; return obj ; } 
public static < T > T convert ( final Object obj , final Class < T > clazz ) { return ( T ) Context . jsToJava ( obj , clazz ) ; } 
protected void doPost ( final HttpServletRequest req , final HttpServletResponse resp ) throws ServletException , IOException { TODO Auto-generated method stub super.doPost(req, resp); } 
private void deleteView ( final String viewname , final Progress progress , final IndexWriter writer ) throws IOException { writer . deleteDocuments ( new Term ( Constants . VIEW , viewname ) ) ; progress . removeView ( viewname ) ; } 
private void deleteDatabase ( final String dbname , final Progress progress , final IndexWriter writer ) throws IOException { writer . deleteDocuments ( new Term ( Constants . DB , dbname ) ) ; progress . removeDatabase ( dbname ) ; } 
public static void jsFunction_add ( final Context cx , final Scriptable thisObj , final Object [ ] args , final Function funObj ) { final RhinoDocument doc = checkInstance ( thisObj ) ; if ( args . length < 1 | | args . length > 2 ) { throw Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } if ( args [ 0 ] = = null ) { throw Context . reportRuntimeError ( " first argument must be non-null. " ) ; } if ( args . length = = 2 & & ( args [ 1 ] = = null | | args [ 1 ] instanceof NativeObject = = false ) ) { throw Context . reportRuntimeError ( " second argument must be an object. " ) ; } final JSONObject defaults = JSONObject . fromObject ( ( String ) cx . getThreadLocal ( " defaults " ) ) ; String language = defaults . optString ( " language " , " en " ) ; String field = defaults . optString ( " field " , Constants . DEFAULT_FIELD ) ; String store = defaults . optString ( " store " , " no " ) ; String index = defaults . optString ( " index " , " analyzed " ) ; String type = defaults . optString ( " type " , " string " ) ; Check for local override. if (args.length == 2) { final NativeObject obj = (NativeObject) args[1]; language = optString(obj, "language", language); field = optString(obj, "field", field); store = optString(obj, "store", store); index = optString(obj, "index", index); type = optString(obj, "type", type); } final Field.Store storeObj = Store.get(store); Fieldable fieldObj = null; if ("int".equals(type)) { fieldObj = new NumericField(field, storeObj, true).setIntValue(Conversion.convert(args[0], Integer.class)); } else if ("float".equals(type)) { fieldObj = new NumericField(field, storeObj, true).setFloatValue(Conversion.convert(args[0], Float.class)); } else if ("double".equals(type)) { fieldObj = new NumericField(field, storeObj, true) .setDoubleValue(Conversion.convert(args[0], Double.class)); } else if ("long".equals(type)) { fieldObj = new NumericField(field, storeObj, true).setLongValue(Conversion.convert(args[0], Long.class)); } else if ("date".equals(type)) { fieldObj = new NumericField(field, storeObj, true).setLongValue(Conversion.convert(args[0], Date.class) .getTime()); } else if ("string".equals(type)) { fieldObj = new Field(field, Conversion.convert(args[0]).toString(), storeObj, Index.get(index)); } else { Ignore. } if (fieldObj != null) doc.add(fieldObj); 
public static Query docQuery ( final String viewname , final String id ) { BooleanQuery q = new BooleanQuery ( ) ; q . add ( new TermQuery ( new Term ( Constants . VIEW , viewname ) ) , Occur . MUST ) ; q . add ( new TermQuery ( new Term ( Constants . ID , id ) ) , Occur . MUST ) ; return q ; } 
public Object getObject ( ) throws Exception { return database . getInfo ( " _config " ) ; } 
public String getStringProperty ( final String name ) throws IOException { return get ( name ) ; } 
public int setStringProperty ( final String name , final String value ) throws IOException { return put ( name , value ) ; } 
public int getIntProperty ( final String name ) throws IOException { return Integer . parseInt ( get ( name ) ) ; } 
public int setIntProperty ( final String name , final int value ) throws IOException { return put ( name , Integer . toString ( value ) ) ; } 
private String get ( final String name ) throws IOException { final HttpGet get = new HttpGet ( url + PREFIX + name ) ; return httpClient . execute ( get , new BasicResponseHandler ( ) ) ; } 
private int put ( final String name , final String value ) throws IOException { final HttpPut put = new HttpPut ( url + PREFIX + name ) ; put . setEntity ( new StringEntity ( value ) ) ; return httpClient . execute ( put , new StatusCodeResponseHandler ( ) ) ; } 
private int put ( final String path , final String body ) throws IOException { final HttpPut put = new HttpPut ( url ( path ) ) ; if ( body ! = null ) { put . setHeader ( " Content-Type " , " application/json " ) ; put . setEntity ( new StringEntity ( body ) ) ; } return httpClient . execute ( put , new StatusCodeResponseHandler ( ) ) ; } 
private int delete ( final String path ) throws IOException { final HttpDelete delete = new HttpDelete ( url ( path ) ) ; return httpClient . execute ( delete , new StatusCodeResponseHandler ( ) ) ; } 
private String execute ( final HttpUriRequest request ) throws IOException { return httpClient . execute ( request , new BasicResponseHandler ( ) ) ; } 
private long leniency ( ) { return MILLISECONDS . toNanos ( OldConfig . COMMIT_MIN ) ; } 
private void sleep ( ) { try { Thread . sleep ( OldConfig . COMMIT_MIN ) ; 
private IndexWriter newWriter ( ) throws IOException { final IndexWriter result = new IndexWriter ( OldConfig . INDEX_DIR , OldConfig . ANALYZER , MaxFieldLength . UNLIMITED ) ; Customize merge policy. final LogByteSizeMergePolicy mp = new LogByteSizeMergePolicy(result); mp.setMergeFactor(5); mp.setMaxMergeMB(1000); mp.setUseCompoundFile(false); result.setMergePolicy(mp); result.setRAMBufferSizeMB(OldConfig.RAM_BUF); if (OldConfig.LUCENE_DEBUG) { result.setInfoStream(System.err); } return result; } 
public static void main ( final String [ ] args ) throws Exception { final File dir = new File ( OldConfig . INDEX_DIR ) ; Create index directory if missing. if (!dir.exists()) { if (!dir.mkdir()) { Utils.LOG.fatal("Unable to create index dir " + dir.getAbsolutePath()); System.exit(1); } } Verify index directory is writable. final File canWrite = new File(dir, ".writable"); canWrite.delete(); delete stale copy. try { canWrite.createNewFile(); } catch (final IOException e) { Utils.LOG.fatal(dir.getAbsolutePath() + " is not writable."); System.exit(1); } finally { canWrite.delete(); } Check index prior to startup if it exists. final Directory d = FSDirectory.getDirectory(dir); if (IndexReader.indexExists(d)) { final CheckIndex check = new CheckIndex(d); final Status status = check.checkIndex(); if (status.clean) Utils.LOG.info("Index is clean."); else Utils.LOG.warn("Index is not clean."); } Utils.LOG.info("indexer started."); final Indexer indexer = new Indexer(d); indexer.updateIndex(); final Thread thread = new Thread(indexer, "index"); thread.setDaemon(true); thread.start(); final Scanner scanner = new Scanner(System.in, "UTF-8"); while (scanner.hasNextLine()) { final String line = scanner.nextLine(); final JSONObject obj = JSONObject.fromObject(line); if (obj.has("type") && obj.has("db")) { indexer.setStale(); } } Utils.LOG.info("indexer stopped."); } 
public Integer handleResponse ( final HttpResponse response ) throws ClientProtocolException , IOException { return response . getStatusLine ( ) . getStatusCode ( ) ; } 
public void run ( ) { try { final JSONObject state = database . getDoc ( " _local " , " lucene " ) ; 
public static void main ( final String [ ] args ) throws Exception { } } 
protected void doPost ( final HttpServletRequest req , final HttpServletResponse resp ) throws ServletException , IOException { super . doPost ( req , resp ) ; } 
private static long size ( final Directory dir ) throws IOException { long result = 0 ; for ( final String name : dir . listAll ( ) ) { result + = dir . fileLength ( name ) ; } return result ; } 
synchronized IndexWriter getIndexWriter ( ) throws IOException { if ( writer = = null ) { writer = new IndexWriter ( dir , Constants . ANALYZER , MaxFieldLength . UNLIMITED ) ; } return writer ; } 
synchronized IndexReader borrowReader ( ) throws IOException { if ( reader = = null ) { if ( realtime ) reader = getIndexWriter ( ) . getReader ( ) ; else reader = IndexReader . open ( dir , true ) ; Prevent closure. reader.incRef(); } reader.incRef(); return reader; } 
synchronized void returnReader ( final IndexReader reader ) throws IOException { reader . decRef ( ) ; } 
synchronized IndexSearcher borrowSearcher ( ) throws IOException { if ( searcher = = null ) { searcher = new IndexSearcher ( reader ) ; } searcher . getIndexReader ( ) . incRef ( ) ; return searcher ; } 
synchronized void returnSearcher ( final IndexSearcher searcher ) throws IOException { searcher . getIndexReader ( ) . decRef ( ) ; } 
void reopenReader ( ) throws IOException { final IndexReader oldReader ; synchronized ( this ) { oldReader = reader ; } final IndexReader newReader = oldReader . reopen ( ) ; if ( reader ! = newReader ) { synchronized ( this ) { 
public static void main ( final String [ ] args ) throws Exception { final Properties properties = new Properties ( ) ; final InputStream in = Main . class . getClassLoader ( ) . getResourceAsStream ( " couchdb-lucene.properties " ) ; properties . load ( in ) ; in . close ( ) ; Directory dir = null ; if ( ! properties . containsKey ( " dir " ) ) { LOG . error ( " No dir property found in configuration file. " ) ; System . exit ( 1 ) ; } else { dir = FSDirectory . open ( new File ( properties . getProperty ( " dir " ) ) ) ; } final LuceneHolder holder = new LuceneHolder ( dir , false ) ; holder . createIndex ( ) ; final Server server = new Server ( Integer . getInteger ( " port " , 5985 ) ) ; final ContextHandlerCollection contexts = new ContextHandlerCollection ( ) ; server . setHandler ( contexts ) ; final Context index = new Context ( contexts , " /index " , Context . NO_SESSIONS ) ; index . addServlet ( new ServletHolder ( new IndexingServlet ( holder ) ) , " / " ) ; final Context search = new Context ( contexts , " /search " , Context . NO_SESSIONS ) ; search . addServlet ( new ServletHolder ( new SearchServlet ( holder ) ) , " /* " ) ; final Context info = new Context ( contexts , " /info " , Context . NO_SESSIONS ) ; info . addServlet ( new ServletHolder ( new InfoServlet ( holder ) ) , " /* " ) ; server . start ( ) ; server . join ( ) ; } 
protected void doGet ( final HttpServletRequest req , final HttpServletResponse resp ) throws ServletException , IOException { final JSONObject json = toJSON ( req ) ; if ( ! json . has ( " query " ) ) { resp . sendError ( 400 , " Missing query attribute. " ) ; return ; } final JSONObject query = json . getJSONObject ( " query " ) ; if ( ! query . has ( " q " ) ) { resp . sendError ( 400 , " Missing q attribute. " ) ; return ; } Refresh reader and searcher unless stale=ok. if (!"ok".equals(query.optString("stale", null))) { holder.reopenReader(); } final JSONArray path = json.getJSONArray("path"); if (path.size() < 3) { resp.sendError(400, "No design document in path."); return; } if (path.size() < 4) { resp.sendError(400, "No view name in path."); return; } if (path.size() > 4) { resp.sendError(400, "Extra path info in request."); return; } final String viewname = Utils.viewname(path); assert path.size() == 4; final SearchRequest request; try { request = new SearchRequest(json); } catch (final ParseException e) { resp.sendError(400, "Failed to parse query."); return; } resp.setContentType(Constants.CONTENT_TYPE); final Writer writer = resp.getWriter(); try { final IndexSearcher searcher = holder.borrowSearcher(); 
private JSONObject toJSON ( final HttpServletRequest req ) throws IOException { final Reader reader = req . getReader ( ) ; try { return JSONObject . fromObject ( IOUtils . toString ( reader ) ) ; 
private IndexReader newReader ( ) throws IOException { if ( realtime ) { return getIndexWriter ( ) . getReader ( ) ; } return IndexReader . open ( dir , true ) ; } 
private IndexWriter newWriter ( ) throws IOException { final IndexWriter result = new IndexWriter ( dir , Constants . ANALYZER , MaxFieldLength . UNLIMITED ) ; final LogByteSizeMergePolicy mp = new LogByteSizeMergePolicy ( result ) ; mp . setMergeFactor ( 5 ) ; mp . setMaxMergeMB ( 1000 ) ; mp . setUseCompoundFile ( false ) ; result . setMergePolicy ( mp ) ; result . setRAMBufferSizeMB ( 16 ) ; return result ; } 
synchronized IndexReader borrowReader ( ) throws IOException { reader . incRef ( ) ; return reader ; } 
synchronized IndexSearcher borrowSearcher ( ) throws IOException { final IndexReader reader = borrowReader ( ) ; return new IndexSearcher ( reader ) ; } 
IndexWriter getIndexWriter ( ) throws IOException { return writer ; } 
synchronized void returnSearcher ( final IndexSearcher searcher ) throws IOException { returnReader ( searcher . getIndexReader ( ) ) ; } 
public static void main ( final String [ ] args ) throws Exception { final Properties properties = new Properties ( ) ; final InputStream in = Main . class . getClassLoader ( ) . getResourceAsStream ( " couchdb-lucene.properties " ) ; properties . load ( in ) ; in . close ( ) ; Directory dir = null ; if ( ! properties . containsKey ( " dir " ) ) { LOG . error ( " No dir property found in configuration file. " ) ; System . exit ( 1 ) ; } else { dir = FSDirectory . open ( new File ( properties . getProperty ( " dir " ) ) ) ; } final LuceneHolder holder = new LuceneHolder ( dir , false ) ; final Server server = new Server ( Integer . getInteger ( " port " , 5985 ) ) ; final ContextHandlerCollection contexts = new ContextHandlerCollection ( ) ; server . setHandler ( contexts ) ; final Context index = new Context ( contexts , " /index " , Context . NO_SESSIONS ) ; index . addServlet ( new ServletHolder ( new IndexingServlet ( holder ) ) , " / " ) ; final Context search = new Context ( contexts , " /search " , Context . NO_SESSIONS ) ; search . addServlet ( new ServletHolder ( new SearchServlet ( holder ) ) , " /* " ) ; final Context info = new Context ( contexts , " /info " , Context . NO_SESSIONS ) ; info . addServlet ( new ServletHolder ( new InfoServlet ( holder ) ) , " /* " ) ; server . start ( ) ; server . join ( ) ; } 
private Sort toSort ( final String sort ) { if ( sort = = null ) { return null ; 
public static void main ( final String [ ] args ) throws Exception { final Properties properties = new Properties ( ) ; final InputStream in = Main . class . getClassLoader ( ) . getResourceAsStream ( " couchdb-lucene.properties " ) ; properties . load ( in ) ; in . close ( ) ; final String luceneDir = properties . getProperty ( " lucene.dir " ) ; final int lucenePort = Integer . parseInt ( properties . getProperty ( " lucene.port " , " 5985 " ) ) ; final String couchUrl = properties . getProperty ( " couchdb.url " ) ; if ( luceneDir = = null ) { LOG . error ( " lucene.dir not set. " ) ; System . exit ( 1 ) ; } if ( couchUrl = = null ) { LOG . error ( " couchdb.url not set. " ) ; System . exit ( 1 ) ; } final Directory dir = FSDirectory . open ( new File ( luceneDir ) ) ; final HttpClient httpClient = new DefaultHttpClient ( ) ; final Database database = new Database ( httpClient , couchUrl ) ; final LuceneHolder holder = new LuceneHolder ( dir , false ) ; final Server server = new Server ( Integer . getInteger ( " port " , 5985 ) ) ; final ContextHandlerCollection contexts = new ContextHandlerCollection ( ) ; server . setHandler ( contexts ) ; final Context index = new Context ( contexts , " /index " , Context . NO_SESSIONS ) ; index . addServlet ( new ServletHolder ( new IndexingServlet ( holder ) ) , " / " ) ; final Context search = new Context ( contexts , " /search " , Context . NO_SESSIONS ) ; search . addServlet ( new ServletHolder ( new SearchServlet ( holder , database ) ) , " /* " ) ; final Context info = new Context ( contexts , " /info " , Context . NO_SESSIONS ) ; info . addServlet ( new ServletHolder ( new InfoServlet ( holder ) ) , " /* " ) ; server . start ( ) ; server . join ( ) ; } 
public static void main ( final String [ ] args ) throws Exception { final Properties properties = new Properties ( ) ; final InputStream in = Main . class . getClassLoader ( ) . getResourceAsStream ( " couchdb-lucene.properties " ) ; properties . load ( in ) ; in . close ( ) ; final String luceneDir = properties . getProperty ( " lucene.dir " ) ; final int lucenePort = Integer . parseInt ( properties . getProperty ( " lucene.port " , " 5985 " ) ) ; final String couchUrl = properties . getProperty ( " couchdb.url " ) ; if ( luceneDir = = null ) { LOG . error ( " lucene.dir not set. " ) ; System . exit ( 1 ) ; } if ( couchUrl = = null ) { LOG . error ( " couchdb.url not set. " ) ; System . exit ( 1 ) ; } final Directory dir = FSDirectory . open ( new File ( luceneDir ) ) ; final HttpClient httpClient = new DefaultHttpClient ( ) ; final Database database = new Database ( httpClient , couchUrl ) ; final LuceneHolder holder = new LuceneHolder ( dir , false ) ; final Server server = new Server ( Integer . getInteger ( " port " , lucenePort ) ) ; server . setStopAtShutdown ( true ) ; server . setSendServerVersion ( false ) ; final Filter gzipFilter = new GzipFilter ( ) ; final ContextHandlerCollection contexts = new ContextHandlerCollection ( ) ; server . setHandler ( contexts ) ; final Context search = new Context ( contexts , " /search " , Context . NO_SESSIONS ) ; search . addFilter ( new FilterHolder ( gzipFilter ) , " /* " , Handler . DEFAULT ) ; search . addServlet ( new ServletHolder ( new SearchServlet ( holder , database ) ) , " /* " ) ; final Context info = new Context ( contexts , " /info " , Context . NO_SESSIONS ) ; info . addServlet ( new ServletHolder ( new InfoServlet ( holder ) ) , " /* " ) ; final Context admin = new Context ( contexts , " /admin " , Context . NO_SESSIONS ) ; admin . addServlet ( new ServletHolder ( new AdminServlet ( holder ) ) , " /* " ) ; server . start ( ) ; server . join ( ) ; } 
protected void doStart ( ) throws Exception { TODO Auto-generated method stub super.doStart(); } 
protected void doStop ( ) throws Exception { TODO Auto-generated method stub super.doStop(); } 
public static void main ( final String [ ] args ) throws Exception { final Properties properties = new Properties ( ) ; final InputStream in = Main . class . getClassLoader ( ) . getResourceAsStream ( " couchdb-lucene.properties " ) ; properties . load ( in ) ; in . close ( ) ; final String luceneDir = properties . getProperty ( " lucene.dir " ) ; final int lucenePort = Integer . parseInt ( properties . getProperty ( " lucene.port " , " 5985 " ) ) ; final String couchUrl = properties . getProperty ( " couchdb.url " ) ; if ( luceneDir = = null ) { LOG . error ( " lucene.dir not set. " ) ; System . exit ( 1 ) ; } if ( couchUrl = = null ) { LOG . error ( " couchdb.url not set. " ) ; System . exit ( 1 ) ; } final Directory dir = FSDirectory . open ( new File ( luceneDir ) ) ; final HttpClient httpClient = new DefaultHttpClient ( ) ; final Database database = new Database ( httpClient , couchUrl ) ; final LuceneHolder holder = new LuceneHolder ( dir , false ) ; Configure Indexer. final Indexer indexer = new Indexer(); Configure Jetty. final Server server = new Server(Integer.getInteger("port", lucenePort)); server.setStopAtShutdown(true); server.setSendServerVersion(false); server.addLifeCycle(indexer); final Filter gzipFilter = new GzipFilter(); final ContextHandlerCollection contexts = new ContextHandlerCollection(); server.setHandler(contexts); final Context search = new Context(contexts, "/search", Context.NO_SESSIONS); search.addFilter(new FilterHolder(gzipFilter), "/*", Handler.DEFAULT); search.addServlet(new ServletHolder(new SearchServlet(holder, database)), "/*"); final Context info = new Context(contexts, "/info", Context.NO_SESSIONS); info.addServlet(new ServletHolder(new InfoServlet(holder)), "/*"); final Context admin = new Context(contexts, "/admin", Context.NO_SESSIONS); admin.addServlet(new ServletHolder(new AdminServlet(holder)), "/*"); server.start(); server.join(); } 
public Void callback ( final IndexWriter writer ) throws IOException { writer . expungeDeletes ( false ) ; return null ; } 
public Void callback ( final IndexWriter writer ) throws IOException { writer . optimize ( false ) ; return null ; } 
abstract Directory map ( final String indexName ) throws IOException ; } private static class LuceneHolder { private final Directory dir ; private IndexReader reader ; private final boolean realtime ; private final IndexWriter writer ; private LuceneHolder ( final Directory dir , final boolean realtime ) throws IOException { this . dir = dir ; this . realtime = realtime ; this . writer = newWriter ( ) ; this . reader = newReader ( ) ; this . reader . incRef ( ) ; } private IndexReader newReader ( ) throws IOException { if ( realtime ) { return getIndexWriter ( ) . getReader ( ) ; } return IndexReader . open ( dir , true ) ; } private IndexWriter newWriter ( ) throws IOException { final IndexWriter result = new IndexWriter ( dir , Constants . ANALYZER , MaxFieldLength . UNLIMITED ) ; final LogByteSizeMergePolicy mp = new LogByteSizeMergePolicy ( result ) ; mp . setMergeFactor ( 5 ) ; mp . setMaxMergeMB ( 1000 ) ; mp . setUseCompoundFile ( false ) ; result . setMergePolicy ( mp ) ; result . setRAMBufferSizeMB ( 16 ) ; return result ; } synchronized IndexReader borrowReader ( ) throws IOException { reader . incRef ( ) ; return reader ; } synchronized IndexSearcher borrowSearcher ( ) throws IOException { final IndexReader reader = borrowReader ( ) ; return new IndexSearcher ( reader ) ; } IndexWriter getIndexWriter ( ) throws IOException { return writer ; } void reopenReader ( ) throws IOException { final IndexReader oldReader ; synchronized ( this ) { oldReader = reader ; } final IndexReader newReader = oldReader . reopen ( ) ; if ( reader ! = newReader ) { synchronized ( this ) { reader = newReader ; oldReader . decRef ( ) ; } } } synchronized void returnReader ( final IndexReader reader ) throws IOException { reader . decRef ( ) ; } synchronized void returnSearcher ( final IndexSearcher searcher ) throws IOException { returnReader ( searcher . getIndexReader ( ) ) ; } } private static class MultiIndexStrategy extends IndexMappingStrategy { private final File baseDir ; private MultiIndexStrategy ( final File baseDir ) { this . baseDir = baseDir ; } @Override public Directory map ( final String indexName ) throws IOException { return FSDirectory . open ( new File ( baseDir , indexName ) ) ; } } private static class SingleIndexStrategy extends IndexMappingStrategy { private final File baseDir ; private SingleIndexStrategy ( final File baseDir ) { this . baseDir = baseDir ; } @Override public Directory map ( final String indexName ) throws IOException { return FSDirectory . open ( baseDir ) ; } } interface ReaderCallback < T > { public T callback ( final IndexReader reader ) throws IOException ; } interface SearcherCallback < T > { public T callback ( final IndexSearcher searcher ) throws IOException ; } interface WriterCallback < T > { public T callback ( final IndexWriter writer ) throws IOException ; } private final Map < String , LuceneHolder > holders = new LinkedHashMap < String , LuceneHolder > ( ) ; private final boolean realtime ; private final IndexMappingStrategy strategy ; LuceneHolders ( final File baseDir , final boolean realtime ) { this . realtime = realtime ; this . strategy = new MultiIndexStrategy ( baseDir ) ; } private synchronized LuceneHolder getHolder ( final String indexName ) throws IOException { LuceneHolder result = holders . get ( indexName ) ; if ( result = = null ) { result = new LuceneHolder ( strategy . map ( indexName ) , realtime ) ; holders . put ( indexName , result ) ; } return result ; } < T > T withReader ( final String indexName , final ReaderCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( indexName ) ; final IndexReader reader = holder . borrowReader ( ) ; try { return callback . callback ( reader ) ; } finally { holder . returnReader ( reader ) ; } } < T > T withSearcher ( final String indexName , final SearcherCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( indexName ) ; final IndexSearcher searcher = holder . borrowSearcher ( ) ; try { return callback . callback ( searcher ) ; } finally { holder . returnSearcher ( searcher ) ; } } < T > T withWriter ( final String indexName , final WriterCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( indexName ) ; final IndexWriter writer = holder . getIndexWriter ( ) ; return callback . callback ( writer ) ; } void reopenReader ( final String indexName ) throws IOException { getHolder ( indexName ) . reopenReader ( ) ; } } 
private IndexReader newReader ( ) throws IOException { if ( realtime ) { return getIndexWriter ( ) . getReader ( ) ; } return IndexReader . open ( dir , true ) ; } 
private IndexWriter newWriter ( ) throws IOException { final IndexWriter result = new IndexWriter ( dir , Constants . ANALYZER , MaxFieldLength . UNLIMITED ) ; final LogByteSizeMergePolicy mp = new LogByteSizeMergePolicy ( result ) ; mp . setMergeFactor ( 5 ) ; mp . setMaxMergeMB ( 1000 ) ; mp . setUseCompoundFile ( false ) ; result . setMergePolicy ( mp ) ; result . setRAMBufferSizeMB ( 16 ) ; return result ; } 
synchronized IndexReader borrowReader ( ) throws IOException { reader . incRef ( ) ; return reader ; } 
synchronized IndexSearcher borrowSearcher ( ) throws IOException { final IndexReader reader = borrowReader ( ) ; return new IndexSearcher ( reader ) ; } 
IndexWriter getIndexWriter ( ) throws IOException { return writer ; } 
void reopenReader ( ) throws IOException { final IndexReader oldReader ; synchronized ( this ) { oldReader = reader ; } final IndexReader newReader = oldReader . reopen ( ) ; if ( reader ! = newReader ) { synchronized ( this ) { 
synchronized void returnReader ( final IndexReader reader ) throws IOException { reader . decRef ( ) ; } 
synchronized void returnSearcher ( final IndexSearcher searcher ) throws IOException { returnReader ( searcher . getIndexReader ( ) ) ; } 
public Directory map ( final String indexName ) throws IOException { return FSDirectory . open ( new File ( baseDir , indexName ) ) ; } 
public Directory map ( final String indexName ) throws IOException { return FSDirectory . open ( baseDir ) ; } 
public T callback ( final IndexReader reader ) throws IOException ; } interface SearcherCallback < T > { public T callback ( final IndexSearcher searcher ) throws IOException ; } interface WriterCallback < T > { public T callback ( final IndexWriter writer ) throws IOException ; } private final Map < String , LuceneHolder > holders = new LinkedHashMap < String , LuceneHolder > ( ) ; private final boolean realtime ; private final IndexMappingStrategy strategy ; LuceneHolders ( final File baseDir , final boolean realtime ) { this . realtime = realtime ; this . strategy = new MultiIndexStrategy ( baseDir ) ; } private synchronized LuceneHolder getHolder ( final String indexName ) throws IOException { LuceneHolder result = holders . get ( indexName ) ; if ( result = = null ) { result = new LuceneHolder ( strategy . map ( indexName ) , realtime ) ; holders . put ( indexName , result ) ; } return result ; } < T > T withReader ( final String indexName , final ReaderCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( indexName ) ; final IndexReader reader = holder . borrowReader ( ) ; try { return callback . callback ( reader ) ; } finally { holder . returnReader ( reader ) ; } } < T > T withSearcher ( final String indexName , final SearcherCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( indexName ) ; final IndexSearcher searcher = holder . borrowSearcher ( ) ; try { return callback . callback ( searcher ) ; } finally { holder . returnSearcher ( searcher ) ; } } < T > T withWriter ( final String indexName , final WriterCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( indexName ) ; final IndexWriter writer = holder . getIndexWriter ( ) ; return callback . callback ( writer ) ; } void reopenReader ( final String indexName ) throws IOException { getHolder ( indexName ) . reopenReader ( ) ; } } 
public T callback ( final IndexSearcher searcher ) throws IOException ; } interface WriterCallback < T > { public T callback ( final IndexWriter writer ) throws IOException ; } private final Map < String , LuceneHolder > holders = new LinkedHashMap < String , LuceneHolder > ( ) ; private final boolean realtime ; private final IndexMappingStrategy strategy ; LuceneHolders ( final File baseDir , final boolean realtime ) { this . realtime = realtime ; this . strategy = new MultiIndexStrategy ( baseDir ) ; } private synchronized LuceneHolder getHolder ( final String indexName ) throws IOException { LuceneHolder result = holders . get ( indexName ) ; if ( result = = null ) { result = new LuceneHolder ( strategy . map ( indexName ) , realtime ) ; holders . put ( indexName , result ) ; } return result ; } < T > T withReader ( final String indexName , final ReaderCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( indexName ) ; final IndexReader reader = holder . borrowReader ( ) ; try { return callback . callback ( reader ) ; } finally { holder . returnReader ( reader ) ; } } < T > T withSearcher ( final String indexName , final SearcherCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( indexName ) ; final IndexSearcher searcher = holder . borrowSearcher ( ) ; try { return callback . callback ( searcher ) ; } finally { holder . returnSearcher ( searcher ) ; } } < T > T withWriter ( final String indexName , final WriterCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( indexName ) ; final IndexWriter writer = holder . getIndexWriter ( ) ; return callback . callback ( writer ) ; } void reopenReader ( final String indexName ) throws IOException { getHolder ( indexName ) . reopenReader ( ) ; } } 
public T callback ( final IndexWriter writer ) throws IOException ; } private final Map < String , LuceneHolder > holders = new LinkedHashMap < String , LuceneHolder > ( ) ; private final boolean realtime ; private final IndexMappingStrategy strategy ; LuceneHolders ( final File baseDir , final boolean realtime ) { this . realtime = realtime ; this . strategy = new MultiIndexStrategy ( baseDir ) ; } private synchronized LuceneHolder getHolder ( final String indexName ) throws IOException { LuceneHolder result = holders . get ( indexName ) ; if ( result = = null ) { result = new LuceneHolder ( strategy . map ( indexName ) , realtime ) ; holders . put ( indexName , result ) ; } return result ; } < T > T withReader ( final String indexName , final ReaderCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( indexName ) ; final IndexReader reader = holder . borrowReader ( ) ; try { return callback . callback ( reader ) ; } finally { holder . returnReader ( reader ) ; } } < T > T withSearcher ( final String indexName , final SearcherCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( indexName ) ; final IndexSearcher searcher = holder . borrowSearcher ( ) ; try { return callback . callback ( searcher ) ; } finally { holder . returnSearcher ( searcher ) ; } } < T > T withWriter ( final String indexName , final WriterCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( indexName ) ; final IndexWriter writer = holder . getIndexWriter ( ) ; return callback . callback ( writer ) ; } void reopenReader ( final String indexName ) throws IOException { getHolder ( indexName ) . reopenReader ( ) ; } } 
private synchronized LuceneHolder getHolder ( final String indexName ) throws IOException { LuceneHolder result = holders . get ( indexName ) ; if ( result = = null ) { result = new LuceneHolder ( strategy . map ( indexName ) , realtime ) ; holders . put ( indexName , result ) ; } return result ; } 
< T > T withReader ( final String indexName , final ReaderCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( indexName ) ; final IndexReader reader = holder . borrowReader ( ) ; try { return callback . callback ( reader ) ; 
< T > T withSearcher ( final String indexName , final SearcherCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( indexName ) ; final IndexSearcher searcher = holder . borrowSearcher ( ) ; try { return callback . callback ( searcher ) ; 
< T > T withWriter ( final String indexName , final WriterCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( indexName ) ; final IndexWriter writer = holder . getIndexWriter ( ) ; return callback . callback ( writer ) ; } 
void reopenReader ( final String indexName ) throws IOException { getHolder ( indexName ) . reopenReader ( ) ; } 
public static void main ( final String [ ] args ) throws Exception { final Properties properties = new Properties ( ) ; final InputStream in = Main . class . getClassLoader ( ) . getResourceAsStream ( " couchdb-lucene.properties " ) ; properties . load ( in ) ; in . close ( ) ; final String luceneDir = properties . getProperty ( " lucene.dir " ) ; final int lucenePort = Integer . parseInt ( properties . getProperty ( " lucene.port " , " 5985 " ) ) ; final String couchUrl = properties . getProperty ( " couchdb.url " ) ; if ( luceneDir = = null ) { LOG . error ( " lucene.dir not set. " ) ; System . exit ( 1 ) ; } if ( couchUrl = = null ) { LOG . error ( " couchdb.url not set. " ) ; System . exit ( 1 ) ; } final HttpClient httpClient = new DefaultHttpClient ( ) ; final Database database = new Database ( httpClient , couchUrl ) ; final LuceneHolders holders = new LuceneHolders ( new File ( luceneDir ) , false ) ; Configure Indexer. final Indexer indexer = new Indexer(database, holders); Configure Jetty. final Server server = new Server(Integer.getInteger("port", lucenePort)); server.setStopAtShutdown(true); server.setSendServerVersion(false); server.addLifeCycle(indexer); final Filter gzipFilter = new GzipFilter(); final ContextHandlerCollection contexts = new ContextHandlerCollection(); server.setHandler(contexts); final Context search = new Context(contexts, "/search", Context.NO_SESSIONS); search.addFilter(new FilterHolder(gzipFilter), "/*", Handler.DEFAULT); search.addServlet(new ServletHolder(new SearchServlet(holders, database)), "/*"); final Context info = new Context(contexts, "/info", Context.NO_SESSIONS); info.addServlet(new ServletHolder(new InfoServlet(holders)), "/*"); final Context admin = new Context(contexts, "/admin", Context.NO_SESSIONS); admin.addServlet(new ServletHolder(new AdminServlet(holders)), "/*"); server.start(); server.join(); } 
private static Sort toSort ( final String sort ) { if ( sort = = null ) { return null ; 
private int put ( final String path , final String body ) throws IOException { final HttpPut put = new HttpPut ( url ( path ) ) ; if ( body ! = null ) { put . setHeader ( " Content-Type " , Constants . CONTENT_TYPE ) ; put . setEntity ( new StringEntity ( body ) ) ; } return httpClient . execute ( put , new StatusCodeResponseHandler ( ) ) ; } 
protected void doStart ( ) throws Exception { scheduler = Executors . newScheduledThreadPool ( 1 ) ; } 
protected void doStop ( ) throws Exception { scheduler . shutdown ( ) ; scheduler . awaitTermination ( 30 , SECONDS ) ; } 
private IndexWriter newWriter ( ) throws IOException { final IndexWriter result = new IndexWriter ( dir , Constants . ANALYZER , MaxFieldLength . UNLIMITED ) ; final LogByteSizeMergePolicy mp = new LogByteSizeMergePolicy ( result ) ; mp . setMergeFactor ( 5 ) ; mp . setMaxMergeMB ( 1000 ) ; mp . setUseCompoundFile ( false ) ; result . setMergePolicy ( mp ) ; return result ; } 
public T callback ( final IndexReader reader ) throws IOException ; } interface SearcherCallback < T > { public T callback ( final IndexSearcher searcher ) throws IOException ; } interface WriterCallback < T > { public T callback ( final IndexWriter writer ) throws IOException ; } private final Map < String , LuceneHolder > holders = new LinkedHashMap < String , LuceneHolder > ( ) ; private final File baseDir ; private final boolean realtime ; LuceneHolders ( final File baseDir , final boolean realtime ) { this . baseDir = baseDir ; this . realtime = realtime ; } private synchronized LuceneHolder getHolder ( final String indexName ) throws IOException { LuceneHolder result = holders . get ( indexName ) ; if ( result = = null ) { result = new LuceneHolder ( FSDirectory . open ( new File ( baseDir , indexName ) ) , realtime ) ; holders . put ( indexName , result ) ; } return result ; } < T > T withReader ( final String indexName , final ReaderCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( indexName ) ; final IndexReader reader = holder . borrowReader ( ) ; try { return callback . callback ( reader ) ; } finally { holder . returnReader ( reader ) ; } } < T > T withSearcher ( final String indexName , final SearcherCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( indexName ) ; final IndexSearcher searcher = holder . borrowSearcher ( ) ; try { return callback . callback ( searcher ) ; } finally { holder . returnSearcher ( searcher ) ; } } < T > T withWriter ( final String indexName , final WriterCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( indexName ) ; final IndexWriter writer = holder . getIndexWriter ( ) ; try { return callback . callback ( writer ) ; } catch ( final OutOfMemoryError e ) { TODO Writer is broken - ensure atomic replacement. throw e; } } void reopenReader(final String indexName) throws IOException { getHolder(indexName).reopenReader(); }} 
public T callback ( final IndexSearcher searcher ) throws IOException ; } interface WriterCallback < T > { public T callback ( final IndexWriter writer ) throws IOException ; } private final Map < String , LuceneHolder > holders = new LinkedHashMap < String , LuceneHolder > ( ) ; private final File baseDir ; private final boolean realtime ; LuceneHolders ( final File baseDir , final boolean realtime ) { this . baseDir = baseDir ; this . realtime = realtime ; } private synchronized LuceneHolder getHolder ( final String indexName ) throws IOException { LuceneHolder result = holders . get ( indexName ) ; if ( result = = null ) { result = new LuceneHolder ( FSDirectory . open ( new File ( baseDir , indexName ) ) , realtime ) ; holders . put ( indexName , result ) ; } return result ; } < T > T withReader ( final String indexName , final ReaderCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( indexName ) ; final IndexReader reader = holder . borrowReader ( ) ; try { return callback . callback ( reader ) ; } finally { holder . returnReader ( reader ) ; } } < T > T withSearcher ( final String indexName , final SearcherCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( indexName ) ; final IndexSearcher searcher = holder . borrowSearcher ( ) ; try { return callback . callback ( searcher ) ; } finally { holder . returnSearcher ( searcher ) ; } } < T > T withWriter ( final String indexName , final WriterCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( indexName ) ; final IndexWriter writer = holder . getIndexWriter ( ) ; try { return callback . callback ( writer ) ; } catch ( final OutOfMemoryError e ) { TODO Writer is broken - ensure atomic replacement. throw e; } } void reopenReader(final String indexName) throws IOException { getHolder(indexName).reopenReader(); }} 
public T callback ( final IndexWriter writer ) throws IOException ; } private final Map < String , LuceneHolder > holders = new LinkedHashMap < String , LuceneHolder > ( ) ; private final File baseDir ; private final boolean realtime ; LuceneHolders ( final File baseDir , final boolean realtime ) { this . baseDir = baseDir ; this . realtime = realtime ; } private synchronized LuceneHolder getHolder ( final String indexName ) throws IOException { LuceneHolder result = holders . get ( indexName ) ; if ( result = = null ) { result = new LuceneHolder ( FSDirectory . open ( new File ( baseDir , indexName ) ) , realtime ) ; holders . put ( indexName , result ) ; } return result ; } < T > T withReader ( final String indexName , final ReaderCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( indexName ) ; final IndexReader reader = holder . borrowReader ( ) ; try { return callback . callback ( reader ) ; } finally { holder . returnReader ( reader ) ; } } < T > T withSearcher ( final String indexName , final SearcherCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( indexName ) ; final IndexSearcher searcher = holder . borrowSearcher ( ) ; try { return callback . callback ( searcher ) ; } finally { holder . returnSearcher ( searcher ) ; } } < T > T withWriter ( final String indexName , final WriterCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( indexName ) ; final IndexWriter writer = holder . getIndexWriter ( ) ; try { return callback . callback ( writer ) ; } catch ( final OutOfMemoryError e ) { TODO Writer is broken - ensure atomic replacement. throw e; } } void reopenReader(final String indexName) throws IOException { getHolder(indexName).reopenReader(); }} 
private synchronized LuceneHolder getHolder ( final String indexName ) throws IOException { LuceneHolder result = holders . get ( indexName ) ; if ( result = = null ) { result = new LuceneHolder ( FSDirectory . open ( new File ( baseDir , indexName ) ) , realtime ) ; holders . put ( indexName , result ) ; } return result ; } 
< T > T withWriter ( final String indexName , final WriterCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( indexName ) ; final IndexWriter writer = holder . getIndexWriter ( ) ; try { return callback . callback ( writer ) ; 
public static void main ( final String [ ] args ) throws Exception { final Properties properties = new Properties ( ) ; final InputStream in = Main . class . getClassLoader ( ) . getResourceAsStream ( " couchdb-lucene.properties " ) ; properties . load ( in ) ; in . close ( ) ; final String luceneDir = properties . getProperty ( " lucene.dir " ) ; final int lucenePort = Integer . parseInt ( properties . getProperty ( " lucene.port " , " 5985 " ) ) ; final String couchUrl = properties . getProperty ( " couchdb.url " ) ; if ( luceneDir = = null ) { LOG . error ( " lucene.dir not set. " ) ; System . exit ( 1 ) ; } if ( couchUrl = = null ) { LOG . error ( " couchdb.url not set. " ) ; System . exit ( 1 ) ; } Configure httpClient. final HttpParams params = new BasicHttpParams(); NECESSARY? ConnManagerParams.setMaxTotalConnections(params, 1000); HttpProtocolParams.setVersion(params, HttpVersion.HTTP_1_1); HttpProtocolParams.setUserAgent(params, HttpProtocolParams.getUserAgent(params) + " couchdb-lucene/0.5"); final SchemeRegistry schemeRegistry = new SchemeRegistry(); schemeRegistry.register(new Scheme("http", PlainSocketFactory.getSocketFactory(), 5984)); final ClientConnectionManager cm = new ThreadSafeClientConnManager(params, schemeRegistry); final HttpClient httpClient = new DefaultHttpClient(cm, params); final Database database = new Database(httpClient, couchUrl); final LuceneHolders holders = new LuceneHolders(new File(luceneDir), false); Configure Indexer. final Indexer indexer = new Indexer(database, holders); Configure Jetty. final Server server = new Server(Integer.getInteger("port", lucenePort)); server.setStopAtShutdown(true); server.setSendServerVersion(false); Register with server. server.addLifeCycle(indexer); final ContextHandlerCollection contexts = new ContextHandlerCollection(); server.setHandler(contexts); final Context search = new Context(contexts, "/search", Context.NO_SESSIONS); search.addFilter(new FilterHolder(new GzipFilter()), "/*", Handler.DEFAULT); search.addServlet(new ServletHolder(new SearchServlet(holders, database)), "/*"); final Context info = new Context(contexts, "/info", Context.NO_SESSIONS); info.addServlet(new ServletHolder(new InfoServlet(holders)), "/*"); final Context admin = new Context(contexts, "/admin", Context.NO_SESSIONS); admin.addServlet(new ServletHolder(new AdminServlet(holders)), "/*"); Lockdown System.setSecurityManager(securityManager); server.start(); server.join(); } 
public static void createSandbox ( ) throws Exception { System . setSecurityManager ( new SecurityManager ( ) ) ; Permissions perms = new Permissions ( ) ; perms . add ( new RuntimePermission ( " accessDeclaredMembers " ) ) ; final CodeSource codeSource = new CodeSource ( null , ( Certificate [ ] ) null ) ; final ProtectionDomain domain = new ProtectionDomain ( codeSource , perms ) ; controlContext = new AccessControlContext ( new ProtectionDomain [ ] { domain } ) ; } 
public void setup ( ) throws Exception { final ScriptEngineManager scriptEngineManager = new ScriptEngineManager ( ) ; scriptEngine = scriptEngineManager . getEngineByName ( " ECMAScript " ) ; invocable = ( Invocable ) scriptEngine ; compilable = ( Compilable ) scriptEngine ; } 
public void nullReturn ( ) throws Exception { final String fun = " function(doc) { return null; } " ; eval ( fun ) ; } 
public void singleDocReturn ( ) throws Exception { final String fun = " function(doc) { var ret = new Document(); ret.add('hello'); return ret; } " ; eval ( fun ) ; } 
public void multiDocReturn ( ) throws Exception { final String fun = " function(doc) { var ret = []; ret.push(new Document()); ret.push(new Document()); return ret; } " ; eval ( fun ) ; } 
public void sandboxEscape ( ) throws Exception { final String fun = " function(doc) {return java.io.File.createTempFile( \" tmp \" , null);} " ; final File result = ( File ) eval ( fun ) ; if ( result . exists ( ) ) { result . delete ( ) ; 
private Object eval ( final String fun ) throws Exception { final String fun2 = " importPackage(com.github.rnewson.couchdb.lucene.v2.eval); var obj = new Object(); obj.indexfun= " + fun ; scriptEngine . eval ( fun2 ) ; final Object obj = scriptEngine . get ( " obj " ) ; final Object result = AccessController . doPrivileged ( new PrivilegedExceptionAction < Object > ( ) { @Override public Object run ( ) throws Exception { return invocable . invokeMethod ( obj , " indexfun " , " hi " ) ; } } , controlContext ) ; System . out . println ( result ) ; return result ; } 
public Object run ( ) throws Exception { return invocable . invokeMethod ( obj , " indexfun " , " hi " ) ; } 
public void add ( final String string ) { delegate . add ( new Field ( " default " , string , Store . NO , Index . ANALYZED ) ) ; } 
public void add ( final String string , final Object settings ) { } @Override public String toString ( ) { return delegate . toString ( ) ; } } 
protected void doStart ( ) throws Exception { startTask ( " databaseScanner " , new DatabaseScanner ( ) ) ; } 
protected void doStop ( ) throws Exception { for ( final Thread thread : activeTasks . values ( ) ) { thread . interrupt ( ) ; 
private void startTask ( final String taskName , final Runnable runnable ) { Thread thread ; synchronized ( activeTasks ) { thread = activeTasks . get ( taskName ) ; Is task already running? if (thread != null && thread.isAlive()) return; thread = new Thread(runnable); thread.setDaemon(true); activeTasks.put(taskName, thread); } Start it. if (!thread.isAlive()) thread.start(); 
public void run ( ) { try { while ( Indexer . this . isRunning ( ) ) { 
public void run ( ) { final HttpClient client = new DefaultHttpClient ( ) ; int since = 0 ; final ResponseHandler < Integer > responseHandler = new ResponseHandler < Integer > ( ) { @Override public Integer handleResponse ( final HttpResponse response ) throws ClientProtocolException , IOException { int last_seq = 0 ; final HttpEntity entity = response . getEntity ( ) ; final BufferedReader reader = new BufferedReader ( new InputStreamReader ( entity . getContent ( ) , " UTF-8 " ) ) ; String line ; while ( ( line = reader . readLine ( ) ) ! = null ) { System . out . println ( line ) ; final JSONObject obj = JSONObject . fromObject ( line ) ; if ( obj . has ( " last_seq " ) ) { last_seq = obj . getInt ( " last_seq " ) ; break ; } final JSONObject doc = database.getDoc(db, obj.getString("id")); System.out.println(doc); } return last_seq; } }; try { while (Indexer.this.isRunning()) { 
public Integer handleResponse ( final HttpResponse response ) throws ClientProtocolException , IOException { int last_seq = 0 ; final HttpEntity entity = response . getEntity ( ) ; final BufferedReader reader = new BufferedReader ( new InputStreamReader ( entity . getContent ( ) , " UTF-8 " ) ) ; String line ; while ( ( line = reader . readLine ( ) ) ! = null ) { System . out . println ( line ) ; final JSONObject obj = JSONObject . fromObject ( line ) ; if ( obj . has ( " last_seq " ) ) { last_seq = obj . getInt ( " last_seq " ) ; break ; } final JSONObject doc = database.getDoc(db, obj.getString("id")); System.out.println(doc); } return last_seq; } 
protected void doStart ( ) throws Exception { timer = new Timer ( true ) ; timer . schedule ( new DatabaseSyncTask ( ) , 5000 , 5000 ) ; } 
private void updateDatabase ( final String databaseName ) throws IOException { final JSONObject designDocuments = database . getAllDocs ( databaseName , " _design " , " _design0 " ) ; final JSONArray arr = designDocuments . getJSONArray ( " rows " ) ; For each design document; for (int i = 0; i < arr.size(); i++) { final JSONObject designDocument = arr.getJSONObject(i).getJSONObject("doc"); 
private long getState ( final String databaseName ) throws IOException { TODO add view digest. try { final JSONObject local = database.getDoc(databaseName, "_local/lucene"); 
private void setState ( final String databaseName , final long newSeq ) throws IOException { final JSONObject obj = new JSONObject ( ) ; obj . put ( " seq " , newSeq ) ; try { database . saveDocument ( databaseName , " _local/lucene " , obj . toString ( ) ) ; 
public Long callback ( final IndexWriter writer ) throws IOException { final JSONObject info = database . getInfo ( databaseName ) ; final long endSequence = info . getLong ( " update_seq " ) ; if ( endSequence = = startSequence ) { We're up to date. return startSequence; } if (endSequence < startSequence) { System.out.println("REGRESSION!"); } long currentSequence = startSequence; while (currentSequence < endSequence) { final JSONObject allDocsBySeq = database.getAllDocsBySeq(databaseName, currentSequence, BATCH_SIZE); final JSONArray rows = allDocsBySeq.getJSONArray("rows"); for (int i = 0, max = rows.size(); i < max; i++) { final JSONObject row = rows.getJSONObject(i); final JSONObject value = row.optJSONObject("value"); final JSONObject doc = row.optJSONObject("doc"); final String docid = row.getString("id"); currentSequence = row.getLong("key"); Do not index design documents. if (docid.startsWith("_design/")) { continue; } System.out.println(value); final Term docTerm = new Term(Constants.ID, docid); if (value.optBoolean("deleted")) { writer.deleteDocuments(docTerm); } else { final Document ldoc = new Document(); ldoc.add(new Field(Constants.ID, docid, Store.YES, Index.ANALYZED)); writer.updateDocument(docTerm, ldoc); } } Commit batch. final Map<String, String> state = new HashMap<String, String>(); state.put("seq", Long.toString(currentSequence)); writer.commit(state); } return endSequence; } 
public static void main ( final String [ ] args ) throws Exception { final Properties properties = new Properties ( ) ; final InputStream in = Main . class . getClassLoader ( ) . getResourceAsStream ( " couchdb-lucene.properties " ) ; properties . load ( in ) ; in . close ( ) ; final String luceneDir = properties . getProperty ( " lucene.dir " ) ; final int lucenePort = Integer . parseInt ( properties . getProperty ( " lucene.port " , " 5985 " ) ) ; final String couchUrl = properties . getProperty ( " couchdb.url " ) ; if ( luceneDir = = null ) { LOG . error ( " lucene.dir not set. " ) ; System . exit ( 1 ) ; } if ( couchUrl = = null ) { LOG . error ( " couchdb.url not set. " ) ; System . exit ( 1 ) ; } Configure httpClient. final HttpParams params = new BasicHttpParams(); NECESSARY? ConnManagerParams.setMaxTotalConnections(params, 1000); HttpProtocolParams.setVersion(params, HttpVersion.HTTP_1_1); HttpProtocolParams.setUserAgent(params, HttpProtocolParams.getUserAgent(params) + " couchdb-lucene/0.5"); final SchemeRegistry schemeRegistry = new SchemeRegistry(); schemeRegistry.register(new Scheme("http", PlainSocketFactory.getSocketFactory(), 5984)); final ClientConnectionManager cm = new ThreadSafeClientConnManager(params, schemeRegistry); final HttpClient httpClient = new DefaultHttpClient(cm, params); final Database database = new Database(httpClient, couchUrl); final LuceneHolders holders = new LuceneHolders(new File(luceneDir), false); Configure Indexer. final Indexer indexer = new Indexer(database, holders); Configure Jetty. final Server server = new Server(Integer.getInteger("port", lucenePort)); server.setStopAtShutdown(true); server.setSendServerVersion(false); server.addLifeCycle(indexer); Configure Rhino. RhinoDocument.CLIENT = httpClient; final ContextHandlerCollection contexts = new ContextHandlerCollection(); server.setHandler(contexts); final Context search = new Context(contexts, "/search", Context.NO_SESSIONS); search.addFilter(new FilterHolder(new GzipFilter()), "/*", Handler.DEFAULT); search.addServlet(new ServletHolder(new SearchServlet(holders, database)), "/*"); final Context info = new Context(contexts, "/info", Context.NO_SESSIONS); info.addServlet(new ServletHolder(new InfoServlet(holders)), "/*"); final Context admin = new Context(contexts, "/admin", Context.NO_SESSIONS); admin.addServlet(new ServletHolder(new AdminServlet(holders)), "/*"); Lockdown System.setSecurityManager(securityManager); server.start(); server.join(); } 
public static void jsFunction_attachment ( final Context cx , final Scriptable thisObj , final Object [ ] args , final Function funObj ) throws IOException { final RhinoDocument doc = checkInstance ( thisObj ) ; if ( args . length < 2 ) { throw Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } final String dbname = ( String ) cx . getThreadLocal ( " dbname " ) ; final String docid = ( String ) cx . getThreadLocal ( " docid " ) ; final String field = args [ 0 ] . toString ( ) ; final String attname = args [ 1 ] . toString ( ) ; final String url = DB . url ( String . format ( " %s/%s/%s " , dbname , DB . encode ( docid ) , DB . encode ( attname ) ) ) ; final HttpGet get = new HttpGet ( url ) ; final ResponseHandler < Void > responseHandler = new ResponseHandler < Void > ( ) { @Override public Void handleResponse ( final HttpResponse response ) throws ClientProtocolException , IOException { final HttpEntity entity = response . getEntity ( ) ; final InputStream in = entity . getContent ( ) ; try { TIKA . parse ( in , entity . getContentType ( ) . getValue ( ) , field , doc . doc ) ; } finally { in . close ( ) ; } return null ; } } ; CLIENT . execute ( get , responseHandler ) ; } 
public Void handleResponse ( final HttpResponse response ) throws ClientProtocolException , IOException { final HttpEntity entity = response . getEntity ( ) ; final InputStream in = entity . getContent ( ) ; try { TIKA . parse ( in , entity . getContentType ( ) . getValue ( ) , field , doc . doc ) ; } finally { in . close ( ) ; } return null ; } 
public static String viewname ( final String databaseName , final String designDocumentName , final String viewName ) { return String . format ( " %s_%s_%s " , databaseName , designDocumentName , viewName ) ; } 
public static String viewname ( final JSONArray path ) { return viewname ( path . getString ( 0 ) , path . getString ( 2 ) , path . getString ( 3 ) ) ; } 
public static void main ( final String [ ] args ) throws Exception { HttpParams params = new BasicHttpParams ( ) ; params . setIntParameter ( CoreConnectionPNames . SOCKET_BUFFER_SIZE , 8 * 1024 ) . setBooleanParameter ( CoreConnectionPNames . STALE_CONNECTION_CHECK , false ) . setBooleanParameter ( CoreConnectionPNames . TCP_NODELAY , true ) . setParameter ( CoreProtocolPNames . USER_AGENT , " HttpComponents/1.1 " ) ; final ConnectingIOReactor ioReactor = new DefaultConnectingIOReactor ( 2 , params ) ; BasicHttpProcessor httpproc = new BasicHttpProcessor ( ) ; httpproc . addInterceptor ( new RequestContent ( ) ) ; httpproc . addInterceptor ( new RequestTargetHost ( ) ) ; httpproc . addInterceptor ( new RequestConnControl ( ) ) ; httpproc . addInterceptor ( new RequestUserAgent ( ) ) ; httpproc . addInterceptor ( new RequestExpectContinue ( ) ) ; final AsyncNHttpClientHandler handler = new AsyncNHttpClientHandler ( httpproc , new MyNHttpRequestExecutionHandler ( ) , new DefaultConnectionReuseStrategy ( ) , params ) ; final IOEventDispatch ioEventDispatch = new DefaultClientIOEventDispatch ( handler , params ) ; final Thread = new Thread ( new Runnable ( ) { public void run ( ) { try { ioReactor . execute ( ioEventDispatch ) ; } catch ( InterruptedIOException ex ) { System . err . println ( " Interrupted " ) ; } catch ( IOException e ) { System . err . println ( " I/O error: " + e . getMessage ( ) ) ; } System . out . println ( " Shutdown " ) ; } } ) ; . start ( ) ; for ( int i = 1 ; i < = 10 ; i + + ) { ioReactor . connect ( new InetSocketAddress ( " localhost " , 5984 ) , null , " /db " + i + " /_changes?feed=continuous " , null ) ; } MINUTES . sleep ( 5 ) ; System . out . println ( " Shutting down I/O reactor " ) ; ioReactor . shutdown ( ) ; System . out . println ( " Done " ) ; } 
public void run ( ) { try { ioReactor . execute ( ioEventDispatch ) ; } catch ( InterruptedIOException ex ) { System . err . println ( " Interrupted " ) ; } catch ( IOException e ) { System . err . println ( " I/O error: " + e . getMessage ( ) ) ; } System . out . println ( " Shutdown " ) ; } 
public void finalizeContext ( HttpContext context ) { context . removeAttribute ( DONE_FLAG ) ; } 
public void initalizeContext ( HttpContext context , Object attachment ) { Empty. context.setAttribute("path", attachment); } 
public HttpRequest submitRequest ( final HttpContext context ) { Submit HTTP GET once Object done = context.getAttribute(DONE_FLAG); if (done == null) { context.setAttribute(DONE_FLAG, Boolean.TRUE); 
public ConsumingNHttpEntity responseEntity ( HttpResponse response , HttpContext context ) throws IOException { return new ConsumingNHttpEntityTemplate ( response . getEntity ( ) , new ContinuousListener ( ) ) ; } 
public void contentAvailable ( final ContentDecoder decoder , final IOControl ioctrl ) throws IOException { this . buffer . consumeContent ( decoder ) ; if ( decoder . isCompleted ( ) ) { this . finished = true ; } final byte [ ] buf = new byte [ 2048 ] ; final int len = buffer . read ( buf ) ; System . out . println ( new String ( buf , 0 , len ) ) ; } 
private IndexWriter newWriter ( ) throws IOException { final IndexWriter result = new IndexWriter ( dir , Constants . ANALYZER , MaxFieldLength . UNLIMITED ) ; result . setMergeFactor ( 5 ) ; return result ; } 
public static File viewdir ( final File baseDir , final String databaseName , final String viewFunction ) { File result = new File ( baseDir , databaseName ) ; return new File ( result , md5 ( viewFunction . replaceAll ( " \\ s+ " , " " ) ) ) ; } 
private static String md5 ( final String str ) { try { final MessageDigest md = MessageDigest . getInstance ( " MD5 " ) ; 
public JSONObject getAllDocsBySeq ( final String dbname , final long startkey ) throws IOException { return JSONObject . fromObject ( get ( String . format ( " %s/_all_docs_by_seq?startkey=%s&include_docs=true " , Utils . urlEncode ( dbname ) , startkey ) ) ) ; 
public boolean createDatabase ( final String dbname ) throws IOException { return put ( Utils . urlEncode ( dbname ) , null ) = = 201 ; } 
public boolean deleteDatabase ( final String dbname ) throws IOException { return delete ( Utils . urlEncode ( dbname ) ) = = 201 ; } 
public boolean saveDocument ( final String dbname , final String id , final String body ) throws IOException { return put ( String . format ( " %s/%s " , Utils . urlEncode ( dbname ) , id ) , body ) = = 201 ; } 
public JSONObject getAllDocs ( final String dbname , final String startkey , final String endkey ) throws IOException { return JSONObject . fromObject ( get ( String . format ( " %s/_all_docs?startkey=%%22%s%%22&endkey=%%22%s%%22&include_docs=true " , Utils . urlEncode ( dbname ) , 
public JSONObject getAllDocsBySeq ( final String dbname , final long startkey , final int limit ) throws IOException { return JSONObject . fromObject ( get ( String . format ( " %s/_all_docs_by_seq?startkey=%d&limit=%d&include_docs=true " , Utils . urlEncode ( dbname ) , startkey , limit ) ) ) ; 
public JSONObject getDoc ( final String dbname , final String id ) throws IOException { return JSONObject . fromObject ( get ( String . format ( " %s/%s " , Utils . urlEncode ( dbname ) , id ) ) ) ; } 
public JSONObject getDocs ( final String dbname , final String . . . ids ) throws IOException { final JSONArray keys = new JSONArray ( ) ; for ( final String id : ids ) { keys . add ( id ) ; } final JSONObject req = new JSONObject ( ) ; req . element ( " keys " , keys ) ; return JSONObject . fromObject ( post ( String . format ( " %s/_all_docs?include_docs=true " , Utils . urlEncode ( dbname ) ) , req . toString ( ) ) ) ; 
public JSONObject getInfo ( final String dbname ) throws IOException { return JSONObject . fromObject ( get ( Utils . urlEncode ( dbname ) ) ) ; } 
public Long callback ( final IndexWriter writer ) throws IOException { final JSONObject info = database . getInfo ( databaseName ) ; final long endSequence = info . getLong ( " update_seq " ) ; if ( endSequence = = startSequence ) { We're up to date. return startSequence; } if (endSequence < startSequence) { System.out.println("REGRESSION!"); } long currentSequence = startSequence; while (currentSequence < endSequence) { final JSONObject allDocsBySeq = database.getAllDocsBySeq(databaseName, currentSequence, BATCH_SIZE); final JSONArray rows = allDocsBySeq.getJSONArray("rows"); for (int i = 0, max = rows.size(); i < max; i++) { final JSONObject row = rows.getJSONObject(i); final JSONObject value = row.optJSONObject("value"); final JSONObject doc = row.optJSONObject("doc"); final String docid = row.getString("id"); currentSequence = row.getLong("key"); Do not index design documents. if (docid.startsWith("_design/")) { continue; } System.out.println(value); final Term docTerm = new Term(Constants.ID, docid); if (value.optBoolean("deleted")) { writer.deleteDocuments(docTerm); } else { TODO optimize GC by reusing Document, Field, NumericField objects. final Document ldoc = new Document(); Add mandatory fields. ldoc.add(new Field(Constants.ID, docid, Store.YES, Index.ANALYZED)); ldoc.add(new NumericField(Constants.SEQ, Constants.SEQ_PRECISION).setLongValue(currentSequence)); writer.updateDocument(docTerm, ldoc); } } writer.commit(); } return endSequence; } 
synchronized IndexReader borrowReader ( final boolean staleOk ) throws IOException { if ( ! staleOk ) reopenReader ( ) ; reader . incRef ( ) ; return reader ; } 
synchronized IndexSearcher borrowSearcher ( final boolean staleOk ) throws IOException { final IndexReader reader = borrowReader ( staleOk ) ; return new IndexSearcher ( reader ) ; } 
void reopenReader ( ) throws IOException { final IndexReader oldReader = reader ; final IndexReader newReader = oldReader . reopen ( ) ; if ( reader ! = newReader ) { reader = newReader ; 
public T callback ( final IndexReader reader ) throws IOException ; } interface SearcherCallback < T > { public T callback ( final IndexSearcher searcher ) throws IOException ; } interface WriterCallback < T > { public T callback ( final IndexWriter writer ) throws IOException ; } private final Map < ViewSignature , LuceneHolder > holders = new LinkedHashMap < ViewSignature , LuceneHolder > ( ) ; private final File baseDir ; private final boolean realtime ; LuceneGateway ( final File baseDir , final boolean realtime ) { this . baseDir = baseDir ; this . realtime = realtime ; } private synchronized LuceneHolder getHolder ( final ViewSignature viewSignature ) throws IOException { LuceneHolder result = holders . get ( viewSignature ) ; if ( result = = null ) { final File dir = viewSignature . toFile ( baseDir ) ; if ( ! dir . exists ( ) & & ! dir . mkdirs ( ) ) throw new IOException ( " Could not make " + dir ) ; result = new LuceneHolder ( FSDirectory . open ( dir ) , realtime ) ; holders . put ( viewSignature , result ) ; } return result ; } < T > T withReader ( final ViewSignature viewSignature , final boolean staleOk , final ReaderCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexReader reader = holder . borrowReader ( staleOk ) ; try { return callback . callback ( reader ) ; } finally { holder . returnReader ( reader ) ; } } < T > T withSearcher ( final ViewSignature viewSignature , final boolean staleOk , final SearcherCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexSearcher searcher = holder . borrowSearcher ( staleOk ) ; try { return callback . callback ( searcher ) ; } finally { holder . returnSearcher ( searcher ) ; } } < T > T withWriter ( final ViewSignature viewSignature , final WriterCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexWriter writer = holder . getIndexWriter ( ) ; try { return callback . callback ( writer ) ; } catch ( final OutOfMemoryError e ) { TODO Writer is broken - ensure atomic replacement. throw e; } }} 
public T callback ( final IndexSearcher searcher ) throws IOException ; } interface WriterCallback < T > { public T callback ( final IndexWriter writer ) throws IOException ; } private final Map < ViewSignature , LuceneHolder > holders = new LinkedHashMap < ViewSignature , LuceneHolder > ( ) ; private final File baseDir ; private final boolean realtime ; LuceneGateway ( final File baseDir , final boolean realtime ) { this . baseDir = baseDir ; this . realtime = realtime ; } private synchronized LuceneHolder getHolder ( final ViewSignature viewSignature ) throws IOException { LuceneHolder result = holders . get ( viewSignature ) ; if ( result = = null ) { final File dir = viewSignature . toFile ( baseDir ) ; if ( ! dir . exists ( ) & & ! dir . mkdirs ( ) ) throw new IOException ( " Could not make " + dir ) ; result = new LuceneHolder ( FSDirectory . open ( dir ) , realtime ) ; holders . put ( viewSignature , result ) ; } return result ; } < T > T withReader ( final ViewSignature viewSignature , final boolean staleOk , final ReaderCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexReader reader = holder . borrowReader ( staleOk ) ; try { return callback . callback ( reader ) ; } finally { holder . returnReader ( reader ) ; } } < T > T withSearcher ( final ViewSignature viewSignature , final boolean staleOk , final SearcherCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexSearcher searcher = holder . borrowSearcher ( staleOk ) ; try { return callback . callback ( searcher ) ; } finally { holder . returnSearcher ( searcher ) ; } } < T > T withWriter ( final ViewSignature viewSignature , final WriterCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexWriter writer = holder . getIndexWriter ( ) ; try { return callback . callback ( writer ) ; } catch ( final OutOfMemoryError e ) { TODO Writer is broken - ensure atomic replacement. throw e; } }} 
public T callback ( final IndexWriter writer ) throws IOException ; } private final Map < ViewSignature , LuceneHolder > holders = new LinkedHashMap < ViewSignature , LuceneHolder > ( ) ; private final File baseDir ; private final boolean realtime ; LuceneGateway ( final File baseDir , final boolean realtime ) { this . baseDir = baseDir ; this . realtime = realtime ; } private synchronized LuceneHolder getHolder ( final ViewSignature viewSignature ) throws IOException { LuceneHolder result = holders . get ( viewSignature ) ; if ( result = = null ) { final File dir = viewSignature . toFile ( baseDir ) ; if ( ! dir . exists ( ) & & ! dir . mkdirs ( ) ) throw new IOException ( " Could not make " + dir ) ; result = new LuceneHolder ( FSDirectory . open ( dir ) , realtime ) ; holders . put ( viewSignature , result ) ; } return result ; } < T > T withReader ( final ViewSignature viewSignature , final boolean staleOk , final ReaderCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexReader reader = holder . borrowReader ( staleOk ) ; try { return callback . callback ( reader ) ; } finally { holder . returnReader ( reader ) ; } } < T > T withSearcher ( final ViewSignature viewSignature , final boolean staleOk , final SearcherCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexSearcher searcher = holder . borrowSearcher ( staleOk ) ; try { return callback . callback ( searcher ) ; } finally { holder . returnSearcher ( searcher ) ; } } < T > T withWriter ( final ViewSignature viewSignature , final WriterCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexWriter writer = holder . getIndexWriter ( ) ; try { return callback . callback ( writer ) ; } catch ( final OutOfMemoryError e ) { TODO Writer is broken - ensure atomic replacement. throw e; } }} 
private synchronized LuceneHolder getHolder ( final ViewSignature viewSignature ) throws IOException { LuceneHolder result = holders . get ( viewSignature ) ; if ( result = = null ) { final File dir = viewSignature . toFile ( baseDir ) ; if ( ! dir . exists ( ) & & ! dir . mkdirs ( ) ) throw new IOException ( " Could not make " + dir ) ; result = new LuceneHolder ( FSDirectory . open ( dir ) , realtime ) ; holders . put ( viewSignature , result ) ; } return result ; } 
< T > T withReader ( final ViewSignature viewSignature , final boolean staleOk , final ReaderCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexReader reader = holder . borrowReader ( staleOk ) ; try { return callback . callback ( reader ) ; 
< T > T withSearcher ( final ViewSignature viewSignature , final boolean staleOk , final SearcherCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexSearcher searcher = holder . borrowSearcher ( staleOk ) ; try { return callback . callback ( searcher ) ; 
< T > T withWriter ( final ViewSignature viewSignature , final WriterCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexWriter writer = holder . getIndexWriter ( ) ; try { return callback . callback ( writer ) ; 
public static void main ( final String [ ] args ) throws Exception { final Properties properties = new Properties ( ) ; final InputStream in = Main . class . getClassLoader ( ) . getResourceAsStream ( " couchdb-lucene.properties " ) ; properties . load ( in ) ; in . close ( ) ; final String luceneDir = properties . getProperty ( " lucene.dir " ) ; final int lucenePort = Integer . parseInt ( properties . getProperty ( " lucene.port " , " 5985 " ) ) ; final String couchUrl = properties . getProperty ( " couchdb.url " ) ; if ( luceneDir = = null ) { LOG . error ( " lucene.dir not set. " ) ; System . exit ( 1 ) ; } if ( couchUrl = = null ) { LOG . error ( " couchdb.url not set. " ) ; System . exit ( 1 ) ; } Configure httpClient. final HttpParams params = new BasicHttpParams(); NECESSARY? ConnManagerParams.setMaxTotalConnections(params, 1000); HttpProtocolParams.setVersion(params, HttpVersion.HTTP_1_1); HttpProtocolParams.setUserAgent(params, HttpProtocolParams.getUserAgent(params) + " couchdb-lucene/0.5"); final SchemeRegistry schemeRegistry = new SchemeRegistry(); schemeRegistry.register(new Scheme("http", PlainSocketFactory.getSocketFactory(), 5984)); final ClientConnectionManager cm = new ThreadSafeClientConnManager(params, schemeRegistry); final HttpClient httpClient = new DefaultHttpClient(cm, params); final Database database = new Database(httpClient, couchUrl); final LuceneGateway holders = new LuceneGateway(new File(luceneDir), false); Configure Indexer. final Indexer indexer = new Indexer(database, holders); Configure Jetty. final Server server = new Server(Integer.getInteger("port", lucenePort)); server.setStopAtShutdown(true); server.setSendServerVersion(false); server.addLifeCycle(indexer); Configure Rhino. RhinoDocument.CLIENT = httpClient; final ContextHandlerCollection contexts = new ContextHandlerCollection(); server.setHandler(contexts); final Context search = new Context(contexts, "/search", Context.NO_SESSIONS); search.addFilter(new FilterHolder(new GzipFilter()), "/*", Handler.DEFAULT); search.addServlet(new ServletHolder(new SearchServlet(holders, database)), "/*"); final Context info = new Context(contexts, "/info", Context.NO_SESSIONS); info.addServlet(new ServletHolder(new InfoServlet(holders)), "/*"); final Context admin = new Context(contexts, "/admin", Context.NO_SESSIONS); admin.addServlet(new ServletHolder(new AdminServlet(holders)), "/*"); Lockdown System.setSecurityManager(securityManager); server.start(); server.join(); } 
public static void jsFunction_attachment ( final Context cx , final Scriptable thisObj , final Object [ ] args , final Function funObj ) throws IOException { final RhinoDocument doc = checkInstance ( thisObj ) ; if ( args . length < 2 ) { throw Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } final String dbname = ( String ) cx . getThreadLocal ( " dbname " ) ; final String docid = ( String ) cx . getThreadLocal ( " docid " ) ; final String field = args [ 0 ] . toString ( ) ; final String attname = args [ 1 ] . toString ( ) ; final String url = DB . url ( String . format ( " %s/%s/%s " , dbname , Utils . urlEncode ( docid ) , Utils . urlEncode ( attname ) ) ) ; final HttpGet get = new HttpGet ( url ) ; final ResponseHandler < Void > responseHandler = new ResponseHandler < Void > ( ) { @Override public Void handleResponse ( final HttpResponse response ) throws ClientProtocolException , IOException { final HttpEntity entity = response . getEntity ( ) ; final InputStream in = entity . getContent ( ) ; try { TIKA . parse ( in , entity . getContentType ( ) . getValue ( ) , field , doc . doc ) ; } finally { in . close ( ) ; } return null ; } } ; CLIENT . execute ( get , responseHandler ) ; } 
public static String urlEncode ( final String path ) { try { return URLEncoder . encode ( path , " UTF-8 " ) ; 
public static String md5 ( final String str ) { try { final MessageDigest md = MessageDigest . getInstance ( " MD5 " ) ; 
public File toFile ( final File base ) { return new File ( new File ( base , dbname ) , this + " .index " ) ; } 
public String toString ( ) { return new BigInteger ( 1 , bytes ) . toString ( 16 ) ; } 
public int hashCode ( ) { final int prime = 31 ; int result = 1 ; result = prime * result + Arrays . hashCode ( bytes ) ; return result ; } 
public boolean equals ( Object obj ) { if ( this = = obj ) return true ; if ( obj = = null ) return false ; if ( getClass ( ) ! = obj . getClass ( ) ) return false ; ViewSignature other = ( ViewSignature ) obj ; if ( ! Arrays . equals ( bytes , other . bytes ) ) return false ; return true ; } 
public void sameOrder ( ) throws Exception { final JSONArray hits25 = JSONObject . fromObject ( FileUtils . readFileToString ( new File ( " /tmp/25hits " ) ) ) . getJSONArray ( " rows " ) ; final JSONArray hits50 = JSONObject . fromObject ( FileUtils . readFileToString ( new File ( " /tmp/50hits " ) ) ) . getJSONArray ( " rows " ) ; for ( int i = 0 ; i < 25 ; i + + ) { final String left = hits25 . getJSONObject ( i ) . getString ( " id " ) ; 
private void close ( ) throws IOException { treader . decRef ( ) ; twriter . rollback ( ) ; } 
private IndexReader newReader ( ) throws IOException { treturn realtime ? getIndexWriter ( ) . getReader ( ) : IndexReader . open ( dir , true ) ; } 
private IndexWriter newWriter ( ) throws IOException { final IndexWriter result = new IndexWriter ( dir , Constants . ANALYZER , MaxFieldLength . UNLIMITED ) ; result . setMergeFactor ( 5 ) ; result . setMergedSegmentWarmer ( newWarmer ( ) ) ; return result ; } 
private IndexReaderWarmer newWarmer ( ) { treturn new IndexReaderWarmer ( ) { 
public void warm ( final IndexReader reader ) throws IOException { FieldCache.DEFAULT.getLongs(reader, Constants.SEQ); 
void reopenReader ( ) throws IOException { if ( realtime ) treturn ; final IndexReader newReader = reader . reopen ( ) ; if ( reader ! = newReader ) { final IndexReader oldReader = reader ; 
public T callback ( final IndexReader reader ) throws IOException ; } interface SearcherCallback < T > { public T callback ( final IndexSearcher searcher ) throws IOException ; } interface WriterCallback < T > { public T callback ( final IndexWriter writer ) throws IOException ; } private final Map < ViewSignature , LuceneHolder > holders = new LinkedHashMap < ViewSignature , LuceneHolder > ( ) ; private final File baseDir ; private final boolean realtime ; LuceneGateway ( final File baseDir , final boolean realtime ) { this . baseDir = baseDir ; this . realtime = realtime ; } private synchronized LuceneHolder getHolder ( final ViewSignature viewSignature ) throws IOException { LuceneHolder result = holders . get ( viewSignature ) ; if ( result = = null ) { final File dir = viewSignature . toFile ( baseDir ) ; if ( ! dir . exists ( ) & & ! dir . mkdirs ( ) ) throw new IOException ( " Could not make " + dir ) ; result = new LuceneHolder ( FSDirectory . open ( dir ) , realtime ) ; holders . put ( viewSignature , result ) ; } return result ; } < T > T withReader ( final ViewSignature viewSignature , final boolean staleOk , final ReaderCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexReader reader = holder . borrowReader ( staleOk ) ; try { return callback . callback ( reader ) ; } finally { holder . returnReader ( reader ) ; } } < T > T withSearcher ( final ViewSignature viewSignature , final boolean staleOk , final SearcherCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexSearcher searcher = holder . borrowSearcher ( staleOk ) ; try { return callback . callback ( searcher ) ; } finally { holder . returnSearcher ( searcher ) ; } } < T > T withWriter ( final ViewSignature viewSignature , final WriterCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexWriter writer = holder . getIndexWriter ( ) ; try { return callback . callback ( writer ) ; } catch ( final OutOfMemoryError e ) { } } 
public T callback ( final IndexSearcher searcher ) throws IOException ; } interface WriterCallback < T > { public T callback ( final IndexWriter writer ) throws IOException ; } private final Map < ViewSignature , LuceneHolder > holders = new LinkedHashMap < ViewSignature , LuceneHolder > ( ) ; private final File baseDir ; private final boolean realtime ; LuceneGateway ( final File baseDir , final boolean realtime ) { this . baseDir = baseDir ; this . realtime = realtime ; } private synchronized LuceneHolder getHolder ( final ViewSignature viewSignature ) throws IOException { LuceneHolder result = holders . get ( viewSignature ) ; if ( result = = null ) { final File dir = viewSignature . toFile ( baseDir ) ; if ( ! dir . exists ( ) & & ! dir . mkdirs ( ) ) throw new IOException ( " Could not make " + dir ) ; result = new LuceneHolder ( FSDirectory . open ( dir ) , realtime ) ; holders . put ( viewSignature , result ) ; } return result ; } < T > T withReader ( final ViewSignature viewSignature , final boolean staleOk , final ReaderCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexReader reader = holder . borrowReader ( staleOk ) ; try { return callback . callback ( reader ) ; } finally { holder . returnReader ( reader ) ; } } < T > T withSearcher ( final ViewSignature viewSignature , final boolean staleOk , final SearcherCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexSearcher searcher = holder . borrowSearcher ( staleOk ) ; try { return callback . callback ( searcher ) ; } finally { holder . returnSearcher ( searcher ) ; } } < T > T withWriter ( final ViewSignature viewSignature , final WriterCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexWriter writer = holder . getIndexWriter ( ) ; try { return callback . callback ( writer ) ; } catch ( final OutOfMemoryError e ) { } } 
public T callback ( final IndexWriter writer ) throws IOException ; } private final Map < ViewSignature , LuceneHolder > holders = new LinkedHashMap < ViewSignature , LuceneHolder > ( ) ; private final File baseDir ; private final boolean realtime ; LuceneGateway ( final File baseDir , final boolean realtime ) { this . baseDir = baseDir ; this . realtime = realtime ; } private synchronized LuceneHolder getHolder ( final ViewSignature viewSignature ) throws IOException { LuceneHolder result = holders . get ( viewSignature ) ; if ( result = = null ) { final File dir = viewSignature . toFile ( baseDir ) ; if ( ! dir . exists ( ) & & ! dir . mkdirs ( ) ) throw new IOException ( " Could not make " + dir ) ; result = new LuceneHolder ( FSDirectory . open ( dir ) , realtime ) ; holders . put ( viewSignature , result ) ; } return result ; } < T > T withReader ( final ViewSignature viewSignature , final boolean staleOk , final ReaderCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexReader reader = holder . borrowReader ( staleOk ) ; try { return callback . callback ( reader ) ; } finally { holder . returnReader ( reader ) ; } } < T > T withSearcher ( final ViewSignature viewSignature , final boolean staleOk , final SearcherCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexSearcher searcher = holder . borrowSearcher ( staleOk ) ; try { return callback . callback ( searcher ) ; } finally { holder . returnSearcher ( searcher ) ; } } < T > T withWriter ( final ViewSignature viewSignature , final WriterCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexWriter writer = holder . getIndexWriter ( ) ; try { return callback . callback ( writer ) ; } catch ( final OutOfMemoryError e ) { } } 
void deleteIndex ( final ViewSignature viewSignature ) throws IOException { } void createIndex ( final ViewSignature viewSignature ) throws IOException { } } 
void createIndex ( final ViewSignature viewSignature ) throws IOException { } } 
public static void main ( final String [ ] args ) throws Exception { final Properties properties = new Properties ( ) ; final InputStream in = Main . class . getClassLoader ( ) . getResourceAsStream ( " couchdb-lucene.properties " ) ; properties . load ( in ) ; in . close ( ) ; final String luceneDir = properties . getProperty ( " lucene.dir " ) ; final int lucenePort = Integer . parseInt ( properties . getProperty ( " lucene.port " , " 5985 " ) ) ; final String couchUrl = properties . getProperty ( " couchdb.url " ) ; final boolean realtime = Boolean . parseBoolean ( properties . getProperty ( " lucene.realtime " , " false " ) ) ; if ( luceneDir = = null ) { LOG . error ( " lucene.dir not set. " ) ; System . exit ( 1 ) ; } if ( couchUrl = = null ) { LOG . error ( " couchdb.url not set. " ) ; System . exit ( 1 ) ; } Configure httpClient. final HttpParams params = new BasicHttpParams(); ConnManagerParams.setMaxTotalConnections(params, 1000); HttpProtocolParams.setVersion(params, HttpVersion.HTTP_1_1); HttpProtocolParams.setUserAgent(params, HttpProtocolParams.getUserAgent(params) + " couchdb-lucene/0.5"); final SchemeRegistry schemeRegistry = new SchemeRegistry(); schemeRegistry.register(new Scheme("http", PlainSocketFactory.getSocketFactory(), 5984)); final ClientConnectionManager cm = new ThreadSafeClientConnManager(params, schemeRegistry); final HttpClient httpClient = new DefaultHttpClient(cm, params); final Database database = new Database(httpClient, couchUrl); final LuceneGateway holders = new LuceneGateway(new File(luceneDir), realtime); Configure Indexer. final Indexer indexer = new Indexer(database, holders); Configure Jetty. final Server server = new Server(Integer.getInteger("port", lucenePort)); server.setStopAtShutdown(true); server.setSendServerVersion(false); server.addLifeCycle(indexer); Configure Rhino. RhinoDocument.CLIENT = httpClient; final ContextHandlerCollection contexts = new ContextHandlerCollection(); server.setHandler(contexts); final Context search = new Context(contexts, "/search", Context.NO_SESSIONS); search.addFilter(new FilterHolder(new GzipFilter()), "/*", Handler.DEFAULT); search.addServlet(new ServletHolder(new SearchServlet(holders, database)), "/*"); final Context info = new Context(contexts, "/info", Context.NO_SESSIONS); info.addServlet(new ServletHolder(new InfoServlet(holders)), "/*"); final Context admin = new Context(contexts, "/admin", Context.NO_SESSIONS); admin.addServlet(new ServletHolder(new AdminServlet(holders)), "/*"); Lockdown System.setSecurityManager(securityManager); server.start(); server.join(); } 
public static void jsFunction_add ( final Context cx , final Scriptable thisObj , final Object [ ] args , final Function funObj ) { final RhinoDocument doc = checkInstance ( thisObj ) ; if ( args . length < 1 | | args . length > 2 ) { throw Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } if ( args [ 0 ] = = null ) { throw Context . reportRuntimeError ( " first argument must be non-null. " ) ; } if ( args . length = = 2 & & ( args [ 1 ] = = null | | args [ 1 ] instanceof NativeObject = = false ) ) { throw Context . reportRuntimeError ( " second argument must be an object. " ) ; } final JSONObject defaults = JSONObject . fromObject ( ( String ) cx . getThreadLocal ( " defaults " ) ) ; String field = defaults . optString ( " field " , Constants . DEFAULT_FIELD ) ; String store = defaults . optString ( " store " , " no " ) ; String index = defaults . optString ( " index " , " analyzed " ) ; String type = defaults . optString ( " type " , " string " ) ; Check for local override. if (args.length == 2) { final NativeObject obj = (NativeObject) args[1]; field = optString(obj, "field", field); store = optString(obj, "store", store); index = optString(obj, "index", index); type = optString(obj, "type", type); } final Field.Store storeObj = Store.get(store); Fieldable fieldObj = null; if ("int".equals(type)) { fieldObj = new NumericField(field, storeObj, true).setIntValue(Conversion.convert(args[0], Integer.class)); } else if ("float".equals(type)) { fieldObj = new NumericField(field, storeObj, true).setFloatValue(Conversion.convert(args[0], Float.class)); } else if ("double".equals(type)) { fieldObj = new NumericField(field, storeObj, true) .setDoubleValue(Conversion.convert(args[0], Double.class)); } else if ("long".equals(type)) { fieldObj = new NumericField(field, storeObj, true).setLongValue(Conversion.convert(args[0], Long.class)); } else if ("date".equals(type)) { fieldObj = new NumericField(field, storeObj, true).setLongValue(Conversion.convert(args[0], Date.class) .getTime()); } else if ("string".equals(type)) { fieldObj = new Field(field, Conversion.convert(args[0]).toString(), storeObj, Index.get(index)); } else { Ignore. } if (fieldObj != null) doc.add(fieldObj); 
public int hashCode ( ) { tfinal int prime = 31 ; tint result = 1 ; tresult = prime * result + ( ( dbname = = null ) ? 0 : dbname . hashCode ( ) ) ; tresult = prime * result + ( ( view = = null ) ? 0 : view . hashCode ( ) ) ; treturn result ; } 
public boolean equals ( Object obj ) { if ( this = = obj ) treturn true ; if ( obj = = null ) treturn false ; if ( getClass ( ) ! = obj . getClass ( ) ) treturn false ; tViewSignature other = ( ViewSignature ) obj ; if ( dbname = = null ) { if ( other . dbname ! = null ) treturn false ; } else if ( ! dbname . equals ( other . dbname ) ) treturn false ; if ( view = = null ) { if ( other . view ! = null ) treturn false ; } else if ( ! view . equals ( other . view ) ) treturn false ; treturn true ; } 
public JSONObject getAllDocsBySeq ( final String dbname , final long startkey ) throws IOException { return JSONObject . fromObject ( get ( String . format ( " %s/_all_docs_by_seq?startkey=%s&include_docs=true " , encode ( dbname ) , startkey ) ) ) ; 
public JSONObject getAllDocs ( final String dbname , final String startkey , final String endkey ) throws IOException { return JSONObject . fromObject ( get ( String . format ( " %s/_all_docs?startkey=%%22%s%%22&endkey=%%22%s%%22&include_docs=true " , encode ( dbname ) , encode ( startkey ) , encode ( endkey ) ) ) ) ; 
public JSONObject getDocs ( final String dbname , final String . . . ids ) throws IOException { final JSONArray keys = new JSONArray ( ) ; for ( final String id : ids ) { keys . add ( id ) ; } final JSONObject req = new JSONObject ( ) ; req . element ( " keys " , keys ) ; return JSONObject . fromObject ( post ( String . format ( " %s/_all_docs?include_docs=true " , encode ( dbname ) ) , req . toString ( ) ) ) ; } 
private void deleteView ( final String viewname , final Progress progress , final IndexWriter writer ) throws IOException { writer . deleteDocuments ( new Term ( Constants . VIEW , viewname ) ) ; progress . removeView ( viewname ) ; } 
private void deleteDatabase ( final String dbname , final Progress progress , final IndexWriter writer ) throws IOException { writer . deleteDocuments ( new Term ( Constants . DB , dbname ) ) ; progress . removeDatabase ( dbname ) ; } 
public static void main ( final String [ ] args ) throws Exception { } } 
public static void jsFunction_add ( final Context cx , final Scriptable thisObj , final Object [ ] args , final Function funObj ) { final RhinoDocument doc = checkInstance ( thisObj ) ; if ( args . length < 1 | | args . length > 2 ) { throw Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } if ( args [ 0 ] = = null ) { throw Context . reportRuntimeError ( " first argument must be non-null. " ) ; } if ( args . length = = 2 & & ( args [ 1 ] = = null | | args [ 1 ] instanceof NativeObject = = false ) ) { throw Context . reportRuntimeError ( " second argument must be an object. " ) ; } final JSONObject defaults = JSONObject . fromObject ( ( String ) cx . getThreadLocal ( " defaults " ) ) ; String language = defaults . optString ( " language " , " en " ) ; String field = defaults . optString ( " field " , Constants . DEFAULT_FIELD ) ; String store = defaults . optString ( " store " , " no " ) ; String index = defaults . optString ( " index " , " analyzed " ) ; String type = defaults . optString ( " type " , " string " ) ; Check for local override. if (args.length == 2) { final NativeObject obj = (NativeObject) args[1]; language = optString(obj, "language", language); field = optString(obj, "field", field); store = optString(obj, "store", store); index = optString(obj, "index", index); type = optString(obj, "type", type); } final Field.Store storeObj = Store.get(store); Fieldable fieldObj = null; if ("int".equals(type)) { fieldObj = new NumericField(field, storeObj, true).setIntValue(Conversion.convert(args[0], Integer.class)); } else if ("float".equals(type)) { fieldObj = new NumericField(field, storeObj, true).setFloatValue(Conversion.convert(args[0], Float.class)); } else if ("double".equals(type)) { fieldObj = new NumericField(field, storeObj, true).setDoubleValue(Conversion.convert(args[0], Double.class)); } else if ("long".equals(type)) { fieldObj = new NumericField(field, storeObj, true).setLongValue(Conversion.convert(args[0], Long.class)); } else if ("date".equals(type)) { fieldObj = new NumericField(field, storeObj, true).setLongValue(Conversion.convert(args[0], Date.class).getTime()); } else if ("string".equals(type)) { fieldObj = new Field(field, Conversion.convert(args[0]).toString(), storeObj, Index.get(index)); } else { Ignore. } if (fieldObj != null) doc.add(fieldObj); 
public static void jsFunction_attachment ( final Context cx , final Scriptable thisObj , final Object [ ] args , final Function funObj ) throws IOException { final RhinoDocument doc = checkInstance ( thisObj ) ; if ( args . length < 2 ) { throw Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } final String dbname = ( String ) cx . getThreadLocal ( " dbname " ) ; final String docid = ( String ) cx . getThreadLocal ( " docid " ) ; final String field = args [ 0 ] . toString ( ) ; final String attname = args [ 1 ] . toString ( ) ; final String url = DB . url ( String . format ( " %s/%s/%s " , dbname , DB . encode ( docid ) , DB . encode ( attname ) ) ) ; final GetMethod get = new GetMethod ( url ) ; try { final int sc = Database . CLIENT . executeMethod ( get ) ; 
public JSONObject getAllDocs ( final String dbname , final String startkey , final String endkey ) throws IOException { return JSONObject . fromObject ( get ( String . format ( " %s/_all_docs?startkey=%%22%s%%22&endkey=%%22%s%%22&include_docs=true " , Utils . urlEncode ( dbname ) , Utils . urlEncode ( startkey ) , Utils . urlEncode ( endkey ) ) ) ) ; 
public JSONArray getAllDesignDocuments ( final String dbname ) throws IOException { return getAllDocs ( dbname , " _design " , " _design0 " ) . getJSONArray ( " rows " ) ; } 
public JSONObject getChanges ( final String dbname , final long since , final boolean includeDocs ) throws IOException { return JSONObject . fromObject ( get ( String . format ( " %s/_changes?since=%d&include_docs=%b " , Utils . urlEncode ( dbname ) , since , includeDocs ) ) ) ; 
public JSONObject getChanges ( final String dbname , final long since , final boolean includeDocs , final int limit ) throws IOException { return JSONObject . fromObject ( get ( String . format ( " %s/_changes?since=%d&include_docs=%b&limit=%d " , Utils . urlEncode ( dbname ) , since , includeDocs , limit ) ) ) ; 
public JSONObject getDocs ( final String dbname , final String . . . ids ) throws IOException { final JSONArray keys = new JSONArray ( ) ; for ( final String id : ids ) { keys . add ( id ) ; } final JSONObject req = new JSONObject ( ) ; req . element ( " keys " , keys ) ; return JSONObject . fromObject ( post ( String . format ( " %s/_all_docs?include_docs=true " , Utils . urlEncode ( dbname ) ) , req . toString ( ) ) ) ; 
public Long callback ( final IndexWriter writer ) throws IOException { final JSONObject info = database . getInfo ( databaseName ) ; final long endSequence = info . getLong ( " update_seq " ) ; if ( endSequence = = startSequence ) { We're up to date. return startSequence; } if (endSequence < startSequence) { System.out.println("REGRESSION!"); } long currentSequence = startSequence; while (currentSequence < endSequence) { final JSONObject allDocsBySeq = database.getAllDocsBySeq(databaseName, currentSequence, BATCH_SIZE); final JSONArray rows = allDocsBySeq.getJSONArray("rows"); for (int i = 0, max = rows.size(); i < max; i++) { final JSONObject row = rows.getJSONObject(i); final JSONObject value = row.optJSONObject("value"); final JSONObject doc = row.optJSONObject("doc"); final String docid = row.getString("id"); currentSequence = row.getLong("key"); Do not index design documents. if (docid.startsWith("_design/")) { continue; } System.out.println(value); final Term docTerm = new Term(Constants.ID, docid); if (value.optBoolean("deleted")) { writer.deleteDocuments(docTerm); } else { TODO optimize GC by reusing Document, Field, NumericField objects. final Document ldoc = new Document(); Add mandatory fields. ldoc.add(new Field(Constants.ID, docid, Store.YES, Index.ANALYZED)); ldoc.add(new NumericField(Constants.SEQ, Constants.SEQ_PRECISION).setLongValue(currentSequence)); writer.updateDocument(docTerm, ldoc); } } writer.commit(); } return endSequence; } 
protected void doStart ( ) throws Exception { bootstrap ( ) ; startThread ( ) ; } 
protected void doStop ( ) throws Exception { stopIndexer ( ) ; closeIndexes ( ) ; } 
private void closeIndexes ( ) throws IOException { state . gateway . close ( ) ; } 
private void stopIndexer ( ) throws InterruptedException { indexerThread . interrupt ( ) ; indexerThread . wait ( 5000 ) ; } 
public void run ( ) { while ( isRunning ( ) ) { updateIndex ( ) ; 
public ViewSignature lookup ( final HttpServletRequest req ) { final String [ ] path = req . getPathInfo ( ) . split ( " / " ) ; if ( path . length ! = 3 ) { return null ; } return lookup ( path ) ; } 
public ViewSignature lookup ( final String databaseName , final String designDocumentName , final String viewName ) { synchronized ( map ) { return map . get ( path ( databaseName , designDocumentName , viewName ) ) ; 
public void update ( final String databaseName , final String designDocumentName , final String viewName , final String viewFunction ) { final ViewSignature viewSignature = new ViewSignature ( databaseName , viewFunction ) ; synchronized ( map ) { map . put ( path ( databaseName , designDocumentName , viewName ) , viewSignature ) ; 
private ViewSignature lookup ( final String [ ] pathComponents ) { if ( pathComponents . length ! = 3 ) { throw new IllegalArgumentException ( " bad path. " ) ; } return lookup ( pathComponents [ 0 ] , pathComponents [ 1 ] , pathComponents [ 2 ] ) ; } 
private String path ( final String databaseName , final String designDocumentName , final String viewName ) { return String . format ( " %s/%s/%s " , databaseName , designDocumentName , viewName ) ; } 
private void close ( ) throws IOException { reader . decRef ( ) ; writer . rollback ( ) ; } 
private IndexReader newReader ( ) throws IOException { return realtime ? getIndexWriter ( ) . getReader ( ) : IndexReader . open ( dir , true ) ; } 
private IndexReaderWarmer newWarmer ( ) { return new IndexReaderWarmer ( ) { 
public void warm ( final IndexReader reader ) throws IOException { Prewarm sequence (is this "insane"?) FieldCache.DEFAULT.getLongs(reader, Constants.SEQ); 
void reopenReader ( ) throws IOException { final IndexReader newReader = reader . reopen ( ) ; if ( reader ! = newReader ) { final IndexReader oldReader = reader ; 
public T callback ( final IndexReader reader ) throws IOException ; } interface SearcherCallback < T > { public T callback ( final IndexSearcher searcher ) throws IOException ; } interface WriterCallback < T > { public T callback ( final IndexWriter writer ) throws IOException ; } private final Map < ViewSignature , LuceneHolder > holders = new LinkedHashMap < ViewSignature , LuceneHolder > ( ) ; private final File baseDir ; private final boolean realtime ; LuceneGateway ( final File baseDir , final boolean realtime ) { this . baseDir = baseDir ; this . realtime = realtime ; } private synchronized LuceneHolder getHolder ( final ViewSignature viewSignature ) throws IOException { LuceneHolder result = holders . get ( viewSignature ) ; if ( result = = null ) { final File dir = viewSignature . toFile ( baseDir ) ; if ( ! dir . exists ( ) & & ! dir . mkdirs ( ) ) throw new IOException ( " Could not make " + dir ) ; result = new LuceneHolder ( FSDirectory . open ( dir ) , realtime ) ; holders . put ( viewSignature , result ) ; } return result ; } < T > T withReader ( final ViewSignature viewSignature , final boolean staleOk , final ReaderCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexReader reader = holder . borrowReader ( staleOk ) ; try { return callback . callback ( reader ) ; } finally { holder . returnReader ( reader ) ; } } < T > T withSearcher ( final ViewSignature viewSignature , final boolean staleOk , final SearcherCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexSearcher searcher = holder . borrowSearcher ( staleOk ) ; try { return callback . callback ( searcher ) ; } finally { holder . returnSearcher ( searcher ) ; } } < T > T withWriter ( final ViewSignature viewSignature , final WriterCallback < T > callback ) throws IOException { LuceneHolder holder = getHolder ( viewSignature ) ; final IndexWriter writer = holder . getIndexWriter ( ) ; try { return callback . callback ( writer ) ; } catch ( final OutOfMemoryError e ) { synchronized ( holders ) { holder = holders . remove ( viewSignature ) ; holder . close ( ) ; } throw e ; } } void deleteIndex ( final ViewSignature viewSignature ) throws IOException { } void createIndex ( final ViewSignature viewSignature ) throws IOException { } synchronized void close ( ) throws IOException { final Iterator < LuceneHolder > it = holders . values ( ) . iterator ( ) ; while ( it . hasNext ( ) ) { it . next ( ) . close ( ) ; it . remove ( ) ; } } } 
public T callback ( final IndexSearcher searcher ) throws IOException ; } interface WriterCallback < T > { public T callback ( final IndexWriter writer ) throws IOException ; } private final Map < ViewSignature , LuceneHolder > holders = new LinkedHashMap < ViewSignature , LuceneHolder > ( ) ; private final File baseDir ; private final boolean realtime ; LuceneGateway ( final File baseDir , final boolean realtime ) { this . baseDir = baseDir ; this . realtime = realtime ; } private synchronized LuceneHolder getHolder ( final ViewSignature viewSignature ) throws IOException { LuceneHolder result = holders . get ( viewSignature ) ; if ( result = = null ) { final File dir = viewSignature . toFile ( baseDir ) ; if ( ! dir . exists ( ) & & ! dir . mkdirs ( ) ) throw new IOException ( " Could not make " + dir ) ; result = new LuceneHolder ( FSDirectory . open ( dir ) , realtime ) ; holders . put ( viewSignature , result ) ; } return result ; } < T > T withReader ( final ViewSignature viewSignature , final boolean staleOk , final ReaderCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexReader reader = holder . borrowReader ( staleOk ) ; try { return callback . callback ( reader ) ; } finally { holder . returnReader ( reader ) ; } } < T > T withSearcher ( final ViewSignature viewSignature , final boolean staleOk , final SearcherCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexSearcher searcher = holder . borrowSearcher ( staleOk ) ; try { return callback . callback ( searcher ) ; } finally { holder . returnSearcher ( searcher ) ; } } < T > T withWriter ( final ViewSignature viewSignature , final WriterCallback < T > callback ) throws IOException { LuceneHolder holder = getHolder ( viewSignature ) ; final IndexWriter writer = holder . getIndexWriter ( ) ; try { return callback . callback ( writer ) ; } catch ( final OutOfMemoryError e ) { synchronized ( holders ) { holder = holders . remove ( viewSignature ) ; holder . close ( ) ; } throw e ; } } void deleteIndex ( final ViewSignature viewSignature ) throws IOException { } void createIndex ( final ViewSignature viewSignature ) throws IOException { } synchronized void close ( ) throws IOException { final Iterator < LuceneHolder > it = holders . values ( ) . iterator ( ) ; while ( it . hasNext ( ) ) { it . next ( ) . close ( ) ; it . remove ( ) ; } } } 
public T callback ( final IndexWriter writer ) throws IOException ; } private final Map < ViewSignature , LuceneHolder > holders = new LinkedHashMap < ViewSignature , LuceneHolder > ( ) ; private final File baseDir ; private final boolean realtime ; LuceneGateway ( final File baseDir , final boolean realtime ) { this . baseDir = baseDir ; this . realtime = realtime ; } private synchronized LuceneHolder getHolder ( final ViewSignature viewSignature ) throws IOException { LuceneHolder result = holders . get ( viewSignature ) ; if ( result = = null ) { final File dir = viewSignature . toFile ( baseDir ) ; if ( ! dir . exists ( ) & & ! dir . mkdirs ( ) ) throw new IOException ( " Could not make " + dir ) ; result = new LuceneHolder ( FSDirectory . open ( dir ) , realtime ) ; holders . put ( viewSignature , result ) ; } return result ; } < T > T withReader ( final ViewSignature viewSignature , final boolean staleOk , final ReaderCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexReader reader = holder . borrowReader ( staleOk ) ; try { return callback . callback ( reader ) ; } finally { holder . returnReader ( reader ) ; } } < T > T withSearcher ( final ViewSignature viewSignature , final boolean staleOk , final SearcherCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexSearcher searcher = holder . borrowSearcher ( staleOk ) ; try { return callback . callback ( searcher ) ; } finally { holder . returnSearcher ( searcher ) ; } } < T > T withWriter ( final ViewSignature viewSignature , final WriterCallback < T > callback ) throws IOException { LuceneHolder holder = getHolder ( viewSignature ) ; final IndexWriter writer = holder . getIndexWriter ( ) ; try { return callback . callback ( writer ) ; } catch ( final OutOfMemoryError e ) { synchronized ( holders ) { holder = holders . remove ( viewSignature ) ; holder . close ( ) ; } throw e ; } } void deleteIndex ( final ViewSignature viewSignature ) throws IOException { } void createIndex ( final ViewSignature viewSignature ) throws IOException { } synchronized void close ( ) throws IOException { final Iterator < LuceneHolder > it = holders . values ( ) . iterator ( ) ; while ( it . hasNext ( ) ) { it . next ( ) . close ( ) ; it . remove ( ) ; } } } 
< T > T withReader ( final ViewSignature viewSignature , final boolean staleOk , final ReaderCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexReader reader = holder . borrowReader ( staleOk ) ; try { return callback . callback ( reader ) ; 
< T > T withSearcher ( final ViewSignature viewSignature , final boolean staleOk , final SearcherCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexSearcher searcher = holder . borrowSearcher ( staleOk ) ; try { return callback . callback ( searcher ) ; 
< T > T withWriter ( final ViewSignature viewSignature , final WriterCallback < T > callback ) throws IOException { LuceneHolder holder = getHolder ( viewSignature ) ; final IndexWriter writer = holder . getIndexWriter ( ) ; try { return callback . callback ( writer ) ; 
void deleteIndex ( final ViewSignature viewSignature ) throws IOException { } void createIndex ( final ViewSignature viewSignature ) throws IOException { } synchronized void close ( ) throws IOException { final Iterator < LuceneHolder > it = holders . values ( ) . iterator ( ) ; while ( it . hasNext ( ) ) { it . next ( ) . close ( ) ; it . remove ( ) ; } } } 
void createIndex ( final ViewSignature viewSignature ) throws IOException { } synchronized void close ( ) throws IOException { final Iterator < LuceneHolder > it = holders . values ( ) . iterator ( ) ; while ( it . hasNext ( ) ) { it . next ( ) . close ( ) ; it . remove ( ) ; } } } 
synchronized void close ( ) throws IOException { final Iterator < LuceneHolder > it = holders . values ( ) . iterator ( ) ; while ( it . hasNext ( ) ) { it . next ( ) . close ( ) ; 
public static void main ( final String [ ] args ) throws Exception { final Properties properties = new Properties ( ) ; final InputStream in = Main . class . getClassLoader ( ) . getResourceAsStream ( " couchdb-lucene.properties " ) ; properties . load ( in ) ; in . close ( ) ; final String luceneDir = properties . getProperty ( " lucene.dir " ) ; final int lucenePort = Integer . parseInt ( properties . getProperty ( " lucene.port " , " 5985 " ) ) ; final String couchUrl = properties . getProperty ( " couchdb.url " ) ; final boolean realtime = Boolean . parseBoolean ( properties . getProperty ( " lucene.realtime " , " false " ) ) ; if ( luceneDir = = null ) { LOG . error ( " lucene.dir not set. " ) ; System . exit ( 1 ) ; } if ( couchUrl = = null ) { LOG . error ( " couchdb.url not set. " ) ; System . exit ( 1 ) ; } Configure httpClient. final HttpParams params = new BasicHttpParams(); ConnManagerParams.setMaxTotalConnections(params, 1000); HttpProtocolParams.setVersion(params, HttpVersion.HTTP_1_1); HttpProtocolParams.setUserAgent(params, HttpProtocolParams.getUserAgent(params) + " couchdb-lucene/0.5"); final SchemeRegistry schemeRegistry = new SchemeRegistry(); schemeRegistry.register(new Scheme("http", PlainSocketFactory.getSocketFactory(), 5984)); final ClientConnectionManager cm = new ThreadSafeClientConnManager(params, schemeRegistry); final HttpClient httpClient = new DefaultHttpClient(cm, params); Configure other objects. final Couch couch = new Couch(httpClient, couchUrl); final Locator locator = new Locator(); final LuceneGateway gateway = new LuceneGateway(new File(luceneDir), realtime); final State state = new State(couch, gateway, locator, httpClient); Configure Indexer. final Indexer3 indexer = new Indexer3(state); Configure Jetty. final Server server = new Server(Integer.getInteger("port", lucenePort)); server.setStopAtShutdown(true); server.setSendServerVersion(false); server.addLifeCycle(indexer); Configure Rhino. TODO deuglify this. RhinoDocument.state = state; final ContextHandlerCollection contexts = new ContextHandlerCollection(); server.setHandler(contexts); final Context search = new Context(contexts, "/search", Context.NO_SESSIONS); search.addFilter(new FilterHolder(new GzipFilter()), "/*", Handler.DEFAULT); search.addServlet(new ServletHolder(new SearchServlet(state)), "/*"); final Context info = new Context(contexts, "/info", Context.NO_SESSIONS); info.addServlet(new ServletHolder(new InfoServlet(state)), "/*"); final Context admin = new Context(contexts, "/admin", Context.NO_SESSIONS); admin.addServlet(new ServletHolder(new AdminServlet(state)), "/*"); Lockdown System.setSecurityManager(securityManager); server.start(); server.join(); } 
public static void jsFunction_add ( final Context cx , final Scriptable thisObj , final Object [ ] args , final Function funObj ) { final RhinoDocument doc = checkInstance ( thisObj ) ; if ( args . length < 1 | | args . length > 2 ) { throw Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } if ( args [ 0 ] = = null ) { throw Context . reportRuntimeError ( " first argument must be non-null. " ) ; } if ( args . length = = 2 & & ( args [ 1 ] = = null | | args [ 1 ] instanceof NativeObject = = false ) ) { throw Context . reportRuntimeError ( " second argument must be an object. " ) ; } final JSONObject defaults = JSONObject . fromObject ( ( String ) cx . getThreadLocal ( " defaults " ) ) ; String field = defaults . optString ( " field " , Constants . DEFAULT_FIELD ) ; String store = defaults . optString ( " store " , " no " ) ; String index = defaults . optString ( " index " , " analyzed " ) ; String type = defaults . optString ( " type " , " string " ) ; Check for local override. if (args.length == 2) { final NativeObject obj = (NativeObject) args[1]; field = optString(obj, "field", field); store = optString(obj, "store", store); index = optString(obj, "index", index); type = optString(obj, "type", type); } final Field.Store storeObj = Store.get(store); Fieldable fieldObj = null; if ("int".equals(type)) { fieldObj = new NumericField(field, storeObj, true).setIntValue(Conversion.convert(args[0], Integer.class)); } else if ("float".equals(type)) { fieldObj = new NumericField(field, storeObj, true).setFloatValue(Conversion.convert(args[0], Float.class)); } else if ("double".equals(type)) { fieldObj = new NumericField(field, storeObj, true).setDoubleValue(Conversion.convert(args[0], Double.class)); } else if ("long".equals(type)) { fieldObj = new NumericField(field, storeObj, true).setLongValue(Conversion.convert(args[0], Long.class)); } else if ("date".equals(type)) { fieldObj = new NumericField(field, storeObj, true).setLongValue(Conversion.convert(args[0], Date.class).getTime()); } else if ("string".equals(type)) { fieldObj = new Field(field, Conversion.convert(args[0]).toString(), storeObj, Index.get(index)); } else { Ignore. } if (fieldObj != null) doc.add(fieldObj); 
public static void jsFunction_attachment ( final Context cx , final Scriptable thisObj , final Object [ ] args , final Function funObj ) throws IOException { final RhinoDocument doc = checkInstance ( thisObj ) ; if ( args . length < 2 ) { throw Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } final String dbname = ( String ) cx . getThreadLocal ( " dbname " ) ; final String docid = ( String ) cx . getThreadLocal ( " docid " ) ; final String field = args [ 0 ] . toString ( ) ; final String attname = args [ 1 ] . toString ( ) ; final String url = state . couch . url ( String . format ( " %s/%s/%s " , dbname , Utils . urlEncode ( docid ) , Utils . urlEncode ( attname ) ) ) ; final HttpGet get = new HttpGet ( url ) ; final ResponseHandler < Void > responseHandler = new ResponseHandler < Void > ( ) { @Override public Void handleResponse ( final HttpResponse response ) throws ClientProtocolException , IOException { final HttpEntity entity = response . getEntity ( ) ; final InputStream in = entity . getContent ( ) ; try { TIKA . parse ( in , entity . getContentType ( ) . getValue ( ) , field , doc . doc ) ; } finally { in . close ( ) ; } return null ; } } ; state . httpClient . execute ( get , responseHandler ) ; } 
public int hashCode ( ) { final int prime = 31 ; int result = 1 ; result = prime * result + ( ( dbname = = null ) ? 0 : dbname . hashCode ( ) ) ; result = prime * result + ( ( view = = null ) ? 0 : view . hashCode ( ) ) ; return result ; } 
public boolean equals ( Object obj ) { if ( this = = obj ) return true ; if ( obj = = null ) return false ; if ( getClass ( ) ! = obj . getClass ( ) ) return false ; ViewSignature other = ( ViewSignature ) obj ; if ( dbname = = null ) { if ( other . dbname ! = null ) return false ; } else if ( ! dbname . equals ( other . dbname ) ) return false ; if ( view = = null ) { if ( other . view ! = null ) return false ; } else if ( ! view . equals ( other . view ) ) return false ; return true ; } 
public String toString ( ) { StringBuffer s = new StringBuffer ( ) . append ( " NGramProfile: " ) . append ( name ) . append ( " " ) ; Iterator i = getSorted ( ) . iterator ( ) ; while ( i . hasNext ( ) ) { NGramEntry entry = ( NGramEntry ) i . next ( ) ; s . append ( " [ " ) . append ( entry . seq ) . append ( " / " ) . append ( entry . count ) . append ( " / " ) . append ( entry . frequency ) . append ( " ] " ) ; } return s . toString ( ) ; } 
public static void main ( String args [ ] ) throws Exception { String usage = " Usage: NGramProfile " + " [-create profilename filename encoding] " + " [-similarity file1 file2] " + " [-score profile-name filename encoding] " ; int command = 0 ; final int CREATE = 1 ; final int SIMILARITY = 2 ; final int SCORE = 3 ; String profilename = " " ; String filename = " " ; String filename2 = " " ; String encoding = " " ; if ( args . length = = 0 ) { System . err . println ( usage ) ; System . exit ( - 1 ) ; } for ( int i = 0 ; i < args . length ; i + + ) { parse command line if (args[i].equals("-create")) { found -create option command = CREATE; profilename = args[++i]; filename = args[++i]; encoding = args[++i]; } if (args[i].equals("-similarity")) { found -similarity option command = SIMILARITY; filename = args[++i]; filename2 = args[++i]; encoding = args[++i]; } if (args[i].equals("-score")) { found -Score option command = SCORE; profilename = args[++i]; filename = args[++i]; encoding = args[++i]; } } switch (command) { 
public void sameOrder ( ) throws Exception { final JSONArray hits25 = JSONObject . fromObject ( FileUtils . readFileToString ( new File ( " /tmp/25hits " ) ) ) . getJSONArray ( " rows " ) ; final JSONArray hits50 = JSONObject . fromObject ( FileUtils . readFileToString ( new File ( " /tmp/50hits " ) ) ) . getJSONArray ( " rows " ) ; for ( int i = 0 ; i < 25 ; i + + ) { final String left = hits25 . getJSONObject ( i ) . getString ( " id " ) ; 
public void testNumerics ( ) throws Exception { final Directory dir = new RAMDirectory ( ) ; final IndexWriter writer = new IndexWriter ( dir , new StandardAnalyzer ( Version . LUCENE_CURRENT ) , true , MaxFieldLength . UNLIMITED ) ; add ( writer , 1 ) ; add ( writer , 2 ) ; add ( writer , 10 ) ; add ( writer , 100 ) ; writer . close ( ) ; final IndexReader reader = IndexReader . open ( dir , true ) ; final IndexSearcher searcher = new IndexSearcher ( reader ) ; final TopDocs td = searcher . search ( NumericRangeQuery . newIntRange ( " int " , 2 , 10 , true , true ) , 10 ) ; assertThat ( td . totalHits , is ( 2 ) ) ; final TopFieldDocs tfd = searcher . search ( NumericRangeQuery . newIntRange ( " int " , 0 , 5 , true , true ) , null , 10 , new Sort ( new SortField ( " int " , SortField . INT ) ) ) ; assertThat ( tfd . totalHits , is ( 2 ) ) ; reader . close ( ) ; } 
public void cleanup ( ) throws IOException { gateway . close ( ) ; FileUtils . cleanDirectory ( dir ) ; } 
public void normalSearch ( ) throws IOException { search ( false , 0 ) ; } 
public void nearRealtimeSearch ( ) throws IOException { search ( true , 1 ) ; } 
private void search ( final boolean realtime , final int expectedCount ) throws IOException { gateway = new LuceneGateway ( dir , realtime ) ; gateway . withWriter ( sig , new WriterCallback < Void > ( ) { @Override public Void callback ( final IndexWriter writer ) throws IOException { writer . addDocument ( doc ) ; return null ; } } ) ; final int count = gateway . withSearcher ( sig , ! realtime , new SearcherCallback < Integer > ( ) { @Override public Integer callback ( final IndexSearcher searcher ) throws IOException { return searcher . search ( new TermQuery ( new Term ( " id " , " 12 " ) ) , 1 ) . totalHits ; } } ) ; assertThat ( count , is ( expectedCount ) ) ; } 
public Void callback ( final IndexWriter writer ) throws IOException { writer . addDocument ( doc ) ; return null ; } 
public Integer callback ( final IndexSearcher searcher ) throws IOException { return searcher . search ( new TermQuery ( new Term ( " id " , " 12 " ) ) , 1 ) . totalHits ; } 
public void run ( ) { while ( isRunning ( ) ) { updateIndex ( ) ; 
protected void doStart ( ) throws Exception { scheduler = Executors . newScheduledThreadPool ( 5 ) ; scheduler . scheduleWithFixedDelay ( new CouchPoller ( ) , 0 , 1 , TimeUnit . MINUTES ) ; } 
protected void doStop ( ) throws Exception { scheduler . shutdown ( ) ; scheduler . awaitTermination ( Long . MAX_VALUE , TimeUnit . DAYS ) ; } 
public void run ( ) { try { final String [ ] databases = state . couch . getAllDatabases ( ) ; 
public void run ( ) { try { mapViewsToIndexes ( ) ; 
private void mapViewsToIndexes ( ) throws IOException { final JSONArray designDocuments = state . couch . getAllDesignDocuments ( databaseName ) ; for ( int i = 0 ; i < designDocuments . size ( ) ; i + + ) { final JSONObject designDocument = designDocuments . getJSONObject ( i ) . getJSONObject ( " doc " ) ; 
private void readCurrentUpdateSequence ( ) throws IOException { TODO read highest seq field from each index or read _local/lucene or something. } private void pullChanges() throws IOException { final String url = state.couch.url(String.format("%s/_changes?feed=continuous&since=%d&include_docs=true", databaseName, since)); state.httpClient.execute(new HttpGet(url), new ChangesResponseHandler()); } private void untrack() { synchronized (activeTasks) { activeTasks.remove(databaseName); } logger.debug("Untracking " + databaseName); } private class ChangesResponseHandler implements ResponseHandler<Void> { @Override public Void handleResponse(final HttpResponse response) throws ClientProtocolException, IOException { final HttpEntity entity = response.getEntity(); final BufferedReader reader = new BufferedReader(new InputStreamReader(entity.getContent(), "UTF-8")); String line; while ((line = reader.readLine()) != null) { final JSONObject json = JSONObject.fromObject(line); System.err.println(json); since = json.getLong("seq"); } return null; } } }} 
private void pullChanges ( ) throws IOException { final String url = state . couch . url ( String . format ( " %s/_changes?feed=continuous&since=%d&include_docs=true " , databaseName , since ) ) ; state . httpClient . execute ( new HttpGet ( url ) , new ChangesResponseHandler ( ) ) ; } 
private void untrack ( ) { synchronized ( activeTasks ) { activeTasks . remove ( databaseName ) ; } logger . debug ( " Untracking " + databaseName ) ; } 
public Void handleResponse ( final HttpResponse response ) throws ClientProtocolException , IOException { final HttpEntity entity = response . getEntity ( ) ; final BufferedReader reader = new BufferedReader ( new InputStreamReader ( entity . getContent ( ) , " UTF-8 " ) ) ; String line ; while ( ( line = reader . readLine ( ) ) ! = null ) { final JSONObject json = JSONObject . fromObject ( line ) ; System . err . println ( json ) ; since = json . getLong ( " seq " ) ; } return null ; } 
public void update ( final String databaseName , final String designDocumentName , final String viewName , final String viewFunction ) { final ViewSignature viewSignature = new ViewSignature ( databaseName , viewFunction ) ; synchronized ( map ) { final String path = path ( databaseName , designDocumentName , viewName ) ; 
public static void main ( final String [ ] args ) throws Exception { final Properties properties = new Properties ( ) ; final InputStream in = Main . class . getClassLoader ( ) . getResourceAsStream ( " couchdb-lucene.properties " ) ; properties . load ( in ) ; in . close ( ) ; final String luceneDir = properties . getProperty ( " lucene.dir " ) ; final int lucenePort = Integer . parseInt ( properties . getProperty ( " lucene.port " , " 5985 " ) ) ; final String couchUrl = properties . getProperty ( " couchdb.url " ) ; final boolean realtime = Boolean . parseBoolean ( properties . getProperty ( " lucene.realtime " , " false " ) ) ; if ( luceneDir = = null ) { LOG . error ( " lucene.dir not set. " ) ; System . exit ( 1 ) ; } if ( couchUrl = = null ) { LOG . error ( " couchdb.url not set. " ) ; System . exit ( 1 ) ; } Configure httpClient. final HttpParams params = new BasicHttpParams(); ConnManagerParams.setMaxTotalConnections(params, 1000); HttpProtocolParams.setVersion(params, HttpVersion.HTTP_1_1); HttpProtocolParams.setUserAgent(params, HttpProtocolParams.getUserAgent(params) + " couchdb-lucene/0.5"); final SchemeRegistry schemeRegistry = new SchemeRegistry(); schemeRegistry.register(new Scheme("http", PlainSocketFactory.getSocketFactory(), 5984)); final ClientConnectionManager cm = new ThreadSafeClientConnManager(params, schemeRegistry); final HttpClient httpClient = new DefaultHttpClient(cm, params); Configure other objects. final Couch couch = new Couch(httpClient, couchUrl); final Locator locator = new Locator(); final LuceneGateway gateway = new LuceneGateway(new File(luceneDir), realtime); final State state = new State(couch, gateway, locator, httpClient); Configure Indexer. final Indexer indexer = new Indexer(state); Configure Jetty. final Server server = new Server(Integer.getInteger("port", lucenePort)); server.setStopAtShutdown(true); server.setSendServerVersion(false); server.addLifeCycle(indexer); Configure Rhino. TODO deuglify this. RhinoDocument.state = state; final ContextHandlerCollection contexts = new ContextHandlerCollection(); server.setHandler(contexts); final Context search = new Context(contexts, "/search", Context.NO_SESSIONS); search.addFilter(new FilterHolder(new GzipFilter()), "/*", Handler.DEFAULT); search.addServlet(new ServletHolder(new SearchServlet(state)), "/*"); final Context info = new Context(contexts, "/info", Context.NO_SESSIONS); info.addServlet(new ServletHolder(new InfoServlet(state)), "/*"); final Context admin = new Context(contexts, "/admin", Context.NO_SESSIONS); admin.addServlet(new ServletHolder(new AdminServlet(state)), "/*"); Lockdown System.setSecurityManager(securityManager); server.start(); server.join(); } 
public void run ( ) { try { enterContext ( ) ; 
private void enterContext ( ) throws Exception { context = ContextFactory . getGlobal ( ) . enterContext ( ) ; context . setClassShutter ( new RestrictiveClassShutter ( ) ) ; scope = context . initStandardObjects ( ) ; ScriptableObject . defineClass ( scope , RhinoDocument . class ) ; context . evaluateString ( scope , loadResource ( " json2.js " ) , " json2 " , 0 , null ) ; } 
private String loadResource ( final String name ) throws IOException { final InputStream in = Rhino . class . getClassLoader ( ) . getResourceAsStream ( name ) ; try { return IOUtils . toString ( in , " UTF-8 " ) ; 
private void updateIndexes ( ) throws IOException { System . err . println ( state . locator . lookupAll ( databaseName ) ) ; final String url = state . couch . url ( String . format ( " %s/_changes?feed=continuous&since=%d&include_docs=true " , databaseName , since ) ) ; state . httpClient . execute ( new HttpGet ( url ) , new ChangesResponseHandler ( ) ) ; } 
public boolean visibleToScripts ( final String fullClassName ) { return false ; } 
public Void handleResponse ( final HttpResponse response ) throws ClientProtocolException , IOException { final HttpEntity entity = response . getEntity ( ) ; final BufferedReader reader = new BufferedReader ( new InputStreamReader ( entity . getContent ( ) , " UTF-8 " ) ) ; String line ; while ( ( line = reader . readLine ( ) ) ! = null ) { if ( line . length ( ) = = 0 ) break ; final JSONObject json = JSONObject . fromObject ( line ) ; System . err . println ( json ) ; if ( json . has ( " seq " ) ) { since = json . getLong ( " seq " ) ; } } return null ; } 
public ViewSignature lookup ( final String databaseName , final String designDocumentName , final String viewName ) { return lookup ( path ( databaseName , designDocumentName , viewName ) ) ; } 
public ViewSignature lookup ( final String path ) { synchronized ( map ) { return map . get ( path ) ; 
public Collection < String > lookupAll ( final String databaseName ) { final Set < String > result = new HashSet < String > ( ) ; synchronized ( map ) { for ( final String path : map . keySet ( ) ) { if ( path . startsWith ( databaseName + " / " ) ) { result . add ( path ) ; } } } return result ; } 
private void mapAllDesignDocuments ( ) throws IOException { final JSONArray designDocuments = state . couch . getAllDesignDocuments ( databaseName ) ; for ( int i = 0 ; i < designDocuments . size ( ) ; i + + ) { mapDesignDocument ( designDocuments . getJSONObject ( i ) . getJSONObject ( " doc " ) ) ; 
private void mapDesignDocument ( final JSONObject designDocument ) { final String designDocumentName = designDocument . getString ( Constants . ID ) . substring ( 8 ) ; final JSONObject fulltext = designDocument . getJSONObject ( " fulltext " ) ; if ( fulltext ! = null ) { for ( final Object obj : fulltext . keySet ( ) ) { 
public Void handleResponse ( final HttpResponse response ) throws ClientProtocolException , IOException { final HttpEntity entity = response . getEntity ( ) ; final BufferedReader reader = new BufferedReader ( new InputStreamReader ( entity . getContent ( ) , " UTF-8 " ) ) ; String line ; while ( ( line = reader . readLine ( ) ) ! = null ) { final JSONObject json = JSONObject . fromObject ( line ) ; End of feed. if (json.has("last_seq")) break; final String id = json.getString("id"); final JSONObject doc = json.getJSONObject("doc"); New, updated or deleted document. if (id.startsWith("_design")) { TODO update locator. logger.warn(id + ": design document updated."); mapDesignDocument(doc); } else if (json.optBoolean("deleted")) { TODO handle deletion. logger.warn(id + ": document deleted."); } else { New or updated document. logger.warn(id + ": new/updated document."); } Remember progress. since = json.getLong("seq"); } return null; } 
private void enterContext ( ) throws Exception { context = ContextFactory . getGlobal ( ) . enterContext ( ) ; Security restrictions context.setClassShutter(new RestrictiveClassShutter()); Setup. scope = context.initStandardObjects(); Allow custom document helper class. ScriptableObject.defineClass(scope, RhinoDocument.class); Load JSON parser. context.evaluateString(scope, loadResource("json2.js"), "json2", 0, null); Define outer function. main = context.compileFunction(scope, "function(json, func){return func(JSON.parse(json));}", "main", 0, null); } 
private void updateIndexes ( ) throws IOException { System.err.println(state.locator.lookupAll(databaseName)); final String url = state.couch.url(String.format("%s/_changes?feed=continuous&since=%d&include_docs=true", databaseName, since)); state.httpClient.execute(new HttpGet(url), new ChangesResponseHandler()); } 
public Void handleResponse ( final HttpResponse response ) throws ClientProtocolException , IOException { final HttpEntity entity = response . getEntity ( ) ; final BufferedReader reader = new BufferedReader ( new InputStreamReader ( entity . getContent ( ) , " UTF-8 " ) ) ; String line ; while ( ( line = reader . readLine ( ) ) ! = null ) { final JSONObject json = JSONObject . fromObject ( line ) ; End of feed. if (json.has("last_seq")) break; final String id = json.getString("id"); final Term docTerm = new Term(Constants.ID, id); final JSONObject doc = json.getJSONObject("doc"); New, updated or deleted document. if (id.startsWith("_design")) { if (logger.isTraceEnabled()) logger.trace(id + ": design document updated."); mapDesignDocument(doc); } else if (json.optBoolean("deleted")) { if (logger.isTraceEnabled()) logger.trace(id + ": document deleted."); writer.deleteDocuments(docTerm); } else { New or updated document. if (logger.isTraceEnabled()) logger.trace(id + ": new/updated document."); for (final Function function : functions.values()) { final Object result = main.call(context, scope, null, new Object[] { doc, function }); System.err.println(result); } } Remember progress. since = json.getLong("seq"); } return null; } 
public ViewSignature update ( final String databaseName , final String designDocumentName , final String viewName , final String viewFunction ) { final ViewSignature viewSignature = new ViewSignature ( databaseName , viewFunction ) ; synchronized ( map ) { final String path = path ( databaseName , designDocumentName , viewName ) ; map . put ( path , viewSignature ) ; logger . debug ( " Mapped " + path + " to " + viewSignature ) ; } return viewSignature ; } 
private void enterContext ( ) throws Exception { context = ContextFactory . getGlobal ( ) . enterContext ( ) ; Basic compilation level. context.setOptimizationLevel(0); Security restrictions context.setClassShutter(new RestrictiveClassShutter()); Setup. scope = context.initStandardObjects(); Allow custom document helper class. ScriptableObject.defineClass(scope, RhinoDocument.class); Load JSON parser. context.evaluateString(scope, loadResource("json2.js"), "json2", 0, null); Define outer function. main = context.compileFunction(scope, "function(json, func){return func(JSON.parse(json));}", "main", 0, null); } 
public boolean visibleToScripts ( final String fullClassName ) { return fullClassName . startsWith ( " net.sf.json " ) ; } 
public Void handleResponse ( final HttpResponse response ) throws ClientProtocolException , IOException { final HttpEntity entity = response . getEntity ( ) ; final BufferedReader reader = new BufferedReader ( new InputStreamReader ( entity . getContent ( ) , " UTF-8 " ) ) ; String line ; while ( ( line = reader . readLine ( ) ) ! = null ) { final JSONObject json = JSONObject . fromObject ( line ) ; End of feed. if (json.has("last_seq")) break; final String id = json.getString("id"); final Term docTerm = new Term(Constants.ID, id); final JSONObject doc = json.getJSONObject("doc"); New, updated or deleted document. if (id.startsWith("_design")) { if (logger.isTraceEnabled()) logger.trace(id + ": design document updated."); mapDesignDocument(doc); } else if (json.optBoolean("deleted")) { if (logger.isTraceEnabled()) logger.trace(id + ": document deleted."); writer.deleteDocuments(docTerm); } else { New or updated document. if (logger.isTraceEnabled()) logger.trace(id + ": new/updated document."); for (final Function function : functions.values()) { try { final Object result = main.call(context, scope, null, new Object[] { doc, function }); System.err.println(result); } catch (final RhinoException e) { logger.warn("doc '" + id + "' caused exception.", e); } } } Remember progress. since = json.getLong("seq"); } return null; } 
private void enterContext ( ) throws Exception { context = ContextFactory . getGlobal ( ) . enterContext ( ) ; Basic compilation level. context.setOptimizationLevel(9); Security restrictions context.setClassShutter(new RestrictiveClassShutter()); Setup. scope = context.initStandardObjects(); Allow custom document helper class. ScriptableObject.defineClass(scope, RhinoDocument.class); Load JSON parser. context.evaluateString(scope, loadResource("json2.js"), "json2", 0, null); Define outer function. main = context.compileFunction(scope, "function(json, func){return func(JSON.parse(json));}", "main", 0, null); } 
private void mapAllDesignDocuments ( ) throws IOException { final JSONArray designDocuments = state . couch . getAllDesignDocuments ( databaseName ) ; for ( int i = 0 ; i < designDocuments . size ( ) ; i + + ) { mapDesignDocument ( designDocuments . getJSONObject ( i ) . getJSONObject ( " doc " ) ) ; } TODO use the real defaults. this.context.putThreadLocal("defaults", "{}"); } 
public Void handleResponse ( final HttpResponse response ) throws ClientProtocolException , IOException { final HttpEntity entity = response . getEntity ( ) ; final BufferedReader reader = new BufferedReader ( new InputStreamReader ( entity . getContent ( ) , " UTF-8 " ) ) ; String line ; while ( ( line = reader . readLine ( ) ) ! = null ) { final JSONObject json = JSONObject . fromObject ( line ) ; End of feed. if (json.has("last_seq")) break; final String id = json.getString("id"); final Term docTerm = new Term(Constants.ID, id); final JSONObject doc = json.getJSONObject("doc"); New, updated or deleted document. if (id.startsWith("_design")) { if (logger.isTraceEnabled()) logger.trace(id + ": design document updated."); mapDesignDocument(doc); } else if (json.optBoolean("deleted")) { if (logger.isTraceEnabled()) logger.trace(id + ": document deleted."); writer.deleteDocuments(docTerm); } else { New or updated document. if (logger.isTraceEnabled()) logger.trace(id + ": new/updated document."); for (final Function function : functions.values()) { try { final Object result = main.call(context, scope, null, new Object[] { doc.toString(), function }); System.err.println(result); } catch (final RhinoException e) { logger.warn("doc '" + id + "' caused exception.", e); } } } Remember progress. since = json.getLong("seq"); } return null; } 
private void mapDesignDocument ( final JSONObject designDocument ) { final String designDocumentName = designDocument . getString ( " _id " ) . substring ( 8 ) ; final JSONObject fulltext = designDocument . getJSONObject ( " fulltext " ) ; if ( fulltext ! = null ) { for ( final Object obj : fulltext . keySet ( ) ) { 
private void updateIndexes ( ) throws IOException { final String url = state . couch . url ( String . format ( " %s/_changes?feed=continuous&since=%d&include_docs=true " , databaseName , since ) ) ; state . httpClient . execute ( new HttpGet ( url ) , new ChangesResponseHandler ( ) ) ; } 
private void deleteDocument ( final JSONObject doc ) throws IOException { for ( final ViewSignature sig : functions . keySet ( ) ) { state . lucene . withWriter ( sig , new WriterCallback < Void > ( ) { 
public Void callback ( final IndexWriter writer ) throws IOException { writer . deleteDocuments ( new Term ( " _id " , doc . getString ( " _id " ) ) ) ; return null ; } 
private void commitDocuments ( ) throws IOException { final Map < String , String > commitUserData = new HashMap < String , String > ( ) ; commitUserData . put ( " update_seq " , Long . toString ( since ) ) ; for ( final ViewSignature sig : functions . keySet ( ) ) { state . lucene . withWriter ( sig , new WriterCallback < Void > ( ) { 
public Void callback ( final IndexWriter writer ) throws IOException { writer . commit ( commitUserData ) ; return null ; } 
private void updateDocument ( final JSONObject doc ) { for ( final Entry < ViewSignature , ViewTuple > entry : functions . entrySet ( ) ) { try { 
private void addDocument ( final ViewSignature sig , final Term id , final RhinoDocument doc , final Analyzer analyzer ) throws IOException { state . lucene . withWriter ( sig , new WriterCallback < Void > ( ) { @Override 
public Void callback ( final IndexWriter writer ) throws IOException { writer . updateDocument ( id , doc . doc , analyzer ) ; return null ; } 
private IndexReaderWarmer newWarmer ( ) { return new IndexReaderWarmer ( ) { @Override 
public void warm ( final IndexReader reader ) throws IOException { Prewarm sequence (is this "insane"?) FieldCache.DEFAULT.getLongs(reader, "_seq"); 
public void setup ( ) { sig = new ViewSignature ( " db1 " , " function(doc){} " ) ; doc = new Document ( ) ; doc . add ( new Field ( " id " , " 12 " , Store . YES , Index . ANALYZED ) ) ; dir = new File ( " target " , " tmp " ) ; dir . mkdir ( ) ; } 
protected void doStart ( ) throws Exception { executor = Executors . newCachedThreadPool ( ) ; scheduler = Executors . newScheduledThreadPool ( 1 ) ; scheduler . scheduleWithFixedDelay ( new CouchPoller ( ) , 0 , 1 , TimeUnit . MINUTES ) ; } 
protected void doStop ( ) throws Exception { scheduler . shutdownNow ( ) ; executor . shutdownNow ( ) ; } 
private void enterContext ( ) throws Exception { context = ContextFactory . getGlobal ( ) . enterContext ( ) ; Optimize as much as possible. context.setOptimizationLevel(9); Security restrictions context.setClassShutter(new RestrictiveClassShutter()); Setup. scope = context.initStandardObjects(); Allow custom document helper class. ScriptableObject.defineClass(scope, RhinoDocument.class); Load JSON parser. context.evaluateString(scope, loadResource("json2.js"), "json2", 0, null); Define outer function. main = context.compileFunction(scope, "function(json, func){return func(JSON.parse(json));}", "main", 0, null); } 
private String loadResource ( final String name ) throws IOException { final InputStream in = Indexer . class . getClassLoader ( ) . getResourceAsStream ( name ) ; try { return IOUtils . toString ( in , " UTF-8 " ) ; 
private void readCheckpoints ( ) throws IOException { for ( final ViewSignature sig : functions . keySet ( ) ) { since = Math . min ( since , state . lucene . withReader ( sig , false , new ReaderCallback < Long > ( ) { @Override public Long callback ( final IndexReader reader ) throws IOException { final Map < String , String > commitUserData = reader . getCommitUserData ( ) ; final String result = commitUserData . get ( " update_seq " ) ; return result ! = null ? Long . parseLong ( result ) : 0 L ; } } ) ) ; } System . err . println ( since ) ; } 
public Long callback ( final IndexReader reader ) throws IOException { final Map < String , String > commitUserData = reader . getCommitUserData ( ) ; final String result = commitUserData . get ( " update_seq " ) ; return result ! = null ? Long . parseLong ( result ) : 0 L ; } 
private void readCheckpoints ( ) throws IOException { for ( final ViewSignature sig : functions . keySet ( ) ) { since = Math . min ( since , state . lucene . withReader ( sig , false , new ReaderCallback < Long > ( ) { @Override public Long callback ( final IndexReader reader ) throws IOException { final Map < String , String > commitUserData = reader . getCommitUserData ( ) ; final String result = commitUserData . get ( " update_seq " ) ; return result ! = null ? Long . parseLong ( result ) : 0 L ; } } ) ) ; } logger . trace ( " Existing indexes at update_seq " + since ) ; } 
private void updateIndexes ( ) throws IOException { final String url = state . couch . url ( String . format ( " %s/_changes?feed=continuous&since=%d&include_docs=true&timeout=10000 " , databaseName , since ) ) ; state . httpClient . execute ( new HttpGet ( url ) , new ChangesResponseHandler ( ) ) ; } 
private void updateIndexes ( ) throws IOException { final String url = state . couch . url ( String . format ( " %s/_changes?feed=continuous&since=%d&include_docs=true&timeout=20000 " , databaseName , since ) ) ; state . httpClient . execute ( new HttpGet ( url ) , new ChangesResponseHandler ( ) ) ; } 
public Void callback ( final IndexWriter writer ) throws IOException { if ( writer . numRamDocs ( ) > 0 ) { logger . trace ( " Committing changes to " + sig ) ; writer . commit ( commitUserData ) ; } return null ; } 
public void run ( ) { logger . debug ( " Tracking begins " ) ; try { enterContext ( ) ; 
private void untrack ( ) { synchronized ( activeTasks ) { activeTasks . remove ( databaseName ) ; } logger . debug ( " Tracking ends " ) ; } 
public ViewSignature lookup ( final HttpServletRequest req ) { final String [ ] path = req . getPathInfo ( ) . substring ( 1 ) . split ( " / " ) ; if ( path . length ! = 3 ) { return null ; } return lookup ( path ) ; } 
public Void callback ( final IndexWriter writer ) throws IOException { doc . doc . add ( Utils . token ( " _id " , id . text ( ) , true ) ) ; writer . updateDocument ( id , doc . doc , analyzer ) ; return null ; } 
public ViewSignature update ( final String databaseName , final String designDocumentName , final String viewName , final String viewFunction ) { final ViewSignature viewSignature = new ViewSignature ( databaseName , viewFunction ) ; synchronized ( map ) { final String path = path ( databaseName , designDocumentName , viewName ) ; map . put ( path , viewSignature ) ; logger . trace ( " Mapped " + path + " to " + viewSignature ) ; } return viewSignature ; } 
public static void main ( final String [ ] args ) throws Exception { final Properties properties = new Properties ( ) ; final InputStream in = Main . class . getClassLoader ( ) . getResourceAsStream ( " couchdb-lucene.properties " ) ; if ( in = = null ) { System . out . println ( " No couchdb-lucene.properties file found. " ) ; return ; } properties . load ( in ) ; in . close ( ) ; final String luceneDir = properties . getProperty ( " lucene.dir " ) ; final int lucenePort = Integer . parseInt ( properties . getProperty ( " lucene.port " , " 5985 " ) ) ; final String couchUrl = properties . getProperty ( " couchdb.url " ) ; final boolean realtime = Boolean . parseBoolean ( properties . getProperty ( " lucene.realtime " , " false " ) ) ; if ( luceneDir = = null ) { LOG . error ( " lucene.dir not set. " ) ; System . exit ( 1 ) ; } if ( couchUrl = = null ) { LOG . error ( " couchdb.url not set. " ) ; System . exit ( 1 ) ; } Configure httpClient. final HttpParams params = new BasicHttpParams(); ConnManagerParams.setMaxTotalConnections(params, 1000); HttpProtocolParams.setVersion(params, HttpVersion.HTTP_1_1); HttpProtocolParams.setUserAgent(params, HttpProtocolParams.getUserAgent(params) + " couchdb-lucene/0.5"); final SchemeRegistry schemeRegistry = new SchemeRegistry(); schemeRegistry.register(new Scheme("http", PlainSocketFactory.getSocketFactory(), 5984)); final ClientConnectionManager cm = new ThreadSafeClientConnManager(params, schemeRegistry); final HttpClient httpClient = new DefaultHttpClient(cm, params); Configure other objects. final Couch couch = new Couch(httpClient, couchUrl); final Locator locator = new Locator(); final LuceneGateway gateway = new LuceneGateway(new File(luceneDir), realtime); final State state = new State(couch, gateway, locator, httpClient); Configure Indexer. final Indexer indexer = new Indexer(state); Configure Jetty. final Server server = new Server(Integer.getInteger("port", lucenePort)); server.setStopAtShutdown(true); server.setSendServerVersion(false); server.addLifeCycle(indexer); Configure Rhino. TODO deuglify this. RhinoDocument.state = state; final ContextHandlerCollection contexts = new ContextHandlerCollection(); server.setHandler(contexts); final Context search = new Context(contexts, "/search", Context.NO_SESSIONS); search.addFilter(new FilterHolder(new GzipFilter()), "/*", Handler.DEFAULT); search.addServlet(new ServletHolder(new SearchServlet(state)), "/*"); final Context info = new Context(contexts, "/info", Context.NO_SESSIONS); info.addServlet(new ServletHolder(new InfoServlet(state)), "/*"); final Context admin = new Context(contexts, "/admin", Context.NO_SESSIONS); admin.addServlet(new ServletHolder(new AdminServlet(state)), "/*"); Lockdown System.setSecurityManager(securityManager); server.start(); server.join(); } 
private void updateIndexes ( ) throws IOException { final String url = state . couch . url ( String . format ( " %s/_changes? " + " feed=continuous& " + " since=%d& " + " include_docs=true& " + " imeout=30000 " , databaseName , since ) ) ; state . httpClient . execute ( new HttpGet ( url ) , new ChangesResponseHandler ( ) ) ; } 
public Void callback ( final IndexWriter writer ) throws IOException { writer . deleteDocuments ( new Term ( " _id " , doc . getString ( " _id " ) ) ) ; pendingCommit = true ; return null ; } 
private void commitDocuments ( ) throws IOException { final Map < String , String > commitUserData = new HashMap < String , String > ( ) ; commitUserData . put ( " update_seq " , Long . toString ( since ) ) ; for ( final ViewSignature sig : functions . keySet ( ) ) { state . lucene . withWriter ( sig , new WriterCallback < Void > ( ) { @Override public Void callback ( final IndexWriter writer ) throws IOException { if ( pendingCommit ) { logger . trace ( " Committing changes to " + sig ) ; writer . commit ( commitUserData ) ; } return null ; } } ) ; } pendingCommit = false ; } 
public Void callback ( final IndexWriter writer ) throws IOException { if ( pendingCommit ) { logger . trace ( " Committing changes to " + sig ) ; writer . commit ( commitUserData ) ; } return null ; } 
public Void callback ( final IndexWriter writer ) throws IOException { doc . doc . add ( Utils . token ( " _id " , id . text ( ) , true ) ) ; writer . updateDocument ( id , doc . doc , analyzer ) ; pendingCommit = true ; return null ; } 
private boolean mapAllDesignDocuments ( ) throws IOException { final JSONArray designDocuments = state . couch . getAllDesignDocuments ( databaseName ) ; boolean isLuceneEnabled = false ; for ( int i = 0 ; i < designDocuments . size ( ) ; i + + ) { isLuceneEnabled | = mapDesignDocument ( designDocuments . getJSONObject ( i ) . getJSONObject ( " doc " ) ) ; } return isLuceneEnabled ; } 
private void readCheckpoints ( ) throws IOException { long since = Long . MAX_VALUE ; for ( final ViewSignature sig : functions . keySet ( ) ) { since = Math . min ( since , state . lucene . withReader ( sig , false , new ReaderCallback < Long > ( ) { @Override public Long callback ( final IndexReader reader ) throws IOException { final Map < String , String > commitUserData = reader . getCommitUserData ( ) ; final String result = commitUserData . get ( " update_seq " ) ; return result ! = null ? Long . parseLong ( result ) : 0 L ; } } ) ) ; } logger . trace ( " Existing indexes at update_seq " + since ) ; } 
private boolean mapDesignDocument ( final JSONObject designDocument ) { final String designDocumentName = designDocument . getString ( " _id " ) . substring ( 8 ) ; final JSONObject fulltext = designDocument . getJSONObject ( " fulltext " ) ; boolean isLuceneEnabled = false ; if ( fulltext ! = null ) { for ( final Object obj : fulltext . keySet ( ) ) { final String viewName = ( String ) obj ; final JSONObject viewValue = fulltext . getJSONObject ( viewName ) ; final String defaults = viewValue . optString ( " defaults " , " {} " ) ; final Analyzer analyzer = Analyzers . getAnalyzer ( viewValue . optString ( " analyzer " , " standard " ) ) ; final String function = viewValue . getString ( " index " ) ; final ViewSignature sig = state . locator . update ( databaseName , designDocumentName , viewName , fulltext . toString ( ) ) ; functions . put ( sig , new ViewTuple ( defaults , analyzer , context . compileFunction ( scope , function , viewName , 0 , null ) ) ) ; isLuceneEnabled = true ; } } return isLuceneEnabled ; } 
public T callback ( final IndexReader reader ) throws IOException ; } interface SearcherCallback < T > { public T callback ( final IndexSearcher searcher ) throws IOException ; } interface WriterCallback < T > { public T callback ( final IndexWriter writer ) throws IOException ; } private final Map < ViewSignature , LuceneHolder > holders = new LinkedHashMap < ViewSignature , LuceneHolder > ( ) ; private final File baseDir ; private final boolean realtime ; LuceneGateway ( final File baseDir , final boolean realtime ) { this . baseDir = baseDir ; this . realtime = realtime ; } private synchronized LuceneHolder getHolder ( final ViewSignature viewSignature ) throws IOException { LuceneHolder result = holders . get ( viewSignature ) ; if ( result = = null ) { final File dir = viewSignature . toFile ( baseDir ) ; if ( ! dir . exists ( ) & & ! dir . mkdirs ( ) ) throw new IOException ( " Could not make " + dir ) ; result = new LuceneHolder ( FSDirectory . open ( dir ) , realtime ) ; holders . put ( viewSignature , result ) ; } return result ; } < T > T withReader ( final ViewSignature viewSignature , final boolean staleOk , final ReaderCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexReader reader = holder . borrowReader ( staleOk ) ; try { return callback . callback ( reader ) ; } finally { holder . returnReader ( reader ) ; } } < T > T withSearcher ( final ViewSignature viewSignature , final boolean staleOk , final SearcherCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexSearcher searcher = holder . borrowSearcher ( staleOk ) ; try { return callback . callback ( searcher ) ; } finally { holder . returnSearcher ( searcher ) ; } } < T > T withWriter ( final ViewSignature viewSignature , final WriterCallback < T > callback ) throws IOException { LuceneHolder holder = getHolder ( viewSignature ) ; final IndexWriter writer = holder . getIndexWriter ( ) ; try { return callback . callback ( writer ) ; } catch ( final OutOfMemoryError e ) { synchronized ( holders ) { holder = holders . remove ( viewSignature ) ; holder . close ( ) ; } throw e ; } } synchronized void close ( ) throws IOException { final Iterator < LuceneHolder > it = holders . values ( ) . iterator ( ) ; while ( it . hasNext ( ) ) { it . next ( ) . close ( ) ; it . remove ( ) ; } } } 
public T callback ( final IndexSearcher searcher ) throws IOException ; } interface WriterCallback < T > { public T callback ( final IndexWriter writer ) throws IOException ; } private final Map < ViewSignature , LuceneHolder > holders = new LinkedHashMap < ViewSignature , LuceneHolder > ( ) ; private final File baseDir ; private final boolean realtime ; LuceneGateway ( final File baseDir , final boolean realtime ) { this . baseDir = baseDir ; this . realtime = realtime ; } private synchronized LuceneHolder getHolder ( final ViewSignature viewSignature ) throws IOException { LuceneHolder result = holders . get ( viewSignature ) ; if ( result = = null ) { final File dir = viewSignature . toFile ( baseDir ) ; if ( ! dir . exists ( ) & & ! dir . mkdirs ( ) ) throw new IOException ( " Could not make " + dir ) ; result = new LuceneHolder ( FSDirectory . open ( dir ) , realtime ) ; holders . put ( viewSignature , result ) ; } return result ; } < T > T withReader ( final ViewSignature viewSignature , final boolean staleOk , final ReaderCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexReader reader = holder . borrowReader ( staleOk ) ; try { return callback . callback ( reader ) ; } finally { holder . returnReader ( reader ) ; } } < T > T withSearcher ( final ViewSignature viewSignature , final boolean staleOk , final SearcherCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexSearcher searcher = holder . borrowSearcher ( staleOk ) ; try { return callback . callback ( searcher ) ; } finally { holder . returnSearcher ( searcher ) ; } } < T > T withWriter ( final ViewSignature viewSignature , final WriterCallback < T > callback ) throws IOException { LuceneHolder holder = getHolder ( viewSignature ) ; final IndexWriter writer = holder . getIndexWriter ( ) ; try { return callback . callback ( writer ) ; } catch ( final OutOfMemoryError e ) { synchronized ( holders ) { holder = holders . remove ( viewSignature ) ; holder . close ( ) ; } throw e ; } } synchronized void close ( ) throws IOException { final Iterator < LuceneHolder > it = holders . values ( ) . iterator ( ) ; while ( it . hasNext ( ) ) { it . next ( ) . close ( ) ; it . remove ( ) ; } } } 
public T callback ( final IndexWriter writer ) throws IOException ; } private final Map < ViewSignature , LuceneHolder > holders = new LinkedHashMap < ViewSignature , LuceneHolder > ( ) ; private final File baseDir ; private final boolean realtime ; LuceneGateway ( final File baseDir , final boolean realtime ) { this . baseDir = baseDir ; this . realtime = realtime ; } private synchronized LuceneHolder getHolder ( final ViewSignature viewSignature ) throws IOException { LuceneHolder result = holders . get ( viewSignature ) ; if ( result = = null ) { final File dir = viewSignature . toFile ( baseDir ) ; if ( ! dir . exists ( ) & & ! dir . mkdirs ( ) ) throw new IOException ( " Could not make " + dir ) ; result = new LuceneHolder ( FSDirectory . open ( dir ) , realtime ) ; holders . put ( viewSignature , result ) ; } return result ; } < T > T withReader ( final ViewSignature viewSignature , final boolean staleOk , final ReaderCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexReader reader = holder . borrowReader ( staleOk ) ; try { return callback . callback ( reader ) ; } finally { holder . returnReader ( reader ) ; } } < T > T withSearcher ( final ViewSignature viewSignature , final boolean staleOk , final SearcherCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexSearcher searcher = holder . borrowSearcher ( staleOk ) ; try { return callback . callback ( searcher ) ; } finally { holder . returnSearcher ( searcher ) ; } } < T > T withWriter ( final ViewSignature viewSignature , final WriterCallback < T > callback ) throws IOException { LuceneHolder holder = getHolder ( viewSignature ) ; final IndexWriter writer = holder . getIndexWriter ( ) ; try { return callback . callback ( writer ) ; } catch ( final OutOfMemoryError e ) { synchronized ( holders ) { holder = holders . remove ( viewSignature ) ; holder . close ( ) ; } throw e ; } } synchronized void close ( ) throws IOException { final Iterator < LuceneHolder > it = holders . values ( ) . iterator ( ) ; while ( it . hasNext ( ) ) { it . next ( ) . close ( ) ; it . remove ( ) ; } } } 
public T callback ( final IndexReader reader ) throws IOException ; } interface SearcherCallback < T > { public T callback ( final IndexSearcher searcher , final String etag ) throws IOException ; } interface WriterCallback < T > { public T callback ( final IndexWriter writer ) throws IOException ; } private final Map < ViewSignature , LuceneHolder > holders = new LinkedHashMap < ViewSignature , LuceneHolder > ( ) ; private final File baseDir ; private final boolean realtime ; LuceneGateway ( final File baseDir , final boolean realtime ) { this . baseDir = baseDir ; this . realtime = realtime ; } private synchronized LuceneHolder getHolder ( final ViewSignature viewSignature ) throws IOException { LuceneHolder result = holders . get ( viewSignature ) ; if ( result = = null ) { final File dir = viewSignature . toFile ( baseDir ) ; if ( ! dir . exists ( ) & & ! dir . mkdirs ( ) ) throw new IOException ( " Could not make " + dir ) ; result = new LuceneHolder ( FSDirectory . open ( dir ) , realtime ) ; holders . put ( viewSignature , result ) ; } return result ; } < T > T withReader ( final ViewSignature viewSignature , final boolean staleOk , final ReaderCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexReader reader = holder . borrowReader ( staleOk ) ; try { return callback . callback ( reader ) ; } finally { holder . returnReader ( reader ) ; } } < T > T withSearcher ( final ViewSignature viewSignature , final boolean staleOk , final SearcherCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexSearcher searcher = holder . borrowSearcher ( staleOk ) ; try { final String etag = Long . toHexString ( searcher . getIndexReader ( ) . getVersion ( ) ) ; return callback . callback ( searcher , etag ) ; } finally { holder . returnSearcher ( searcher ) ; } } < T > T withWriter ( final ViewSignature viewSignature , final WriterCallback < T > callback ) throws IOException { LuceneHolder holder = getHolder ( viewSignature ) ; final IndexWriter writer = holder . getIndexWriter ( ) ; try { return callback . callback ( writer ) ; } catch ( final OutOfMemoryError e ) { synchronized ( holders ) { holder = holders . remove ( viewSignature ) ; holder . close ( ) ; } throw e ; } } synchronized void close ( ) throws IOException { final Iterator < LuceneHolder > it = holders . values ( ) . iterator ( ) ; while ( it . hasNext ( ) ) { it . next ( ) . close ( ) ; it . remove ( ) ; } } } 
public T callback ( final IndexSearcher searcher , final String etag ) throws IOException ; } interface WriterCallback < T > { public T callback ( final IndexWriter writer ) throws IOException ; } private final Map < ViewSignature , LuceneHolder > holders = new LinkedHashMap < ViewSignature , LuceneHolder > ( ) ; private final File baseDir ; private final boolean realtime ; LuceneGateway ( final File baseDir , final boolean realtime ) { this . baseDir = baseDir ; this . realtime = realtime ; } private synchronized LuceneHolder getHolder ( final ViewSignature viewSignature ) throws IOException { LuceneHolder result = holders . get ( viewSignature ) ; if ( result = = null ) { final File dir = viewSignature . toFile ( baseDir ) ; if ( ! dir . exists ( ) & & ! dir . mkdirs ( ) ) throw new IOException ( " Could not make " + dir ) ; result = new LuceneHolder ( FSDirectory . open ( dir ) , realtime ) ; holders . put ( viewSignature , result ) ; } return result ; } < T > T withReader ( final ViewSignature viewSignature , final boolean staleOk , final ReaderCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexReader reader = holder . borrowReader ( staleOk ) ; try { return callback . callback ( reader ) ; } finally { holder . returnReader ( reader ) ; } } < T > T withSearcher ( final ViewSignature viewSignature , final boolean staleOk , final SearcherCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexSearcher searcher = holder . borrowSearcher ( staleOk ) ; try { final String etag = Long . toHexString ( searcher . getIndexReader ( ) . getVersion ( ) ) ; return callback . callback ( searcher , etag ) ; } finally { holder . returnSearcher ( searcher ) ; } } < T > T withWriter ( final ViewSignature viewSignature , final WriterCallback < T > callback ) throws IOException { LuceneHolder holder = getHolder ( viewSignature ) ; final IndexWriter writer = holder . getIndexWriter ( ) ; try { return callback . callback ( writer ) ; } catch ( final OutOfMemoryError e ) { synchronized ( holders ) { holder = holders . remove ( viewSignature ) ; holder . close ( ) ; } throw e ; } } synchronized void close ( ) throws IOException { final Iterator < LuceneHolder > it = holders . values ( ) . iterator ( ) ; while ( it . hasNext ( ) ) { it . next ( ) . close ( ) ; it . remove ( ) ; } } } 
public T callback ( final IndexWriter writer ) throws IOException ; } private final Map < ViewSignature , LuceneHolder > holders = new LinkedHashMap < ViewSignature , LuceneHolder > ( ) ; private final File baseDir ; private final boolean realtime ; LuceneGateway ( final File baseDir , final boolean realtime ) { this . baseDir = baseDir ; this . realtime = realtime ; } private synchronized LuceneHolder getHolder ( final ViewSignature viewSignature ) throws IOException { LuceneHolder result = holders . get ( viewSignature ) ; if ( result = = null ) { final File dir = viewSignature . toFile ( baseDir ) ; if ( ! dir . exists ( ) & & ! dir . mkdirs ( ) ) throw new IOException ( " Could not make " + dir ) ; result = new LuceneHolder ( FSDirectory . open ( dir ) , realtime ) ; holders . put ( viewSignature , result ) ; } return result ; } < T > T withReader ( final ViewSignature viewSignature , final boolean staleOk , final ReaderCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexReader reader = holder . borrowReader ( staleOk ) ; try { return callback . callback ( reader ) ; } finally { holder . returnReader ( reader ) ; } } < T > T withSearcher ( final ViewSignature viewSignature , final boolean staleOk , final SearcherCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexSearcher searcher = holder . borrowSearcher ( staleOk ) ; try { final String etag = Long . toHexString ( searcher . getIndexReader ( ) . getVersion ( ) ) ; return callback . callback ( searcher , etag ) ; } finally { holder . returnSearcher ( searcher ) ; } } < T > T withWriter ( final ViewSignature viewSignature , final WriterCallback < T > callback ) throws IOException { LuceneHolder holder = getHolder ( viewSignature ) ; final IndexWriter writer = holder . getIndexWriter ( ) ; try { return callback . callback ( writer ) ; } catch ( final OutOfMemoryError e ) { synchronized ( holders ) { holder = holders . remove ( viewSignature ) ; holder . close ( ) ; } throw e ; } } synchronized void close ( ) throws IOException { final Iterator < LuceneHolder > it = holders . values ( ) . iterator ( ) ; while ( it . hasNext ( ) ) { it . next ( ) . close ( ) ; it . remove ( ) ; } } } 
< T > T withSearcher ( final ViewSignature viewSignature , final boolean staleOk , final SearcherCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexSearcher searcher = holder . borrowSearcher ( staleOk ) ; try { final String etag = Long . toHexString ( searcher . getIndexReader ( ) . getVersion ( ) ) ; 
public static void main ( final String [ ] args ) throws Exception { final Properties properties = new Properties ( ) ; final InputStream in = Main . class . getClassLoader ( ) . getResourceAsStream ( " couchdb-lucene.properties " ) ; if ( in = = null ) { System . out . println ( " No couchdb-lucene.properties file found. " ) ; return ; } properties . load ( in ) ; in . close ( ) ; final String luceneDir = properties . getProperty ( " lucene.dir " ) ; final int lucenePort = Integer . parseInt ( properties . getProperty ( " lucene.port " , " 5985 " ) ) ; final String couchUrl = properties . getProperty ( " couchdb.url " ) ; final boolean realtime = Boolean . parseBoolean ( properties . getProperty ( " lucene.realtime " , " false " ) ) ; if ( luceneDir = = null ) { LOG . error ( " lucene.dir not set. " ) ; System . exit ( 1 ) ; } if ( couchUrl = = null ) { LOG . error ( " couchdb.url not set. " ) ; System . exit ( 1 ) ; } Configure httpClient. final HttpParams params = new BasicHttpParams(); ConnManagerParams.setMaxTotalConnections(params, 1000); HttpProtocolParams.setVersion(params, HttpVersion.HTTP_1_1); HttpProtocolParams.setUserAgent(params, HttpProtocolParams.getUserAgent(params) + " couchdb-lucene/0.5"); final SchemeRegistry schemeRegistry = new SchemeRegistry(); schemeRegistry.register(new Scheme("http", PlainSocketFactory.getSocketFactory(), 5984)); final ClientConnectionManager cm = new ThreadSafeClientConnManager(params, schemeRegistry); final HttpClient httpClient = new DefaultHttpClient(cm, params); Configure other objects. final Couch couch = new Couch(httpClient, couchUrl); final Locator locator = new Locator(); final LuceneGateway gateway = new LuceneGateway(new File(luceneDir), realtime); final State state = new State(couch, gateway, locator, httpClient); Configure Indexer. final Indexer indexer = new Indexer(state); Configure Jetty. final Server server = new Server(Integer.getInteger("port", lucenePort)); server.setStopAtShutdown(true); server.setSendServerVersion(false); server.addLifeCycle(indexer); TODO deuglify this. RhinoDocument.state = state; final ContextHandlerCollection contexts = new ContextHandlerCollection(); server.setHandler(contexts); final Context search = new Context(contexts, "/search", Context.NO_SESSIONS); search.addServlet(new ServletHolder(new SearchServlet(state)), "/*"); setupContext(search); final Context info = new Context(contexts, "/info", Context.NO_SESSIONS); info.addServlet(new ServletHolder(new InfoServlet(state)), "/*"); setupContext(info); final Context admin = new Context(contexts, "/admin", Context.NO_SESSIONS); admin.addServlet(new ServletHolder(new AdminServlet(state)), "/*"); setupContext(admin); Lockdown System.setSecurityManager(securityManager); server.start(); server.join(); } 
private static void setupContext ( final Context context ) { context . addFilter ( new FilterHolder ( new GzipFilter ( ) ) , " /* " , Handler . DEFAULT ) ; } 
public T callback ( final IndexReader reader ) throws IOException ; } interface SearcherCallback < T > { public T callback ( final IndexSearcher searcher , final String etag ) throws IOException ; } interface WriterCallback < T > { public T callback ( final IndexWriter writer ) throws IOException ; } private final Map < ViewSignature , LuceneHolder > holders = new LinkedHashMap < ViewSignature , LuceneHolder > ( ) ; private final File baseDir ; private final boolean realtime ; private long lastUpdated ; LuceneGateway ( final File baseDir , final boolean realtime ) { this . baseDir = baseDir ; this . realtime = realtime ; this . lastUpdated = now ( ) ; } private synchronized LuceneHolder getHolder ( final ViewSignature viewSignature ) throws IOException { LuceneHolder result = holders . get ( viewSignature ) ; if ( result = = null ) { final File dir = viewSignature . toFile ( baseDir ) ; if ( ! dir . exists ( ) & & ! dir . mkdirs ( ) ) throw new IOException ( " Could not make " + dir ) ; result = new LuceneHolder ( FSDirectory . open ( dir ) , realtime ) ; holders . put ( viewSignature , result ) ; } return result ; } < T > T withReader ( final ViewSignature viewSignature , final boolean staleOk , final ReaderCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexReader reader = holder . borrowReader ( staleOk ) ; try { return callback . callback ( reader ) ; } finally { holder . returnReader ( reader ) ; } } < T > T withSearcher ( final ViewSignature viewSignature , final boolean staleOk , final SearcherCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexSearcher searcher = holder . borrowSearcher ( staleOk ) ; try { long version = realtime ? lastUpdated : searcher . getIndexReader ( ) . getVersion ( ) ; final String etag = Long . toHexString ( version ) ; return callback . callback ( searcher , etag ) ; } finally { holder . returnSearcher ( searcher ) ; } } < T > T withWriter ( final ViewSignature viewSignature , final WriterCallback < T > callback ) throws IOException { LuceneHolder holder = getHolder ( viewSignature ) ; final IndexWriter writer = holder . getIndexWriter ( ) ; try { final T result = callback . callback ( writer ) ; lastUpdated = now ( ) ; return result ; } catch ( final OutOfMemoryError e ) { synchronized ( holders ) { holder = holders . remove ( viewSignature ) ; holder . close ( ) ; } throw e ; } } synchronized void close ( ) throws IOException { final Iterator < LuceneHolder > it = holders . values ( ) . iterator ( ) ; while ( it . hasNext ( ) ) { it . next ( ) . close ( ) ; it . remove ( ) ; } } private long now ( ) { return System . nanoTime ( ) ; } } 
public T callback ( final IndexSearcher searcher , final String etag ) throws IOException ; } interface WriterCallback < T > { public T callback ( final IndexWriter writer ) throws IOException ; } private final Map < ViewSignature , LuceneHolder > holders = new LinkedHashMap < ViewSignature , LuceneHolder > ( ) ; private final File baseDir ; private final boolean realtime ; private long lastUpdated ; LuceneGateway ( final File baseDir , final boolean realtime ) { this . baseDir = baseDir ; this . realtime = realtime ; this . lastUpdated = now ( ) ; } private synchronized LuceneHolder getHolder ( final ViewSignature viewSignature ) throws IOException { LuceneHolder result = holders . get ( viewSignature ) ; if ( result = = null ) { final File dir = viewSignature . toFile ( baseDir ) ; if ( ! dir . exists ( ) & & ! dir . mkdirs ( ) ) throw new IOException ( " Could not make " + dir ) ; result = new LuceneHolder ( FSDirectory . open ( dir ) , realtime ) ; holders . put ( viewSignature , result ) ; } return result ; } < T > T withReader ( final ViewSignature viewSignature , final boolean staleOk , final ReaderCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexReader reader = holder . borrowReader ( staleOk ) ; try { return callback . callback ( reader ) ; } finally { holder . returnReader ( reader ) ; } } < T > T withSearcher ( final ViewSignature viewSignature , final boolean staleOk , final SearcherCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexSearcher searcher = holder . borrowSearcher ( staleOk ) ; try { long version = realtime ? lastUpdated : searcher . getIndexReader ( ) . getVersion ( ) ; final String etag = Long . toHexString ( version ) ; return callback . callback ( searcher , etag ) ; } finally { holder . returnSearcher ( searcher ) ; } } < T > T withWriter ( final ViewSignature viewSignature , final WriterCallback < T > callback ) throws IOException { LuceneHolder holder = getHolder ( viewSignature ) ; final IndexWriter writer = holder . getIndexWriter ( ) ; try { final T result = callback . callback ( writer ) ; lastUpdated = now ( ) ; return result ; } catch ( final OutOfMemoryError e ) { synchronized ( holders ) { holder = holders . remove ( viewSignature ) ; holder . close ( ) ; } throw e ; } } synchronized void close ( ) throws IOException { final Iterator < LuceneHolder > it = holders . values ( ) . iterator ( ) ; while ( it . hasNext ( ) ) { it . next ( ) . close ( ) ; it . remove ( ) ; } } private long now ( ) { return System . nanoTime ( ) ; } } 
public T callback ( final IndexWriter writer ) throws IOException ; } private final Map < ViewSignature , LuceneHolder > holders = new LinkedHashMap < ViewSignature , LuceneHolder > ( ) ; private final File baseDir ; private final boolean realtime ; private long lastUpdated ; LuceneGateway ( final File baseDir , final boolean realtime ) { this . baseDir = baseDir ; this . realtime = realtime ; this . lastUpdated = now ( ) ; } private synchronized LuceneHolder getHolder ( final ViewSignature viewSignature ) throws IOException { LuceneHolder result = holders . get ( viewSignature ) ; if ( result = = null ) { final File dir = viewSignature . toFile ( baseDir ) ; if ( ! dir . exists ( ) & & ! dir . mkdirs ( ) ) throw new IOException ( " Could not make " + dir ) ; result = new LuceneHolder ( FSDirectory . open ( dir ) , realtime ) ; holders . put ( viewSignature , result ) ; } return result ; } < T > T withReader ( final ViewSignature viewSignature , final boolean staleOk , final ReaderCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexReader reader = holder . borrowReader ( staleOk ) ; try { return callback . callback ( reader ) ; } finally { holder . returnReader ( reader ) ; } } < T > T withSearcher ( final ViewSignature viewSignature , final boolean staleOk , final SearcherCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexSearcher searcher = holder . borrowSearcher ( staleOk ) ; try { long version = realtime ? lastUpdated : searcher . getIndexReader ( ) . getVersion ( ) ; final String etag = Long . toHexString ( version ) ; return callback . callback ( searcher , etag ) ; } finally { holder . returnSearcher ( searcher ) ; } } < T > T withWriter ( final ViewSignature viewSignature , final WriterCallback < T > callback ) throws IOException { LuceneHolder holder = getHolder ( viewSignature ) ; final IndexWriter writer = holder . getIndexWriter ( ) ; try { final T result = callback . callback ( writer ) ; lastUpdated = now ( ) ; return result ; } catch ( final OutOfMemoryError e ) { synchronized ( holders ) { holder = holders . remove ( viewSignature ) ; holder . close ( ) ; } throw e ; } } synchronized void close ( ) throws IOException { final Iterator < LuceneHolder > it = holders . values ( ) . iterator ( ) ; while ( it . hasNext ( ) ) { it . next ( ) . close ( ) ; it . remove ( ) ; } } private long now ( ) { return System . nanoTime ( ) ; } } 
< T > T withSearcher ( final ViewSignature viewSignature , final boolean staleOk , final SearcherCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexSearcher searcher = holder . borrowSearcher ( staleOk ) ; try { long version = realtime ? lastUpdated : searcher . getIndexReader ( ) . getVersion ( ) ; 
< T > T withWriter ( final ViewSignature viewSignature , final WriterCallback < T > callback ) throws IOException { LuceneHolder holder = getHolder ( viewSignature ) ; final IndexWriter writer = holder . getIndexWriter ( ) ; try { final T result = callback . callback ( writer ) ; 
public static void main ( final String [ ] args ) throws Exception { final Properties properties = new Properties ( ) ; final InputStream in = Main . class . getClassLoader ( ) . getResourceAsStream ( " couchdb-lucene.properties " ) ; if ( in = = null ) { System . out . println ( " No couchdb-lucene.properties file found. " ) ; return ; } properties . load ( in ) ; in . close ( ) ; final String luceneDir = properties . getProperty ( " lucene.dir " ) ; final int lucenePort = Integer . parseInt ( properties . getProperty ( " lucene.port " , " 5985 " ) ) ; final String couchUrl = properties . getProperty ( " couchdb.url " ) ; final boolean realtime = Boolean . parseBoolean ( properties . getProperty ( " lucene.realtime " , " false " ) ) ; if ( luceneDir = = null ) { LOG . error ( " lucene.dir not set. " ) ; System . exit ( 1 ) ; } if ( couchUrl = = null ) { LOG . error ( " couchdb.url not set. " ) ; System . exit ( 1 ) ; } Configure httpClient. final HttpParams params = new BasicHttpParams(); ConnManagerParams.setMaxTotalConnections(params, 1000); HttpProtocolParams.setVersion(params, HttpVersion.HTTP_1_1); HttpProtocolParams.setUserAgent(params, HttpProtocolParams.getUserAgent(params) + " couchdb-lucene/0.5"); HttpProtocolParams.setUseExpectContinue(params, false); final SchemeRegistry schemeRegistry = new SchemeRegistry(); schemeRegistry.register(new Scheme("http", PlainSocketFactory.getSocketFactory(), 5984)); final ClientConnectionManager cm = new ThreadSafeClientConnManager(params, schemeRegistry); final HttpClient httpClient = new DefaultHttpClient(cm, params); Configure other objects. final Couch couch = new Couch(httpClient, couchUrl); final Locator locator = new Locator(); final LuceneGateway gateway = new LuceneGateway(new File(luceneDir), realtime); final State state = new State(couch, gateway, locator, httpClient); Configure Indexer. final Indexer indexer = new Indexer(state); Configure Jetty. final Server server = new Server(Integer.getInteger("port", lucenePort)); server.setStopAtShutdown(true); server.setSendServerVersion(false); server.addLifeCycle(indexer); TODO deuglify this. RhinoDocument.state = state; final ContextHandlerCollection contexts = new ContextHandlerCollection(); server.setHandler(contexts); final Context search = new Context(contexts, "/search", Context.NO_SESSIONS); search.addServlet(new ServletHolder(new SearchServlet(state)), "/*"); setupContext(search); final Context info = new Context(contexts, "/info", Context.NO_SESSIONS); info.addServlet(new ServletHolder(new InfoServlet(state)), "/*"); setupContext(info); final Context admin = new Context(contexts, "/admin", Context.NO_SESSIONS); admin.addServlet(new ServletHolder(new AdminServlet(state)), "/*"); setupContext(admin); Lockdown System.setSecurityManager(securityManager); server.start(); server.join(); } 
private void search ( final boolean realtime , final int expectedCount ) throws IOException { gateway = new LuceneGateway ( dir , realtime ) ; gateway . withWriter ( sig , new WriterCallback < Void > ( ) { @Override public Void callback ( final IndexWriter writer ) throws IOException { writer . addDocument ( doc ) ; return null ; } } ) ; final int count = gateway . withSearcher ( sig , ! realtime , new SearcherCallback < Integer > ( ) { @Override public Integer callback ( final IndexSearcher searcher , final String etag ) throws IOException { return searcher . search ( new TermQuery ( new Term ( " id " , " 12 " ) ) , 1 ) . totalHits ; } } ) ; assertThat ( count , is ( expectedCount ) ) ; } 
public Integer callback ( final IndexSearcher searcher , final String etag ) throws IOException { return searcher . search ( new TermQuery ( new Term ( " id " , " 12 " ) ) , 1 ) . totalHits ; } 
private void readCheckpoints ( ) throws IOException { long since = Long . MAX_VALUE ; for ( final ViewSignature sig : functions . keySet ( ) ) { since = Math . min ( since , state . lucene . withReader ( sig , false , new ReaderCallback < Long > ( ) { public Long callback ( final IndexReader reader ) throws IOException { final Map < String , String > commitUserData = reader . getCommitUserData ( ) ; final String result = commitUserData . get ( " update_seq " ) ; return result ! = null ? Long . parseLong ( result ) : 0 L ; } } ) ) ; } logger . trace ( " Existing indexes at update_seq " + since ) ; } 
private void commitDocuments ( ) throws IOException { final Map < String , String > commitUserData = new HashMap < String , String > ( ) ; commitUserData . put ( " update_seq " , Long . toString ( since ) ) ; for ( final ViewSignature sig : functions . keySet ( ) ) { state . lucene . withWriter ( sig , new WriterCallback < Void > ( ) { public Void callback ( final IndexWriter writer ) throws IOException { if ( pendingCommit ) { logger . trace ( " Committing changes to " + sig ) ; writer . commit ( commitUserData ) ; } return null ; } } ) ; } pendingCommit = false ; } 
private void addDocument ( final ViewSignature sig , final Term id , final RhinoDocument doc , final Analyzer analyzer ) throws IOException { state . lucene . withWriter ( sig , new WriterCallback < Void > ( ) { public Void callback ( final IndexWriter writer ) throws IOException { 
public static void jsFunction_attachment ( final Context cx , final Scriptable thisObj , final Object [ ] args , final Function funObj ) throws IOException { final RhinoDocument doc = checkInstance ( thisObj ) ; if ( args . length < 2 ) { throw Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } final String dbname = ( String ) cx . getThreadLocal ( " dbname " ) ; final String docid = ( String ) cx . getThreadLocal ( " docid " ) ; final String field = args [ 0 ] . toString ( ) ; final String attname = args [ 1 ] . toString ( ) ; final String url = state . couch . url ( String . format ( " %s/%s/%s " , dbname , Utils . urlEncode ( docid ) , Utils . urlEncode ( attname ) ) ) ; final HttpGet get = new HttpGet ( url ) ; final ResponseHandler < Void > responseHandler = new ResponseHandler < Void > ( ) { public Void handleResponse ( final HttpResponse response ) throws ClientProtocolException , IOException { final HttpEntity entity = response . getEntity ( ) ; final InputStream in = entity . getContent ( ) ; try { TIKA . parse ( in , entity . getContentType ( ) . getValue ( ) , field , doc . doc ) ; } finally { in . close ( ) ; } return null ; } } ; state . httpClient . execute ( get , responseHandler ) ; } 
private void search ( final boolean realtime , final int expectedCount ) throws IOException { gateway = new LuceneGateway ( dir , realtime ) ; gateway . withWriter ( sig , new WriterCallback < Void > ( ) { public Void callback ( final IndexWriter writer ) throws IOException { writer . addDocument ( doc ) ; return null ; } } ) ; final int count = gateway . withSearcher ( sig , ! realtime , new SearcherCallback < Integer > ( ) { public Integer callback ( final IndexSearcher searcher , final String etag ) throws IOException { return searcher . search ( new TermQuery ( new Term ( " id " , " 12 " ) ) , 1 ) . totalHits ; } } ) ; assertThat ( count , is ( expectedCount ) ) ; } 
protected void doStart ( ) throws Exception { executor = Executors . newCachedThreadPool ( ) ; scheduler = Executors . newScheduledThreadPool ( 1 ) ; scheduler . scheduleWithFixedDelay ( new CouchPoller ( ) , 0 , 60 , TimeUnit . SECONDS ) ; } 
public static void main ( final String [ ] args ) throws Exception { final Properties properties = new Properties ( ) ; final InputStream in = Main . class . getClassLoader ( ) . getResourceAsStream ( " couchdb-lucene.properties " ) ; if ( in = = null ) { System . out . println ( " No couchdb-lucene.properties file found. " ) ; return ; } properties . load ( in ) ; in . close ( ) ; final String luceneDir = properties . getProperty ( " lucene.dir " ) ; final int lucenePort = Integer . parseInt ( properties . getProperty ( " lucene.port " , " 5985 " ) ) ; final String couchUrl = properties . getProperty ( " couchdb.url " ) ; final boolean realtime = Boolean . parseBoolean ( properties . getProperty ( " lucene.realtime " , " false " ) ) ; if ( luceneDir = = null ) { LOG . error ( " lucene.dir not set. " ) ; System . exit ( 1 ) ; } if ( couchUrl = = null ) { LOG . error ( " couchdb.url not set. " ) ; System . exit ( 1 ) ; } Configure httpClient. final HttpParams params = new BasicHttpParams(); ConnManagerParams.setMaxTotalConnections(params, 1000); HttpProtocolParams.setVersion(params, HttpVersion.HTTP_1_1); HttpProtocolParams.setUseExpectContinue(params, false); final SchemeRegistry schemeRegistry = new SchemeRegistry(); schemeRegistry.register(new Scheme("http", PlainSocketFactory.getSocketFactory(), 5984)); final ClientConnectionManager cm = new ThreadSafeClientConnManager(params, schemeRegistry); final HttpClient httpClient = new DefaultHttpClient(cm, params); Configure other objects. final Couch couch = new Couch(httpClient, couchUrl); final Locator locator = new Locator(); final LuceneGateway gateway = new LuceneGateway(new File(luceneDir), realtime); final State state = new State(couch, gateway, locator, httpClient); Configure Indexer. final Indexer indexer = new Indexer(state); Configure Jetty. final Server server = new Server(Integer.getInteger("port", lucenePort)); server.setStopAtShutdown(true); server.setSendServerVersion(false); server.addLifeCycle(indexer); TODO deuglify this. RhinoDocument.state = state; final ContextHandlerCollection contexts = new ContextHandlerCollection(); server.setHandler(contexts); final Context search = new Context(contexts, "/search", Context.NO_SESSIONS); search.addServlet(new ServletHolder(new SearchServlet(state)), "/*"); setupContext(search); final Context info = new Context(contexts, "/info", Context.NO_SESSIONS); info.addServlet(new ServletHolder(new InfoServlet(state)), "/*"); setupContext(info); final Context admin = new Context(contexts, "/admin", Context.NO_SESSIONS); admin.addServlet(new ServletHolder(new AdminServlet(state)), "/*"); setupContext(admin); Lockdown System.setSecurityManager(securityManager); server.start(); server.join(); } 
public Void callback ( final IndexWriter writer ) throws IOException { final Document d = doc . toDocument ( ) ; d . add ( Utils . token ( " _id " , id . text ( ) , true ) ) ; writer . updateDocument ( id , d , analyzer ) ; pendingCommit = true ; return null ; } 
private boolean mapDesignDocument ( final JSONObject designDocument ) { final String designDocumentName = designDocument . getString ( " _id " ) . substring ( 8 ) ; final JSONObject fulltext = designDocument . getJSONObject ( " fulltext " ) ; boolean isLuceneEnabled = false ; if ( fulltext ! = null ) { for ( final Object obj : fulltext . keySet ( ) ) { final String viewName = ( String ) obj ; final JSONObject viewValue = fulltext . getJSONObject ( viewName ) ; final JSONObject defaults = viewValue . has ( " defaults " ) ? viewValue . getJSONObject ( " defaults " ) : defaults ( ) ; final Analyzer analyzer = Analyzers . getAnalyzer ( viewValue . optString ( " analyzer " , " standard " ) ) ; final String function = viewValue . getString ( " index " ) ; final ViewSignature sig = state . locator . update ( databaseName , designDocumentName , viewName , fulltext . toString ( ) ) ; functions . put ( sig , new ViewTuple ( defaults , analyzer , context . compileFunction ( scope , function , viewName , 0 , null ) ) ) ; isLuceneEnabled = true ; } } return isLuceneEnabled ; } 
private JSONObject defaults ( ) { final JSONObject result = new JSONObject ( ) ; result . put ( " field " , Constants . DEFAULT_FIELD ) ; result . put ( " store " , " no " ) ; result . put ( " index " , " analyzed " ) ; result . put ( " type " , " string " ) ; return result ; } 
private void updateDocument ( final JSONObject doc ) { for ( final Entry < ViewSignature , ViewTuple > entry : functions . entrySet ( ) ) { final RhinoContext rhinoContext = new RhinoContext ( ) ; 
public static void main ( final String [ ] args ) throws Exception { final Properties properties = new Properties ( ) ; final InputStream in = Main . class . getClassLoader ( ) . getResourceAsStream ( " couchdb-lucene.properties " ) ; if ( in = = null ) { System . out . println ( " No couchdb-lucene.properties file found. " ) ; return ; } properties . load ( in ) ; in . close ( ) ; final String luceneDir = properties . getProperty ( " lucene.dir " ) ; final int lucenePort = Integer . parseInt ( properties . getProperty ( " lucene.port " , " 5985 " ) ) ; final String couchUrl = properties . getProperty ( " couchdb.url " ) ; final boolean realtime = Boolean . parseBoolean ( properties . getProperty ( " lucene.realtime " , " false " ) ) ; if ( luceneDir = = null ) { LOG . error ( " lucene.dir not set. " ) ; System . exit ( 1 ) ; } if ( couchUrl = = null ) { LOG . error ( " couchdb.url not set. " ) ; System . exit ( 1 ) ; } Configure httpClient. final HttpParams params = new BasicHttpParams(); ConnManagerParams.setMaxTotalConnections(params, 1000); HttpProtocolParams.setVersion(params, HttpVersion.HTTP_1_1); HttpProtocolParams.setUseExpectContinue(params, false); final SchemeRegistry schemeRegistry = new SchemeRegistry(); schemeRegistry.register(new Scheme("http", PlainSocketFactory.getSocketFactory(), 5984)); final ClientConnectionManager cm = new ThreadSafeClientConnManager(params, schemeRegistry); final HttpClient httpClient = new DefaultHttpClient(cm, params); Configure other objects. final Couch couch = new Couch(httpClient, couchUrl); final Locator locator = new Locator(); final LuceneGateway gateway = new LuceneGateway(new File(luceneDir), realtime); final Tika tika = new Tika(); final State state = new State(couch, gateway, locator, httpClient, tika); Configure Indexer. final Indexer indexer = new Indexer(state); Configure Jetty. final Server server = new Server(Integer.getInteger("port", lucenePort)); server.setStopAtShutdown(true); server.setSendServerVersion(false); server.addLifeCycle(indexer); final ContextHandlerCollection contexts = new ContextHandlerCollection(); server.setHandler(contexts); final Context search = new Context(contexts, "/search", Context.NO_SESSIONS); search.addServlet(new ServletHolder(new SearchServlet(state)), "/*"); setupContext(search); final Context info = new Context(contexts, "/info", Context.NO_SESSIONS); info.addServlet(new ServletHolder(new InfoServlet(state)), "/*"); setupContext(info); final Context admin = new Context(contexts, "/admin", Context.NO_SESSIONS); admin.addServlet(new ServletHolder(new AdminServlet(state)), "/*"); setupContext(admin); Lockdown System.setSecurityManager(securityManager); server.start(); server.join(); } 
public static void jsFunction_add ( final Context cx , final Scriptable thisObj , final Object [ ] args , final Function funObj ) { final RhinoDocument doc = checkInstance ( thisObj ) ; if ( args . length < 1 | | args . length > 2 ) { throw Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } if ( args [ 0 ] = = null ) { throw Context . reportRuntimeError ( " first argument must be non-null. " ) ; } if ( args . length = = 2 & & ( args [ 1 ] = = null | | args [ 1 ] instanceof NativeObject = = false ) ) { throw Context . reportRuntimeError ( " second argument must be an object. " ) ; } final RhinoField field = new RhinoField ( ) ; field . value = args [ 0 ] ; if ( args . length = = 2 ) { field . settings = ( NativeObject ) args [ 1 ] ; } doc . fields . add ( field ) ; } 
public void addDocument ( final RhinoContext context , final IndexWriter out ) throws IOException { final Document doc = new Document ( ) ; Add id. doc.add(Utils.token("_id", context.documentId, true)); Add user-supplied fields. for (final RhinoField field : fields) { addField(field, context, doc); } Parse user-requested attachments. for (final RhinoAttachment attachment : attachments) { addAttachment(attachment, context, doc); } out.updateDocument(new Term("_id", context.documentId), doc, context.analyzer); } 
private void addField ( final RhinoField field , final RhinoContext context , final Document out ) { String fieldName = context . defaults . optString ( " field " , Constants . DEFAULT_FIELD ) ; String store = context . defaults . optString ( " store " , " no " ) ; String index = context . defaults . optString ( " index " , " analyzed " ) ; String type = context . defaults . optString ( " type " , " string " ) ; Check for local settings. if (field.settings != null) { fieldName = optString(field.settings, "field", fieldName); store = optString(field.settings, "store", store); index = optString(field.settings, "index", index); type = optString(field.settings, "type", type); } final Field.Store storeObj = Store.get(store); if ("int".equals(type)) { out.add(new NumericField(fieldName, storeObj, true).setIntValue(Conversion.convert(field.value, Integer.class))); 
private void addAttachment ( final RhinoAttachment attachment , final RhinoContext context , final Document out ) throws IOException { final String url = context . state . couch . url ( String . format ( " %s/%s/%s " , context . databaseName , Utils . urlEncode ( context . documentId ) , Utils . urlEncode ( attachment . attachmentName ) ) ) ; final HttpGet get = new HttpGet ( url ) ; final ResponseHandler < Void > responseHandler = new ResponseHandler < Void > ( ) { public Void handleResponse ( final HttpResponse response ) throws ClientProtocolException , IOException { final HttpEntity entity = response . getEntity ( ) ; final InputStream in = entity . getContent ( ) ; try { context . state . tika . parse ( in , entity . getContentType ( ) . getValue ( ) , attachment . fieldName , out ) ; } finally { in . close ( ) ; } return null ; } } ; context . state . httpClient . execute ( get , responseHandler ) ; } 
public Void handleResponse ( final HttpResponse response ) throws ClientProtocolException , IOException { final HttpEntity entity = response . getEntity ( ) ; final InputStream in = entity . getContent ( ) ; try { context . state . tika . parse ( in , entity . getContentType ( ) . getValue ( ) , attachment . fieldName , out ) ; } finally { in . close ( ) ; } return null ; } 
public static void jsFunction_attachment ( final Context cx , final Scriptable thisObj , final Object [ ] args , final Function funObj ) throws IOException { final RhinoDocument doc = checkInstance ( thisObj ) ; if ( args . length < 2 ) { throw Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } final RhinoAttachment attachment = new RhinoAttachment ( ) ; attachment . fieldName = args [ 0 ] . toString ( ) ; attachment . attachmentName = args [ 1 ] . toString ( ) ; doc . attachments . add ( attachment ) ; } 
private void readCheckpoints ( ) throws IOException { long since = Long . MAX_VALUE ; for ( final ViewSignature sig : functions . keySet ( ) ) { since = Math . min ( since , state . lucene . withReader ( sig , false , new ReaderCallback < Long > ( ) { public Long callback ( final IndexReader reader ) throws IOException { final Map < String , String > commitUserData = reader . getCommitUserData ( ) ; final String result = commitUserData . get ( " update_seq " ) ; return result ! = null ? Long . parseLong ( result ) : 0 L ; } } ) ) ; } this . since = since ; logger . debug ( " Existing indexes at update_seq " + since ) ; } 
private void commitDocuments ( ) throws IOException { final Map < String , String > commitUserData = new HashMap < String , String > ( ) ; commitUserData . put ( " update_seq " , Long . toString ( since ) ) ; for ( final ViewSignature sig : functions . keySet ( ) ) { state . lucene . withWriter ( sig , new WriterCallback < Void > ( ) { public Void callback ( final IndexWriter writer ) throws IOException { if ( pendingCommit ) { logger . debug ( " Committing changes to " + sig + " at update seq " + since ) ; writer . commit ( commitUserData ) ; } return null ; } } ) ; } pendingCommit = false ; } 
public Void callback ( final IndexWriter writer ) throws IOException { if ( pendingCommit ) { logger . debug ( " Committing changes to " + sig + " at update seq " + since ) ; writer . commit ( commitUserData ) ; } return null ; } 
private void commitDocuments ( ) throws IOException { final Map < String , String > commitUserData = new HashMap < String , String > ( ) ; commitUserData . put ( " update_seq " , Long . toString ( since ) ) ; for ( final ViewSignature sig : functions . keySet ( ) ) { final String uuid = state . lucene . withReader ( sig , false , new ReaderCallback < String > ( ) { public String callback ( final IndexReader reader ) throws IOException { final String result = ( String ) reader . getCommitUserData ( ) . get ( " uuid " ) ; return result ! = null ? result : UUID . randomUUID ( ) . toString ( ) ; } } ) ; commitUserData . put ( " uuid " , uuid ) ; state . lucene . withWriter ( sig , new WriterCallback < Void > ( ) { public Void callback ( final IndexWriter writer ) throws IOException { if ( pendingCommit ) { logger . debug ( " Committing changes to " + sig + " with " + commitUserData ) ; writer . commit ( commitUserData ) ; } return null ; } } ) ; } pendingCommit = false ; } 
public String callback ( final IndexReader reader ) throws IOException { final String result = ( String ) reader . getCommitUserData ( ) . get ( " uuid " ) ; return result ! = null ? result : UUID . randomUUID ( ) . toString ( ) ; } 
public Void callback ( final IndexWriter writer ) throws IOException { if ( pendingCommit ) { logger . debug ( " Committing changes to " + sig + " with " + commitUserData ) ; writer . commit ( commitUserData ) ; } return null ; } 
private void updateIndexes ( ) throws IOException { final String url = state . couch . url ( String . format ( " %s/_changes? " + " feed=continuous& " + " since=%d& " + " include_docs=true& " + " imeout= " + POLL_TIMEOUT , databaseName , since ) ) ; state . httpClient . execute ( new HttpGet ( url ) , new ChangesResponseHandler ( ) ) ; } 
public Void callback ( final IndexWriter writer ) throws IOException { writer . deleteDocuments ( new Term ( " _id " , doc . getString ( " _id " ) ) ) ; setPendingCommit ( true ) ; return null ; } 
private void commitDocuments ( ) throws IOException { final JSONObject tracker = fetchTrackingDocument ( ) ; tracker . put ( " update_seq " , since ) ; for ( final ViewSignature sig : functions . keySet ( ) ) { Fetch or generate index uuid. final String uuid = state.lucene.withReader(sig, true, new ReaderCallback<String>() { public String callback(final IndexReader reader) throws IOException { final String result = (String) reader.getCommitUserData().get("uuid"); return result != null ? result : UUID.randomUUID().toString(); } }); tracker.put(sig.toString(), uuid); Tell Lucene. state.lucene.withWriter(sig, new WriterCallback<Void>() { public Void callback(final IndexWriter writer) throws IOException { final Map<String, String> commitUserData = new HashMap<String, String>(); commitUserData.put("update_seq", Long.toString(since)); commitUserData.put("uuid", uuid); logger.debug("Committing changes to " + sig + " with " + commitUserData); writer.commit(commitUserData); return null; } }); } Tell Couch. state.couch.saveDocument(databaseName, "_local/lucene", tracker.toString()); setPendingCommit(false); } 
public Void callback ( final IndexWriter writer ) throws IOException { final Map < String , String > commitUserData = new HashMap < String , String > ( ) ; commitUserData . put ( " update_seq " , Long . toString ( since ) ) ; commitUserData . put ( " uuid " , uuid ) ; logger . debug ( " Committing changes to " + sig + " with " + commitUserData ) ; writer . commit ( commitUserData ) ; return null ; } 
private JSONObject fetchTrackingDocument ( ) throws IOException { try { return state . couch . getDoc ( databaseName , " _local/lucene " ) ; 
private boolean hasPendingCommit ( final boolean ignoreTimeout ) { if ( ignoreTimeout ) return pendingCommit ; if ( ! pendingCommit ) return false ; return ( now ( ) - pendingSince ) > = COMMIT_INTERVAL ; } 
private boolean mapDesignDocument ( final JSONObject designDocument ) { final String designDocumentName = designDocument . getString ( " _id " ) . substring ( 8 ) ; final JSONObject fulltext = designDocument . getJSONObject ( " fulltext " ) ; boolean isLuceneEnabled = false ; if ( fulltext ! = null ) { for ( final Object obj : fulltext . keySet ( ) ) { final String viewName = ( String ) obj ; final JSONObject viewValue = fulltext . getJSONObject ( viewName ) ; final JSONObject defaults = viewValue . has ( " defaults " ) ? viewValue . getJSONObject ( " defaults " ) : defaults ( ) ; final Analyzer analyzer = Analyzers . getAnalyzer ( viewValue . optString ( " analyzer " , " standard " ) ) ; String function = viewValue . getString ( " index " ) ; function = function . replaceFirst ( " ^ \" " , " " ) ; function = function . replaceFirst ( " \" $ " , " " ) ; final ViewSignature sig = state . locator . update ( databaseName , designDocumentName , viewName , viewValue . toString ( ) ) ; functions . put ( sig , new ViewTuple ( defaults , analyzer , context . compileFunction ( scope , function , viewName , 0 , null ) ) ) ; isLuceneEnabled = true ; } } return isLuceneEnabled ; } 
private void commitDocuments ( ) throws IOException { final JSONObject tracker = fetchTrackingDocument ( ) ; tracker . put ( " update_seq " , since ) ; for ( final ViewSignature sig : functions . keySet ( ) ) { Fetch or generate index uuid. final String uuid = state.lucene.withReader(sig, true, new ReaderCallback<String>() { public String callback(final IndexReader reader) throws IOException { final String result = (String) reader.getCommitUserData().get("uuid"); return result != null ? result : UUID.randomUUID().toString(); } }); tracker.put(sig.toString(), uuid); Tell Lucene. state.lucene.withWriter(sig, new WriterCallback<Void>() { public Void callback(final IndexWriter writer) throws IOException { final Map<String, String> commitUserData = new HashMap<String, String>(); commitUserData.put("update_seq", Long.toString(since)); commitUserData.put("uuid", uuid); logger.debug("Committing changes to " + sig + " with " + commitUserData); commit data is not written if there are no documents. if (writer.maxDoc() ==0) { writer.addDocument(new Document()); } writer.commit(commitUserData); return null; } }); } Tell Couch. state.couch.saveDocument(databaseName, "_local/lucene", tracker.toString()); setPendingCommit(false); } 
public Void callback ( final IndexWriter writer ) throws IOException { final Map < String , String > commitUserData = new HashMap < String , String > ( ) ; commitUserData . put ( " update_seq " , Long . toString ( since ) ) ; commitUserData . put ( " uuid " , uuid ) ; logger . debug ( " Committing changes to " + sig + " with " + commitUserData ) ; commit data is not written if there are no documents. if (writer.maxDoc() ==0) { writer.addDocument(new Document()); } writer.commit(commitUserData); return null; } 
static Couch getInstance ( final HttpClient client , final String url ) throws IOException { final HttpGet get = new HttpGet ( url ) ; final ResponseHandler < String > handler = new ResponseHandler < String > ( ) { public String handleResponse ( final HttpResponse response ) throws ClientProtocolException , IOException { return response . getFirstHeader ( " Server " ) . getValue ( ) ; } } ; final String server = client . execute ( get , handler ) ; if ( server . contains ( " CouchDB/0.11 " ) ) { LOG . info ( " CouchDB 0.11 detected. " ) ; return new CouchV11 ( client , url ) ; } if ( server . contains ( " CouchDB/0.10 " ) ) { LOG . info ( " CouchDB 0.10 detected. " ) ; return new CouchV10 ( client , url ) ; } throw new UnsupportedOperationException ( " No support for " + server ) ; } 
public String handleResponse ( final HttpResponse response ) throws ClientProtocolException , IOException { return response . getFirstHeader ( " Server " ) . getValue ( ) ; } 
public abstract JSONObject getChanges ( final String dbname , final long since , final boolean includeDocs ) throws IOException ; public abstract JSONObject getChanges ( final String dbname , final long since , final boolean includeDocs , final int limit ) throws IOException ; public JSONObject getDoc ( final String dbname , final String id ) throws IOException { return JSONObject . fromObject ( get ( String . format ( " %s/%s " , Utils . urlEncode ( dbname ) , id ) ) ) ; } public JSONObject getDocs ( final String dbname , final String . . . ids ) throws IOException { final JSONArray keys = new JSONArray ( ) ; for ( final String id : ids ) { keys . add ( id ) ; } final JSONObject req = new JSONObject ( ) ; req . element ( " keys " , keys ) ; return JSONObject . fromObject ( post ( String . format ( " %s/_all_docs?include_docs=true " , Utils . urlEncode ( dbname ) ) , req . toString ( ) ) ) ; } public JSONObject getInfo ( final String dbname ) throws IOException { return JSONObject . fromObject ( get ( Utils . urlEncode ( dbname ) ) ) ; } public boolean saveDocument ( final String dbname , final String id , final String body ) throws IOException { return put ( String . format ( " %s/%s " , Utils . urlEncode ( dbname ) , id ) , body ) = = 201 ; } private int delete ( final String path ) throws IOException { final HttpDelete delete = new HttpDelete ( url ( path ) ) ; return httpClient . execute ( delete , new StatusCodeResponseHandler ( ) ) ; } private String execute ( final HttpUriRequest request ) throws IOException { return httpClient . execute ( request , new BasicResponseHandler ( ) ) ; } protected final String get ( final String path ) throws IOException { return execute ( new HttpGet ( url ( path ) ) ) ; } private String post ( final String path , final String body ) throws IOException { final HttpPost post = new HttpPost ( url ( path ) ) ; post . setEntity ( new StringEntity ( body ) ) ; return execute ( post ) ; } private int put ( final String path , final String body ) throws IOException { final HttpPut put = new HttpPut ( url ( path ) ) ; if ( body ! = null ) { put . setHeader ( " Content-Type " , Constants . CONTENT_TYPE ) ; put . setEntity ( new StringEntity ( body ) ) ; } return httpClient . execute ( put , new StatusCodeResponseHandler ( ) ) ; } String url ( final String path ) { return String . format ( " %s/%s " , url , path ) ; } } nfinal class CouchV10 extends Couch { public CouchV10 ( HttpClient httpClient , String url ) { super ( httpClient , url ) ; } public JSONObject getChanges ( final String dbname , final long since , final boolean includeDocs ) throws IOException { return JSONObject . fromObject ( get ( String . format ( " %s/_all_docs_by_seq?startkey=%d&include_docs=%b " , Utils . urlEncode ( dbname ) , since , includeDocs ) ) ) ; } public JSONObject getChanges ( final String dbname , final long since , final boolean includeDocs , final int limit ) throws IOException { return JSONObject . fromObject ( get ( String . format ( " %s/_all_docs_by_seq?startkey=%d&include_docs=%b&limit=%d " , Utils . urlEncode ( dbname ) , since , includeDocs , limit ) ) ) ; } } nfinal class CouchV11 extends Couch { public CouchV11 ( HttpClient httpClient , String url ) { super ( httpClient , url ) ; } public JSONObject getChanges ( final String dbname , final long since , final boolean includeDocs ) throws IOException { return JSONObject . fromObject ( get ( String . format ( " %s/_changes?since=%d&include_docs=%b " , Utils . urlEncode ( dbname ) , since , includeDocs ) ) ) ; } public JSONObject getChanges ( final String dbname , final long since , final boolean includeDocs , final int limit ) throws IOException { return JSONObject . fromObject ( get ( String . format ( " %s/_changes?since=%d&include_docs=%b&limit=%d " , Utils . urlEncode ( dbname ) , since , includeDocs , limit ) ) ) ; } } 
public abstract JSONObject getChanges ( final String dbname , final long since , final boolean includeDocs , final int limit ) throws IOException ; public JSONObject getDoc ( final String dbname , final String id ) throws IOException { return JSONObject . fromObject ( get ( String . format ( " %s/%s " , Utils . urlEncode ( dbname ) , id ) ) ) ; } public JSONObject getDocs ( final String dbname , final String . . . ids ) throws IOException { final JSONArray keys = new JSONArray ( ) ; for ( final String id : ids ) { keys . add ( id ) ; } final JSONObject req = new JSONObject ( ) ; req . element ( " keys " , keys ) ; return JSONObject . fromObject ( post ( String . format ( " %s/_all_docs?include_docs=true " , Utils . urlEncode ( dbname ) ) , req . toString ( ) ) ) ; } public JSONObject getInfo ( final String dbname ) throws IOException { return JSONObject . fromObject ( get ( Utils . urlEncode ( dbname ) ) ) ; } public boolean saveDocument ( final String dbname , final String id , final String body ) throws IOException { return put ( String . format ( " %s/%s " , Utils . urlEncode ( dbname ) , id ) , body ) = = 201 ; } private int delete ( final String path ) throws IOException { final HttpDelete delete = new HttpDelete ( url ( path ) ) ; return httpClient . execute ( delete , new StatusCodeResponseHandler ( ) ) ; } private String execute ( final HttpUriRequest request ) throws IOException { return httpClient . execute ( request , new BasicResponseHandler ( ) ) ; } protected final String get ( final String path ) throws IOException { return execute ( new HttpGet ( url ( path ) ) ) ; } private String post ( final String path , final String body ) throws IOException { final HttpPost post = new HttpPost ( url ( path ) ) ; post . setEntity ( new StringEntity ( body ) ) ; return execute ( post ) ; } private int put ( final String path , final String body ) throws IOException { final HttpPut put = new HttpPut ( url ( path ) ) ; if ( body ! = null ) { put . setHeader ( " Content-Type " , Constants . CONTENT_TYPE ) ; put . setEntity ( new StringEntity ( body ) ) ; } return httpClient . execute ( put , new StatusCodeResponseHandler ( ) ) ; } String url ( final String path ) { return String . format ( " %s/%s " , url , path ) ; } } nfinal class CouchV10 extends Couch { public CouchV10 ( HttpClient httpClient , String url ) { super ( httpClient , url ) ; } public JSONObject getChanges ( final String dbname , final long since , final boolean includeDocs ) throws IOException { return JSONObject . fromObject ( get ( String . format ( " %s/_all_docs_by_seq?startkey=%d&include_docs=%b " , Utils . urlEncode ( dbname ) , since , includeDocs ) ) ) ; } public JSONObject getChanges ( final String dbname , final long since , final boolean includeDocs , final int limit ) throws IOException { return JSONObject . fromObject ( get ( String . format ( " %s/_all_docs_by_seq?startkey=%d&include_docs=%b&limit=%d " , Utils . urlEncode ( dbname ) , since , includeDocs , limit ) ) ) ; } } nfinal class CouchV11 extends Couch { public CouchV11 ( HttpClient httpClient , String url ) { super ( httpClient , url ) ; } public JSONObject getChanges ( final String dbname , final long since , final boolean includeDocs ) throws IOException { return JSONObject . fromObject ( get ( String . format ( " %s/_changes?since=%d&include_docs=%b " , Utils . urlEncode ( dbname ) , since , includeDocs ) ) ) ; } public JSONObject getChanges ( final String dbname , final long since , final boolean includeDocs , final int limit ) throws IOException { return JSONObject . fromObject ( get ( String . format ( " %s/_changes?since=%d&include_docs=%b&limit=%d " , Utils . urlEncode ( dbname ) , since , includeDocs , limit ) ) ) ; } } 
protected final String get ( final String path ) throws IOException { return execute ( new HttpGet ( url ( path ) ) ) ; } 
public JSONObject getChanges ( final String dbname , final long since , final boolean includeDocs ) throws IOException { return JSONObject . fromObject ( get ( String . format ( " %s/_all_docs_by_seq?startkey=%d&include_docs=%b " , Utils . urlEncode ( dbname ) , since , includeDocs ) ) ) ; 
public JSONObject getChanges ( final String dbname , final long since , final boolean includeDocs , final int limit ) throws IOException { return JSONObject . fromObject ( get ( String . format ( " %s/_all_docs_by_seq?startkey=%d&include_docs=%b&limit=%d " , Utils . urlEncode ( dbname ) , since , includeDocs , limit ) ) ) ; 
static Couch getInstance ( final HttpClient client , final String url ) throws IOException { final HttpGet get = new HttpGet ( url ) ; final ResponseHandler < String > handler = new ResponseHandler < String > ( ) { public String handleResponse ( final HttpResponse response ) throws ClientProtocolException , IOException { return response . getFirstHeader ( " Server " ) . getValue ( ) ; } } ; final String server = client . execute ( get , handler ) ; if ( server . contains ( " CouchDB/0.11 " ) ) { LOG . info ( " CouchDB 0.11 detected. " ) ; return new CouchV11 ( client , url ) ; } if ( server . contains ( " CouchDB/0.10 " ) ) { LOG . info ( " CouchDB 0.10 detected. " ) ; return new CouchV10 ( client , url ) ; } TODO support 0.9.0 and 0.9.1 throw new UnsupportedOperationException("No support for " + server); } 
synchronized IndexReader borrowReader ( final boolean staleOk ) throws IOException { if ( ! staleOk ) { reopenReader ( ) ; lastOpened = now ( ) ; } reader . incRef ( ) ; return reader ; } 
public T callback ( final IndexReader reader ) throws IOException ; } interface SearcherCallback < T > { public T callback ( final IndexSearcher searcher , final String etag ) throws IOException ; } interface WriterCallback < T > { public T callback ( final IndexWriter writer ) throws IOException ; } private final Map < ViewSignature , LuceneHolder > holders = new LinkedHashMap < ViewSignature , LuceneHolder > ( ) ; private final File baseDir ; private final boolean realtime ; LuceneGateway ( final File baseDir , final boolean realtime ) { this . baseDir = baseDir ; this . realtime = realtime ; } private synchronized LuceneHolder getHolder ( final ViewSignature viewSignature ) throws IOException { LuceneHolder result = holders . get ( viewSignature ) ; if ( result = = null ) { final File dir = viewSignature . toFile ( baseDir ) ; if ( ! dir . exists ( ) & & ! dir . mkdirs ( ) ) throw new IOException ( " Could not make " + dir ) ; result = new LuceneHolder ( FSDirectory . open ( dir ) , realtime ) ; holders . put ( viewSignature , result ) ; } return result ; } < T > T withReader ( final ViewSignature viewSignature , final boolean staleOk , final ReaderCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexReader reader = holder . borrowReader ( staleOk ) ; try { return callback . callback ( reader ) ; } finally { holder . returnReader ( reader ) ; } } < T > T withSearcher ( final ViewSignature viewSignature , final boolean staleOk , final SearcherCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexSearcher searcher = holder . borrowSearcher ( staleOk ) ; try { return callback . callback ( searcher , holder . getETag ( staleOk ) ) ; } finally { holder . returnSearcher ( searcher ) ; } } < T > T withWriter ( final ViewSignature viewSignature , final WriterCallback < T > callback ) throws IOException { LuceneHolder holder = getHolder ( viewSignature ) ; final IndexWriter writer = holder . getIndexWriter ( ) ; try { final T result = callback . callback ( writer ) ; holder . lastUpdated = now ( ) ; return result ; } catch ( final OutOfMemoryError e ) { synchronized ( holders ) { holder = holders . remove ( viewSignature ) ; holder . close ( ) ; } throw e ; } } synchronized void close ( ) throws IOException { final Iterator < LuceneHolder > it = holders . values ( ) . iterator ( ) ; while ( it . hasNext ( ) ) { it . next ( ) . close ( ) ; it . remove ( ) ; } } private static long now ( ) { return System . nanoTime ( ) ; } } 
public T callback ( final IndexSearcher searcher , final String etag ) throws IOException ; } interface WriterCallback < T > { public T callback ( final IndexWriter writer ) throws IOException ; } private final Map < ViewSignature , LuceneHolder > holders = new LinkedHashMap < ViewSignature , LuceneHolder > ( ) ; private final File baseDir ; private final boolean realtime ; LuceneGateway ( final File baseDir , final boolean realtime ) { this . baseDir = baseDir ; this . realtime = realtime ; } private synchronized LuceneHolder getHolder ( final ViewSignature viewSignature ) throws IOException { LuceneHolder result = holders . get ( viewSignature ) ; if ( result = = null ) { final File dir = viewSignature . toFile ( baseDir ) ; if ( ! dir . exists ( ) & & ! dir . mkdirs ( ) ) throw new IOException ( " Could not make " + dir ) ; result = new LuceneHolder ( FSDirectory . open ( dir ) , realtime ) ; holders . put ( viewSignature , result ) ; } return result ; } < T > T withReader ( final ViewSignature viewSignature , final boolean staleOk , final ReaderCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexReader reader = holder . borrowReader ( staleOk ) ; try { return callback . callback ( reader ) ; } finally { holder . returnReader ( reader ) ; } } < T > T withSearcher ( final ViewSignature viewSignature , final boolean staleOk , final SearcherCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexSearcher searcher = holder . borrowSearcher ( staleOk ) ; try { return callback . callback ( searcher , holder . getETag ( staleOk ) ) ; } finally { holder . returnSearcher ( searcher ) ; } } < T > T withWriter ( final ViewSignature viewSignature , final WriterCallback < T > callback ) throws IOException { LuceneHolder holder = getHolder ( viewSignature ) ; final IndexWriter writer = holder . getIndexWriter ( ) ; try { final T result = callback . callback ( writer ) ; holder . lastUpdated = now ( ) ; return result ; } catch ( final OutOfMemoryError e ) { synchronized ( holders ) { holder = holders . remove ( viewSignature ) ; holder . close ( ) ; } throw e ; } } synchronized void close ( ) throws IOException { final Iterator < LuceneHolder > it = holders . values ( ) . iterator ( ) ; while ( it . hasNext ( ) ) { it . next ( ) . close ( ) ; it . remove ( ) ; } } private static long now ( ) { return System . nanoTime ( ) ; } } 
public T callback ( final IndexWriter writer ) throws IOException ; } private final Map < ViewSignature , LuceneHolder > holders = new LinkedHashMap < ViewSignature , LuceneHolder > ( ) ; private final File baseDir ; private final boolean realtime ; LuceneGateway ( final File baseDir , final boolean realtime ) { this . baseDir = baseDir ; this . realtime = realtime ; } private synchronized LuceneHolder getHolder ( final ViewSignature viewSignature ) throws IOException { LuceneHolder result = holders . get ( viewSignature ) ; if ( result = = null ) { final File dir = viewSignature . toFile ( baseDir ) ; if ( ! dir . exists ( ) & & ! dir . mkdirs ( ) ) throw new IOException ( " Could not make " + dir ) ; result = new LuceneHolder ( FSDirectory . open ( dir ) , realtime ) ; holders . put ( viewSignature , result ) ; } return result ; } < T > T withReader ( final ViewSignature viewSignature , final boolean staleOk , final ReaderCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexReader reader = holder . borrowReader ( staleOk ) ; try { return callback . callback ( reader ) ; } finally { holder . returnReader ( reader ) ; } } < T > T withSearcher ( final ViewSignature viewSignature , final boolean staleOk , final SearcherCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexSearcher searcher = holder . borrowSearcher ( staleOk ) ; try { return callback . callback ( searcher , holder . getETag ( staleOk ) ) ; } finally { holder . returnSearcher ( searcher ) ; } } < T > T withWriter ( final ViewSignature viewSignature , final WriterCallback < T > callback ) throws IOException { LuceneHolder holder = getHolder ( viewSignature ) ; final IndexWriter writer = holder . getIndexWriter ( ) ; try { final T result = callback . callback ( writer ) ; holder . lastUpdated = now ( ) ; return result ; } catch ( final OutOfMemoryError e ) { synchronized ( holders ) { holder = holders . remove ( viewSignature ) ; holder . close ( ) ; } throw e ; } } synchronized void close ( ) throws IOException { final Iterator < LuceneHolder > it = holders . values ( ) . iterator ( ) ; while ( it . hasNext ( ) ) { it . next ( ) . close ( ) ; it . remove ( ) ; } } private static long now ( ) { return System . nanoTime ( ) ; } } 
< T > T withSearcher ( final ViewSignature viewSignature , final boolean staleOk , final SearcherCallback < T > callback ) throws IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexSearcher searcher = holder . borrowSearcher ( staleOk ) ; try { return callback . callback ( searcher , holder . getETag ( staleOk ) ) ; 
private boolean mapDesignDocument ( final JSONObject designDocument ) { final String designDocumentName = designDocument . getString ( " _id " ) . substring ( 8 ) ; final JSONObject fulltext = designDocument . getJSONObject ( " fulltext " ) ; boolean isLuceneEnabled = false ; if ( fulltext ! = null ) { for ( final Object obj : fulltext . keySet ( ) ) { final String viewName = ( String ) obj ; final JSONObject viewValue = fulltext . getJSONObject ( viewName ) ; final JSONObject defaults = viewValue . has ( " defaults " ) ? viewValue . getJSONObject ( " defaults " ) : defaults ( ) ; final Analyzer analyzer = Analyzers . getAnalyzer ( viewValue . optString ( " analyzer " , " standard " ) ) ; String function = viewValue . getString ( " index " ) ; function = function . replaceFirst ( " ^ \" " , " " ) ; function = function . replaceFirst ( " \" $ " , " " ) ; final ViewSignature sig = state . locator . update ( databaseName , designDocumentName , viewName , viewValue . toString ( ) ) ; functions . put ( sig , new ViewTuple ( defaults , analyzer , context . compileFunction ( scope , function , viewName , 0 , null ) ) ) ; isLuceneEnabled = true ; } } return isLuceneEnabled ; } 
private boolean updateIndexes ( ) throws IOException { final String url = state . couch . url ( String . format ( " %s/_changes? " + " feed=continuous& " + " since=%d& " + " include_docs=true& " + " imeout= " + POLL_TIMEOUT , databaseName , since ) ) ; return state . httpClient . execute ( new HttpGet ( url ) , new ChangesResponseHandler ( ) ) ; } 
private void commitDocuments ( ) throws IOException { final JSONObject tracker = fetchTrackingDocument ( databaseName ) ; tracker . put ( " update_seq " , since ) ; for ( final ViewSignature sig : functions . keySet ( ) ) { Fetch or generate index uuid. final String uuid = state.lucene.withReader(sig, true, new ReaderCallback<String>() { public String callback(final IndexReader reader) throws IOException { final String result = (String) reader.getCommitUserData().get("uuid"); return result != null ? result : UUID.randomUUID().toString(); } }); tracker.put(sig.toString(), uuid); Tell Lucene. state.lucene.withWriter(sig, new WriterCallback<Void>() { public Void callback(final IndexWriter writer) throws IOException { final Map<String, String> commitUserData = new HashMap<String, String>(); commitUserData.put("update_seq", Long.toString(since)); commitUserData.put("uuid", uuid); logger.debug("Committing changes to " + sig + " with " + commitUserData); commit data is not written if there are no documents. if (writer.maxDoc() == 0) { writer.addDocument(new Document()); } writer.commit(commitUserData); return null; } }); } Tell Couch. state.couch.saveDocument(databaseName, "_local/lucene", tracker.toString()); setPendingCommit(false); } 
public Void callback ( final IndexWriter writer ) throws IOException { final Map < String , String > commitUserData = new HashMap < String , String > ( ) ; commitUserData . put ( " update_seq " , Long . toString ( since ) ) ; commitUserData . put ( " uuid " , uuid ) ; logger . debug ( " Committing changes to " + sig + " with " + commitUserData ) ; commit data is not written if there are no documents. if (writer.maxDoc() == 0) { writer.addDocument(new Document()); } writer.commit(commitUserData); return null; } 
private JSONObject fetchTrackingDocument ( final String databaseName ) throws IOException { try { return state . couch . getDoc ( databaseName , " _local/lucene " ) ; 
private boolean mapDesignDocument ( final JSONObject designDocument ) { final String designDocumentName = designDocument . getString ( " _id " ) . substring ( 8 ) ; final JSONObject fulltext = designDocument . getJSONObject ( " fulltext " ) ; boolean isLuceneEnabled = false ; if ( fulltext ! = null ) { for ( final Object obj : fulltext . keySet ( ) ) { final String viewName = ( String ) obj ; final JSONObject viewValue = fulltext . getJSONObject ( viewName ) ; final JSONObject defaults = viewValue . has ( " defaults " ) ? viewValue . getJSONObject ( " defaults " ) : defaults ( ) ; final Analyzer analyzer = Analyzers . getAnalyzer ( viewValue . optString ( " analyzer " , " standard " ) ) ; String function = viewValue . getString ( " index " ) ; function = function . replaceFirst ( " ^ \" " , " " ) ; function = function . replaceFirst ( " \" $ " , " " ) ; final ViewSignature sig = state . locator . update ( databaseName , designDocumentName , viewName , viewValue . toString ( ) ) ; functions . put ( sig , new ViewTuple ( defaults , analyzer , context . compileFunction ( scope , function , viewName , 0 , null ) ) ) ; isLuceneEnabled = true ; } } return isLuceneEnabled ; } 
private String toPlan ( final Query query ) { final StringBuilder builder = new StringBuilder ( 300 ) ; toPlan ( builder , query ) ; return builder . toString ( ) ; } 
private void toPlan ( final StringBuilder builder , final Query query ) { builder . append ( query . getClass ( ) . getSimpleName ( ) ) ; builder . append ( " ( " ) ; if ( query instanceof TermQuery ) { planTermQuery ( builder , ( TermQuery ) query ) ; } else if ( query instanceof BooleanQuery ) { planBooleanQuery ( builder , ( BooleanQuery ) query ) ; } else if ( query instanceof TermRangeQuery ) { planTermRangeQuery ( builder , ( TermRangeQuery ) query ) ; } else if ( query instanceof PrefixQuery ) { planPrefixQuery ( builder , ( PrefixQuery ) query ) ; } builder . append ( " ,boost= " + query . getBoost ( ) + " ) " ) ; } 
private void planPrefixQuery ( final StringBuilder builder , final PrefixQuery query ) { builder . append ( query . getPrefix ( ) ) ; } 
private void planTermRangeQuery ( final StringBuilder builder , final TermRangeQuery query ) { builder . append ( query . getLowerTerm ( ) ) ; builder . append ( " TO " ) ; builder . append ( query . getUpperTerm ( ) ) ; } 
private void planTermQuery ( final StringBuilder builder , final TermQuery query ) { builder . append ( query . getTerm ( ) ) ; } 
private void addField ( final RhinoField field , final RhinoContext context , final Document out ) { String fieldName = context . defaults . optString ( " field " , Constants . DEFAULT_FIELD ) ; String store = context . defaults . optString ( " store " , " no " ) ; String index = context . defaults . optString ( " index " , " analyzed " ) ; String type = context . defaults . optString ( " type " , " string " ) ; Check for local settings. if (field.settings != null) { fieldName = optString(field.settings, "field", fieldName); store = optString(field.settings, "store", store); index = optString(field.settings, "index", index); type = optString(field.settings, "type", type); } final Field.Store storeObj = Store.get(store); if ("int".equals(type)) { out.add(new NumericField(fieldName, 4, storeObj, true).setIntValue(Conversion.convert(field.value, Integer.class))); 
private void toPlan ( final StringBuilder builder , final Query query ) { builder . append ( query . getClass ( ) . getSimpleName ( ) ) ; builder . append ( " ( " ) ; if ( query instanceof TermQuery ) { planTermQuery ( builder , ( TermQuery ) query ) ; } else if ( query instanceof BooleanQuery ) { planBooleanQuery ( builder , ( BooleanQuery ) query ) ; } else if ( query instanceof TermRangeQuery ) { planTermRangeQuery ( builder , ( TermRangeQuery ) query ) ; } else if ( query instanceof PrefixQuery ) { planPrefixQuery ( builder , ( PrefixQuery ) query ) ; } else if ( query instanceof WildcardQuery ) { planWildcardQuery ( builder , ( WildcardQuery ) query ) ; } builder . append ( " ,boost= " + query . getBoost ( ) + " ) " ) ; } 
private void planWildcardQuery ( final StringBuilder builder , final WildcardQuery query ) { builder . append ( query . getTerm ( ) ) ; } 
private void toPlan ( final StringBuilder builder , final Query query ) { builder . append ( query . getClass ( ) . getSimpleName ( ) ) ; builder . append ( " ( " ) ; if ( query instanceof TermQuery ) { planTermQuery ( builder , ( TermQuery ) query ) ; } else if ( query instanceof BooleanQuery ) { planBooleanQuery ( builder , ( BooleanQuery ) query ) ; } else if ( query instanceof TermRangeQuery ) { planTermRangeQuery ( builder , ( TermRangeQuery ) query ) ; } else if ( query instanceof PrefixQuery ) { planPrefixQuery ( builder , ( PrefixQuery ) query ) ; } else if ( query instanceof WildcardQuery ) { planWildcardQuery ( builder , ( WildcardQuery ) query ) ; } else if ( query instanceof FuzzyQuery ) { planFuzzyQuery ( builder , ( FuzzyQuery ) query ) ; } builder . append ( " ,boost= " + query . getBoost ( ) + " ) " ) ; } 
private void planFuzzyQuery ( final StringBuilder builder , final FuzzyQuery query ) { builder . append ( query . getTerm ( ) ) ; builder . append ( " ,prefixLength= " ) ; builder . append ( query . getPrefixLength ( ) ) ; builder . append ( " ,minSimilarity= " ) ; builder . append ( query . getMinSimilarity ( ) ) ; } 
private void readCheckpoints ( ) throws IOException { long since = Long . MAX_VALUE ; for ( final ViewSignature sig : functions . keySet ( ) ) { since = Math . min ( since , state . lucene . withReader ( sig , new ReaderCallback < Long > ( ) { public Long callback ( final IndexReader reader ) throws IOException { final Map < String , String > commitUserData = reader . getCommitUserData ( ) ; final String result = commitUserData . get ( " update_seq " ) ; return result ! = null ? Long . parseLong ( result ) : 0 L ; } } ) ) ; } this . since = since ; logger . debug ( " Existing indexes at update_seq " + since ) ; } 
private void commitDocuments ( ) throws IOException { final JSONObject tracker = fetchTrackingDocument ( databaseName ) ; tracker . put ( " update_seq " , since ) ; for ( final ViewSignature sig : functions . keySet ( ) ) { Fetch or generate index uuid. final String uuid = state.lucene.withReader(sig, new ReaderCallback<String>() { public String callback(final IndexReader reader) throws IOException { final String result = (String) reader.getCommitUserData().get("uuid"); return result != null ? result : UUID.randomUUID().toString(); } }); tracker.put(sig.toString(), uuid); Tell Lucene. state.lucene.withWriter(sig, new WriterCallback<Void>() { public Void callback(final IndexWriter writer) throws IOException { final Map<String, String> commitUserData = new HashMap<String, String>(); commitUserData.put("update_seq", Long.toString(since)); commitUserData.put("uuid", uuid); logger.debug("Committing changes to " + sig + " with " + commitUserData); commit data is not written if there are no documents. if (writer.maxDoc() == 0) { writer.addDocument(new Document()); } writer.commit(commitUserData); return null; } }); } Tell Couch. state.couch.saveDocument(databaseName, "_local/lucene", tracker.toString()); setPendingCommit(false); } 
public T callback ( final IndexReader reader ) throws IOException ; } interface SearcherCallback < T > { public T callback ( final IndexSearcher searcher , final String etag ) throws IOException ; } interface WriterCallback < T > { public T callback ( final IndexWriter writer ) throws IOException ; } private final File baseDir ; private static class Holder { private IndexWriter writer ; private String etag ; } private final Map < ViewSignature , Holder > holders = new HashMap < ViewSignature , Holder > ( ) ; LuceneGateway ( final File baseDir ) { this . baseDir = baseDir ; } private String newEtag ( ) { return Long . toHexString ( System . nanoTime ( ) ) ; } private synchronized Holder getHolder ( final ViewSignature viewSignature ) throws IOException { Holder result = holders . get ( viewSignature ) ; if ( result = = null ) { final File dir = viewSignature . toFile ( baseDir ) ; if ( ! dir . exists ( ) & & ! dir . mkdirs ( ) ) { throw new IOException ( " Could not make " + dir ) ; } result = new Holder ( ) ; result . writer = newWriter ( FSDirectory . open ( dir ) ) ; result . etag = newEtag ( ) ; holders . put ( viewSignature , result ) ; } return result ; } private IndexWriter newWriter ( final Directory dir ) throws IOException { final IndexWriter result = new IndexWriter ( dir , Constants . ANALYZER , MaxFieldLength . UNLIMITED ) ; result . setMergeFactor ( 5 ) ; return result ; } synchronized void close ( ) throws IOException { final Iterator < Holder > it = holders . values ( ) . iterator ( ) ; while ( it . hasNext ( ) ) { it . next ( ) . writer . rollback ( ) ; it . remove ( ) ; } } < T > T withReader ( final ViewSignature viewSignature , final ReaderCallback < T > callback ) throws IOException { return callback . callback ( getHolder ( viewSignature ) . writer . getReader ( ) ) ; } < T > T withSearcher ( final ViewSignature viewSignature , final SearcherCallback < T > callback ) throws IOException { final Holder holder = getHolder ( viewSignature ) ; return callback . callback ( new IndexSearcher ( holder . writer . getReader ( ) ) , holder . etag ) ; } < T > T withWriter ( final ViewSignature viewSignature , final WriterCallback < T > callback ) throws IOException { boolean oom = false ; try { return callback . callback ( getHolder ( viewSignature ) . writer ) ; } catch ( final OutOfMemoryError e ) { oom = true ; throw e ; } finally { synchronized ( this ) { if ( oom ) { holders . remove ( viewSignature ) . writer . rollback ( ) ; } else { getHolder ( viewSignature ) . etag = newEtag ( ) ; } } } } } 
public T callback ( final IndexSearcher searcher , final String etag ) throws IOException ; } interface WriterCallback < T > { public T callback ( final IndexWriter writer ) throws IOException ; } private final File baseDir ; private static class Holder { private IndexWriter writer ; private String etag ; } private final Map < ViewSignature , Holder > holders = new HashMap < ViewSignature , Holder > ( ) ; LuceneGateway ( final File baseDir ) { this . baseDir = baseDir ; } private String newEtag ( ) { return Long . toHexString ( System . nanoTime ( ) ) ; } private synchronized Holder getHolder ( final ViewSignature viewSignature ) throws IOException { Holder result = holders . get ( viewSignature ) ; if ( result = = null ) { final File dir = viewSignature . toFile ( baseDir ) ; if ( ! dir . exists ( ) & & ! dir . mkdirs ( ) ) { throw new IOException ( " Could not make " + dir ) ; } result = new Holder ( ) ; result . writer = newWriter ( FSDirectory . open ( dir ) ) ; result . etag = newEtag ( ) ; holders . put ( viewSignature , result ) ; } return result ; } private IndexWriter newWriter ( final Directory dir ) throws IOException { final IndexWriter result = new IndexWriter ( dir , Constants . ANALYZER , MaxFieldLength . UNLIMITED ) ; result . setMergeFactor ( 5 ) ; return result ; } synchronized void close ( ) throws IOException { final Iterator < Holder > it = holders . values ( ) . iterator ( ) ; while ( it . hasNext ( ) ) { it . next ( ) . writer . rollback ( ) ; it . remove ( ) ; } } < T > T withReader ( final ViewSignature viewSignature , final ReaderCallback < T > callback ) throws IOException { return callback . callback ( getHolder ( viewSignature ) . writer . getReader ( ) ) ; } < T > T withSearcher ( final ViewSignature viewSignature , final SearcherCallback < T > callback ) throws IOException { final Holder holder = getHolder ( viewSignature ) ; return callback . callback ( new IndexSearcher ( holder . writer . getReader ( ) ) , holder . etag ) ; } < T > T withWriter ( final ViewSignature viewSignature , final WriterCallback < T > callback ) throws IOException { boolean oom = false ; try { return callback . callback ( getHolder ( viewSignature ) . writer ) ; } catch ( final OutOfMemoryError e ) { oom = true ; throw e ; } finally { synchronized ( this ) { if ( oom ) { holders . remove ( viewSignature ) . writer . rollback ( ) ; } else { getHolder ( viewSignature ) . etag = newEtag ( ) ; } } } } } 
public T callback ( final IndexWriter writer ) throws IOException ; } private final File baseDir ; private static class Holder { private IndexWriter writer ; private String etag ; } private final Map < ViewSignature , Holder > holders = new HashMap < ViewSignature , Holder > ( ) ; LuceneGateway ( final File baseDir ) { this . baseDir = baseDir ; } private String newEtag ( ) { return Long . toHexString ( System . nanoTime ( ) ) ; } private synchronized Holder getHolder ( final ViewSignature viewSignature ) throws IOException { Holder result = holders . get ( viewSignature ) ; if ( result = = null ) { final File dir = viewSignature . toFile ( baseDir ) ; if ( ! dir . exists ( ) & & ! dir . mkdirs ( ) ) { throw new IOException ( " Could not make " + dir ) ; } result = new Holder ( ) ; result . writer = newWriter ( FSDirectory . open ( dir ) ) ; result . etag = newEtag ( ) ; holders . put ( viewSignature , result ) ; } return result ; } private IndexWriter newWriter ( final Directory dir ) throws IOException { final IndexWriter result = new IndexWriter ( dir , Constants . ANALYZER , MaxFieldLength . UNLIMITED ) ; result . setMergeFactor ( 5 ) ; return result ; } synchronized void close ( ) throws IOException { final Iterator < Holder > it = holders . values ( ) . iterator ( ) ; while ( it . hasNext ( ) ) { it . next ( ) . writer . rollback ( ) ; it . remove ( ) ; } } < T > T withReader ( final ViewSignature viewSignature , final ReaderCallback < T > callback ) throws IOException { return callback . callback ( getHolder ( viewSignature ) . writer . getReader ( ) ) ; } < T > T withSearcher ( final ViewSignature viewSignature , final SearcherCallback < T > callback ) throws IOException { final Holder holder = getHolder ( viewSignature ) ; return callback . callback ( new IndexSearcher ( holder . writer . getReader ( ) ) , holder . etag ) ; } < T > T withWriter ( final ViewSignature viewSignature , final WriterCallback < T > callback ) throws IOException { boolean oom = false ; try { return callback . callback ( getHolder ( viewSignature ) . writer ) ; } catch ( final OutOfMemoryError e ) { oom = true ; throw e ; } finally { synchronized ( this ) { if ( oom ) { holders . remove ( viewSignature ) . writer . rollback ( ) ; } else { getHolder ( viewSignature ) . etag = newEtag ( ) ; } } } } } 
private String newEtag ( ) { return Long . toHexString ( System . nanoTime ( ) ) ; } 
private synchronized Holder getHolder ( final ViewSignature viewSignature ) throws IOException { Holder result = holders . get ( viewSignature ) ; if ( result = = null ) { final File dir = viewSignature . toFile ( baseDir ) ; if ( ! dir . exists ( ) & & ! dir . mkdirs ( ) ) { throw new IOException ( " Could not make " + dir ) ; } result = new Holder ( ) ; result . writer = newWriter ( FSDirectory . open ( dir ) ) ; result . etag = newEtag ( ) ; holders . put ( viewSignature , result ) ; } return result ; } 
private IndexWriter newWriter ( final Directory dir ) throws IOException { final IndexWriter result = new IndexWriter ( dir , Constants . ANALYZER , MaxFieldLength . UNLIMITED ) ; result . setMergeFactor ( 5 ) ; return result ; } 
synchronized void close ( ) throws IOException { final Iterator < Holder > it = holders . values ( ) . iterator ( ) ; while ( it . hasNext ( ) ) { it . next ( ) . writer . rollback ( ) ; 
< T > T withReader ( final ViewSignature viewSignature , final ReaderCallback < T > callback ) throws IOException { return callback . callback ( getHolder ( viewSignature ) . writer . getReader ( ) ) ; } 
< T > T withSearcher ( final ViewSignature viewSignature , final SearcherCallback < T > callback ) throws IOException { final Holder holder = getHolder ( viewSignature ) ; return callback . callback ( new IndexSearcher ( holder . writer . getReader ( ) ) , holder . etag ) ; } 
< T > T withWriter ( final ViewSignature viewSignature , final WriterCallback < T > callback ) throws IOException { boolean oom = false ; try { return callback . callback ( getHolder ( viewSignature ) . writer ) ; 
static Couch getInstance ( final HttpClient client , final String url ) throws IOException { final HttpGet get = new HttpGet ( url ) ; final ResponseHandler < String > handler = new ResponseHandler < String > ( ) { public String handleResponse ( final HttpResponse response ) throws ClientProtocolException , IOException { return response . getFirstHeader ( " Server " ) . getValue ( ) ; } } ; final String server = client . execute ( get , handler ) ; if ( server . contains ( " CouchDB/0.11 " ) ) { LOG . info ( " CouchDB 0.11 detected. " ) ; return new CouchV11 ( client , url ) ; } if ( server . contains ( " CouchDB/0.10 " ) ) { LOG . info ( " CouchDB 0.10 detected. " ) ; return new CouchV10 ( client , url ) ; } if ( server . contains ( " CouchDB/0.9.1 " ) ) { LOG . info ( " CouchDB 0.9.1 detected. " ) ; return new CouchV10 ( client , url ) ; } throw new UnsupportedOperationException ( " No support for " + server ) ; } 
private static Query toQuery ( final HttpServletRequest req ) { Parse query. final Analyzer analyzer = Analyzers.getAnalyzer(getParameter(req, "analyzer", "standard")); final QueryParser parser = new QueryParser(Constants.DEFAULT_FIELD, analyzer); try { return fixup(parser.parse(req.getParameter("q"))); 
private static Object fixup ( final String value ) { if ( value . matches ( " \\ d+ \\ . \\ d+f " ) ) return Float . parseFloat ( value ) ; if ( value . matches ( " \\ d+ \\ . \\ d+ " ) ) return Double . parseDouble ( value ) ; if ( value . matches ( " \\ d+[lL] " ) ) return Long . parseLong ( value ) ; if ( value . matches ( " \\ d+ " ) ) return Integer . parseInt ( value ) ; return String . class ; } 
private void toPlan ( final StringBuilder builder , final Query query ) { builder . append ( query . getClass ( ) . getSimpleName ( ) ) ; builder . append ( " ( " ) ; if ( query instanceof TermQuery ) { planTermQuery ( builder , ( TermQuery ) query ) ; } else if ( query instanceof BooleanQuery ) { planBooleanQuery ( builder , ( BooleanQuery ) query ) ; } else if ( query instanceof TermRangeQuery ) { planTermRangeQuery ( builder , ( TermRangeQuery ) query ) ; } else if ( query instanceof PrefixQuery ) { planPrefixQuery ( builder , ( PrefixQuery ) query ) ; } else if ( query instanceof WildcardQuery ) { planWildcardQuery ( builder , ( WildcardQuery ) query ) ; } else if ( query instanceof FuzzyQuery ) { planFuzzyQuery ( builder , ( FuzzyQuery ) query ) ; } else if ( query instanceof NumericRangeQuery ) { planNumericRangeQuery ( builder , ( NumericRangeQuery ) query ) ; } builder . append ( " ,boost= " + query . getBoost ( ) + " ) " ) ; } 
private void planNumericRangeQuery ( final StringBuilder builder , final NumericRangeQuery query ) { builder . append ( query . getMin ( ) ) ; builder . append ( " TO " ) ; builder . append ( query . getMax ( ) ) ; builder . append ( " AS " ) ; builder . append ( query . getMin ( ) . getClass ( ) . getSimpleName ( ) ) ; } 
private void planWildcardQuery ( final StringBuilder builder , final WildcardQuery query ) { builder . append ( query . getTerm ( ) ) ; } 
private static Object fixup ( final String value ) { if ( value . matches ( " \\ d+ \\ . \\ d+f " ) ) return Float . parseFloat ( value ) ; if ( value . matches ( " \\ d+ \\ . \\ d+ " ) ) return Double . parseDouble ( value ) ; if ( value . matches ( " \\ d+[lL] " ) ) return Long . parseLong ( value . substring ( 0 , value . length ( ) - 1 ) ) ; if ( value . matches ( " \\ d+ " ) ) return Integer . parseInt ( value ) ; return String . class ; } 
private void commitDocuments ( ) throws IOException { final JSONObject tracker = fetchTrackingDocument ( database ) ; tracker . put ( " update_seq " , since ) ; for ( final ViewSignature sig : functions . keySet ( ) ) { Fetch or generate index uuid. final String uuid = state.lucene.withReader(sig, new ReaderCallback<String>() { public String callback(final IndexReader reader) throws IOException { final String result = (String) reader.getCommitUserData().get("uuid"); return result != null ? result : UUID.randomUUID().toString(); } }); tracker.put(sig.toString(), uuid); Tell Lucene. state.lucene.withWriter(sig, new WriterCallback<Void>() { public Void callback(final IndexWriter writer) throws IOException { final Map<String, String> commitUserData = new HashMap<String, String>(); commitUserData.put("update_seq", Long.toString(since)); commitUserData.put("uuid", uuid); logger.debug("Committing changes to " + sig + " with " + commitUserData); commit data is not written if there are no documents. if (writer.maxDoc() == 0) { writer.addDocument(new Document()); } writer.commit(commitUserData); return null; } }); } Tell Couch. database.saveDocument("_local/lucene", tracker.toString()); setPendingCommit(false); } 
private boolean hasPendingCommit ( final boolean ignoreTimeout ) { if ( ignoreTimeout ) { return pendingCommit ; } if ( ! pendingCommit ) { return false ; } return ( now ( ) - pendingSince ) > = COMMIT_INTERVAL ; } 
private boolean mapAllDesignDocuments ( ) throws IOException { final JSONArray designDocuments = database . getAllDesignDocuments ( databaseName ) ; boolean isLuceneEnabled = false ; for ( int i = 0 ; i < designDocuments . size ( ) ; i + + ) { isLuceneEnabled | = mapDesignDocument ( designDocuments . getJSONObject ( i ) . getJSONObject ( " doc " ) ) ; } return isLuceneEnabled ; } 
private boolean updateIndexes ( ) throws IOException { return database . handleChanges ( since , new ChangesResponseHandler ( ) ) ; } 
private JSONObject fetchTrackingDocument ( final Database database ) throws IOException { try { return database . getDocument ( " _local/lucene " ) ; 
public T callback ( final IndexReader reader ) throws IOException ; } interface SearcherCallback < T > { public T callback ( final IndexSearcher searcher , final String etag ) throws IOException ; } interface WriterCallback < T > { public T callback ( final IndexWriter writer ) throws IOException ; } private final File baseDir ; private final Map < ViewSignature , Holder > holders = new HashMap < ViewSignature , Holder > ( ) ; LuceneGateway ( final File baseDir ) { this . baseDir = baseDir ; } private synchronized Holder getHolder ( final ViewSignature viewSignature ) throws IOException { Holder result = holders . get ( viewSignature ) ; if ( result = = null ) { final File dir = viewSignature . toFile ( baseDir ) ; if ( ! dir . exists ( ) & & ! dir . mkdirs ( ) ) { throw new IOException ( " Could not make " + dir ) ; } result = new Holder ( ) ; result . writer = newWriter ( FSDirectory . open ( dir ) ) ; result . etag = newEtag ( ) ; holders . put ( viewSignature , result ) ; } return result ; } private String newEtag ( ) { return Long . toHexString ( System . nanoTime ( ) ) ; } private IndexWriter newWriter ( final Directory dir ) throws IOException { final IndexWriter result = new IndexWriter ( dir , Constants . ANALYZER , MaxFieldLength . UNLIMITED ) ; result . setMergeFactor ( 5 ) ; return result ; } synchronized void close ( ) throws IOException { final Iterator < Holder > it = holders . values ( ) . iterator ( ) ; while ( it . hasNext ( ) ) { it . next ( ) . writer . rollback ( ) ; it . remove ( ) ; } } < T > T withReader ( final ViewSignature viewSignature , final ReaderCallback < T > callback ) throws IOException { return callback . callback ( getHolder ( viewSignature ) . writer . getReader ( ) ) ; } < T > T withSearcher ( final ViewSignature viewSignature , final SearcherCallback < T > callback ) throws IOException { final Holder holder = getHolder ( viewSignature ) ; return callback . callback ( new IndexSearcher ( holder . writer . getReader ( ) ) , holder . etag ) ; } < T > T withWriter ( final ViewSignature viewSignature , final WriterCallback < T > callback ) throws IOException { boolean oom = false ; try { return callback . callback ( getHolder ( viewSignature ) . writer ) ; } catch ( final OutOfMemoryError e ) { oom = true ; throw e ; } finally { synchronized ( this ) { if ( oom ) { holders . remove ( viewSignature ) . writer . rollback ( ) ; } else { getHolder ( viewSignature ) . etag = newEtag ( ) ; } } } } } 
public T callback ( final IndexSearcher searcher , final String etag ) throws IOException ; } interface WriterCallback < T > { public T callback ( final IndexWriter writer ) throws IOException ; } private final File baseDir ; private final Map < ViewSignature , Holder > holders = new HashMap < ViewSignature , Holder > ( ) ; LuceneGateway ( final File baseDir ) { this . baseDir = baseDir ; } private synchronized Holder getHolder ( final ViewSignature viewSignature ) throws IOException { Holder result = holders . get ( viewSignature ) ; if ( result = = null ) { final File dir = viewSignature . toFile ( baseDir ) ; if ( ! dir . exists ( ) & & ! dir . mkdirs ( ) ) { throw new IOException ( " Could not make " + dir ) ; } result = new Holder ( ) ; result . writer = newWriter ( FSDirectory . open ( dir ) ) ; result . etag = newEtag ( ) ; holders . put ( viewSignature , result ) ; } return result ; } private String newEtag ( ) { return Long . toHexString ( System . nanoTime ( ) ) ; } private IndexWriter newWriter ( final Directory dir ) throws IOException { final IndexWriter result = new IndexWriter ( dir , Constants . ANALYZER , MaxFieldLength . UNLIMITED ) ; result . setMergeFactor ( 5 ) ; return result ; } synchronized void close ( ) throws IOException { final Iterator < Holder > it = holders . values ( ) . iterator ( ) ; while ( it . hasNext ( ) ) { it . next ( ) . writer . rollback ( ) ; it . remove ( ) ; } } < T > T withReader ( final ViewSignature viewSignature , final ReaderCallback < T > callback ) throws IOException { return callback . callback ( getHolder ( viewSignature ) . writer . getReader ( ) ) ; } < T > T withSearcher ( final ViewSignature viewSignature , final SearcherCallback < T > callback ) throws IOException { final Holder holder = getHolder ( viewSignature ) ; return callback . callback ( new IndexSearcher ( holder . writer . getReader ( ) ) , holder . etag ) ; } < T > T withWriter ( final ViewSignature viewSignature , final WriterCallback < T > callback ) throws IOException { boolean oom = false ; try { return callback . callback ( getHolder ( viewSignature ) . writer ) ; } catch ( final OutOfMemoryError e ) { oom = true ; throw e ; } finally { synchronized ( this ) { if ( oom ) { holders . remove ( viewSignature ) . writer . rollback ( ) ; } else { getHolder ( viewSignature ) . etag = newEtag ( ) ; } } } } } 
public T callback ( final IndexWriter writer ) throws IOException ; } private final File baseDir ; private final Map < ViewSignature , Holder > holders = new HashMap < ViewSignature , Holder > ( ) ; LuceneGateway ( final File baseDir ) { this . baseDir = baseDir ; } private synchronized Holder getHolder ( final ViewSignature viewSignature ) throws IOException { Holder result = holders . get ( viewSignature ) ; if ( result = = null ) { final File dir = viewSignature . toFile ( baseDir ) ; if ( ! dir . exists ( ) & & ! dir . mkdirs ( ) ) { throw new IOException ( " Could not make " + dir ) ; } result = new Holder ( ) ; result . writer = newWriter ( FSDirectory . open ( dir ) ) ; result . etag = newEtag ( ) ; holders . put ( viewSignature , result ) ; } return result ; } private String newEtag ( ) { return Long . toHexString ( System . nanoTime ( ) ) ; } private IndexWriter newWriter ( final Directory dir ) throws IOException { final IndexWriter result = new IndexWriter ( dir , Constants . ANALYZER , MaxFieldLength . UNLIMITED ) ; result . setMergeFactor ( 5 ) ; return result ; } synchronized void close ( ) throws IOException { final Iterator < Holder > it = holders . values ( ) . iterator ( ) ; while ( it . hasNext ( ) ) { it . next ( ) . writer . rollback ( ) ; it . remove ( ) ; } } < T > T withReader ( final ViewSignature viewSignature , final ReaderCallback < T > callback ) throws IOException { return callback . callback ( getHolder ( viewSignature ) . writer . getReader ( ) ) ; } < T > T withSearcher ( final ViewSignature viewSignature , final SearcherCallback < T > callback ) throws IOException { final Holder holder = getHolder ( viewSignature ) ; return callback . callback ( new IndexSearcher ( holder . writer . getReader ( ) ) , holder . etag ) ; } < T > T withWriter ( final ViewSignature viewSignature , final WriterCallback < T > callback ) throws IOException { boolean oom = false ; try { return callback . callback ( getHolder ( viewSignature ) . writer ) ; } catch ( final OutOfMemoryError e ) { oom = true ; throw e ; } finally { synchronized ( this ) { if ( oom ) { holders . remove ( viewSignature ) . writer . rollback ( ) ; } else { getHolder ( viewSignature ) . etag = newEtag ( ) ; } } } } } 
public static Scriptable jsConstructor ( final Context cx , final Object [ ] args , final Function ctorObj , final boolean inNewExpr ) { final RhinoDocument doc = new RhinoDocument ( ) ; if ( args . length > = 2 ) { jsFunction_add ( cx , doc , args , ctorObj ) ; } return doc ; } 
private static RhinoDocument checkInstance ( final Scriptable obj ) { if ( obj = = null | | ! ( obj instanceof RhinoDocument ) ) { throw Context . reportRuntimeError ( " called on incompatible object. " ) ; } return ( RhinoDocument ) obj ; } 
private void addAttachment ( final RhinoAttachment attachment , final RhinoContext context , final Document out ) throws IOException { final ResponseHandler < Void > handler = new ResponseHandler < Void > ( ) { public Void handleResponse ( final HttpResponse response ) throws ClientProtocolException , IOException { final HttpEntity entity = response . getEntity ( ) ; final InputStream in = entity . getContent ( ) ; try { context . state . tika . parse ( in , entity . getContentType ( ) . getValue ( ) , attachment . fieldName , out ) ; } finally { in . close ( ) ; } return null ; } } ; context . database . handleAttachment ( context . documentId , attachment . attachmentName , handler ) ; } 
private static Object fixup ( final String value ) { if ( value . matches ( " \\ d+ \\ . \\ d+f " ) ) { return Float . parseFloat ( value ) ; } if ( value . matches ( " \\ d+ \\ . \\ d+ " ) ) { return Double . parseDouble ( value ) ; } if ( value . matches ( " \\ d+[lL] " ) ) { return Long . parseLong ( value . substring ( 0 , value . length ( ) - 1 ) ) ; } if ( value . matches ( " \\ d+ " ) ) { return Integer . parseInt ( value ) ; } return String . class ; } 
public void parse ( final InputStream in , final String contentType , final String fieldName , final Document doc ) throws IOException { final AutoDetectParser parser = new AutoDetectParser ( ) ; final Metadata md = new Metadata ( ) ; md . set ( HttpHeaders . CONTENT_TYPE , contentType ) ; final Reader reader = new ParsingReader ( parser , in , md ) ; final String body ; try { try { body = IOUtils . toString ( reader ) ; } finally { reader . close ( ) ; } } catch ( final IOException e ) { log . warn ( " Failed to index an attachment. " , e ) ; return ; } Add body text. doc.add(text(fieldName, body, false)); Add DC attributes. addDublinCoreAttributes(md, doc); Detect language. final String language = LanguageIdentifier.identifyLanguage(body); if (language != null && language.length() > 0) { doc.add(text(DC + DublinCore.LANGUAGE, language, false)); 
public static Couch getInstance ( final HttpClient client , final String url ) throws IOException { final String version = getCouchVersion ( client , url ) ; if ( version . contains ( " CouchDB/0.11 " ) ) { LOG . info ( " CouchDB 0.11 detected. " ) ; return new CouchV11 ( client , url ) ; } if ( version . contains ( " CouchDB/0.10 " ) ) { LOG . info ( " CouchDB 0.10 detected. " ) ; return new CouchV10 ( client , url ) ; } if ( version . contains ( " CouchDB/0.9.1 " ) ) { LOG . info ( " CouchDB 0.9.1 detected. " ) ; return new CouchV10 ( client , url ) ; } throw new UnsupportedOperationException ( " No support for " + version ) ; } 
private static String getCouchVersion ( final HttpClient client , final String url ) throws IOException , ClientProtocolException { final ResponseHandler < String > handler = new ResponseHandler < String > ( ) { public String handleResponse ( final HttpResponse response ) throws ClientProtocolException , IOException { return response . getFirstHeader ( " Server " ) . getValue ( ) ; } } ; return client . execute ( new HttpGet ( url ) , handler ) ; } 
public final String [ ] getAllDatabases ( ) throws IOException { final String response = HttpUtils . get ( httpClient , url + " _all_dbs " ) ; final JSONArray arr = JSONArray . fromObject ( response ) ; return ( String [ ] ) arr . toArray ( new String [ 0 ] ) ; } 
public JSONObject getChanges ( final long since , final boolean includeDocs ) throws IOException { final String response = HttpUtils . get ( httpClient , url + " _all_docs_by_seq?startkey= " + since + " &include_docs= " + includeDocs ) ; return JSONObject . fromObject ( response ) ; } 
public JSONObject getChanges ( final long since , final boolean includeDocs , final int limit ) throws IOException { final String response = HttpUtils . get ( httpClient , url + " _all_docs_by_seq?startkey= " + since + " &include_docs= " + includeDocs + " &limit= " + limit ) ; return JSONObject . fromObject ( response ) ; } 
public < T > T handleChanges ( final long since , final ResponseHandler < T > handler ) throws IOException { throw new UnsupportedOperationException ( " handleChanges for 0.10 and earlier not supported. " ) ; } 
public JSONObject getChanges ( final long since , final boolean includeDocs ) throws IOException { final String response = HttpUtils . get ( httpClient , url + " _changes?since= " + since + " &include_docs= " + includeDocs ) ; return JSONObject . fromObject ( response ) ; } 
public JSONObject getChanges ( final long since , final boolean includeDocs , final int limit ) throws IOException { final String response = HttpUtils . get ( httpClient , url + " _changes?since= " + since + " &include_docs= " + includeDocs + " &limit= " + limit ) ; return JSONObject . fromObject ( response ) ; } 
public < T > T handleChanges ( final long since , final ResponseHandler < T > handler ) throws IOException { final HttpGet get = new HttpGet ( url + " _changes?feed=continuous&timeout=30000&include_docs=true&since= " + since ) ; return httpClient . execute ( get , handler ) ; } 
public final boolean create ( ) throws IOException { return HttpUtils . put ( httpClient , url , null ) = = 201 ; } 
public final boolean delete ( ) throws IOException { return HttpUtils . delete ( httpClient , url ) = = 201 ; } 
public JSONArray getAllDesignDocuments ( final String dbname ) throws IOException { return getDocuments ( " _design " , " _design0 " ) . getJSONArray ( " rows " ) ; } 
public abstract JSONObject getChanges ( final long since , final boolean includeDocs ) throws IOException ; public abstract JSONObject getChanges ( final long since , final boolean includeDocs , final int limit ) throws IOException ; public final JSONObject getDocument ( final String id ) throws IOException { final String response = HttpUtils . get ( httpClient , url + " / " + Utils . urlEncode ( id ) ) ; return JSONObject . fromObject ( response ) ; } public final JSONObject getDocuments ( final String . . . ids ) throws IOException { final JSONArray keys = new JSONArray ( ) ; for ( final String id : ids ) { keys . add ( id ) ; } final JSONObject req = new JSONObject ( ) ; req . element ( " keys " , keys ) ; final String response = HttpUtils . post ( httpClient , url + " _all_docs?include_docs=true " , req . toString ( ) ) ; return JSONObject . fromObject ( response ) ; } public final JSONObject getDocuments ( final String startkey , final String endkey ) throws IOException { return JSONObject . fromObject ( HttpUtils . get ( httpClient , String . format ( " %s/_all_docs?startkey=%%22%s%%22&endkey=%%22%s%%22&include_docs=true " , url , Utils . urlEncode ( startkey ) , Utils . urlEncode ( endkey ) ) ) ) ; } public final JSONObject getInfo ( ) throws IOException { return JSONObject . fromObject ( HttpUtils . get ( httpClient , url ) ) ; } public final < T > T handleAttachment ( final String doc , final String att , final ResponseHandler < T > handler ) throws IOException { final HttpGet get = new HttpGet ( url + " / " + Utils . urlEncode ( doc ) + " / " + Utils . urlEncode ( att ) ) ; return httpClient . execute ( get , handler ) ; } public abstract < T > T handleChanges ( final long since , final ResponseHandler < T > handler ) throws IOException ; public final boolean saveDocument ( final String id , final String body ) throws IOException { return HttpUtils . put ( httpClient , url + " / " + id , body ) = = 201 ; } } 
public abstract JSONObject getChanges ( final long since , final boolean includeDocs , final int limit ) throws IOException ; public final JSONObject getDocument ( final String id ) throws IOException { final String response = HttpUtils . get ( httpClient , url + " / " + Utils . urlEncode ( id ) ) ; return JSONObject . fromObject ( response ) ; } public final JSONObject getDocuments ( final String . . . ids ) throws IOException { final JSONArray keys = new JSONArray ( ) ; for ( final String id : ids ) { keys . add ( id ) ; } final JSONObject req = new JSONObject ( ) ; req . element ( " keys " , keys ) ; final String response = HttpUtils . post ( httpClient , url + " _all_docs?include_docs=true " , req . toString ( ) ) ; return JSONObject . fromObject ( response ) ; } public final JSONObject getDocuments ( final String startkey , final String endkey ) throws IOException { return JSONObject . fromObject ( HttpUtils . get ( httpClient , String . format ( " %s/_all_docs?startkey=%%22%s%%22&endkey=%%22%s%%22&include_docs=true " , url , Utils . urlEncode ( startkey ) , Utils . urlEncode ( endkey ) ) ) ) ; } public final JSONObject getInfo ( ) throws IOException { return JSONObject . fromObject ( HttpUtils . get ( httpClient , url ) ) ; } public final < T > T handleAttachment ( final String doc , final String att , final ResponseHandler < T > handler ) throws IOException { final HttpGet get = new HttpGet ( url + " / " + Utils . urlEncode ( doc ) + " / " + Utils . urlEncode ( att ) ) ; return httpClient . execute ( get , handler ) ; } public abstract < T > T handleChanges ( final long since , final ResponseHandler < T > handler ) throws IOException ; public final boolean saveDocument ( final String id , final String body ) throws IOException { return HttpUtils . put ( httpClient , url + " / " + id , body ) = = 201 ; } } 
public final JSONObject getDocument ( final String id ) throws IOException { final String response = HttpUtils . get ( httpClient , url + " / " + Utils . urlEncode ( id ) ) ; return JSONObject . fromObject ( response ) ; } 
public final JSONObject getDocuments ( final String . . . ids ) throws IOException { final JSONArray keys = new JSONArray ( ) ; for ( final String id : ids ) { keys . add ( id ) ; } final JSONObject req = new JSONObject ( ) ; req . element ( " keys " , keys ) ; final String response = HttpUtils . post ( httpClient , url + " _all_docs?include_docs=true " , req . toString ( ) ) ; return JSONObject . fromObject ( response ) ; } 
public final JSONObject getDocuments ( final String startkey , final String endkey ) throws IOException { return JSONObject . fromObject ( HttpUtils . get ( httpClient , String . format ( " %s/_all_docs?startkey=%%22%s%%22&endkey=%%22%s%%22&include_docs=true " , url , Utils . urlEncode ( startkey ) , Utils 
public final JSONObject getInfo ( ) throws IOException { return JSONObject . fromObject ( HttpUtils . get ( httpClient , url ) ) ; } 
public final < T > T handleAttachment ( final String doc , final String att , final ResponseHandler < T > handler ) throws IOException { final HttpGet get = new HttpGet ( url + " / " + Utils . urlEncode ( doc ) + " / " + Utils . urlEncode ( att ) ) ; return httpClient . execute ( get , handler ) ; } 
public abstract < T > T handleChanges ( final long since , final ResponseHandler < T > handler ) throws IOException ; public final boolean saveDocument ( final String id , final String body ) throws IOException { return HttpUtils . put ( httpClient , url + " / " + id , body ) = = 201 ; } } 
public final boolean saveDocument ( final String id , final String body ) throws IOException { return HttpUtils . put ( httpClient , url + " / " + id , body ) = = 201 ; } 
public static final int delete ( final HttpClient httpClient , final String url ) throws IOException { return httpClient . execute ( new HttpDelete ( url ) , new StatusCodeResponseHandler ( ) ) ; } 
public static final String execute ( final HttpClient httpClient , final HttpUriRequest request ) throws IOException { return httpClient . execute ( request , new BasicResponseHandler ( ) ) ; } 
public static final String get ( final HttpClient httpClient , final String url ) throws IOException { return execute ( httpClient , new HttpGet ( url ) ) ; } 
public static final String post ( final HttpClient httpClient , final String url , final String body ) throws IOException { final HttpPost post = new HttpPost ( url ) ; post . setEntity ( new StringEntity ( body ) ) ; return execute ( httpClient , post ) ; } 
public static final int put ( final HttpClient httpClient , final String url , final String body ) throws IOException { final HttpPut put = new HttpPut ( url ) ; if ( body ! = null ) { put . setHeader ( " Content-Type " , Constants . CONTENT_TYPE ) ; put . setEntity ( new StringEntity ( body ) ) ; } return httpClient . execute ( put , new StatusCodeResponseHandler ( ) ) ; } 
public static Object convert ( final Object obj ) { if ( obj instanceof NativeObject ) { return convertObject ( ( NativeObject ) obj ) ; } else if ( obj instanceof NativeArray ) { return convertArray ( ( NativeArray ) obj ) ; } return obj ; } 
private static Object convertArray ( final NativeArray arr ) { final int len = ( int ) arr . getLength ( ) ; final JSONArray result = new JSONArray ( ) ; for ( int i = 0 ; i < len ; i + + ) { Object value = arr . get ( i , null ) ; if ( value instanceof NativeObject ) { value = convertObject ( ( NativeObject ) value ) ; } if ( value instanceof NativeArray ) { value = convertArray ( ( NativeArray ) value ) ; } result . add ( value ) ; } return result ; } 
public String identify ( final InputStream is ) throws IOException { return identify ( is , null ) ; } 
public String identify ( final InputStream is , final String charset ) throws IOException { final ByteArrayOutputStream out = new ByteArrayOutputStream ( ) ; final byte [ ] buffer = new byte [ 2048 ] ; int len = 0 ; while ( ( ( len = is . read ( buffer ) ) ! = - 1 ) & & ( ( analyzeLength = = 0 ) | | ( out . size ( ) < analyzeLength ) ) ) { if ( analyzeLength ! = 0 ) { len = Math . min ( len , analyzeLength - out . size ( ) ) ; } out . write ( buffer , 0 , len ) ; } return identify ( ( charset = = null ) ? out . toString ( ) : out . toString ( charset ) ) ; } 
public String identify ( final String content ) { return identify ( new StringBuffer ( content ) ) ; } 
public String identify ( final StringBuffer content ) { StringBuffer text = content ; if ( ( analyzeLength > 0 ) & & ( content . length ( ) > analyzeLength ) ) { text = new StringBuffer ( ) . append ( content ) ; text . setLength ( analyzeLength ) ; } suspect . analyze ( text ) ; final Iterator iter = suspect . getSorted ( ) . iterator ( ) ; float topscore = Float . MIN_VALUE ; String lang = " " ; final HashMap scores = new HashMap ( ) ; NGramEntry searched = null ; while ( iter . hasNext ( ) ) { searched = ( NGramEntry ) iter . next ( ) ; final NGramEntry [ ] ngrams = ( NGramEntry [ ] ) ngramsIdx . get ( searched . getSeq ( ) ) ; if ( ngrams ! = null ) { for ( final NGramEntry ngram : ngrams ) { final NGramProfile profile = ngram . getProfile ( ) ; Float pScore = ( Float ) scores . get ( profile ) ; if ( pScore = = null ) { pScore = new Float ( 0 ) ; } float plScore = pScore . floatValue ( ) ; plScore + = ngram . getFrequency ( ) + searched . getFrequency ( ) ; scores . put ( profile , new Float ( plScore ) ) ; if ( plScore > topscore ) { topscore = plScore ; lang = profile . getName ( ) ; } } } } return lang ; } 
public char charAt ( final int index ) { return value [ index ] ; } 
public CharSequence subSequence ( final int start , final int end ) { return new String ( value , start , end - start ) ; } 
private void expandCapacity ( final int minimumCapacity ) { int newCapacity = ( value . length + 1 ) * 2 ; if ( newCapacity < 0 ) { newCapacity = Integer . MAX_VALUE ; } else if ( minimumCapacity > newCapacity ) { newCapacity = minimumCapacity ; } final char newValue [ ] = new char [ newCapacity ] ; System . arraycopy ( value , 0 , newValue , 0 , count ) ; value = newValue ; } 
QuickStringBuffer append ( final char c ) { final int newcount = count + 1 ; if ( newcount > value . length ) { expandCapacity ( newcount ) ; } value [ count + + ] = c ; return this ; } 
QuickStringBuffer append ( String str ) { if ( str = = null ) { str = String . valueOf ( str ) ; } final int len = str . length ( ) ; final int newcount = count + len ; if ( newcount > value . length ) { expandCapacity ( newcount ) ; } str . getChars ( 0 , len , value , count ) ; count = newcount ; return this ; } 
public int compareTo ( final Object o ) { final NGramEntry ngram = ( NGramEntry ) o ; final int diff = Float . compare ( ngram . getFrequency ( ) , frequency ) ; if ( diff ! = 0 ) { return diff ; 
public boolean equals ( final Object obj ) { NGramEntry ngram = null ; try { ngram = ( NGramEntry ) obj ; 
public static NGramProfile create ( final String name , final InputStream is , final String encoding ) { final NGramProfile newProfile = new NGramProfile ( name , ABSOLUTE_MIN_NGRAM_LENGTH , ABSOLUTE_MAX_NGRAM_LENGTH ) ; final BufferedInputStream bis = new BufferedInputStream ( is ) ; final byte buffer [ ] = new byte [ 4096 ] ; final StringBuffer text = new StringBuffer ( ) ; int len ; try { while ( ( len = bis . read ( buffer ) ) ! = - 1 ) { text . append ( new String ( buffer , 0 , len , encoding ) ) ; } } catch ( final IOException e ) { LOGGER . warn ( " Exception raised while creating profile. " , e ) ; } newProfile . analyze ( text ) ; return newProfile ; } 
public static void main ( final String args [ ] ) throws Exception { final String usage = " Usage: NGramProfile " + " [-create profilename filename encoding] " + " [-similarity file1 file2] " + " [-score profile-name filename encoding] " ; int command = 0 ; final int CREATE = 1 ; final int SIMILARITY = 2 ; final int SCORE = 3 ; String profilename = " " ; String filename = " " ; String filename2 = " " ; String encoding = " " ; if ( args . length = = 0 ) { System . err . println ( usage ) ; System . exit ( - 1 ) ; } for ( int i = 0 ; i < args . length ; i + + ) { parse command line if (args[i].equals("-create")) { found -create option command = CREATE; profilename = args[++i]; filename = args[++i]; encoding = args[++i]; } if (args[i].equals("-similarity")) { found -similarity option command = SIMILARITY; filename = args[++i]; filename2 = args[++i]; encoding = args[++i]; } if (args[i].equals("-score")) { found -Score option command = SCORE; profilename = args[++i]; filename = args[++i]; encoding = args[++i]; } } switch (command) { 
public void add ( final StringBuffer word ) { for ( int i = minLength ; ( i < = maxLength ) & & ( i < word . length ( ) ) ; i + + ) { add ( word , i ) ; 
public void add ( final Token ) { add ( new StringBuffer ( ) . append ( SEPARATOR ) . append ( . termText ( ) ) . append ( SEPARATOR ) ) ; } 
public void analyze ( final StringBuffer text ) { if ( ngrams ! = null ) { ngrams . clear ( ) ; sorted = null ; ngramcounts = null ; } word . clear ( ) . append ( SEPARATOR ) ; for ( int i = 0 ; i < text . length ( ) ; i + + ) { final char c = Character . toLowerCase ( text . charAt ( i ) ) ; if ( Character . isLetter ( c ) ) { add ( word . append ( c ) ) ; } else { found word boundary if (word.length() > 1) { we have a word! add(word.append(SEPARATOR)); word.clear().append(SEPARATOR); } } } if (word.length() > 1) { we have a word! add(word.append(SEPARATOR)); } normalize(); } 
public void load ( final InputStream is ) throws IOException { ngrams . clear ( ) ; ngramcounts = new int [ maxLength + 1 ] ; final BufferedReader reader = new BufferedReader ( new InputStreamReader ( is , " UTF-8 " ) ) ; String line = null ; while ( ( line = reader . readLine ( ) ) ! = null ) { # starts a comment line if (line.charAt(0) != '#') { final int spacepos = line.indexOf(' '); final String ngramsequence = line.substring(0, spacepos).trim(); final int len = ngramsequence.length(); if ((len >= minLength) && (len <= maxLength)) { final int ngramcount = Integer.parseInt(line.substring(spacepos + 1)); final NGramEntry en = new NGramEntry(ngramsequence, ngramcount); ngrams.put(en.getSeq(), en); ngramcounts[len] += ngramcount; } } } normalize(); } 
public String toString ( ) { final StringBuffer s = new StringBuffer ( ) . append ( " NGramProfile: " ) . append ( name ) . append ( " " ) ; final Iterator i = getSorted ( ) . iterator ( ) ; while ( i . hasNext ( ) ) { final NGramEntry entry = ( NGramEntry ) i . next ( ) ; s . append ( " [ " ) . append ( entry . seq ) . append ( " / " ) . append ( entry . count ) . append ( " / " ) . append ( entry . frequency ) . append ( " ] " ) ; } return s . toString ( ) ; } 
private void add ( final CharSequence cs ) { if ( cs . equals ( SEP_CHARSEQ ) ) { return ; } NGramEntry nge = ( NGramEntry ) ngrams . get ( cs ) ; if ( nge = = null ) { nge = new NGramEntry ( cs ) ; ngrams . put ( cs , nge ) ; } nge . inc ( ) ; } 
private void add ( final QuickStringBuffer word ) { final int wlen = word . length ( ) ; if ( wlen > = minLength ) { final int max = Math . min ( maxLength , wlen ) ; 
private void add ( final StringBuffer word , final int ) { for ( int i = 0 ; i < = word . length ( ) - ; i + + ) { add ( word . subSequence ( i , i + ) ) ; 
private void commitDocuments ( ) throws IOException { final JSONObject tracker = fetchTrackingDocument ( database ) ; tracker . put ( " update_seq " , since ) ; for ( final ViewSignature sig : functions . keySet ( ) ) { Fetch or generate index uuid. final String uuid = state.lucene.withReader(sig, new ReaderCallback<String>() { public String callback(final IndexReader reader) throws IOException { final String result = (String) reader.getCommitUserData().get("uuid"); return result != null ? result : UUID.randomUUID().toString(); } }); tracker.put(sig.toString(), uuid); Tell Lucene. state.lucene.withWriter(sig, new WriterCallback<Void>() { public Void callback(final IndexWriter writer) throws IOException { final Map<String, String> commitUserData = new HashMap<String, String>(); commitUserData.put("update_seq", Long.toString(since)); commitUserData.put("uuid", uuid); logger.debug("Committing changes to " + sig + " with " + commitUserData); if (writer.maxDoc() == 0) { writer.addDocument(new Document()); } writer.commit(commitUserData); return null; } }); } Tell Couch. database.saveDocument("_local/lucene", tracker.toString()); setPendingCommit(false); } 
public Void callback ( final IndexWriter writer ) throws IOException { final Map < String , String > commitUserData = new HashMap < String , String > ( ) ; commitUserData . put ( " update_seq " , Long . toString ( since ) ) ; commitUserData . put ( " uuid " , uuid ) ; logger . debug ( " Committing changes to " + sig + " with " + commitUserData ) ; if ( writer . maxDoc ( ) = = 0 ) { writer . addDocument ( new Document ( ) ) ; } writer . commit ( commitUserData ) ; return null ; } 
protected void doPost ( final HttpServletRequest req , final HttpServletResponse resp ) throws ServletException , IOException { final ViewSignature sig = state . locator . lookup ( req ) ; if ( sig = = null ) { resp . sendError ( 400 , " Invalid path. " ) ; return ; } final String command = req . getParameter ( " cmd " ) ; if ( " expunge " . equals ( command ) ) { state . lucene . withWriter ( sig , new WriterCallback < Void > ( ) { public Void callback ( final IndexWriter writer ) throws IOException { writer . expungeDeletes ( false ) ; return null ; } } ) ; resp . setStatus ( 202 ) ; return ; } if ( " optimize " . equals ( command ) ) { state . lucene . withWriter ( sig , new WriterCallback < Void > ( ) { public Void callback ( final IndexWriter writer ) throws IOException { writer . optimize ( false ) ; return null ; } } ) ; resp . setStatus ( 202 ) ; return ; } resp . sendError ( 400 , " Bad request " ) ; } 
private static void setupContext ( final Context context ) { context . addFilter ( new FilterHolder ( new GzipFilter ( ) ) , " /* " , Handler . DEFAULT ) ; context . setErrorHandler ( new JSONErrorHandler ( ) ) ; } 
public void onError ( final JSONObject error ) { if ( error . optString ( " reason " ) . equals ( " no_db_file " ) ) { logger . warn ( " Database deleted. " ) ; 
public void onEndOfSequence ( final long seq ) throws IOException { if ( hasPendingCommit ( true ) ) { commitDocuments ( ) ; 
public void onChange ( final long seq , final JSONObject doc ) throws IOException { Time's up. if (hasPendingCommit(false)) { commitDocuments(); } final String id = doc.getString("_id"); New, updated or deleted document. if (id.startsWith("_design")) { if (logger.isTraceEnabled()) { logger.trace(id + ": design document updated."); } mapDesignDocument(doc); } else if (doc.optBoolean("_deleted")) { if (logger.isTraceEnabled()) { logger.trace(id + ": document deleted."); } deleteDocument(doc); } else { New or updated document. if (logger.isTraceEnabled()) { logger.trace(id + ": new/updated document."); } updateDocument(doc); } Remember progress. since = seq; } 
private Action updateIndexes ( ) throws IOException { return database . handleChanges ( since , new DatabaseChangesHandler ( ) ) ; } 
protected void doStart ( ) throws Exception { executor = Executors . newCachedThreadPool ( ) ; scheduler = Executors . newScheduledThreadPool ( 1 ) ; scheduler . scheduleWithFixedDelay ( new CouchIndexer ( ) , 0 , 60 , TimeUnit . SECONDS ) ; } 
public void handle ( String target , HttpServletRequest request , HttpServletResponse response , int dispatch ) throws IOException { HttpConnection connection = HttpConnection . getCurrentConnection ( ) ; connection . getRequest ( ) . setHandled ( true ) ; response . setContentType ( " application/json; charset=utf-8 " ) ; response . setHeader ( HttpHeaders . CACHE_CONTROL , " must-revalidate,no-cache,no-store " ) ; final JSONObject obj = new JSONObject ( ) ; obj . put ( " code " , connection . getResponse ( ) . getStatus ( ) ) ; obj . put ( " reason " , connection . getResponse ( ) . getReason ( ) ) ; final byte [ ] body = obj . toString ( ) . getBytes ( " UTF-8 " ) ; response . setContentLength ( body . length ) ; response . getOutputStream ( ) . write ( body ) ; } 
public Action handleChanges ( final long since , final ChangesHandler changesHandler ) throws IOException { final int limit = 100 ; final ResponseHandler < Action > responseHandler = new ResponseHandler < Action > ( ) { public Action handleResponse ( final HttpResponse response ) throws ClientProtocolException , IOException { final HttpEntity entity = response . getEntity ( ) ; final String line = IOUtils . toString ( entity . getContent ( ) ) ; final JSONObject json = JSONObject . fromObject ( line ) ; final JSONArray rows = json . getJSONArray ( " rows " ) ; long seq = 0 ; for ( int i = 0 ; i < rows . size ( ) ; i + + ) { final JSONObject row = rows . getJSONObject ( i ) ; seq = row . getLong ( " key " ) ; changesHandler . onChange ( seq , row . getJSONObject ( " doc " ) ) ; } changesHandler . onEndOfSequence ( seq ) ; return limit = = rows . size ( ) ? Action . CONTINUE : Action . PAUSE ; } } ; final HttpGet get = new HttpGet ( url + " _all_docs_by_seq?include_docs=true&limit= " + limit + " &startkey= " + since ) ; return httpClient . execute ( get , responseHandler ) ; } 
public Action handleResponse ( final HttpResponse response ) throws ClientProtocolException , IOException { final HttpEntity entity = response . getEntity ( ) ; final String line = IOUtils . toString ( entity . getContent ( ) ) ; final JSONObject json = JSONObject . fromObject ( line ) ; final JSONArray rows = json . getJSONArray ( " rows " ) ; long seq = 0 ; for ( int i = 0 ; i < rows . size ( ) ; i + + ) { final JSONObject row = rows . getJSONObject ( i ) ; seq = row . getLong ( " key " ) ; changesHandler . onChange ( seq , row . getJSONObject ( " doc " ) ) ; } changesHandler . onEndOfSequence ( seq ) ; return limit = = rows . size ( ) ? Action . CONTINUE : Action . PAUSE ; } 
public Action handleChanges ( final long since , final ChangesHandler changesHandler ) throws IOException { final ResponseHandler < Action > responseHandler = new ResponseHandler < Action > ( ) { public Action handleResponse ( HttpResponse response ) throws ClientProtocolException , IOException { final HttpEntity entity = response . getEntity ( ) ; final BufferedReader reader = new BufferedReader ( new InputStreamReader ( entity . getContent ( ) , " UTF-8 " ) ) ; String line ; while ( ( line = reader . readLine ( ) ) ! = null ) { final JSONObject json = JSONObject . fromObject ( line ) ; if ( json . has ( " error " ) ) { changesHandler . onError ( json ) ; return Action . ABORT ; } if ( json . has ( " last_seq " ) ) { changesHandler . onEndOfSequence ( json . getLong ( " last_seq " ) ) ; return Action . CONTINUE ; } changesHandler . onChange ( json . getLong ( " seq " ) , json . getJSONObject ( " doc " ) ) ; } return Action . CONTINUE ; } } ; final HttpGet get = new HttpGet ( url + " _changes?feed=continuous&timeout=30000&include_docs=true&since= " + since ) ; return httpClient . execute ( get , responseHandler ) ; } 
public Action handleResponse ( HttpResponse response ) throws ClientProtocolException , IOException { final HttpEntity entity = response . getEntity ( ) ; final BufferedReader reader = new BufferedReader ( new InputStreamReader ( entity . getContent ( ) , " UTF-8 " ) ) ; String line ; while ( ( line = reader . readLine ( ) ) ! = null ) { final JSONObject json = JSONObject . fromObject ( line ) ; if ( json . has ( " error " ) ) { changesHandler . onError ( json ) ; return Action . ABORT ; } if ( json . has ( " last_seq " ) ) { changesHandler . onEndOfSequence ( json . getLong ( " last_seq " ) ) ; return Action . CONTINUE ; } changesHandler . onChange ( json . getLong ( " seq " ) , json . getJSONObject ( " doc " ) ) ; } return Action . CONTINUE ; } 
public abstract Action handleChanges ( final long since , final ChangesHandler handler ) throws IOException ; public enum Action { CONTINUE , ABORT , PAUSE ; } public interface ChangesHandler { void onChange ( final long seq , final JSONObject doc ) throws IOException ; void onError ( final JSONObject error ) throws IOException ; void onEndOfSequence ( final long seq ) throws IOException ; } public final boolean saveDocument ( final String id , final String body ) throws IOException { return HttpUtils . put ( httpClient , url + " / " + id , body ) = = 201 ; } } 
void onChange ( final long seq , final JSONObject doc ) throws IOException ; void onError ( final JSONObject error ) throws IOException ; void onEndOfSequence ( final long seq ) throws IOException ; } public final boolean saveDocument ( final String id , final String body ) throws IOException { return HttpUtils . put ( httpClient , url + " / " + id , body ) = = 201 ; } } 
void onError ( final JSONObject error ) throws IOException ; void onEndOfSequence ( final long seq ) throws IOException ; } public final boolean saveDocument ( final String id , final String body ) throws IOException { return HttpUtils . put ( httpClient , url + " / " + id , body ) = = 201 ; } } 
void onEndOfSequence ( final long seq ) throws IOException ; } public final boolean saveDocument ( final String id , final String body ) throws IOException { return HttpUtils . put ( httpClient , url + " / " + id , body ) = = 201 ; } } 
public void onChange ( final long seq , final JSONObject doc ) throws IOException { Time's up. if (hasPendingCommit(false)) { commitDocuments(); } final String id = doc.getString("_id"); New, updated or deleted document. if (id.startsWith("_design")) { logUpdate(seq, id, "updated"); mapDesignDocument(doc); } else if (doc.optBoolean("_deleted")) { logUpdate(seq, id, "deleted"); deleteDocument(doc); } else { logUpdate(seq, id, "updated"); updateDocument(doc); } Remember progress. since = seq; } 
private void logUpdate ( final long seq , final String id , final String suffix ) { if ( logger . isTraceEnabled ( ) ) { logger . trace ( String . format ( " seq:%d id:%s %s " , seq , id , suffix ) ) ; 
private DirtiableIndexWriter newWriter ( final Directory dir ) throws IOException { final DirtiableIndexWriter result = new DirtiableIndexWriter ( dir , Constants . ANALYZER , MaxFieldLength . UNLIMITED ) ; result . setMergeFactor ( 5 ) ; return result ; } 
public final boolean isDirty ( ) { return isDirty ; } 
public void addDocument ( Document doc , Analyzer analyzer ) throws CorruptIndexException , IOException { super . addDocument ( doc , analyzer ) ; setDirty ( true ) ; } 
public void addDocument ( Document doc ) throws CorruptIndexException , IOException { super . addDocument ( doc ) ; setDirty ( true ) ; } 
public void addIndexes ( Directory [ ] dirs ) throws CorruptIndexException , IOException { super . addIndexes ( dirs ) ; setDirty ( true ) ; } 
public void addIndexes ( IndexReader [ ] readers ) throws CorruptIndexException , IOException { super . addIndexes ( readers ) ; setDirty ( true ) ; } 
public void addIndexesNoOptimize ( Directory [ ] dirs ) throws CorruptIndexException , IOException { super . addIndexesNoOptimize ( dirs ) ; setDirty ( true ) ; } 
public void deleteDocuments ( Query query ) throws CorruptIndexException , IOException { super . deleteDocuments ( query ) ; setDirty ( true ) ; } 
public void deleteDocuments ( Query [ ] queries ) throws CorruptIndexException , IOException { super . deleteDocuments ( queries ) ; setDirty ( true ) ; } 
public void deleteDocuments ( Term term ) throws CorruptIndexException , IOException { super . deleteDocuments ( term ) ; setDirty ( true ) ; } 
public void deleteDocuments ( Term [ ] terms ) throws CorruptIndexException , IOException { super . deleteDocuments ( terms ) ; setDirty ( true ) ; } 
public void updateDocument ( Term term , Document doc , Analyzer analyzer ) throws CorruptIndexException , IOException { super . updateDocument ( term , doc , analyzer ) ; setDirty ( true ) ; } 
public void updateDocument ( Term term , Document doc ) throws CorruptIndexException , IOException { super . updateDocument ( term , doc ) ; setDirty ( true ) ; } 
public void onChange ( final long seq , final JSONObject doc ) throws IOException { Time's up. if (hasPendingCommit(false)) { commitDocuments(); } final String id = doc.getString("_id"); New, updated or deleted document. if (id.startsWith("_design")) { logUpdate(seq, id, "updated"); mapDesignDocument(doc); TODO force reindexing of this function ONLY. } else if (doc.optBoolean("_deleted")) { logUpdate(seq, id, "deleted"); deleteDocument(doc); } else { logUpdate(seq, id, "updated"); updateDocument(doc); } Remember progress. since = seq; } 
private synchronized Holder getHolder ( final ViewSignature viewSignature ) throws IOException { Holder result = holders . get ( viewSignature ) ; if ( result = = null ) { final File dir = viewSignature . toViewDir ( baseDir ) ; if ( ! dir . exists ( ) & & ! dir . mkdirs ( ) ) { throw new IOException ( " Could not make " + dir ) ; } result = new Holder ( ) ; result . writer = newWriter ( FSDirectory . open ( dir ) ) ; result . etag = newEtag ( ) ; holders . put ( viewSignature , result ) ; } return result ; } 
public synchronized void close ( ) throws IOException { final Iterator < Holder > it = holders . values ( ) . iterator ( ) ; while ( it . hasNext ( ) ) { it . next ( ) . writer . rollback ( ) ; 
public < T > T withReader ( final ViewSignature viewSignature , final ReaderCallback < T > callback ) throws IOException { return callback . callback ( getHolder ( viewSignature ) . writer . getReader ( ) ) ; } 
public < T > T withSearcher ( final ViewSignature viewSignature , final SearcherCallback < T > callback ) throws IOException { final Holder holder = getHolder ( viewSignature ) ; return callback . callback ( new IndexSearcher ( holder . writer . getReader ( ) ) , holder . etag ) ; } 
public < T > T withWriter ( final ViewSignature viewSignature , final WriterCallback < T > callback ) throws IOException { boolean oom = false ; try { return callback . callback ( getHolder ( viewSignature ) . writer ) ; 
public File toViewDir ( final File base ) { return new File ( toDatabaseDir ( base ) , this + " .index " ) ; } 
public File toDatabaseDir ( final File base ) { return new File ( base , dbname ) ; } 
public final JSONObject getDocuments ( final String startkey , final String endkey ) throws IOException { return JSONObject . fromObject ( HttpUtils . get ( httpClient , String . format ( " %s_all_docs?startkey=%%22%s%%22&endkey=%%22%s%%22&include_docs=true " , url , Utils . urlEncode ( startkey ) , Utils 
public void parse ( final InputStream in , final String contentType , final String fieldName , final Document doc ) throws IOException { final AutoDetectParser parser = new AutoDetectParser ( ) ; final Metadata md = new Metadata ( ) ; md . set ( HttpHeaders . CONTENT_TYPE , contentType ) ; final Reader reader = new ParsingReader ( parser , in , md ) ; final String body ; try { try { body = IOUtils . toString ( reader ) ; } finally { reader . close ( ) ; } } catch ( final IOException e ) { log . warn ( " Failed to index an attachment. " , e ) ; return ; } Add body text. doc.add(text(fieldName, body, false)); Add DC attributes. addDublinCoreAttributes(md, doc); } 
private boolean mapAllDesignDocuments ( ) throws IOException { final JSONArray designDocuments = database . getAllDesignDocuments ( ) ; boolean isLuceneEnabled = false ; for ( int i = 0 ; i < designDocuments . size ( ) ; i + + ) { isLuceneEnabled | = mapDesignDocument ( designDocuments . getJSONObject ( i ) . getJSONObject ( " doc " ) ) ; } return isLuceneEnabled ; } 
public JSONArray getAllDesignDocuments ( ) throws IOException { return getDocuments ( " _design " , " _design0 " ) . getJSONArray ( " rows " ) ; } 
private void updateDocument ( final JSONObject doc ) { for ( final Entry < ViewSignature , ViewIndexer > entry : functions . entrySet ( ) ) { final RhinoContext rhinoContext = new RhinoContext ( ) ; 
private boolean mapDesignDocument ( final JSONObject designDocument ) { final String designDocumentName = designDocument . getString ( " _id " ) . substring ( 8 ) ; final JSONObject fulltext = designDocument . getJSONObject ( " fulltext " ) ; boolean isLuceneEnabled = false ; if ( fulltext ! = null ) { for ( final Object obj : fulltext . keySet ( ) ) { final String viewName = ( String ) obj ; final JSONObject viewValue = fulltext . getJSONObject ( viewName ) ; final JSONObject defaults = viewValue . has ( " defaults " ) ? viewValue . getJSONObject ( " defaults " ) : defaults ( ) ; final Analyzer analyzer = Analyzers . getAnalyzer ( viewValue . optString ( " analyzer " , " standard " ) ) ; String function = viewValue . getString ( " index " ) ; function = function . replaceFirst ( " ^ \" " , " " ) ; function = function . replaceFirst ( " \" $ " , " " ) ; final ViewSignature sig = state . locator . update ( databaseName , designDocumentName , viewName , viewValue . toString ( ) ) ; functions . put ( sig , new ViewIndexer ( defaults , analyzer , context . compileFunction ( scope , function , viewName , 0 , null ) ) ) ; isLuceneEnabled = true ; } } return isLuceneEnabled ; } 
private void commitDocuments ( ) throws IOException { final JSONObject tracker = fetchTrackingDocument ( database ) ; tracker . put ( " update_seq " , since ) ; for ( final ViewSignature sig : functions . keySet ( ) ) { Fetch or generate index uuid. final String uuid = state.lucene.withReader(sig, new ReaderCallback<String>() { public String callback(final IndexReader reader) throws IOException { final String result = (String) reader.getCommitUserData().get("uuid"); return result != null ? result : UUID.randomUUID().toString(); } }); tracker.put(sig.toString(), uuid); Tell Lucene. state.lucene.withWriter(sig, new WriterCallback<Void>() { public Void callback(final IndexWriter writer) throws IOException { final Map<String, String> commitUserData = new HashMap<String, String>(); commitUserData.put("update_seq", Long.toString(since)); commitUserData.put("uuid", uuid); logger.debug("Committing changes to " + sig + " with " + commitUserData); if (writer.maxDoc() == 0) { writer.addDocument(new Document()); } writer.commit(commitUserData); return null; } }); } Tell Couch. database.saveDocument(LOCAL_LUCENE, tracker.toString()); setPendingCommit(false); } 
private JSONObject fetchTrackingDocument ( final Database database ) throws IOException { try { return database . getDocument ( LOCAL_LUCENE ) ; 
private boolean mapDesignDocument ( final JSONObject designDocument ) { final String designDocumentName = designDocument . getString ( " _id " ) . substring ( 8 ) ; final JSONObject fulltext = designDocument . getJSONObject ( " fulltext " ) ; boolean isLuceneEnabled = false ; if ( fulltext ! = null ) { for ( final Object obj : fulltext . keySet ( ) ) { final String viewName = ( String ) obj ; final JSONObject viewValue = fulltext . getJSONObject ( viewName ) ; final JSONObject defaults = viewValue . has ( " defaults " ) ? viewValue . getJSONObject ( " defaults " ) : defaults ( ) ; final Analyzer analyzer = Analyzers . getAnalyzer ( viewValue . optString ( " analyzer " , " standard " ) ) ; String function = viewValue . getString ( " index " ) ; function = function . replaceFirst ( " ^ \" " , " " ) ; function = function . replaceFirst ( " \" $ " , " " ) ; final ViewSignature sig = state . locator . update ( databaseName , designDocumentName , viewName , viewValue . toString ( ) ) ; functions . put ( sig , new ViewIndexer ( defaults , analyzer , context . compileFunction ( scope , function , viewName , 0 , null ) ) ) ; isLuceneEnabled = true ; } } return isLuceneEnabled ; } 
public boolean visibleToScripts ( final String fullClassName ) { return false ; } 
public void onHeartbeat ( ) throws IOException { commitIfPending ( ) ; } 
public void onEndOfSequence ( final long seq ) throws IOException { commitIfPending ( ) ; } 
private void commitIfPending ( ) throws IOException { if ( hasPendingCommit ( true ) ) { commitDocuments ( ) ; 
public Action handleChanges ( final long since , final ChangesHandler changesHandler ) throws IOException { final ResponseHandler < Action > responseHandler = new ResponseHandler < Action > ( ) { public Action handleResponse ( HttpResponse response ) throws ClientProtocolException , IOException { final HttpEntity entity = response . getEntity ( ) ; final BufferedReader reader = new BufferedReader ( new InputStreamReader ( entity . getContent ( ) , " UTF-8 " ) ) ; String line ; while ( ( line = reader . readLine ( ) ) ! = null ) { if ( line . isEmpty ( ) ) { changesHandler . onHeartbeat ( ) ; } final JSONObject json = JSONObject . fromObject ( line ) ; if ( json . has ( " error " ) ) { changesHandler . onError ( json ) ; return Action . ABORT ; } if ( json . has ( " last_seq " ) ) { changesHandler . onEndOfSequence ( json . getLong ( " last_seq " ) ) ; return Action . CONTINUE ; } changesHandler . onChange ( json . getLong ( " seq " ) , json . getJSONObject ( " doc " ) ) ; } return Action . CONTINUE ; } } ; final HttpGet get = new HttpGet ( url + " _changes?feed=continuous&timeout=30000&heartbeat=15000&include_docs=true&since= " + since ) ; return httpClient . execute ( get , responseHandler ) ; } 
public Action handleResponse ( HttpResponse response ) throws ClientProtocolException , IOException { final HttpEntity entity = response . getEntity ( ) ; final BufferedReader reader = new BufferedReader ( new InputStreamReader ( entity . getContent ( ) , " UTF-8 " ) ) ; String line ; while ( ( line = reader . readLine ( ) ) ! = null ) { if ( line . isEmpty ( ) ) { changesHandler . onHeartbeat ( ) ; } final JSONObject json = JSONObject . fromObject ( line ) ; if ( json . has ( " error " ) ) { changesHandler . onError ( json ) ; return Action . ABORT ; } if ( json . has ( " last_seq " ) ) { changesHandler . onEndOfSequence ( json . getLong ( " last_seq " ) ) ; return Action . CONTINUE ; } changesHandler . onChange ( json . getLong ( " seq " ) , json . getJSONObject ( " doc " ) ) ; } return Action . CONTINUE ; } 
public abstract Action handleChanges ( final long since , final ChangesHandler handler ) throws IOException ; public enum Action { CONTINUE , ABORT , PAUSE ; } public interface ChangesHandler { void onChange ( final long seq , final JSONObject doc ) throws IOException ; void onHeartbeat ( ) throws IOException ; void onError ( final JSONObject error ) throws IOException ; void onEndOfSequence ( final long seq ) throws IOException ; } public final boolean saveDocument ( final String id , final String body ) throws IOException { return HttpUtils . put ( httpClient , url + " / " + id , body ) = = 201 ; } } 
void onChange ( final long seq , final JSONObject doc ) throws IOException ; void onHeartbeat ( ) throws IOException ; void onError ( final JSONObject error ) throws IOException ; void onEndOfSequence ( final long seq ) throws IOException ; } public final boolean saveDocument ( final String id , final String body ) throws IOException { return HttpUtils . put ( httpClient , url + " / " + id , body ) = = 201 ; } } 
void onHeartbeat ( ) throws IOException ; void onError ( final JSONObject error ) throws IOException ; void onEndOfSequence ( final long seq ) throws IOException ; } public final boolean saveDocument ( final String id , final String body ) throws IOException { return HttpUtils . put ( httpClient , url + " / " + id , body ) = = 201 ; } } 
public final JSONObject getDocument ( final String id ) throws IOException { final String response = HttpUtils . get ( httpClient , url + Utils . urlEncode ( id ) ) ; return JSONObject . fromObject ( response ) ; } 
public abstract Action handleChanges ( final long since , final ChangesHandler handler ) throws IOException ; public enum Action { CONTINUE , ABORT , PAUSE ; } public interface ChangesHandler { void onChange ( final long seq , final JSONObject doc ) throws IOException ; void onHeartbeat ( ) throws IOException ; void onError ( final JSONObject error ) throws IOException ; void onEndOfSequence ( final long seq ) throws IOException ; } public final boolean saveDocument ( final String id , final String body ) throws IOException { return HttpUtils . put ( httpClient , url + Utils . urlEncode ( id ) , body ) = = 201 ; } } 
void onChange ( final long seq , final JSONObject doc ) throws IOException ; void onHeartbeat ( ) throws IOException ; void onError ( final JSONObject error ) throws IOException ; void onEndOfSequence ( final long seq ) throws IOException ; } public final boolean saveDocument ( final String id , final String body ) throws IOException { return HttpUtils . put ( httpClient , url + Utils . urlEncode ( id ) , body ) = = 201 ; } } 
void onHeartbeat ( ) throws IOException ; void onError ( final JSONObject error ) throws IOException ; void onEndOfSequence ( final long seq ) throws IOException ; } public final boolean saveDocument ( final String id , final String body ) throws IOException { return HttpUtils . put ( httpClient , url + Utils . urlEncode ( id ) , body ) = = 201 ; } } 
void onError ( final JSONObject error ) throws IOException ; void onEndOfSequence ( final long seq ) throws IOException ; } public final boolean saveDocument ( final String id , final String body ) throws IOException { return HttpUtils . put ( httpClient , url + Utils . urlEncode ( id ) , body ) = = 201 ; } } 
void onEndOfSequence ( final long seq ) throws IOException ; } public final boolean saveDocument ( final String id , final String body ) throws IOException { return HttpUtils . put ( httpClient , url + Utils . urlEncode ( id ) , body ) = = 201 ; } } 
public final boolean saveDocument ( final String id , final String body ) throws IOException { return HttpUtils . put ( httpClient , url + Utils . urlEncode ( id ) , body ) = = 201 ; } 
public void onChange ( final long seq , final JSONObject doc ) throws IOException { Time's up? commitDocuments(false); final String id = doc.getString("_id"); New, updated or deleted document. if (id.startsWith("_design")) { logUpdate(seq, id, "updated"); mapDesignDocument(doc); TODO force reindexing of this function ONLY. } else if (doc.optBoolean("_deleted")) { logUpdate(seq, id, "deleted"); deleteDocument(doc); } else { logUpdate(seq, id, "updated"); updateDocument(doc); } Remember progress. since = seq; } 
public void onHeartbeat ( ) throws IOException { commitDocuments ( true ) ; } 
public void onEndOfSequence ( final long seq ) throws IOException { commitDocuments ( true ) ; } 
private void commitDocuments ( final boolean ignoreTimeout ) throws IOException { if ( ! hasPendingCommit ( ignoreTimeout ) ) return ; final JSONObject tracker = fetchTrackingDocument ( database ) ; tracker . put ( " update_seq " , since ) ; for ( final ViewSignature sig : functions . keySet ( ) ) { Fetch or generate index uuid. final String uuid = state.lucene.withReader(sig, new ReaderCallback<String>() { public String callback(final IndexReader reader) throws IOException { final String result = (String) reader.getCommitUserData().get("uuid"); return result != null ? result : UUID.randomUUID().toString(); } }); tracker.put(sig.toString(), uuid); Tell Lucene. state.lucene.withWriter(sig, new WriterCallback<Void>() { public Void callback(final IndexWriter writer) throws IOException { final Map<String, String> commitUserData = new HashMap<String, String>(); commitUserData.put("update_seq", Long.toString(since)); commitUserData.put("uuid", uuid); logger.debug("Committing changes to " + sig + " with " + commitUserData); if (writer.maxDoc() == 0) { writer.addDocument(new Document()); } writer.commit(commitUserData); return null; } }); } Tell Couch. database.saveDocument(LOCAL_LUCENE, tracker.toString()); setPendingCommit(false); } 
public Action handleChanges ( final long since , final ChangesHandler changesHandler ) throws IOException { final ResponseHandler < Action > responseHandler = new ResponseHandler < Action > ( ) { public Action handleResponse ( HttpResponse response ) throws ClientProtocolException , IOException { final HttpEntity entity = response . getEntity ( ) ; final BufferedReader reader = new BufferedReader ( new InputStreamReader ( entity . getContent ( ) , " UTF-8 " ) ) ; String line ; while ( ( line = reader . readLine ( ) ) ! = null ) { Consume response heartbeat. if (line.isEmpty()) { changesHandler.onHeartbeat(); continue; } final JSONObject json = JSONObject.fromObject(line); Error. if (json.has("error")) { changesHandler.onError(json); return Action.ABORT; } End of response. if (json.has("last_seq")) { changesHandler.onEndOfSequence(json.getLong("last_seq")); return Action.CONTINUE; } A document update. changesHandler.onChange(json.getLong("seq"), json.getJSONObject("doc")); } return Action.CONTINUE; } }; final HttpGet get = new HttpGet(url + "_changes?feed=continuous&timeout=30000&heartbeat=15000&include_docs=true&since=" + since); return httpClient.execute(get, responseHandler); } 
public Action handleResponse ( HttpResponse response ) throws ClientProtocolException , IOException { final HttpEntity entity = response . getEntity ( ) ; final BufferedReader reader = new BufferedReader ( new InputStreamReader ( entity . getContent ( ) , " UTF-8 " ) ) ; String line ; while ( ( line = reader . readLine ( ) ) ! = null ) { Consume response heartbeat. if (line.isEmpty()) { changesHandler.onHeartbeat(); continue; } final JSONObject json = JSONObject.fromObject(line); Error. if (json.has("error")) { changesHandler.onError(json); return Action.ABORT; } End of response. if (json.has("last_seq")) { changesHandler.onEndOfSequence(json.getLong("last_seq")); return Action.CONTINUE; } A document update. changesHandler.onChange(json.getLong("seq"), json.getJSONObject("doc")); } return Action.CONTINUE; } 
private void enterContext ( ) throws Exception { context = ContextFactory . getGlobal ( ) . enterContext ( ) ; Optimize as much as possible. context.setOptimizationLevel(9); Security restrictions context.setClassShutter(new RestrictiveClassShutter()); Setup. scope = context.initStandardObjects(); Allow custom document helper class. ScriptableObject.defineClass(scope, RhinoDocument.class); Add a log object ScriptableObject.putProperty(scope, "log", new JSLog()); Load JSON parser. context.evaluateString(scope, loadResource("json2.js"), "json2", 0, null); Define outer function. main = context.compileFunction(scope, "function(json, func){return func(JSON.parse(json));}", "main", 0, null); } 
public static void main ( String [ ] args ) throws Exception { final HttpClient client = new DefaultHttpClient ( ) ; long progress = 0 ; UUID uuid = null ; long sleep = 1 ; final Directory dir = new RAMDirectory ( ) ; final IndexWriter writer = new IndexWriter ( dir , new StandardAnalyzer ( Version . LUCENE_CURRENT ) , MaxFieldLength . UNLIMITED ) ; while ( true ) { try { 
public Long handleResponse ( final HttpResponse response ) throws ClientProtocolException , IOException { final HttpEntity entity = response . getEntity ( ) ; final BufferedReader reader = new BufferedReader ( new InputStreamReader ( entity . getContent ( ) , " UTF-8 " ) ) ; String line ; Map commit = writer . getReader ( ) . getCommitUserData ( ) ; long update_seq = 0 , new_seq = 0 ; if ( commit . containsKey ( " update_seq " ) ) { update_seq = Long . parseLong ( ( String ) commit . get ( " update_seq " ) ) ; new_seq = update_seq ; } LOG . info ( " current update_seq is " + update_seq ) ; LOG . info ( " numDocs = " + writer . numDocs ( ) ) ; while ( ( line = reader . readLine ( ) ) ! = null ) { Commit on heartbeat (or end of sequence). if (line.isEmpty()) { LOG.info("heartbeat"); if (update_seq != new_seq) { commit = new HashMap(); commit.put("update_seq", Long.toString(new_seq)); writer.commit(commit); LOG.info("committed " + commit); update_seq = new_seq; } continue; } Convert the line to JSON. final JSONObject json = JSONObject.fromObject(line); Error? if (json.has("error")) { LOG.info("error"); break; } End of feed. if (json.has("last_seq")) { break; } Update. final long seq = json.getLong("seq"); if (seq > new_seq) { LOG.info("seq: " + seq); final String id = json.getString("id"); final Document doc = new Document(); doc.add(new NumericField("seq", Store.NO, true).setLongValue(seq)); doc.add(new Field("id", id, Store.YES, Index.NOT_ANALYZED_NO_NORMS)); writer.updateDocument(new Term("id", id), doc); new_seq = seq; } else { LOG.info("Ignoring applied update at seq " + seq); } } LOG.info("handler exiting."); return update_seq; } 
public static void main ( String [ ] args ) throws Exception { final HttpClient client = new DefaultHttpClient ( ) ; long progress = 0 ; UUID uuid = null ; long sleep = 1 ; while ( true ) { try { 
public Long handleResponse ( final HttpResponse response ) throws IOException { final HttpEntity entity = response . getEntity ( ) ; final BufferedReader reader = new BufferedReader ( new InputStreamReader ( entity . getContent ( ) , " UTF-8 " ) ) ; String line ; Map commit = writer . getReader ( ) . getCommitUserData ( ) ; long update_seq = 0 , new_seq = 0 ; if ( commit . containsKey ( " update_seq " ) ) { update_seq = Long . parseLong ( ( String ) commit . get ( " update_seq " ) ) ; new_seq = update_seq ; } LOG . info ( " current update_seq is " + update_seq ) ; LOG . info ( " numDocs = " + writer . numDocs ( ) ) ; while ( ( line = reader . readLine ( ) ) ! = null ) { Commit on heartbeat (or end of sequence). if (line.isEmpty()) { if (update_seq != new_seq) { commit = new HashMap(); commit.put("update_seq", Long.toString(new_seq)); writer.commit(commit); LOG.info("committed " + commit); update_seq = new_seq; } continue; } Convert the line to JSON. final JSONObject json = JSONObject.fromObject(line); Error? if (json.has("error")) { LOG.info("error"); break; } End of feed. if (json.has("last_seq")) { break; } Update. final long seq = json.getLong("seq"); if (seq > new_seq) { LOG.info("seq: " + seq); final String id = json.getString("id"); final Document doc = new Document(); doc.add(new NumericField("seq", Store.NO, true).setLongValue(seq)); doc.add(new Field("id", id, Store.YES, Index.NOT_ANALYZED_NO_NORMS)); LOG.info(doc); writer.updateDocument(new Term("id", id), doc); new_seq = seq; } else { LOG.info("Ignoring applied update at seq " + seq); } } LOG.info("handler exiting."); return update_seq; } 
public Long handleResponse ( final HttpResponse response ) throws IOException { final HttpEntity entity = response . getEntity ( ) ; final BufferedReader reader = new BufferedReader ( new InputStreamReader ( entity . getContent ( ) , " UTF-8 " ) ) ; String line ; Map commit = writer . getReader ( ) . getCommitUserData ( ) ; long update_seq = 0 , new_seq = 0 ; if ( commit . containsKey ( " update_seq " ) ) { update_seq = Long . parseLong ( ( String ) commit . get ( " update_seq " ) ) ; new_seq = update_seq ; } LOG . info ( " current update_seq is " + update_seq ) ; LOG . info ( " numDocs = " + writer . numDocs ( ) ) ; while ( ( line = reader . readLine ( ) ) ! = null ) { Commit on heartbeat (or end of sequence). if (line.length() == 0) { if (update_seq != new_seq) { commit = new HashMap(); commit.put("update_seq", Long.toString(new_seq)); writer.commit(commit); LOG.info("committed " + commit); update_seq = new_seq; } continue; } Convert the line to JSON. final JSONObject json = JSONObject.fromObject(line); Error? if (json.has("error")) { LOG.info("error"); break; } End of feed. if (json.has("last_seq")) { break; } Update. final long seq = json.getLong("seq"); if (seq > new_seq) { LOG.info("seq: " + seq); final String id = json.getString("id"); final Document doc = new Document(); doc.add(new NumericField("seq", Store.NO, true).setLongValue(seq)); doc.add(new Field("id", id, Store.YES, Index.NOT_ANALYZED_NO_NORMS)); LOG.info(doc); writer.updateDocument(new Term("id", id), doc); new_seq = seq; } else { LOG.info("Ignoring applied update at seq " + seq); } } LOG.info("handler exiting."); return update_seq; } 
public Action handleChanges ( final long since , final ChangesHandler changesHandler ) throws IOException { final ResponseHandler < Action > responseHandler = new ResponseHandler < Action > ( ) { public Action handleResponse ( HttpResponse response ) throws ClientProtocolException , IOException { final HttpEntity entity = response . getEntity ( ) ; final BufferedReader reader = new BufferedReader ( new InputStreamReader ( entity . getContent ( ) , " UTF-8 " ) ) ; String line ; while ( ( line = reader . readLine ( ) ) ! = null ) { Consume response heartbeat. if (line.length() == 0) { changesHandler.onHeartbeat(); continue; } final JSONObject json = JSONObject.fromObject(line); Error. if (json.has("error")) { changesHandler.onError(json); return Action.ABORT; } End of response. if (json.has("last_seq")) { changesHandler.onEndOfSequence(json.getLong("last_seq")); return Action.CONTINUE; } A document update. changesHandler.onChange(json.getLong("seq"), json.getJSONObject("doc")); } return Action.CONTINUE; } }; final HttpGet get = new HttpGet(url + "_changes?feed=continuous&timeout=30000&heartbeat=15000&include_docs=true&since=" + since); return httpClient.execute(get, responseHandler); } 
public Action handleResponse ( HttpResponse response ) throws ClientProtocolException , IOException { final HttpEntity entity = response . getEntity ( ) ; final BufferedReader reader = new BufferedReader ( new InputStreamReader ( entity . getContent ( ) , " UTF-8 " ) ) ; String line ; while ( ( line = reader . readLine ( ) ) ! = null ) { Consume response heartbeat. if (line.length() == 0) { changesHandler.onHeartbeat(); continue; } final JSONObject json = JSONObject.fromObject(line); Error. if (json.has("error")) { changesHandler.onError(json); return Action.ABORT; } End of response. if (json.has("last_seq")) { changesHandler.onEndOfSequence(json.getLong("last_seq")); return Action.CONTINUE; } A document update. changesHandler.onChange(json.getLong("seq"), json.getJSONObject("doc")); } return Action.CONTINUE; } 
public void addDocument ( final RhinoContext context , final IndexWriter out ) throws IOException { final Document doc = new Document ( ) ; Add id. doc.add(Utils.token("_id", context.documentId, true)); Add user-supplied fields. for (final RhinoField field : fields) { addField(field, context, doc); } Parse user-requested attachments. for (final RhinoAttachment attachment : attachments) { addAttachment(attachment, context, doc); } out.addDocument(doc, context.analyzer); } 
protected void doPost ( final HttpServletRequest req , final HttpServletResponse resp ) throws ServletException , IOException { final ViewSignature sig = state . locator . lookup ( req ) ; if ( sig = = null ) { resp . sendError ( 400 , " Invalid path. " ) ; return ; } final String command = req . getParameter ( " cmd " ) ; if ( " expunge " . equals ( command ) ) { state . lucene . withWriter ( sig , new WriterCallback ( ) { public boolean callback ( final IndexWriter writer ) throws IOException { writer . expungeDeletes ( false ) ; return false ; } } ) ; resp . setStatus ( 202 ) ; return ; } if ( " optimize " . equals ( command ) ) { state . lucene . withWriter ( sig , new WriterCallback ( ) { public boolean callback ( final IndexWriter writer ) throws IOException { writer . optimize ( false ) ; return false ; } } ) ; resp . setStatus ( 202 ) ; return ; } resp . sendError ( 400 , " Bad request " ) ; } 
public boolean callback ( final IndexWriter writer ) throws IOException { writer . expungeDeletes ( false ) ; return false ; } 
public boolean callback ( final IndexWriter writer ) throws IOException { writer . optimize ( false ) ; return false ; } 
private void commitDocuments ( final boolean ignoreTimeout ) throws IOException { if ( ! hasPendingCommit ( ignoreTimeout ) ) return ; final JSONObject tracker = fetchTrackingDocument ( database ) ; tracker . put ( " update_seq " , since ) ; for ( final ViewSignature sig : functions . keySet ( ) ) { Fetch or generate index uuid. final String uuid = state.lucene.withReader(sig, new ReaderCallback<String>() { public String callback(final IndexReader reader) throws IOException { final String result = (String) reader.getCommitUserData().get("uuid"); return result != null ? result : UUID.randomUUID().toString(); } }); tracker.put(sig.toString(), uuid); Tell Lucene. state.lucene.withWriter(sig, new WriterCallback() { public boolean callback(final IndexWriter writer) throws IOException { final Map<String, String> commitUserData = new HashMap<String, String>(); commitUserData.put("update_seq", Long.toString(since)); commitUserData.put("uuid", uuid); logger.debug("Committing changes to " + sig + " with " + commitUserData); if (writer.maxDoc() == 0) { writer.addDocument(new Document()); } writer.commit(commitUserData); return false; } }); } Tell Couch. database.saveDocument(LOCAL_LUCENE, tracker.toString()); setPendingCommit(false); } 
public boolean callback ( final IndexWriter writer ) throws IOException { final Map < String , String > commitUserData = new HashMap < String , String > ( ) ; commitUserData . put ( " update_seq " , Long . toString ( since ) ) ; commitUserData . put ( " uuid " , uuid ) ; logger . debug ( " Committing changes to " + sig + " with " + commitUserData ) ; if ( writer . maxDoc ( ) = = 0 ) { writer . addDocument ( new Document ( ) ) ; } writer . commit ( commitUserData ) ; return false ; } 
private void deleteDocument ( final JSONObject doc ) throws IOException { for ( final ViewSignature sig : functions . keySet ( ) ) { state . lucene . withWriter ( sig , new WriterCallback ( ) { 
public boolean callback ( final IndexWriter writer ) throws IOException { writer . deleteDocuments ( new Term ( " _id " , doc . getString ( " _id " ) ) ) ; setPendingCommit ( true ) ; return true ; } 
private void commitDocuments ( final boolean ignoreTimeout ) throws IOException { if ( ! hasPendingCommit ( ignoreTimeout ) ) return ; final JSONObject tracker = fetchTrackingDocument ( database ) ; tracker . put ( " update_seq " , since ) ; for ( final ViewSignature sig : functions . keySet ( ) ) { Fetch or generate index uuid. final String uuid = state.lucene.withReader(sig, new ReaderCallback<String>() { public String callback(final IndexReader reader) throws IOException { final String result = (String) reader.getCommitUserData().get("uuid"); return result != null ? result : UUID.randomUUID().toString(); } }); tracker.put(sig.toString(), uuid); Tell Lucene. state.lucene.withWriter(sig, new WriterCallback() { public boolean callback(final IndexWriter writer) throws IOException { final Map<String, String> commitUserData = new HashMap<String, String>(); commitUserData.put("update_seq", Long.toString(since)); commitUserData.put("uuid", uuid); logger.debug("Committing changes to " + sig + " with " + commitUserData); if (writer.maxDoc() == 0) { writer.addDocument(new Document()); } writer.commit(commitUserData); return false; } }); } Tell Couch. database.saveDocument(LOCAL_LUCENE, tracker.toString()); setPendingCommit(false); } 
private boolean hasPendingCommit ( final boolean ignoreTimeout ) { final boolean imeoutReached = ( now ( ) - pendingSince ) > = COMMIT_INTERVAL ; logger . trace ( String . format ( " pending commit: %b, timeout reached: %b " , pendingCommit , imeoutReached ) ) ; return ignoreTimeout ? pendingCommit : pendingCommit & & imeoutReached ; } 
public Action handleChanges ( final long since , final ChangesHandler changesHandler ) throws IOException { final ResponseHandler < Action > responseHandler = new ResponseHandler < Action > ( ) { public Action handleResponse ( HttpResponse response ) throws ClientProtocolException , IOException { final HttpEntity entity = response . getEntity ( ) ; final BufferedReader reader = new BufferedReader ( new InputStreamReader ( entity . getContent ( ) , " UTF-8 " ) ) ; String line ; while ( ( line = reader . readLine ( ) ) ! = null ) { Consume response heartbeat. if (line.length() == 0) { changesHandler.onHeartbeat(); continue; } final JSONObject json = JSONObject.fromObject(line); Error. if (json.has("error")) { changesHandler.onError(json); return Action.ABORT; } End of response. if (json.has("last_seq")) { changesHandler.onEndOfSequence(json.getLong("last_seq")); return Action.CONTINUE; } A document update. changesHandler.onChange(json.getLong("seq"), json.getJSONObject("doc")); } return Action.CONTINUE; } }; final HttpGet get = new HttpGet(url + "_changes?feed=continuous&heartbeat=15000&include_docs=true&since=" + since); return httpClient.execute(get, responseHandler); } 
private String loadResource ( final String name ) throws IOException { final InputStream in = Indexer . class . getClassLoader ( ) . getResourceAsStream ( name ) ; try { return IOUtils . toString ( in , " UTF-8 " ) ; 
public void onChange ( final long seq , final JSONObject doc ) throws IOException { Time's up? commitDocuments(false); final String id = doc.getString("_id"); New, updated or deleted document. if (id.startsWith("_design")) { logUpdate(seq, id, "updated"); mapDesignDocument(doc); TODO force reindexing of this function ONLY. } else if (doc.optBoolean("_deleted")) { logUpdate(seq, id, "deleted"); deleteDocument(doc); } else { logUpdate(seq, id, "updated"); updateDocument(doc); } TODO index design document if options { "include_design"true"} Remember progress. since = seq; } 
private void commitDocuments ( final boolean ignoreTimeout ) throws IOException { if ( ! hasPendingCommit ( ignoreTimeout ) ) return ; final JSONObject tracker = fetchTrackingDocument ( database ) ; tracker . put ( " update_seq " , since ) ; for ( final ViewSignature sig : viewIndexers . keySet ( ) ) { Fetch or generate index uuid. final String uuid = state.lucene.withReader(sig, new ReaderCallback<String>() { public String callback(final IndexReader reader) throws IOException { final String result = (String) reader.getCommitUserData().get("uuid"); return result != null ? result : UUID.randomUUID().toString(); } }); tracker.put(sig.toString(), uuid); Tell Lucene. state.lucene.withWriter(sig, new WriterCallback() { public boolean callback(final IndexWriter writer) throws IOException { final Map<String, String> commitUserData = new HashMap<String, String>(); commitUserData.put("update_seq", Long.toString(since)); commitUserData.put("uuid", uuid); logger.debug("Committing changes to " + sig + " with " + commitUserData); if (writer.maxDoc() == 0) { writer.addDocument(new Document()); } writer.commit(commitUserData); return false; } }); } Tell Couch. database.saveDocument(LOCAL_LUCENE, tracker.toString()); setPendingCommit(false); } 
private void deleteDocument ( final JSONObject doc ) throws IOException { for ( final ViewSignature sig : viewIndexers . keySet ( ) ) { state . lucene . withWriter ( sig , new WriterCallback ( ) { 
private void updateDocument ( final JSONObject doc ) { for ( final Entry < ViewSignature , ViewIndexer > entry : viewIndexers . entrySet ( ) ) { final RhinoContext rhinoContext = new RhinoContext ( ) ; 
public boolean callback ( final IndexWriter writer ) throws IOException { writer . deleteDocuments ( new Term ( " _id " , rhinoContext . documentId ) ) ; for ( final Document result : results ) { writer . addDocument ( result , rhinoContext . analyzer ) ; } return true ; } 
private void enterContext ( ) throws Exception { context = ContextFactory . getGlobal ( ) . enterContext ( ) ; Optimize as much as possible. context.setOptimizationLevel(9); Security restrictions context.setClassShutter(new RestrictiveClassShutter()); } 
private boolean mapAllDesignDocuments ( ) throws Exception { final JSONArray designDocuments = database . getAllDesignDocuments ( ) ; boolean isLuceneEnabled = false ; for ( int i = 0 ; i < designDocuments . size ( ) ; i + + ) { isLuceneEnabled | = mapDesignDocument ( designDocuments . getJSONObject ( i ) . getJSONObject ( " doc " ) ) ; } return isLuceneEnabled ; } 
private boolean mapDesignDocument ( final JSONObject designDocument ) throws IOException { final String designDocumentName = designDocument . getString ( " _id " ) . substring ( 8 ) ; final JSONObject fulltext = designDocument . getJSONObject ( " fulltext " ) ; boolean isLuceneEnabled = false ; if ( fulltext ! = null ) { for ( final Object obj : fulltext . keySet ( ) ) { final String viewName = ( String ) obj ; final JSONObject viewValue = fulltext . getJSONObject ( viewName ) ; final JSONObject defaults = viewValue . has ( " defaults " ) ? viewValue . getJSONObject ( " defaults " ) : defaults ( ) ; final Analyzer analyzer = Analyzers . getAnalyzer ( viewValue . optString ( " analyzer " , " standard " ) ) ; String function = viewValue . getString ( " index " ) ; function = function . replaceFirst ( " ^ \" " , " " ) ; function = function . replaceFirst ( " \" $ " , " " ) ; final ViewSignature sig = state . locator . update ( databaseName , designDocumentName , viewName , viewValue . toString ( ) ) ; viewIndexers . put ( sig , new ViewIndexer ( context , defaults , analyzer , viewName , function ) ) ; isLuceneEnabled = true ; } } return isLuceneEnabled ; } 
private void readCheckpoints ( ) throws IOException { long since = Long . MAX_VALUE ; for ( final ViewSignature sig : viewIndexers . keySet ( ) ) { since = Math . min ( since , state . lucene . withReader ( sig , new ReaderCallback < Long > ( ) { public Long callback ( final IndexReader reader ) throws IOException { final Map < String , String > commitUserData = reader . getCommitUserData ( ) ; final String result = commitUserData . get ( " update_seq " ) ; return result ! = null ? Long . parseLong ( result ) : 0 L ; } } ) ) ; } this . since = since ; logger . debug ( " Existing indexes at update_seq " + since ) ; } 
public Document toDocument ( final RhinoContext context ) throws IOException { final Document result = new Document ( ) ; Add id. result.add(Utils.token("_id", context.documentId, true)); Add user-supplied fields. for (final RhinoField field : fields) { addField(field, context, result); } Parse user-requested attachments. for (final RhinoAttachment attachment : attachments) { addAttachment(attachment, context, result); } return result; } 
public Action handleChanges ( final long since , final ChangesHandler changesHandler ) throws IOException { final int limit = 100 ; final ResponseHandler < Action > responseHandler = new ResponseHandler < Action > ( ) { public Action handleResponse ( final HttpResponse response ) throws IOException { final HttpEntity entity = response . getEntity ( ) ; final String line = IOUtils . toString ( entity . getContent ( ) ) ; final JSONObject json = JSONObject . fromObject ( line ) ; final JSONArray rows = json . getJSONArray ( " rows " ) ; long seq = 0 ; for ( int i = 0 ; i < rows . size ( ) ; i + + ) { final JSONObject row = rows . getJSONObject ( i ) ; seq = row . getLong ( " key " ) ; changesHandler . onChange ( seq , row . getJSONObject ( " doc " ) ) ; } changesHandler . onEndOfSequence ( seq ) ; return limit = = rows . size ( ) ? Action . CONTINUE : Action . PAUSE ; } } ; final HttpGet get = new HttpGet ( url + " _all_docs_by_seq?include_docs=true&limit= " + limit + " &startkey= " + since ) ; return httpClient . execute ( get , responseHandler ) ; } 
public Action handleResponse ( final HttpResponse response ) throws IOException { final HttpEntity entity = response . getEntity ( ) ; final String line = IOUtils . toString ( entity . getContent ( ) ) ; final JSONObject json = JSONObject . fromObject ( line ) ; final JSONArray rows = json . getJSONArray ( " rows " ) ; long seq = 0 ; for ( int i = 0 ; i < rows . size ( ) ; i + + ) { final JSONObject row = rows . getJSONObject ( i ) ; seq = row . getLong ( " key " ) ; changesHandler . onChange ( seq , row . getJSONObject ( " doc " ) ) ; } changesHandler . onEndOfSequence ( seq ) ; return limit = = rows . size ( ) ? Action . CONTINUE : Action . PAUSE ; } 
public Action handleChanges ( final long since , final ChangesHandler changesHandler ) throws IOException { final ResponseHandler < Action > responseHandler = new ResponseHandler < Action > ( ) { public Action handleResponse ( HttpResponse response ) throws IOException { final HttpEntity entity = response . getEntity ( ) ; final BufferedReader reader = new BufferedReader ( new InputStreamReader ( entity . getContent ( ) , " UTF-8 " ) ) ; String line ; while ( ( line = reader . readLine ( ) ) ! = null ) { Consume response heartbeat. if (line.length() == 0) { changesHandler.onHeartbeat(); continue; } final JSONObject json = JSONObject.fromObject(line); Error. if (json.has("error")) { changesHandler.onError(json); return Action.ABORT; } End of response. if (json.has("last_seq")) { changesHandler.onEndOfSequence(json.getLong("last_seq")); return Action.CONTINUE; } A document update. changesHandler.onChange(json.getLong("seq"), json.getJSONObject("doc")); } return Action.CONTINUE; } }; final HttpGet get = new HttpGet(url + "_changes?feed=continuous&heartbeat=15000&include_docs=true&since=" + since); return httpClient.execute(get, responseHandler); } 
public Action handleResponse ( HttpResponse response ) throws IOException { final HttpEntity entity = response . getEntity ( ) ; final BufferedReader reader = new BufferedReader ( new InputStreamReader ( entity . getContent ( ) , " UTF-8 " ) ) ; String line ; while ( ( line = reader . readLine ( ) ) ! = null ) { Consume response heartbeat. if (line.length() == 0) { changesHandler.onHeartbeat(); continue; } final JSONObject json = JSONObject.fromObject(line); Error. if (json.has("error")) { changesHandler.onError(json); return Action.ABORT; } End of response. if (json.has("last_seq")) { changesHandler.onEndOfSequence(json.getLong("last_seq")); return Action.CONTINUE; } A document update. changesHandler.onChange(json.getLong("seq"), json.getJSONObject("doc")); } return Action.CONTINUE; } 
private void updateDocument ( final JSONObject doc ) { for ( final Entry < ViewSignature , ViewIndexer > entry : viewIndexers . entrySet ( ) ) { try { 
public boolean callback ( final IndexWriter writer ) throws IOException { writer . deleteDocuments ( new Term ( " _id " , id ) ) ; for ( final Document result : results ) { writer . addDocument ( result , entry . getValue ( ) . analyzer ) ; } return true ; } 
public Document toDocument ( final String id , final JSONObject defaults , final Database database ) throws IOException { final Document result = new Document ( ) ; Add id. result.add(Utils.token("_id", id, true)); Add user-supplied fields. for (final RhinoField field : fields) { addField(field, defaults, result); } Parse user-requested attachments. for (final RhinoAttachment attachment : attachments) { addAttachment(attachment, id, database, result); } return result; } 
private void addAttachment ( final RhinoAttachment attachment , final String id , final Database database , final Document out ) throws IOException { final ResponseHandler < Void > handler = new ResponseHandler < Void > ( ) { public Void handleResponse ( final HttpResponse response ) throws ClientProtocolException , IOException { final HttpEntity entity = response . getEntity ( ) ; final InputStream in = entity . getContent ( ) ; try { Tika . INSTANCE . parse ( in , entity . getContentType ( ) . getValue ( ) , attachment . fieldName , out ) ; } finally { in . close ( ) ; } return null ; } } ; database . handleAttachment ( id , attachment . attachmentName , handler ) ; } 
public Void handleResponse ( final HttpResponse response ) throws ClientProtocolException , IOException { final HttpEntity entity = response . getEntity ( ) ; final InputStream in = entity . getContent ( ) ; try { Tika . INSTANCE . parse ( in , entity . getContentType ( ) . getValue ( ) , attachment . fieldName , out ) ; } finally { in . close ( ) ; } return null ; } 
private void addField ( final RhinoField field , final JSONObject defaults , final Document out ) { String fieldName = defaults . optString ( " field " , Constants . DEFAULT_FIELD ) ; String store = defaults . optString ( " store " , " no " ) ; String index = defaults . optString ( " index " , " analyzed " ) ; String type = defaults . optString ( " type " , " string " ) ; Check for local settings. if (field.settings != null) { fieldName = optString(field.settings, "field", fieldName); store = optString(field.settings, "store", store); index = optString(field.settings, "index", index); type = optString(field.settings, "type", type); } final Field.Store storeObj = Store.get(store); if ("int".equals(type)) { out.add(new NumericField(fieldName, 4, storeObj, true).setIntValue(Conversion.convert(field.value, Integer.class))); 
private void parse ( final String resource , final String type , final String field ) throws IOException { final InputStream in = getClass ( ) . getClassLoader ( ) . getResourceAsStream ( resource ) ; try { Tika . INSTANCE . parse ( in , type , field , doc ) ; 
private void commitDocuments ( final boolean ignoreTimeout ) throws IOException { if ( ! hasPendingCommit ( ignoreTimeout ) ) return ; final JSONObject tracker = fetchTrackingDocument ( database ) ; tracker . put ( " update_seq " , since ) ; for ( final ViewSignature sig : viewIndexers . keySet ( ) ) { Fetch or generate index uuid. final String uuid = state.lucene.withReader(sig, false, new ReaderCallback<String>() { public String callback(final IndexReader reader) throws IOException { final String result = (String) reader.getCommitUserData().get("uuid"); return result != null ? result : UUID.randomUUID().toString(); } }); tracker.put(sig.toString(), uuid); Tell Lucene. state.lucene.withWriter(sig, new WriterCallback() { public boolean callback(final IndexWriter writer) throws IOException { final Map<String, String> commitUserData = new HashMap<String, String>(); commitUserData.put("update_seq", Long.toString(since)); commitUserData.put("uuid", uuid); logger.debug("Committing changes to " + sig + " with " + commitUserData); if (writer.maxDoc() == 0) { writer.addDocument(new Document()); } writer.commit(commitUserData); return false; } }); } Tell Couch. database.saveDocument(LOCAL_LUCENE, tracker.toString()); setPendingCommit(false); } 
private void readCheckpoints ( ) throws IOException { long since = Long . MAX_VALUE ; for ( final ViewSignature sig : viewIndexers . keySet ( ) ) { since = Math . min ( since , state . lucene . withReader ( sig , false , new ReaderCallback < Long > ( ) { public Long callback ( final IndexReader reader ) throws IOException { final Map < String , String > commitUserData = reader . getCommitUserData ( ) ; final String result = commitUserData . get ( " update_seq " ) ; return result ! = null ? Long . parseLong ( result ) : 0 L ; } } ) ) ; } this . since = since ; logger . debug ( " Existing indexes at update_seq " + since ) ; } 
private IndexWriter newWriter ( final Directory dir ) throws IOException { final IndexWriter result = new IndexWriter ( dir , Constants . ANALYZER , MaxFieldLength . UNLIMITED ) ; result . setMergeFactor ( 5 ) ; result . setUseCompoundFile ( false ) ; return result ; } 
public synchronized void close ( ) throws IOException { for ( final Holder holder : holders . values ( ) ) { holder . reader . clone ( ) ; holder . writer . rollback ( ) ; } holders . clear ( ) ; } 
public < T > T withReader ( final ViewSignature viewSignature , final boolean staleOk , final ReaderCallback < T > callback ) throws IOException { final Holder holder = getHolder ( viewSignature ) ; final IndexReader reader ; synchronized ( holder ) { if ( holder . reader = = null ) { holder . reader = holder . writer . getReader ( ) ; holder . reader . incRef ( ) ; } if ( ! staleOk ) { final IndexReader newReader = holder . reader . reopen ( ) ; if ( newReader ! = holder . reader ) { holder . reader . decRef ( ) ; holder . reader = newReader ; } } reader = holder . reader ; } reader . incRef ( ) ; try { return callback . callback ( reader ) ; 
public < T > T withSearcher ( final ViewSignature viewSignature , final boolean staleOk , final SearcherCallback < T > callback ) throws IOException { final Holder holder = getHolder ( viewSignature ) ; return withReader ( viewSignature , staleOk , new ReaderCallback < T > ( ) { 
public T callback ( final IndexReader reader ) throws IOException { return callback . callback ( new IndexSearcher ( reader ) , holder . etag ) ; } 
private synchronized Holder getHolder ( final ViewSignature viewSignature ) throws IOException { Holder result = holders . get ( viewSignature ) ; if ( result = = null ) { final File dir = viewSignature . toViewDir ( baseDir ) ; if ( ! dir . exists ( ) & & ! dir . mkdirs ( ) ) { throw new IOException ( " Could not make " + dir ) ; } result = new Holder ( ) ; result . writer = newWriter ( FSDirectory . open ( dir ) ) ; holders . put ( viewSignature , result ) ; } return result ; } 
public < T > T withReader ( final ViewSignature viewSignature , final boolean staleOk , final ReaderCallback < T > callback ) throws IOException { final Holder holder = getHolder ( viewSignature ) ; final IndexReader reader ; synchronized ( holder ) { if ( holder . reader = = null ) { holder . reader = holder . writer . getReader ( ) ; holder . etag = newEtag ( ) ; holder . dirty = false ; holder . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { holder.reader.decRef(); allow the reader to close. holder.reader = holder.writer.getReader(); if (holder.dirty) { holder.etag = newEtag(); holder.dirty = false; } } reader = holder.reader; } reader.incRef(); try { return callback.callback(reader); 
public void withWriter ( final ViewSignature viewSignature , final WriterCallback callback ) throws IOException { try { final Holder holder = getHolder ( viewSignature ) ; 
public void handle ( String target , HttpServletRequest request , HttpServletResponse response , int dispatch ) throws IOException { HttpConnection connection = HttpConnection . getCurrentConnection ( ) ; connection . getRequest ( ) . setHandled ( true ) ; Utils . setResponseContentTypeAndEncoding ( request , response ) ; response . setHeader ( HttpHeaders . CACHE_CONTROL , " must-revalidate,no-cache,no-store " ) ; final JSONObject obj = new JSONObject ( ) ; obj . put ( " code " , connection . getResponse ( ) . getStatus ( ) ) ; obj . put ( " reason " , connection . getResponse ( ) . getReason ( ) ) ; final byte [ ] body = obj . toString ( ) . getBytes ( " UTF-8 " ) ; response . setContentLength ( body . length ) ; response . getOutputStream ( ) . write ( body ) ; } 
protected void doPost ( final HttpServletRequest req , final HttpServletResponse resp ) throws ServletException , IOException { final ViewSignature sig = locator . lookup ( req ) ; if ( sig = = null ) { resp . sendError ( 400 , " Invalid path. " ) ; return ; } final String command = req . getParameter ( " cmd " ) ; if ( " expunge " . equals ( command ) ) { lucene . withWriter ( sig , new WriterCallback ( ) { public boolean callback ( final IndexWriter writer ) throws IOException { writer . expungeDeletes ( false ) ; return false ; } } ) ; resp . setStatus ( 202 ) ; return ; } if ( " optimize " . equals ( command ) ) { lucene . withWriter ( sig , new WriterCallback ( ) { public boolean callback ( final IndexWriter writer ) throws IOException { writer . optimize ( false ) ; return false ; } } ) ; resp . setStatus ( 202 ) ; return ; } resp . sendError ( 400 , " Bad request " ) ; } 
public void run ( ) { try { final String [ ] databases = couch . getAllDatabases ( ) ; 
private void commitDocuments ( final boolean ignoreTimeout ) throws IOException { if ( ! hasPendingCommit ( ignoreTimeout ) ) { return ; } final JSONObject tracker = fetchTrackingDocument ( database ) ; tracker . put ( " update_seq " , since ) ; for ( final ViewSignature sig : viewIndexers . keySet ( ) ) { Fetch or generate index uuid. final String uuid = lucene.withReader(sig, false, new ReaderCallback<String>() { public String callback(final IndexReader reader) throws IOException { final String result = (String) reader.getCommitUserData().get("uuid"); return result != null ? result : UUID.randomUUID().toString(); } }); tracker.put(sig.toString(), uuid); Tell Lucene. lucene.withWriter(sig, new WriterCallback() { public boolean callback(final IndexWriter writer) throws IOException { final Map<String, String> commitUserData = new HashMap<String, String>(); commitUserData.put("update_seq", Long.toString(since)); commitUserData.put("uuid", uuid); logger.debug("Committing changes to " + sig + " with " + commitUserData); if (writer.maxDoc() == 0) { writer.addDocument(new Document()); } writer.commit(commitUserData); return false; } }); } Tell Couch. database.saveDocument(LOCAL_LUCENE, tracker.toString()); setPendingCommit(false); } 
private void deleteDocument ( final JSONObject doc ) throws IOException { for ( final ViewSignature sig : viewIndexers . keySet ( ) ) { lucene . withWriter ( sig , new WriterCallback ( ) { 
private boolean mapDesignDocument ( final JSONObject designDocument ) throws IOException { final String designDocumentName = designDocument . getString ( " _id " ) . substring ( 8 ) ; final JSONObject fulltext = designDocument . getJSONObject ( " fulltext " ) ; boolean isLuceneEnabled = false ; if ( fulltext ! = null ) { for ( final Object obj : fulltext . keySet ( ) ) { final String viewName = ( String ) obj ; final JSONObject viewValue = fulltext . getJSONObject ( viewName ) ; final JSONObject defaults = viewValue . has ( " defaults " ) ? viewValue . getJSONObject ( " defaults " ) : defaults ( ) ; final Analyzer analyzer = Analyzers . getAnalyzer ( viewValue . optString ( " analyzer " , " standard " ) ) ; String function = viewValue . getString ( " index " ) ; function = function . replaceFirst ( " ^ \" " , " " ) ; function = function . replaceFirst ( " \" $ " , " " ) ; final ViewSignature sig = locator . update ( databaseName , designDocumentName , viewName , viewValue . toString ( ) ) ; viewIndexers . put ( sig , new ViewIndexer ( context , defaults , analyzer , viewName , function ) ) ; isLuceneEnabled = true ; } } return isLuceneEnabled ; } 
private void readCheckpoints ( ) throws IOException { long since = Long . MAX_VALUE ; for ( final ViewSignature sig : viewIndexers . keySet ( ) ) { since = Math . min ( since , lucene . withReader ( sig , false , new ReaderCallback < Long > ( ) { public Long callback ( final IndexReader reader ) throws IOException { final Map < String , String > commitUserData = reader . getCommitUserData ( ) ; final String result = commitUserData . get ( " update_seq " ) ; return result ! = null ? Long . parseLong ( result ) : 0 L ; } } ) ) ; } this . since = since ; logger . debug ( " Existing indexes at update_seq " + since ) ; } 
private static void setupContext ( final ContextHandlerCollection contexts , final String root , final HttpServlet servlet ) { final Context context = new Context ( contexts , root , Context . NO_SESSIONS ) ; context . addServlet ( new ServletHolder ( servlet ) , " /* " ) ; context . addFilter ( new FilterHolder ( new GzipFilter ( ) ) , " /* " , Handler . DEFAULT ) ; context . setErrorHandler ( new JSONErrorHandler ( ) ) ; } 
private Object fixup ( final String value ) { if ( value . matches ( " \\ d+ \\ . \\ d+f " ) ) { return Float . parseFloat ( value ) ; } if ( value . matches ( " \\ d+ \\ . \\ d+ " ) ) { return Double . parseDouble ( value ) ; } if ( value . matches ( " \\ d+[lL] " ) ) { return Long . parseLong ( value . substring ( 0 , value . length ( ) - 1 ) ) ; } if ( value . matches ( " \\ d+ " ) ) { return Integer . parseInt ( value ) ; } return String . class ; } 
private Query toQuery ( final HttpServletRequest req ) { Parse query. final Analyzer analyzer = Analyzers.getAnalyzer(getParameter(req, "analyzer", "standard")); final QueryParser parser = new QueryParser(Constants.DEFAULT_FIELD, analyzer); try { return fixup(parser.parse(req.getParameter("q"))); 
protected void doPost ( final HttpServletRequest req , final HttpServletResponse resp ) throws ServletException , IOException { final IndexKey key = new IndexKey ( req ) ; final String command = req . getParameter ( " cmd " ) ; if ( " expunge " . equals ( command ) ) { lucene . withWriter ( key , new WriterCallback ( ) { public boolean callback ( final IndexWriter writer ) throws IOException { writer . expungeDeletes ( false ) ; return false ; } public void onMissing ( ) throws IOException { resp . sendError ( 404 ) ; } } ) ; resp . setStatus ( 202 ) ; return ; } if ( " optimize " . equals ( command ) ) { lucene . withWriter ( key , new WriterCallback ( ) { public boolean callback ( final IndexWriter writer ) throws IOException { writer . optimize ( false ) ; return false ; } public void onMissing ( ) throws IOException { resp . sendError ( 404 ) ; } } ) ; resp . setStatus ( 202 ) ; return ; } resp . sendError ( 400 , " Bad request " ) ; } 
public void onMissing ( ) throws IOException { resp . sendError ( 404 ) ; } 
public synchronized void register ( final String key , final String url ) { map . put ( key , url . endsWith ( " / " ) ? url : url + " / " ) ; } 
public synchronized String url ( final String key , final String path ) { final String url = map . get ( key ) ; if ( url = = null ) return null ; return key + path ; } 
public synchronized void submit ( final K key , final Runnable runnable ) { Clean up. final Iterator<Thread> it = tasks.values().iterator(); while (it.hasNext()) { if (!it.next().isAlive()) it.remove(); } if (!tasks.containsKey(key)) { final Thread thread = new Thread(runnable, key.toString()); 
public synchronized void shutdownNow ( ) { for ( final Thread thread : tasks . values ( ) ) { thread . interrupt ( ) ; } tasks . clear ( ) ; } 
public int hashCode ( ) { final int prime = 31 ; int result = 1 ; result = prime * result + databaseName . hashCode ( ) ; result = prime * result + designDocumentName . hashCode ( ) ; result = prime * result + hostKey . hashCode ( ) ; result = prime * result + viewName . hashCode ( ) ; return result ; } 
public void onMissing ( ) throws IOException { resp . sendError ( 404 ) ; } 
public void callback ( final IndexReader reader ) throws IOException ; public void onMissing ( ) throws IOException ; } public interface SearcherCallback { public void callback ( final IndexSearcher searcher , final String version ) throws IOException ; public void onMissing ( ) throws IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) throws IOException ; public void onMissing ( ) throws IOException ; } public Lucene ( final File root , final CouchDbRegistry registry ) { this . root = root ; this . registry = registry ; } public void startIndexing ( final IndexKey indexKey ) { final String url = registry . url ( indexKey . getHostKey ( ) , " " ) ; executor . submit ( new TaskKey ( indexKey ) , new DatabaseIndexer ( url ) ) ; } public void withReader ( final IndexKey key , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple = map . get ( key ) ; if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexKey key, final boolean staleOk, final SearcherCallback callback) throws IOException { final String version = map.get(key).version; withReader(key, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexKey key, final WriterCallback callback) throws IOException { final Tuple tuple = map.get(key); if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(key).writer.rollback(); throw e; } } public void close() { executor.shutdownNow(); } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); } private static class TaskKey { private final String hostKey; private final String databaseName; public TaskKey(final IndexKey key) { this.hostKey = key.getHostKey(); this.databaseName = key.getDatabaseName(); } @Override public int hashCode() { final int prime = 31; int result = 1; result = prime * result + databaseName.hashCode(); result = prime * result + hostKey.hashCode(); return result; } @Override public boolean equals(Object obj) { if (this == obj) return true; if (obj == null) return false; if (getClass() != obj.getClass()) return false; TaskKey other = (TaskKey) obj; if (!databaseName.equals(other.databaseName)) return false; if (!hostKey.equals(other.hostKey)) return false; return true; } }} 
public void onMissing ( ) throws IOException ; } public interface SearcherCallback { public void callback ( final IndexSearcher searcher , final String version ) throws IOException ; public void onMissing ( ) throws IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) throws IOException ; public void onMissing ( ) throws IOException ; } public Lucene ( final File root , final CouchDbRegistry registry ) { this . root = root ; this . registry = registry ; } public void startIndexing ( final IndexKey indexKey ) { final String url = registry . url ( indexKey . getHostKey ( ) , " " ) ; executor . submit ( new TaskKey ( indexKey ) , new DatabaseIndexer ( url ) ) ; } public void withReader ( final IndexKey key , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple = map . get ( key ) ; if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexKey key, final boolean staleOk, final SearcherCallback callback) throws IOException { final String version = map.get(key).version; withReader(key, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexKey key, final WriterCallback callback) throws IOException { final Tuple tuple = map.get(key); if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(key).writer.rollback(); throw e; } } public void close() { executor.shutdownNow(); } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); } private static class TaskKey { private final String hostKey; private final String databaseName; public TaskKey(final IndexKey key) { this.hostKey = key.getHostKey(); this.databaseName = key.getDatabaseName(); } @Override public int hashCode() { final int prime = 31; int result = 1; result = prime * result + databaseName.hashCode(); result = prime * result + hostKey.hashCode(); return result; } @Override public boolean equals(Object obj) { if (this == obj) return true; if (obj == null) return false; if (getClass() != obj.getClass()) return false; TaskKey other = (TaskKey) obj; if (!databaseName.equals(other.databaseName)) return false; if (!hostKey.equals(other.hostKey)) return false; return true; } }} 
public void callback ( final IndexSearcher searcher , final String version ) throws IOException ; public void onMissing ( ) throws IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) throws IOException ; public void onMissing ( ) throws IOException ; } public Lucene ( final File root , final CouchDbRegistry registry ) { this . root = root ; this . registry = registry ; } public void startIndexing ( final IndexKey indexKey ) { final String url = registry . url ( indexKey . getHostKey ( ) , " " ) ; executor . submit ( new TaskKey ( indexKey ) , new DatabaseIndexer ( url ) ) ; } public void withReader ( final IndexKey key , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple = map . get ( key ) ; if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexKey key, final boolean staleOk, final SearcherCallback callback) throws IOException { final String version = map.get(key).version; withReader(key, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexKey key, final WriterCallback callback) throws IOException { final Tuple tuple = map.get(key); if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(key).writer.rollback(); throw e; } } public void close() { executor.shutdownNow(); } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); } private static class TaskKey { private final String hostKey; private final String databaseName; public TaskKey(final IndexKey key) { this.hostKey = key.getHostKey(); this.databaseName = key.getDatabaseName(); } @Override public int hashCode() { final int prime = 31; int result = 1; result = prime * result + databaseName.hashCode(); result = prime * result + hostKey.hashCode(); return result; } @Override public boolean equals(Object obj) { if (this == obj) return true; if (obj == null) return false; if (getClass() != obj.getClass()) return false; TaskKey other = (TaskKey) obj; if (!databaseName.equals(other.databaseName)) return false; if (!hostKey.equals(other.hostKey)) return false; return true; } }} 
public void onMissing ( ) throws IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) throws IOException ; public void onMissing ( ) throws IOException ; } public Lucene ( final File root , final CouchDbRegistry registry ) { this . root = root ; this . registry = registry ; } public void startIndexing ( final IndexKey indexKey ) { final String url = registry . url ( indexKey . getHostKey ( ) , " " ) ; executor . submit ( new TaskKey ( indexKey ) , new DatabaseIndexer ( url ) ) ; } public void withReader ( final IndexKey key , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple = map . get ( key ) ; if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexKey key, final boolean staleOk, final SearcherCallback callback) throws IOException { final String version = map.get(key).version; withReader(key, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexKey key, final WriterCallback callback) throws IOException { final Tuple tuple = map.get(key); if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(key).writer.rollback(); throw e; } } public void close() { executor.shutdownNow(); } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); } private static class TaskKey { private final String hostKey; private final String databaseName; public TaskKey(final IndexKey key) { this.hostKey = key.getHostKey(); this.databaseName = key.getDatabaseName(); } @Override public int hashCode() { final int prime = 31; int result = 1; result = prime * result + databaseName.hashCode(); result = prime * result + hostKey.hashCode(); return result; } @Override public boolean equals(Object obj) { if (this == obj) return true; if (obj == null) return false; if (getClass() != obj.getClass()) return false; TaskKey other = (TaskKey) obj; if (!databaseName.equals(other.databaseName)) return false; if (!hostKey.equals(other.hostKey)) return false; return true; } }} 
public boolean callback ( final IndexWriter writer ) throws IOException ; public void onMissing ( ) throws IOException ; } public Lucene ( final File root , final CouchDbRegistry registry ) { this . root = root ; this . registry = registry ; } public void startIndexing ( final IndexKey indexKey ) { final String url = registry . url ( indexKey . getHostKey ( ) , " " ) ; executor . submit ( new TaskKey ( indexKey ) , new DatabaseIndexer ( url ) ) ; } public void withReader ( final IndexKey key , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple = map . get ( key ) ; if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexKey key, final boolean staleOk, final SearcherCallback callback) throws IOException { final String version = map.get(key).version; withReader(key, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexKey key, final WriterCallback callback) throws IOException { final Tuple tuple = map.get(key); if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(key).writer.rollback(); throw e; } } public void close() { executor.shutdownNow(); } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); } private static class TaskKey { private final String hostKey; private final String databaseName; public TaskKey(final IndexKey key) { this.hostKey = key.getHostKey(); this.databaseName = key.getDatabaseName(); } @Override public int hashCode() { final int prime = 31; int result = 1; result = prime * result + databaseName.hashCode(); result = prime * result + hostKey.hashCode(); return result; } @Override public boolean equals(Object obj) { if (this == obj) return true; if (obj == null) return false; if (getClass() != obj.getClass()) return false; TaskKey other = (TaskKey) obj; if (!databaseName.equals(other.databaseName)) return false; if (!hostKey.equals(other.hostKey)) return false; return true; } }} 
public void onMissing ( ) throws IOException ; } public Lucene ( final File root , final CouchDbRegistry registry ) { this . root = root ; this . registry = registry ; } public void startIndexing ( final IndexKey indexKey ) { final String url = registry . url ( indexKey . getHostKey ( ) , " " ) ; executor . submit ( new TaskKey ( indexKey ) , new DatabaseIndexer ( url ) ) ; } public void withReader ( final IndexKey key , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple = map . get ( key ) ; if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexKey key, final boolean staleOk, final SearcherCallback callback) throws IOException { final String version = map.get(key).version; withReader(key, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexKey key, final WriterCallback callback) throws IOException { final Tuple tuple = map.get(key); if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(key).writer.rollback(); throw e; } } public void close() { executor.shutdownNow(); } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); } private static class TaskKey { private final String hostKey; private final String databaseName; public TaskKey(final IndexKey key) { this.hostKey = key.getHostKey(); this.databaseName = key.getDatabaseName(); } @Override public int hashCode() { final int prime = 31; int result = 1; result = prime * result + databaseName.hashCode(); result = prime * result + hostKey.hashCode(); return result; } @Override public boolean equals(Object obj) { if (this == obj) return true; if (obj == null) return false; if (getClass() != obj.getClass()) return false; TaskKey other = (TaskKey) obj; if (!databaseName.equals(other.databaseName)) return false; if (!hostKey.equals(other.hostKey)) return false; return true; } }} 
public void startIndexing ( final IndexKey indexKey ) { final String url = registry . url ( indexKey . getHostKey ( ) , " " ) ; executor . submit ( new TaskKey ( indexKey ) , new DatabaseIndexer ( url ) ) ; } 
public void withReader ( final IndexKey key , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple = map . get ( key ) ; if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); 
public void withSearcher ( final IndexKey key , final boolean staleOk , final SearcherCallback callback ) throws IOException { final String version = map . get ( key ) . version ; withReader ( key , staleOk , new ReaderCallback ( ) { 
public void callback ( final IndexReader reader ) throws IOException { callback . callback ( new IndexSearcher ( reader ) , version ) ; } 
public void onMissing ( ) throws IOException { callback . onMissing ( ) ; } 
public void withWriter ( final IndexKey key , final WriterCallback callback ) throws IOException { final Tuple tuple = map . get ( key ) ; if ( tuple = = null ) { callback . onMissing ( ) ; return ; } try { final boolean dirty = callback . callback ( tuple . writer ) ; 
private String newVersion ( ) { return Long . toHexString ( System . nanoTime ( ) ) ; } 
public int hashCode ( ) { final int prime = 31 ; int result = 1 ; result = prime * result + databaseName . hashCode ( ) ; result = prime * result + hostKey . hashCode ( ) ; return result ; } 
public boolean equals ( Object obj ) { if ( this = = obj ) return true ; if ( obj = = null ) return false ; if ( getClass ( ) ! = obj . getClass ( ) ) return false ; TaskKey other = ( TaskKey ) obj ; if ( ! databaseName . equals ( other . databaseName ) ) return false ; if ( ! hostKey . equals ( other . hostKey ) ) return false ; return true ; } 
public static void main ( String [ ] args ) throws Exception { final Properties properties = loadProperties ( ) ; final File dir = new File ( properties . getProperty ( " lucene.dir " ) , " indexes " ) ; if ( dir = = null ) { LOG . error ( " lucene.dir not set. " ) ; System . exit ( 1 ) ; } if ( ! dir . canRead ( ) ) { LOG . error ( dir + " is not readable. " ) ; System . exit ( 1 ) ; } if ( ! dir . canWrite ( ) ) { LOG . error ( dir + " is not writable. " ) ; System . exit ( 1 ) ; } LOG . info ( " Index output goes to : " + dir . getCanonicalPath ( ) ) ; final CouchDbRegistry registry = new CouchDbRegistry ( properties , " couchdb.url. " ) ; final Lucene lucene = new Lucene ( dir , registry ) ; final HttpClient client = httpClient ( ) ; final int port = Integer . parseInt ( properties . getProperty ( " lucene.port " , " 5985 " ) ) ; final Server jetty = jetty ( lucene , port ) ; jetty . start ( ) ; jetty . join ( ) ; } 
private static Properties loadProperties ( ) throws IOException { final Properties properties = new Properties ( ) ; final InputStream in = Main . class . getClassLoader ( ) . getResourceAsStream ( " couchdb-lucene.properties " ) ; if ( in = = null ) { LOG . error ( " No couchdb-lucene.properties file found. " ) ; return null ; } properties . load ( in ) ; in . close ( ) ; return properties ; } 
private static Server jetty ( final Lucene lucene , final int port ) { Configure Jetty. final Server server = new Server(Integer.getInteger("port", port)); server.setStopAtShutdown(true); server.setSendServerVersion(false); final ContextHandlerCollection contexts = new ContextHandlerCollection(); server.setHandler(contexts); final SearchServlet search = new SearchServlet(); search.setLucene(lucene); setupContext(contexts, "/search", search); final InfoServlet info = new InfoServlet(); info.setLucene(lucene); setupContext(contexts, "/info", info); final AdminServlet admin = new AdminServlet(); admin.setLucene(lucene); setupContext(contexts, "/admin", admin); return server; } 
private Query toQuery ( final HttpServletRequest req ) { Parse query. final Analyzer analyzer = Analyzers.getAnalyzer(getParameter(req, "analyzer", "standard")); final QueryParser parser = new QueryParser(Version.LUCENE_CURRENT, Constants.DEFAULT_FIELD, analyzer); try { return fixup(parser.parse(req.getParameter("q"))); 
public void onMissing ( ) throws IOException { resp . sendError ( 404 , " Index for " + key + " is missing. " ) ; } 
public void testSingleDocumentReturn ( ) throws Exception { final DocumentConverter converter = new DocumentConverter ( context , " single " , " function(doc) {return new Document();} " ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" } " ) , new JSONObject ( ) , null ) ; assertThat ( result . length , is ( 1 ) ) ; assertThat ( result [ 0 ] . get ( " _id " ) , is ( " hello " ) ) ; } 
public void testMultipleDocumentReturn ( ) throws Exception { final DocumentConverter converter = new DocumentConverter ( context , " multi " , " function(doc) {var ret = new Array(); ret.push(new Document()); ret.push(new Document()); return ret;} " ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" } " ) , new JSONObject ( ) , null ) ; assertThat ( result . length , is ( 2 ) ) ; assertThat ( result [ 0 ] . get ( " _id " ) , is ( " hello " ) ) ; assertThat ( result [ 1 ] . get ( " _id " ) , is ( " hello " ) ) ; } 
public void testNullReturn ( ) throws Exception { final DocumentConverter converter = new DocumentConverter ( context , " null " , " function(doc) {return null;} " ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" } " ) , new JSONObject ( ) , null ) ; assertThat ( result . length , is ( 0 ) ) ; } 
public void testUndefinedReturn ( ) throws Exception { final DocumentConverter converter = new DocumentConverter ( context , " null " , " function(doc) {return doc.nope;} " ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" } " ) , new JSONObject ( ) , null ) ; assertThat ( result . length , is ( 0 ) ) ; } 
public void testRuntimeException ( ) throws Exception { final DocumentConverter converter = new DocumentConverter ( context , " null " , " function(doc) {throw {bad : \" stuff \" }} " ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" } " ) , new JSONObject ( ) , null ) ; assertThat ( result . length , is ( 0 ) ) ; } 
private JSONObject doc ( final String json ) { return JSONObject . fromObject ( json ) ; } 
public synchronized void submit ( final K key , final Runnable runnable ) { cleanup ( ) ; if ( ! tasks . containsKey ( key ) ) { final Thread thread = new Thread ( runnable , key . toString ( ) ) ; 
private void cleanup ( ) { assert Thread . holdsLock ( this ) ; final Iterator < Thread > it = tasks . values ( ) . iterator ( ) ; while ( it . hasNext ( ) ) { if ( ! it . next ( ) . isAlive ( ) ) 
public void setup ( ) { executor = new IdempotentExecutor < Integer > ( ) ; } 
public void testRunTaskToCompletion ( ) throws Exception { final MyRunnable r = new MyRunnable ( ) ; r . countdown ( ) ; executor . submit ( 0 , r ) ; Thread . sleep ( 10 ) ; assertThat ( r . ran , is ( true ) ) ; assertThat ( executor . getTaskCount ( ) , is ( 0 ) ) ; } 
public void testIdempotency ( ) { final MyRunnable r1 = new MyRunnable ( ) ; final MyRunnable r2 = new MyRunnable ( ) ; executor . submit ( 0 , r1 ) ; executor . submit ( 0 , r2 ) ; assertThat ( executor . getTaskCount ( ) , is ( 1 ) ) ; } 
public void testConcurrency ( ) { final MyRunnable r1 = new MyRunnable ( ) ; final MyRunnable r2 = new MyRunnable ( ) ; executor . submit ( 0 , r1 ) ; executor . submit ( 1 , r2 ) ; assertThat ( executor . getTaskCount ( ) , is ( 2 ) ) ; } 
public void testShutdown ( ) { final MyRunnable r1 = new MyRunnable ( ) ; final MyRunnable r2 = new MyRunnable ( ) ; executor . submit ( 0 , r1 ) ; executor . submit ( 1 , r2 ) ; assertThat ( executor . getTaskCount ( ) , is ( 2 ) ) ; executor . shutdownNow ( ) ; assertThat ( executor . getTaskCount ( ) , is ( 0 ) ) ; } 
public synchronized String url ( final String key , final String path ) { final String url = map . get ( key ) ; if ( url = = null ) return null ; return url + path ; } 
private static HttpClient httpClient ( ) { final HttpParams params = new BasicHttpParams ( ) ; HttpProtocolParams . setVersion ( params , HttpVersion . HTTP_1_1 ) ; HttpProtocolParams . setUseExpectContinue ( params , false ) ; return new DefaultHttpClient ( params ) ; } 
public void run ( ) { setup ( ) ; try { while ( true ) { 
private void setup ( ) { client = httpClient ( ) ; context = Context . enter ( ) ; context . setClassShutter ( new RestrictiveClassShutter ( ) ) ; context . setOptimizationLevel ( 9 ) ; } 
private void index ( ) throws IOException { HttpGet get = new HttpGet ( url + " /_local/lucene " ) ; uuid = getDatabaseUuid ( get ) ; if ( uuid = = null ) { storeNewUuid ( ) ; 
private UUID getDatabaseUuid ( HttpGet get ) throws IOException , ClientProtocolException { return client . execute ( get , new UUIDHandler ( ) ) ; } 
private void storeNewUuid ( ) throws UnsupportedEncodingException , IOException , ClientProtocolException { final JSONObject json = new JSONObject ( ) ; final UUID newUUID = UUID . randomUUID ( ) ; json . put ( " uuid " , newUUID . toString ( ) ) ; final HttpPut put = new HttpPut ( url + " /_local/lucene " ) ; put . setEntity ( new StringEntity ( json . toString ( ) ) ) ; client . execute ( put , new BasicResponseHandler ( ) ) ; } 
public String toString ( ) { return " IndexKey [databaseName= " + databaseName + " , designDocumentName= " + designDocumentName + " , hostKey= " + hostKey + " , viewName= " + viewName + " ] " ; 
public void callback ( final IndexReader reader ) throws IOException ; public void onMissing ( ) throws IOException ; } public interface SearcherCallback { public void callback ( final IndexSearcher searcher , final String version ) throws IOException ; public void onMissing ( ) throws IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) throws IOException ; public void onMissing ( ) throws IOException ; } public Lucene ( final File root , final CouchDbRegistry registry ) { this . root = root ; this . registry = registry ; } public void startIndexing ( final IndexKey indexKey ) { final String url = registry . url ( indexKey . getHostKey ( ) , indexKey . getDatabaseName ( ) ) ; executor . submit ( new TaskKey ( indexKey ) , new DatabaseIndexer ( url ) ) ; } public void withReader ( final IndexKey key , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple = map . get ( key ) ; if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexKey key, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(key, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(key).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexKey key, final WriterCallback callback) throws IOException { final Tuple tuple = map.get(key); if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(key).writer.rollback(); throw e; } } public void close() { executor.shutdownNow(); } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); } private static class TaskKey { private final String hostKey; private final String databaseName; public TaskKey(final IndexKey key) { this.hostKey = key.getHostKey(); this.databaseName = key.getDatabaseName(); } @Override public int hashCode() { final int prime = 31; int result = 1; result = prime * result + databaseName.hashCode(); result = prime * result + hostKey.hashCode(); return result; } @Override public boolean equals(Object obj) { if (this == obj) return true; if (obj == null) return false; if (getClass() != obj.getClass()) return false; TaskKey other = (TaskKey) obj; if (!databaseName.equals(other.databaseName)) return false; if (!hostKey.equals(other.hostKey)) return false; return true; } }} 
public void onMissing ( ) throws IOException ; } public interface SearcherCallback { public void callback ( final IndexSearcher searcher , final String version ) throws IOException ; public void onMissing ( ) throws IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) throws IOException ; public void onMissing ( ) throws IOException ; } public Lucene ( final File root , final CouchDbRegistry registry ) { this . root = root ; this . registry = registry ; } public void startIndexing ( final IndexKey indexKey ) { final String url = registry . url ( indexKey . getHostKey ( ) , indexKey . getDatabaseName ( ) ) ; executor . submit ( new TaskKey ( indexKey ) , new DatabaseIndexer ( url ) ) ; } public void withReader ( final IndexKey key , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple = map . get ( key ) ; if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexKey key, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(key, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(key).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexKey key, final WriterCallback callback) throws IOException { final Tuple tuple = map.get(key); if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(key).writer.rollback(); throw e; } } public void close() { executor.shutdownNow(); } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); } private static class TaskKey { private final String hostKey; private final String databaseName; public TaskKey(final IndexKey key) { this.hostKey = key.getHostKey(); this.databaseName = key.getDatabaseName(); } @Override public int hashCode() { final int prime = 31; int result = 1; result = prime * result + databaseName.hashCode(); result = prime * result + hostKey.hashCode(); return result; } @Override public boolean equals(Object obj) { if (this == obj) return true; if (obj == null) return false; if (getClass() != obj.getClass()) return false; TaskKey other = (TaskKey) obj; if (!databaseName.equals(other.databaseName)) return false; if (!hostKey.equals(other.hostKey)) return false; return true; } }} 
public void callback ( final IndexSearcher searcher , final String version ) throws IOException ; public void onMissing ( ) throws IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) throws IOException ; public void onMissing ( ) throws IOException ; } public Lucene ( final File root , final CouchDbRegistry registry ) { this . root = root ; this . registry = registry ; } public void startIndexing ( final IndexKey indexKey ) { final String url = registry . url ( indexKey . getHostKey ( ) , indexKey . getDatabaseName ( ) ) ; executor . submit ( new TaskKey ( indexKey ) , new DatabaseIndexer ( url ) ) ; } public void withReader ( final IndexKey key , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple = map . get ( key ) ; if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexKey key, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(key, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(key).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexKey key, final WriterCallback callback) throws IOException { final Tuple tuple = map.get(key); if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(key).writer.rollback(); throw e; } } public void close() { executor.shutdownNow(); } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); } private static class TaskKey { private final String hostKey; private final String databaseName; public TaskKey(final IndexKey key) { this.hostKey = key.getHostKey(); this.databaseName = key.getDatabaseName(); } @Override public int hashCode() { final int prime = 31; int result = 1; result = prime * result + databaseName.hashCode(); result = prime * result + hostKey.hashCode(); return result; } @Override public boolean equals(Object obj) { if (this == obj) return true; if (obj == null) return false; if (getClass() != obj.getClass()) return false; TaskKey other = (TaskKey) obj; if (!databaseName.equals(other.databaseName)) return false; if (!hostKey.equals(other.hostKey)) return false; return true; } }} 
public void onMissing ( ) throws IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) throws IOException ; public void onMissing ( ) throws IOException ; } public Lucene ( final File root , final CouchDbRegistry registry ) { this . root = root ; this . registry = registry ; } public void startIndexing ( final IndexKey indexKey ) { final String url = registry . url ( indexKey . getHostKey ( ) , indexKey . getDatabaseName ( ) ) ; executor . submit ( new TaskKey ( indexKey ) , new DatabaseIndexer ( url ) ) ; } public void withReader ( final IndexKey key , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple = map . get ( key ) ; if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexKey key, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(key, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(key).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexKey key, final WriterCallback callback) throws IOException { final Tuple tuple = map.get(key); if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(key).writer.rollback(); throw e; } } public void close() { executor.shutdownNow(); } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); } private static class TaskKey { private final String hostKey; private final String databaseName; public TaskKey(final IndexKey key) { this.hostKey = key.getHostKey(); this.databaseName = key.getDatabaseName(); } @Override public int hashCode() { final int prime = 31; int result = 1; result = prime * result + databaseName.hashCode(); result = prime * result + hostKey.hashCode(); return result; } @Override public boolean equals(Object obj) { if (this == obj) return true; if (obj == null) return false; if (getClass() != obj.getClass()) return false; TaskKey other = (TaskKey) obj; if (!databaseName.equals(other.databaseName)) return false; if (!hostKey.equals(other.hostKey)) return false; return true; } }} 
public boolean callback ( final IndexWriter writer ) throws IOException ; public void onMissing ( ) throws IOException ; } public Lucene ( final File root , final CouchDbRegistry registry ) { this . root = root ; this . registry = registry ; } public void startIndexing ( final IndexKey indexKey ) { final String url = registry . url ( indexKey . getHostKey ( ) , indexKey . getDatabaseName ( ) ) ; executor . submit ( new TaskKey ( indexKey ) , new DatabaseIndexer ( url ) ) ; } public void withReader ( final IndexKey key , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple = map . get ( key ) ; if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexKey key, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(key, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(key).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexKey key, final WriterCallback callback) throws IOException { final Tuple tuple = map.get(key); if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(key).writer.rollback(); throw e; } } public void close() { executor.shutdownNow(); } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); } private static class TaskKey { private final String hostKey; private final String databaseName; public TaskKey(final IndexKey key) { this.hostKey = key.getHostKey(); this.databaseName = key.getDatabaseName(); } @Override public int hashCode() { final int prime = 31; int result = 1; result = prime * result + databaseName.hashCode(); result = prime * result + hostKey.hashCode(); return result; } @Override public boolean equals(Object obj) { if (this == obj) return true; if (obj == null) return false; if (getClass() != obj.getClass()) return false; TaskKey other = (TaskKey) obj; if (!databaseName.equals(other.databaseName)) return false; if (!hostKey.equals(other.hostKey)) return false; return true; } }} 
public void onMissing ( ) throws IOException ; } public Lucene ( final File root , final CouchDbRegistry registry ) { this . root = root ; this . registry = registry ; } public void startIndexing ( final IndexKey indexKey ) { final String url = registry . url ( indexKey . getHostKey ( ) , indexKey . getDatabaseName ( ) ) ; executor . submit ( new TaskKey ( indexKey ) , new DatabaseIndexer ( url ) ) ; } public void withReader ( final IndexKey key , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple = map . get ( key ) ; if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexKey key, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(key, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(key).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexKey key, final WriterCallback callback) throws IOException { final Tuple tuple = map.get(key); if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(key).writer.rollback(); throw e; } } public void close() { executor.shutdownNow(); } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); } private static class TaskKey { private final String hostKey; private final String databaseName; public TaskKey(final IndexKey key) { this.hostKey = key.getHostKey(); this.databaseName = key.getDatabaseName(); } @Override public int hashCode() { final int prime = 31; int result = 1; result = prime * result + databaseName.hashCode(); result = prime * result + hostKey.hashCode(); return result; } @Override public boolean equals(Object obj) { if (this == obj) return true; if (obj == null) return false; if (getClass() != obj.getClass()) return false; TaskKey other = (TaskKey) obj; if (!databaseName.equals(other.databaseName)) return false; if (!hostKey.equals(other.hostKey)) return false; return true; } }} 
public void startIndexing ( final IndexKey indexKey ) { final String url = registry . url ( indexKey . getHostKey ( ) , indexKey . getDatabaseName ( ) ) ; executor . submit ( new TaskKey ( indexKey ) , new DatabaseIndexer ( url ) ) ; } 
public void withSearcher ( final IndexKey key , final boolean staleOk , final SearcherCallback callback ) throws IOException { withReader ( key , staleOk , new ReaderCallback ( ) { 
public void callback ( final IndexReader reader ) throws IOException { callback . callback ( new IndexSearcher ( reader ) , map . get ( key ) . version ) ; } 
public static void main ( String [ ] args ) throws Exception { final Properties properties = loadProperties ( ) ; final File dir = new File ( properties . getProperty ( " lucene.dir " , " indexes " ) ) ; if ( dir = = null ) { LOG . error ( " lucene.dir not set. " ) ; System . exit ( 1 ) ; } if ( ! dir . canRead ( ) ) { LOG . error ( dir + " is not readable. " ) ; System . exit ( 1 ) ; } if ( ! dir . canWrite ( ) ) { LOG . error ( dir + " is not writable. " ) ; System . exit ( 1 ) ; } LOG . info ( " Index output goes to : " + dir . getCanonicalPath ( ) ) ; final CouchDbRegistry registry = new CouchDbRegistry ( properties , " couchdb.url. " ) ; final Lucene lucene = new Lucene ( dir , registry ) ; final int port = Integer . parseInt ( properties . getProperty ( " lucene.port " , " 5985 " ) ) ; final Server jetty = jetty ( lucene , port ) ; jetty . start ( ) ; jetty . join ( ) ; } 
public void onMissing ( ) throws IOException { resp . sendError ( 404 , " Index for " + key . getDatabaseName ( ) + " is missing. " ) ; } 
public synchronized void mapHostKeyToUrl ( final String key , final String url ) { hostMap . put ( key , url . endsWith ( " / " ) ? url : url + " / " ) ; } 
public synchronized String createUrlByHostKey ( final String key , final String path ) { final String url = hostMap . get ( key ) ; if ( url = = null ) return null ; return url + path ; } 
public String toString ( ) { final StringBuffer buffer = new StringBuffer ( 100 ) ; buffer . append ( hostKey ) ; buffer . append ( " / " ) ; buffer . append ( databaseName ) ; buffer . append ( " / " ) ; buffer . append ( designDocumentName ) ; buffer . append ( " / " ) ; buffer . append ( viewName ) ; return buffer . toString ( ) ; } 
public void callback ( final IndexReader reader ) throws IOException ; public void onMissing ( ) throws IOException ; } public interface SearcherCallback { public void callback ( final IndexSearcher searcher , final String version ) throws IOException ; public void onMissing ( ) throws IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) throws IOException ; public void onMissing ( ) throws IOException ; } public Lucene ( final File root , final CouchDbRegistry registry ) { this . root = root ; this . registry = registry ; } public void startIndexing ( final IndexKey indexKey ) { executor . submit ( indexKey , new ViewIndexer ( this , registry , indexKey ) ) ; } public void withReader ( final IndexKey key , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple ; synchronized ( map ) { tuple = map . get ( key ) ; } if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexKey key, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(key, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(key).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexKey key, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(key); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(key).writer.rollback(); throw e; } } public void createWriter(final IndexKey key, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { if (map.containsKey(key)) return; final Directory d = FSDirectory.open(dir); final Tuple tuple = new Tuple(newWriter(d)); map.put(key, tuple); } } public void close() { executor.shutdownNow(); } private String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }} 
public void onMissing ( ) throws IOException ; } public interface SearcherCallback { public void callback ( final IndexSearcher searcher , final String version ) throws IOException ; public void onMissing ( ) throws IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) throws IOException ; public void onMissing ( ) throws IOException ; } public Lucene ( final File root , final CouchDbRegistry registry ) { this . root = root ; this . registry = registry ; } public void startIndexing ( final IndexKey indexKey ) { executor . submit ( indexKey , new ViewIndexer ( this , registry , indexKey ) ) ; } public void withReader ( final IndexKey key , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple ; synchronized ( map ) { tuple = map . get ( key ) ; } if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexKey key, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(key, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(key).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexKey key, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(key); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(key).writer.rollback(); throw e; } } public void createWriter(final IndexKey key, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { if (map.containsKey(key)) return; final Directory d = FSDirectory.open(dir); final Tuple tuple = new Tuple(newWriter(d)); map.put(key, tuple); } } public void close() { executor.shutdownNow(); } private String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }} 
public void callback ( final IndexSearcher searcher , final String version ) throws IOException ; public void onMissing ( ) throws IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) throws IOException ; public void onMissing ( ) throws IOException ; } public Lucene ( final File root , final CouchDbRegistry registry ) { this . root = root ; this . registry = registry ; } public void startIndexing ( final IndexKey indexKey ) { executor . submit ( indexKey , new ViewIndexer ( this , registry , indexKey ) ) ; } public void withReader ( final IndexKey key , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple ; synchronized ( map ) { tuple = map . get ( key ) ; } if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexKey key, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(key, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(key).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexKey key, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(key); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(key).writer.rollback(); throw e; } } public void createWriter(final IndexKey key, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { if (map.containsKey(key)) return; final Directory d = FSDirectory.open(dir); final Tuple tuple = new Tuple(newWriter(d)); map.put(key, tuple); } } public void close() { executor.shutdownNow(); } private String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }} 
public void onMissing ( ) throws IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) throws IOException ; public void onMissing ( ) throws IOException ; } public Lucene ( final File root , final CouchDbRegistry registry ) { this . root = root ; this . registry = registry ; } public void startIndexing ( final IndexKey indexKey ) { executor . submit ( indexKey , new ViewIndexer ( this , registry , indexKey ) ) ; } public void withReader ( final IndexKey key , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple ; synchronized ( map ) { tuple = map . get ( key ) ; } if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexKey key, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(key, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(key).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexKey key, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(key); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(key).writer.rollback(); throw e; } } public void createWriter(final IndexKey key, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { if (map.containsKey(key)) return; final Directory d = FSDirectory.open(dir); final Tuple tuple = new Tuple(newWriter(d)); map.put(key, tuple); } } public void close() { executor.shutdownNow(); } private String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }} 
public boolean callback ( final IndexWriter writer ) throws IOException ; public void onMissing ( ) throws IOException ; } public Lucene ( final File root , final CouchDbRegistry registry ) { this . root = root ; this . registry = registry ; } public void startIndexing ( final IndexKey indexKey ) { executor . submit ( indexKey , new ViewIndexer ( this , registry , indexKey ) ) ; } public void withReader ( final IndexKey key , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple ; synchronized ( map ) { tuple = map . get ( key ) ; } if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexKey key, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(key, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(key).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexKey key, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(key); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(key).writer.rollback(); throw e; } } public void createWriter(final IndexKey key, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { if (map.containsKey(key)) return; final Directory d = FSDirectory.open(dir); final Tuple tuple = new Tuple(newWriter(d)); map.put(key, tuple); } } public void close() { executor.shutdownNow(); } private String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }} 
public void onMissing ( ) throws IOException ; } public Lucene ( final File root , final CouchDbRegistry registry ) { this . root = root ; this . registry = registry ; } public void startIndexing ( final IndexKey indexKey ) { executor . submit ( indexKey , new ViewIndexer ( this , registry , indexKey ) ) ; } public void withReader ( final IndexKey key , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple ; synchronized ( map ) { tuple = map . get ( key ) ; } if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexKey key, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(key, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(key).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexKey key, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(key); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(key).writer.rollback(); throw e; } } public void createWriter(final IndexKey key, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { if (map.containsKey(key)) return; final Directory d = FSDirectory.open(dir); final Tuple tuple = new Tuple(newWriter(d)); map.put(key, tuple); } } public void close() { executor.shutdownNow(); } private String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }} 
public void startIndexing ( final IndexKey indexKey ) { executor . submit ( indexKey , new ViewIndexer ( this , registry , indexKey ) ) ; } 
public void withReader ( final IndexKey key , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple ; synchronized ( map ) { tuple = map . get ( key ) ; } if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); 
public void withWriter ( final IndexKey key , final WriterCallback callback ) throws IOException { final Tuple tuple ; synchronized ( map ) { tuple = map . get ( key ) ; } if ( tuple = = null ) { callback . onMissing ( ) ; return ; } try { final boolean dirty = callback . callback ( tuple . writer ) ; 
public void createWriter ( final IndexKey key , final UUID uuid , final String function ) throws IOException { final String digest = digest ( function ) ; final File dir = new File ( new File ( root , uuid . toString ( ) ) , digest ) ; dir . mkdirs ( ) ; synchronized ( map ) { if ( map . containsKey ( key ) ) 
private String digest ( final String function ) { try { final MessageDigest md = MessageDigest . getInstance ( " MD5 " ) ; 
public static void main ( String [ ] args ) throws Exception { final Properties properties = loadProperties ( ) ; final File dir = new File ( properties . getProperty ( " lucene.dir " , " indexes " ) ) ; if ( dir = = null ) { LOG . error ( " lucene.dir not set. " ) ; System . exit ( 1 ) ; } if ( ! dir . canRead ( ) ) { LOG . error ( dir + " is not readable. " ) ; System . exit ( 1 ) ; } if ( ! dir . canWrite ( ) ) { LOG . error ( dir + " is not writable. " ) ; System . exit ( 1 ) ; } LOG . info ( " Index output goes to: " + dir . getCanonicalPath ( ) ) ; final CouchDbRegistry registry = new CouchDbRegistry ( properties , " couchdb.url. " ) ; final Lucene lucene = new Lucene ( dir , registry ) ; final int port = Integer . parseInt ( properties . getProperty ( " lucene.port " , " 5985 " ) ) ; final Server jetty = jetty ( lucene , port ) ; jetty . start ( ) ; jetty . join ( ) ; } 
public void run ( ) { try { setup ( ) ; } catch ( final IOException e ) { logger . warn ( " I/O exception starting indexing: " + e . getMessage ( ) ) ; } try { index ( ) ; 
private void setup ( ) throws IOException { logger . info ( " Starting. " ) ; context = Context . enter ( ) ; context . setClassShutter ( new RestrictiveClassShutter ( ) ) ; context . setOptimizationLevel ( 9 ) ; client = httpClient ( ) ; url = registry . createUrlByHostKey ( key . getHostKey ( ) , key . getDatabaseName ( ) ) ; final Couch couch = Couch . getInstance ( client , registry . createUrlByHostKey ( key . getHostKey ( ) , " " ) ) ; logger . info ( couch + " detected. " ) ; database = couch . getDatabase ( key . getDatabaseName ( ) ) ; } 
private void teardown ( ) { logger . info ( " Stopping. " ) ; client . getConnectionManager ( ) . shutdown ( ) ; Context . exit ( ) ; } 
private void index ( ) throws IOException { final UUID uuid = getDatabaseUuid ( ) ; final JSONObject ddoc = database . getDocument ( " _design/ " + key . getDesignDocumentName ( ) ) ; final JSONObject fulltext = ddoc . getJSONObject ( " fulltext " ) ; final JSONObject view = fulltext . getJSONObject ( key . getViewName ( ) ) ; final JSONObject defaults = view . has ( " defaults " ) ? view . getJSONObject ( " defaults " ) : defaults ( ) ; final Analyzer analyzer = Analyzers . getAnalyzer ( view . optString ( " analyzer " , " standard " ) ) ; final String function = StringUtils . trim ( view . getString ( " index " ) ) ; lucene . createWriter ( key , uuid , function ) ; lucene . withReader ( key , false , new ReaderCallback ( ) { public void callback ( final IndexReader reader ) throws IOException { final Map commit = reader . getCommitUserData ( ) ; if ( commit ! = null & & commit . containsKey ( " last_seq " ) ) { since = Long . parseLong ( ( String ) commit . get ( " last_seq " ) ) ; } } public void onMissing ( ) throws IOException { since = 0 ; } } ) ; logger . info ( " Fetching changes since update_seq " + since ) ; database . handleChanges ( since , new ViewChangesHandler ( ) ) ; } 
public void callback ( final IndexReader reader ) throws IOException { final Map commit = reader . getCommitUserData ( ) ; if ( commit ! = null & & commit . containsKey ( " last_seq " ) ) { since = Long . parseLong ( ( String ) commit . get ( " last_seq " ) ) ; 
public void onMissing ( ) throws IOException { since = 0 ; } 
private HttpClient httpClient ( ) { final HttpParams params = new BasicHttpParams ( ) ; HttpProtocolParams . setVersion ( params , HttpVersion . HTTP_1_1 ) ; HttpProtocolParams . setUseExpectContinue ( params , false ) ; return new DefaultHttpClient ( params ) ; } 
private JSONObject defaults ( ) { final JSONObject result = new JSONObject ( ) ; result . put ( " field " , Constants . DEFAULT_FIELD ) ; result . put ( " store " , " no " ) ; result . put ( " index " , " analyzed " ) ; result . put ( " type " , " string " ) ; return result ; } 
private UUID getDatabaseUuid ( ) throws IOException { final HttpGet get = new HttpGet ( url + " /_local/lucene " ) ; UUID result = client . execute ( get , new UUIDHandler ( ) ) ; if ( result = = null ) { result = UUID . randomUUID ( ) ; final String doc = String . format ( " { \" uuid \" : \" %s \" } " , result ) ; final HttpPut put = new HttpPut ( url + " /_local/lucene " ) ; put . setEntity ( new StringEntity ( doc ) ) ; final int sc = client . execute ( put , new StatusCodeResponseHandler ( ) ) ; switch ( sc ) { case 201 : break ; case 404 : case 409 : result = getDatabaseUuid ( ) ; break ; default : throw new IOException ( " Unexpected error code: " + sc ) ; } } logger . info ( " Database has uuid " + result ) ; return result ; } 
public void onChange ( long seq , JSONObject doc ) throws IOException { TODO Auto-generated method stub System.err.println(seq); } 
public void onEndOfSequence ( long seq ) throws IOException { TODO Auto-generated method stub } public void onError(JSONObject error) throws IOException { TODO Auto-generated method stub } public void onHeartbeat() throws IOException { TODO Auto-generated method stub } }} 
public void onError ( JSONObject error ) throws IOException { TODO Auto-generated method stub } public void onHeartbeat() throws IOException { TODO Auto-generated method stub } }} 
public void onHeartbeat ( ) throws IOException { TODO Auto-generated method stub } }} 
public String toString ( ) { return " CouchDB without _changes " ; } 
public String toString ( ) { return " CouchDB with _changes " ; } 
public static Couch getInstance ( final HttpClient client , final String url ) throws IOException { final String version = getCouchVersion ( client , url ) ; if ( version . contains ( " CouchDB/0.11 " ) ) { return new CouchWithChanges ( client , url ) ; } if ( version . contains ( " CouchDB/0.10 " ) ) { return new CouchWithoutChanges ( client , url ) ; } if ( version . contains ( " CouchDB/0.9.1 " ) ) { return new CouchWithoutChanges ( client , url ) ; } throw new UnsupportedOperationException ( " No support for " + version ) ; } 
private String loadResource ( final String name ) throws IOException { final InputStream in = DocumentConverter . class . getClassLoader ( ) . getResourceAsStream ( name ) ; try { return IOUtils . toString ( in , " UTF-8 " ) ; 
public void callback ( final IndexReader reader ) throws IOException ; public void onMissing ( ) throws IOException ; } public interface SearcherCallback { public void callback ( final IndexSearcher searcher , final String version ) throws IOException ; public void onMissing ( ) throws IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) throws IOException ; public void onMissing ( ) throws IOException ; } public Lucene ( final File root , final CouchDbRegistry registry ) { this . root = root ; this . registry = registry ; } public void startIndexing ( final IndexKey indexKey ) { executor . submit ( indexKey , new ViewIndexer ( this , registry , indexKey ) ) ; } public void withReader ( final IndexKey key , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple ; synchronized ( map ) { tuple = map . get ( key ) ; } if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexKey key, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(key, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(key).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexKey key, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(key); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(key).writer.rollback(); throw e; } } public void createWriter(final IndexKey key, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { if (map.containsKey(key)) return; final Directory d = FSDirectory.open(dir); final Tuple tuple = new Tuple(newWriter(d)); map.put(key, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }} 
public void onMissing ( ) throws IOException ; } public interface SearcherCallback { public void callback ( final IndexSearcher searcher , final String version ) throws IOException ; public void onMissing ( ) throws IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) throws IOException ; public void onMissing ( ) throws IOException ; } public Lucene ( final File root , final CouchDbRegistry registry ) { this . root = root ; this . registry = registry ; } public void startIndexing ( final IndexKey indexKey ) { executor . submit ( indexKey , new ViewIndexer ( this , registry , indexKey ) ) ; } public void withReader ( final IndexKey key , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple ; synchronized ( map ) { tuple = map . get ( key ) ; } if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexKey key, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(key, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(key).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexKey key, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(key); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(key).writer.rollback(); throw e; } } public void createWriter(final IndexKey key, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { if (map.containsKey(key)) return; final Directory d = FSDirectory.open(dir); final Tuple tuple = new Tuple(newWriter(d)); map.put(key, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }} 
public void callback ( final IndexSearcher searcher , final String version ) throws IOException ; public void onMissing ( ) throws IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) throws IOException ; public void onMissing ( ) throws IOException ; } public Lucene ( final File root , final CouchDbRegistry registry ) { this . root = root ; this . registry = registry ; } public void startIndexing ( final IndexKey indexKey ) { executor . submit ( indexKey , new ViewIndexer ( this , registry , indexKey ) ) ; } public void withReader ( final IndexKey key , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple ; synchronized ( map ) { tuple = map . get ( key ) ; } if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexKey key, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(key, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(key).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexKey key, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(key); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(key).writer.rollback(); throw e; } } public void createWriter(final IndexKey key, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { if (map.containsKey(key)) return; final Directory d = FSDirectory.open(dir); final Tuple tuple = new Tuple(newWriter(d)); map.put(key, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }} 
public void onMissing ( ) throws IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) throws IOException ; public void onMissing ( ) throws IOException ; } public Lucene ( final File root , final CouchDbRegistry registry ) { this . root = root ; this . registry = registry ; } public void startIndexing ( final IndexKey indexKey ) { executor . submit ( indexKey , new ViewIndexer ( this , registry , indexKey ) ) ; } public void withReader ( final IndexKey key , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple ; synchronized ( map ) { tuple = map . get ( key ) ; } if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexKey key, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(key, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(key).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexKey key, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(key); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(key).writer.rollback(); throw e; } } public void createWriter(final IndexKey key, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { if (map.containsKey(key)) return; final Directory d = FSDirectory.open(dir); final Tuple tuple = new Tuple(newWriter(d)); map.put(key, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }} 
public boolean callback ( final IndexWriter writer ) throws IOException ; public void onMissing ( ) throws IOException ; } public Lucene ( final File root , final CouchDbRegistry registry ) { this . root = root ; this . registry = registry ; } public void startIndexing ( final IndexKey indexKey ) { executor . submit ( indexKey , new ViewIndexer ( this , registry , indexKey ) ) ; } public void withReader ( final IndexKey key , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple ; synchronized ( map ) { tuple = map . get ( key ) ; } if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexKey key, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(key, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(key).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexKey key, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(key); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(key).writer.rollback(); throw e; } } public void createWriter(final IndexKey key, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { if (map.containsKey(key)) return; final Directory d = FSDirectory.open(dir); final Tuple tuple = new Tuple(newWriter(d)); map.put(key, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }} 
public void onMissing ( ) throws IOException ; } public Lucene ( final File root , final CouchDbRegistry registry ) { this . root = root ; this . registry = registry ; } public void startIndexing ( final IndexKey indexKey ) { executor . submit ( indexKey , new ViewIndexer ( this , registry , indexKey ) ) ; } public void withReader ( final IndexKey key , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple ; synchronized ( map ) { tuple = map . get ( key ) ; } if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexKey key, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(key, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(key).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexKey key, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(key); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(key).writer.rollback(); throw e; } } public void createWriter(final IndexKey key, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { if (map.containsKey(key)) return; final Directory d = FSDirectory.open(dir); final Tuple tuple = new Tuple(newWriter(d)); map.put(key, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }} 
public static String digest ( final String function ) { try { final MessageDigest md = MessageDigest . getInstance ( " MD5 " ) ; 
public void run ( ) { try { setup ( ) ; } catch ( final Exception e ) { logger . warn ( " Exception starting indexing. " , e ) ; return ; } try { index ( ) ; 
private void setup ( ) throws IOException { logger . info ( " Starting. " ) ; context = Context . enter ( ) ; context . setClassShutter ( new RestrictiveClassShutter ( ) ) ; context . setOptimizationLevel ( 9 ) ; client = httpClient ( ) ; url = registry . createUrlByHostKey ( key . getHostKey ( ) , key . getDatabaseName ( ) ) ; final Couch couch = new Couch ( client , registry . createUrlByHostKey ( key . getHostKey ( ) , " " ) ) ; database = couch . getDatabase ( key . getDatabaseName ( ) ) ; } 
private void index ( ) throws IOException { final UUID uuid = getDatabaseUuid ( ) ; final JSONObject ddoc = database . getDocument ( " _design/ " + key . getDesignDocumentName ( ) ) ; new ViewChangesHandler ( uuid , ddoc ) . start ( ) ; } 
public void callback ( final IndexReader reader ) throws IOException { final Map commit = reader . getCommitUserData ( ) ; if ( commit ! = null & & commit . containsKey ( " last_seq " ) ) { since = Long . parseLong ( ( String ) commit . get ( " last_seq " ) ) ; 
public void onMissing ( ) throws IOException { since = 0 ; } 
private JSONObject extractView ( final JSONObject ddoc ) { final JSONObject fulltext = ddoc . getJSONObject ( " fulltext " ) ; return fulltext . getJSONObject ( key . getViewName ( ) ) ; } 
private String extractFunction ( final JSONObject ddoc ) { return StringUtils . trim ( extractView ( ddoc ) . getString ( " index " ) ) ; } 
public void start ( ) throws IOException { database . getChanges ( since , this ) ; } 
public boolean callback ( final IndexWriter writer ) throws IOException { writer . deleteDocuments ( new Term ( " _id " , id ) ) ; return true ; } 
public boolean callback ( final IndexWriter writer ) throws IOException { writer . deleteDocuments ( new Term ( " _id " , id ) ) ; for ( final Document doc : docs ) { writer . addDocument ( doc , analyzer ) ; } return true ; } 
private void commitDocuments ( ) throws IOException { if ( ! hasPendingCommit ( ) ) return ; lucene . withWriter ( key , new WriterCallback ( ) { public boolean callback ( final IndexWriter writer ) throws IOException { final Map < String , String > userData = new HashMap < String , String > ( ) ; userData . put ( " last_seq " , Long . toString ( since ) ) ; logger . info ( " Committing update_seq " + since ) ; writer . commit ( userData ) ; return false ; } public void onMissing ( ) throws IOException { Ignore. } }); setPendingCommit(false); } 
public boolean callback ( final IndexWriter writer ) throws IOException { final Map < String , String > userData = new HashMap < String , String > ( ) ; userData . put ( " last_seq " , Long . toString ( since ) ) ; logger . info ( " Committing update_seq " + since ) ; writer . commit ( userData ) ; return false ; } 
private boolean hasPendingCommit ( ) { final boolean imeoutReached = ( now ( ) - pendingSince ) > = COMMIT_INTERVAL ; return pendingCommit & & imeoutReached ; } 
public < T > T getChanges ( final long since , final ResponseHandler < T > handler ) throws IOException { final HttpGet get = new HttpGet ( url + " _changes?feed=continuous&heartbeat=15000&include_docs=true&since= " + since ) ; return httpClient . execute ( get , handler ) ; } 
private void commitDocuments ( ) throws IOException { if ( ! hasPendingCommit ( ) ) return ; lucene . withWriter ( key , new WriterCallback ( ) { public boolean callback ( final IndexWriter writer ) throws IOException { final Map < String , String > userData = new HashMap < String , String > ( ) ; userData . put ( " last_seq " , Long . toString ( since ) ) ; logger . info ( " Checkpoint at update_seq " + since ) ; writer . commit ( userData ) ; return false ; } public void onMissing ( ) throws IOException { Ignore. } }); setPendingCommit(false); } 
public boolean callback ( final IndexWriter writer ) throws IOException { final Map < String , String > userData = new HashMap < String , String > ( ) ; userData . put ( " last_seq " , Long . toString ( since ) ) ; logger . info ( " Checkpoint at update_seq " + since ) ; writer . commit ( userData ) ; return false ; } 
public static void jsFunction_add ( final Context cx , final Scriptable thisObj , final Object [ ] args , final Function funObj ) { final RhinoDocument doc = checkInstance ( thisObj ) ; if ( args . length < 1 | | args . length > 2 ) { throw Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } if ( args [ 0 ] = = null ) { throw Context . reportRuntimeError ( " first argument must be non-null. " ) ; } if ( args [ 0 ] instanceof Undefined ) { Ignore return; } if (args.length == 2 && (args[1] == null || args[1] instanceof NativeObject == false)) { throw Context.reportRuntimeError("second argument must be an object."); } final RhinoField field = new RhinoField(); field.value = args[0]; if (args.length == 2) { field.settings = (NativeObject) args[1]; } doc.fields.add(field); } 
public void testNullAddsAreIgnored ( ) throws Exception { final DocumentConverter converter = new DocumentConverter ( context , " null " , " function(doc) {var ret=new Document(); ret.add(doc.nope); return ret;} " ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" } " ) , new JSONObject ( ) , null ) ; assertThat ( result . length , is ( 1 ) ) ; } 
public void handle ( String target , HttpServletRequest request , HttpServletResponse response , int dispatch ) throws IOException { HttpConnection connection = HttpConnection . getCurrentConnection ( ) ; connection . getRequest ( ) . setHandled ( true ) ; ServletUtils . sendJSONError ( request , response , connection . getResponse ( ) . getStatus ( ) , connection . getResponse ( ) . getReason ( ) ) ; } 
public void onMissing ( ) throws IOException { ServletUtils . sendJSONError ( req , resp , 404 , " Index for " + key . getDatabaseName ( ) + " is missing. " ) ; } 
public static void sendJSONError ( final HttpServletRequest request , final HttpServletResponse response , final int code , final String reason ) throws IOException { final JSONObject obj = new JSONObject ( ) ; obj . put ( " code " , code ) ; obj . put ( " reason " , reason ) ; Utils . setResponseContentTypeAndEncoding ( request , response ) ; response . setHeader ( HttpHeaders . CACHE_CONTROL , " must-revalidate,no-cache,no-store " ) ; final Writer writer = response . getWriter ( ) ; try { writer . write ( obj . toString ( ) ) ; 
public void close ( ) throws IOException { if ( reader ! = null ) reader . close ( ) ; if ( writer ! = null ) writer . close ( ) ; 
public void callback ( final IndexReader reader ) throws IOException ; public void onMissing ( ) throws IOException ; } public interface SearcherCallback { public void callback ( final IndexSearcher searcher , final String version ) throws IOException ; public void onMissing ( ) throws IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) throws IOException ; public void onMissing ( ) throws IOException ; } public Lucene ( final File root , final CouchDbRegistry registry ) { this . root = root ; this . registry = registry ; } public void startIndexing ( final IndexKey indexKey ) { executor . submit ( indexKey , new ViewIndexer ( this , registry , indexKey ) ) ; } public void withReader ( final IndexKey key , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple ; synchronized ( map ) { tuple = map . get ( key ) ; } if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexKey key, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(key, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(key).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexKey key, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(key); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(key).writer.rollback(); throw e; } } public void createWriter(final IndexKey key, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(key); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(key, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }} 
public void onMissing ( ) throws IOException ; } public interface SearcherCallback { public void callback ( final IndexSearcher searcher , final String version ) throws IOException ; public void onMissing ( ) throws IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) throws IOException ; public void onMissing ( ) throws IOException ; } public Lucene ( final File root , final CouchDbRegistry registry ) { this . root = root ; this . registry = registry ; } public void startIndexing ( final IndexKey indexKey ) { executor . submit ( indexKey , new ViewIndexer ( this , registry , indexKey ) ) ; } public void withReader ( final IndexKey key , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple ; synchronized ( map ) { tuple = map . get ( key ) ; } if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexKey key, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(key, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(key).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexKey key, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(key); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(key).writer.rollback(); throw e; } } public void createWriter(final IndexKey key, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(key); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(key, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }} 
public void callback ( final IndexSearcher searcher , final String version ) throws IOException ; public void onMissing ( ) throws IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) throws IOException ; public void onMissing ( ) throws IOException ; } public Lucene ( final File root , final CouchDbRegistry registry ) { this . root = root ; this . registry = registry ; } public void startIndexing ( final IndexKey indexKey ) { executor . submit ( indexKey , new ViewIndexer ( this , registry , indexKey ) ) ; } public void withReader ( final IndexKey key , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple ; synchronized ( map ) { tuple = map . get ( key ) ; } if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexKey key, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(key, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(key).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexKey key, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(key); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(key).writer.rollback(); throw e; } } public void createWriter(final IndexKey key, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(key); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(key, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }} 
public void onMissing ( ) throws IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) throws IOException ; public void onMissing ( ) throws IOException ; } public Lucene ( final File root , final CouchDbRegistry registry ) { this . root = root ; this . registry = registry ; } public void startIndexing ( final IndexKey indexKey ) { executor . submit ( indexKey , new ViewIndexer ( this , registry , indexKey ) ) ; } public void withReader ( final IndexKey key , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple ; synchronized ( map ) { tuple = map . get ( key ) ; } if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexKey key, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(key, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(key).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexKey key, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(key); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(key).writer.rollback(); throw e; } } public void createWriter(final IndexKey key, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(key); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(key, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }} 
public boolean callback ( final IndexWriter writer ) throws IOException ; public void onMissing ( ) throws IOException ; } public Lucene ( final File root , final CouchDbRegistry registry ) { this . root = root ; this . registry = registry ; } public void startIndexing ( final IndexKey indexKey ) { executor . submit ( indexKey , new ViewIndexer ( this , registry , indexKey ) ) ; } public void withReader ( final IndexKey key , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple ; synchronized ( map ) { tuple = map . get ( key ) ; } if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexKey key, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(key, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(key).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexKey key, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(key); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(key).writer.rollback(); throw e; } } public void createWriter(final IndexKey key, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(key); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(key, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }} 
public void onMissing ( ) throws IOException ; } public Lucene ( final File root , final CouchDbRegistry registry ) { this . root = root ; this . registry = registry ; } public void startIndexing ( final IndexKey indexKey ) { executor . submit ( indexKey , new ViewIndexer ( this , registry , indexKey ) ) ; } public void withReader ( final IndexKey key , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple ; synchronized ( map ) { tuple = map . get ( key ) ; } if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexKey key, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(key, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(key).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexKey key, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(key); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(key).writer.rollback(); throw e; } } public void createWriter(final IndexKey key, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(key); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(key, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }} 
public void createWriter ( final IndexKey key , final UUID uuid , final String function ) throws IOException { final String digest = digest ( function ) ; final File dir = new File ( new File ( root , uuid . toString ( ) ) , digest ) ; dir . mkdirs ( ) ; synchronized ( map ) { Tuple tuple = map . remove ( key ) ; 
public void run ( ) { try { setup ( ) ; } catch ( final Exception e ) { logger . debug ( " Exception starting indexing. " , e ) ; return ; } try { index ( ) ; 
public void start ( ) throws IOException { get = new HttpGet ( url + " /_changes?feed=continuous&heartbeat=15000&include_docs=true&since= " + since ) ; client . execute ( get , this ) ; } 
public static void main ( String [ ] args ) throws Exception { final Properties properties = loadProperties ( ) ; final File dir = new File ( properties . getProperty ( " lucene.dir " , " indexes " ) ) ; if ( dir = = null ) { LOG . error ( " lucene.dir not set. " ) ; System . exit ( 1 ) ; } if ( ! dir . exists ( ) & & ! dir . mkdir ( ) ) { LOG . error ( " Could not create " + dir . getCanonicalPath ( ) ) ; System . exit ( 1 ) ; } if ( ! dir . canRead ( ) ) { LOG . error ( dir + " is not readable. " ) ; System . exit ( 1 ) ; } if ( ! dir . canWrite ( ) ) { LOG . error ( dir + " is not writable. " ) ; System . exit ( 1 ) ; } LOG . info ( " Index output goes to: " + dir . getCanonicalPath ( ) ) ; final CouchDbRegistry registry = new CouchDbRegistry ( properties , " couchdb.url. " ) ; final Lucene lucene = new Lucene ( dir , registry ) ; final int port = Integer . parseInt ( properties . getProperty ( " lucene.port " , " 5985 " ) ) ; final Server jetty = jetty ( lucene , port ) ; jetty . start ( ) ; jetty . join ( ) ; } 
public static void sendJSONError ( final HttpServletRequest request , final HttpServletResponse response , final int code , final String reason ) throws IOException { final JSONObject obj = new JSONObject ( ) ; obj . put ( " code " , code ) ; obj . put ( " reason " , reason ) ; Utils . setResponseContentTypeAndEncoding ( request , response ) ; response . setHeader ( HttpHeaders . CACHE_CONTROL , " must-revalidate,no-cache,no-store " ) ; response . setStatus ( code ) ; final Writer writer = response . getWriter ( ) ; try { writer . write ( obj . toString ( ) ) ; 
public void callback ( final IndexReader reader ) throws IOException ; public void onMissing ( ) throws IOException ; } public interface SearcherCallback { public void callback ( final IndexSearcher searcher , final String version ) throws IOException ; public void onMissing ( ) throws IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) throws IOException ; public void onMissing ( ) throws IOException ; } public Lucene ( final File root ) { this . root = root ; } public void startIndexing ( final String path ) { executor . submit ( path , new ViewIndexer ( this , path ) ) ; } public void withReader ( final String path , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple ; synchronized ( map ) { tuple = map . get ( path ) ; } if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final String path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final String path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final String path, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }} 
public void onMissing ( ) throws IOException ; } public interface SearcherCallback { public void callback ( final IndexSearcher searcher , final String version ) throws IOException ; public void onMissing ( ) throws IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) throws IOException ; public void onMissing ( ) throws IOException ; } public Lucene ( final File root ) { this . root = root ; } public void startIndexing ( final String path ) { executor . submit ( path , new ViewIndexer ( this , path ) ) ; } public void withReader ( final String path , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple ; synchronized ( map ) { tuple = map . get ( path ) ; } if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final String path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final String path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final String path, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }} 
public void callback ( final IndexSearcher searcher , final String version ) throws IOException ; public void onMissing ( ) throws IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) throws IOException ; public void onMissing ( ) throws IOException ; } public Lucene ( final File root ) { this . root = root ; } public void startIndexing ( final String path ) { executor . submit ( path , new ViewIndexer ( this , path ) ) ; } public void withReader ( final String path , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple ; synchronized ( map ) { tuple = map . get ( path ) ; } if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final String path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final String path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final String path, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }} 
public void onMissing ( ) throws IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) throws IOException ; public void onMissing ( ) throws IOException ; } public Lucene ( final File root ) { this . root = root ; } public void startIndexing ( final String path ) { executor . submit ( path , new ViewIndexer ( this , path ) ) ; } public void withReader ( final String path , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple ; synchronized ( map ) { tuple = map . get ( path ) ; } if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final String path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final String path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final String path, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }} 
public boolean callback ( final IndexWriter writer ) throws IOException ; public void onMissing ( ) throws IOException ; } public Lucene ( final File root ) { this . root = root ; } public void startIndexing ( final String path ) { executor . submit ( path , new ViewIndexer ( this , path ) ) ; } public void withReader ( final String path , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple ; synchronized ( map ) { tuple = map . get ( path ) ; } if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final String path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final String path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final String path, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }} 
public void onMissing ( ) throws IOException ; } public Lucene ( final File root ) { this . root = root ; } public void startIndexing ( final String path ) { executor . submit ( path , new ViewIndexer ( this , path ) ) ; } public void withReader ( final String path , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple ; synchronized ( map ) { tuple = map . get ( path ) ; } if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final String path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final String path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final String path, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }} 
public void startIndexing ( final String path ) { executor . submit ( path , new ViewIndexer ( this , path ) ) ; } 
public void withReader ( final String path , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple ; synchronized ( map ) { tuple = map . get ( path ) ; } if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); 
public void withSearcher ( final String path , final boolean staleOk , final SearcherCallback callback ) throws IOException { withReader ( path , staleOk , new ReaderCallback ( ) { 
public void callback ( final IndexReader reader ) throws IOException { callback . callback ( new IndexSearcher ( reader ) , map . get ( path ) . version ) ; } 
public void withWriter ( final String path , final WriterCallback callback ) throws IOException { final Tuple tuple ; synchronized ( map ) { tuple = map . get ( path ) ; } if ( tuple = = null ) { callback . onMissing ( ) ; return ; } try { final boolean dirty = callback . callback ( tuple . writer ) ; 
public void createWriter ( final String path , final UUID uuid , final String function ) throws IOException { final String digest = digest ( function ) ; final File dir = new File ( new File ( root , uuid . toString ( ) ) , digest ) ; dir . mkdirs ( ) ; synchronized ( map ) { Tuple tuple = map . remove ( path ) ; 
public static void main ( String [ ] args ) throws Exception { final Properties properties = loadProperties ( ) ; final File dir = new File ( properties . getProperty ( " lucene.dir " , " indexes " ) ) ; if ( dir = = null ) { LOG . error ( " lucene.dir not set. " ) ; System . exit ( 1 ) ; } if ( ! dir . exists ( ) & & ! dir . mkdir ( ) ) { LOG . error ( " Could not create " + dir . getCanonicalPath ( ) ) ; System . exit ( 1 ) ; } if ( ! dir . canRead ( ) ) { LOG . error ( dir + " is not readable. " ) ; System . exit ( 1 ) ; } if ( ! dir . canWrite ( ) ) { LOG . error ( dir + " is not writable. " ) ; System . exit ( 1 ) ; } LOG . info ( " Index output goes to: " + dir . getCanonicalPath ( ) ) ; final Lucene lucene = new Lucene ( dir ) ; final int port = Integer . parseInt ( properties . getProperty ( " lucene.port " , " 5985 " ) ) ; final Server jetty = jetty ( lucene , port ) ; jetty . start ( ) ; jetty . join ( ) ; } 
public void onMissing ( ) throws IOException { ServletUtils . sendJSONError ( req , resp , 404 , " Index for " + req . getPathInfo ( ) + " is missing. " ) ; } 
private void setup ( ) throws IOException { logger . info ( " Starting. " ) ; context = Context . enter ( ) ; context . setClassShutter ( new RestrictiveClassShutter ( ) ) ; context . setOptimizationLevel ( 9 ) ; client = httpClient ( ) ; final String url = String . format ( " http:%s:%d/ " , Utils . getHost ( path ) , Utils . getPort ( path ) ) ; final Couch couch = new Couch ( client , url ) ; database = couch . getDatabase ( Utils . getDatabase ( path ) ) ; } 
private void index ( ) throws IOException { final UUID uuid = getDatabaseUuid ( ) ; final JSONObject ddoc = database . getDocument ( " _design/ " + Utils . getDesignDocumentName ( path ) ) ; new ViewChangesHandler ( uuid , ddoc ) . start ( ) ; } 
private UUID getDatabaseUuid ( ) throws IOException { try { final JSONObject local = database . getDocument ( " _local/lucene " ) ; 
private JSONObject extractView ( final JSONObject ddoc ) { final JSONObject fulltext = ddoc . getJSONObject ( " fulltext " ) ; return fulltext . getJSONObject ( Utils . getViewName ( path ) ) ; } 
public void start ( ) throws IOException { database . handleChanges ( since , this ) ; } 
private void commitDocuments ( ) throws IOException { if ( ! hasPendingCommit ( ) ) return ; lucene . withWriter ( path , new WriterCallback ( ) { public boolean callback ( final IndexWriter writer ) throws IOException { final Map < String , String > userData = new HashMap < String , String > ( ) ; userData . put ( " last_seq " , Long . toString ( since ) ) ; logger . info ( " Checkpoint at update_seq " + since ) ; writer . commit ( userData ) ; return false ; } public void onMissing ( ) throws IOException { Ignore. } }); setPendingCommit(false); } 
public < T > T handleChanges ( final long since , final ResponseHandler < T > handler ) throws IOException { final HttpGet get = new HttpGet ( url + " /_changes?feed=continuous&heartbeat=15000&include_docs=true&since= " + since ) ; return httpClient . execute ( get , handler ) ; } 
private static String [ ] split ( final String path ) { final String [ ] result = path . substring ( 1 ) . split ( " / " ) ; if ( result . length ! = 5 ) { throw new IllegalArgumentException ( " Malformed path ( " + Arrays . toString ( result ) + " ) " ) ; } return result ; } 
public synchronized boolean submit ( final K key , final Runnable runnable ) { cleanup ( ) ; if ( tasks . containsKey ( key ) ) { return false ; } final Thread thread = new Thread ( runnable , key . toString ( ) ) ; tasks . put ( key , thread ) ; thread . start ( ) ; return true ; } 
public void callback ( final IndexReader reader ) throws IOException ; public void onMissing ( ) throws IOException ; } public interface SearcherCallback { public void callback ( final IndexSearcher searcher , final String version ) throws IOException ; public void onMissing ( ) throws IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) throws IOException ; public void onMissing ( ) throws IOException ; } public Lucene ( final File root ) { this . root = root ; } public void startIndexing ( final String path ) { final ViewIndexer viewIndexer = new ViewIndexer ( this , path ) ; if ( executor . submit ( path , viewIndexer ) ) { viewIndexer . awaitInitialIndexing ( ) ; } } public void withReader ( final String path , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple ; synchronized ( map ) { tuple = map . get ( path ) ; } if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final String path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final String path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final String path, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }} 
public void onMissing ( ) throws IOException ; } public interface SearcherCallback { public void callback ( final IndexSearcher searcher , final String version ) throws IOException ; public void onMissing ( ) throws IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) throws IOException ; public void onMissing ( ) throws IOException ; } public Lucene ( final File root ) { this . root = root ; } public void startIndexing ( final String path ) { final ViewIndexer viewIndexer = new ViewIndexer ( this , path ) ; if ( executor . submit ( path , viewIndexer ) ) { viewIndexer . awaitInitialIndexing ( ) ; } } public void withReader ( final String path , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple ; synchronized ( map ) { tuple = map . get ( path ) ; } if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final String path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final String path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final String path, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }} 
public void callback ( final IndexSearcher searcher , final String version ) throws IOException ; public void onMissing ( ) throws IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) throws IOException ; public void onMissing ( ) throws IOException ; } public Lucene ( final File root ) { this . root = root ; } public void startIndexing ( final String path ) { final ViewIndexer viewIndexer = new ViewIndexer ( this , path ) ; if ( executor . submit ( path , viewIndexer ) ) { viewIndexer . awaitInitialIndexing ( ) ; } } public void withReader ( final String path , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple ; synchronized ( map ) { tuple = map . get ( path ) ; } if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final String path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final String path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final String path, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }} 
public void onMissing ( ) throws IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) throws IOException ; public void onMissing ( ) throws IOException ; } public Lucene ( final File root ) { this . root = root ; } public void startIndexing ( final String path ) { final ViewIndexer viewIndexer = new ViewIndexer ( this , path ) ; if ( executor . submit ( path , viewIndexer ) ) { viewIndexer . awaitInitialIndexing ( ) ; } } public void withReader ( final String path , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple ; synchronized ( map ) { tuple = map . get ( path ) ; } if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final String path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final String path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final String path, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }} 
public boolean callback ( final IndexWriter writer ) throws IOException ; public void onMissing ( ) throws IOException ; } public Lucene ( final File root ) { this . root = root ; } public void startIndexing ( final String path ) { final ViewIndexer viewIndexer = new ViewIndexer ( this , path ) ; if ( executor . submit ( path , viewIndexer ) ) { viewIndexer . awaitInitialIndexing ( ) ; } } public void withReader ( final String path , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple ; synchronized ( map ) { tuple = map . get ( path ) ; } if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final String path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final String path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final String path, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }} 
public void onMissing ( ) throws IOException ; } public Lucene ( final File root ) { this . root = root ; } public void startIndexing ( final String path ) { final ViewIndexer viewIndexer = new ViewIndexer ( this , path ) ; if ( executor . submit ( path , viewIndexer ) ) { viewIndexer . awaitInitialIndexing ( ) ; } } public void withReader ( final String path , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple ; synchronized ( map ) { tuple = map . get ( path ) ; } if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final String path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final String path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final String path, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }} 
public void startIndexing ( final String path ) { final ViewIndexer viewIndexer = new ViewIndexer ( this , path ) ; if ( executor . submit ( path , viewIndexer ) ) { viewIndexer . awaitInitialIndexing ( ) ; 
public void awaitInitialIndexing ( ) { try { latch . await ( ) ; 
private void index ( ) throws IOException { final UUID uuid = getDatabaseUuid ( ) ; final JSONObject ddoc = database . getDocument ( " _design/ " + Utils . getDesignDocumentName ( path ) ) ; final JSONObject info = database . getInfo ( ) ; new ViewChangesHandler ( uuid , ddoc , info . getLong ( " update_seq " ) ) . start ( ) ; } 
public synchronized V submit ( final K key , final V value ) { cleanup ( ) ; if ( values . containsKey ( key ) ) { return values . get ( key ) ; } final Thread thread = new Thread ( value , key . toString ( ) ) ; values . put ( key , value ) ; threads . put ( key , thread ) ; thread . start ( ) ; return value ; } 
public synchronized void shutdownNow ( ) { for ( final Thread thread : threads . values ( ) ) { thread . interrupt ( ) ; } threads . clear ( ) ; values . clear ( ) ; } 
private void cleanup ( ) { assert Thread . holdsLock ( this ) ; final Iterator < Entry < K , Thread > > it = threads . entrySet ( ) . iterator ( ) ; while ( it . hasNext ( ) ) { final Entry < K , Thread > entry = it . next ( ) ; 
public void callback ( final IndexReader reader ) throws IOException ; public void onMissing ( ) throws IOException ; } public interface SearcherCallback { public void callback ( final IndexSearcher searcher , final String version ) throws IOException ; public void onMissing ( ) throws IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) throws IOException ; public void onMissing ( ) throws IOException ; } public Lucene ( final File root ) { this . root = root ; } public void startIndexing ( final String path ) { final ViewIndexer viewIndexer = executor . submit ( path , new ViewIndexer ( this , path ) ) ; viewIndexer . awaitInitialIndexing ( ) ; } public void withReader ( final String path , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple ; synchronized ( map ) { tuple = map . get ( path ) ; } if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final String path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final String path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final String path, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }} 
public void onMissing ( ) throws IOException ; } public interface SearcherCallback { public void callback ( final IndexSearcher searcher , final String version ) throws IOException ; public void onMissing ( ) throws IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) throws IOException ; public void onMissing ( ) throws IOException ; } public Lucene ( final File root ) { this . root = root ; } public void startIndexing ( final String path ) { final ViewIndexer viewIndexer = executor . submit ( path , new ViewIndexer ( this , path ) ) ; viewIndexer . awaitInitialIndexing ( ) ; } public void withReader ( final String path , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple ; synchronized ( map ) { tuple = map . get ( path ) ; } if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final String path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final String path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final String path, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }} 
public void callback ( final IndexSearcher searcher , final String version ) throws IOException ; public void onMissing ( ) throws IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) throws IOException ; public void onMissing ( ) throws IOException ; } public Lucene ( final File root ) { this . root = root ; } public void startIndexing ( final String path ) { final ViewIndexer viewIndexer = executor . submit ( path , new ViewIndexer ( this , path ) ) ; viewIndexer . awaitInitialIndexing ( ) ; } public void withReader ( final String path , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple ; synchronized ( map ) { tuple = map . get ( path ) ; } if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final String path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final String path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final String path, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }} 
public void onMissing ( ) throws IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) throws IOException ; public void onMissing ( ) throws IOException ; } public Lucene ( final File root ) { this . root = root ; } public void startIndexing ( final String path ) { final ViewIndexer viewIndexer = executor . submit ( path , new ViewIndexer ( this , path ) ) ; viewIndexer . awaitInitialIndexing ( ) ; } public void withReader ( final String path , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple ; synchronized ( map ) { tuple = map . get ( path ) ; } if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final String path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final String path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final String path, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }} 
public boolean callback ( final IndexWriter writer ) throws IOException ; public void onMissing ( ) throws IOException ; } public Lucene ( final File root ) { this . root = root ; } public void startIndexing ( final String path ) { final ViewIndexer viewIndexer = executor . submit ( path , new ViewIndexer ( this , path ) ) ; viewIndexer . awaitInitialIndexing ( ) ; } public void withReader ( final String path , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple ; synchronized ( map ) { tuple = map . get ( path ) ; } if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final String path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final String path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final String path, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }} 
public void onMissing ( ) throws IOException ; } public Lucene ( final File root ) { this . root = root ; } public void startIndexing ( final String path ) { final ViewIndexer viewIndexer = executor . submit ( path , new ViewIndexer ( this , path ) ) ; viewIndexer . awaitInitialIndexing ( ) ; } public void withReader ( final String path , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple ; synchronized ( map ) { tuple = map . get ( path ) ; } if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final String path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final String path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final String path, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }} 
public void startIndexing ( final String path ) { final ViewIndexer viewIndexer = executor . submit ( path , new ViewIndexer ( this , path ) ) ; viewIndexer . awaitInitialIndexing ( ) ; } 
private void teardown ( ) { latch . countDown ( ) ; logger . info ( " Stopping. " ) ; client . getConnectionManager ( ) . shutdown ( ) ; Context . exit ( ) ; } 
public void setup ( ) { executor = new IdempotentExecutor < Integer , MyRunnable > ( ) ; } 
public Query parse ( final String query ) throws ParseException { return fixup ( delegate . parse ( query ) ) ; } 
public String toPlan ( final Query query ) { final StringBuilder builder = new StringBuilder ( 300 ) ; toPlan ( builder , query ) ; return builder . toString ( ) ; } 
private Query toQuery ( final HttpServletRequest req ) { Parse query. final Analyzer analyzer = Analyzers.getAnalyzer(getParameter(req, "analyzer", "standard")); final CustomQueryParser parser = new CustomQueryParser(new QueryParser(Version.LUCENE_CURRENT, Constants.DEFAULT_FIELD, analyzer)); try { return parser.parse(req.getParameter("q")); 
public Sort toSort ( final String sort ) { if ( sort = = null ) { return null ; 
public static long directorySize ( final Directory dir ) throws IOException { long result = 0 ; for ( final String name : dir . listAll ( ) ) { result + = dir . fileLength ( name ) ; } return result ; } 
public synchronized V submit ( final K key , final V value ) { cleanup ( ) ; if ( values . containsKey ( key ) ) { LOG . debug ( " Existing view indexer found for " + key ) ; return values . get ( key ) ; } final Thread thread = new Thread ( value , key . toString ( ) ) ; values . put ( key , value ) ; threads . put ( key , thread ) ; thread . start ( ) ; LOG . debug ( " Started new view indexer found for " + key ) ; return value ; } 
public static boolean validatePath ( final String path ) { return split ( path , false ) . length = = 5 ; } 
private static String [ ] split ( final String path , final boolean throwIfWrong ) { final String [ ] result = path . substring ( 1 ) . split ( " / " ) ; if ( throwIfWrong & & result . length ! = 5 ) { throw new IllegalArgumentException ( " Malformed path ( " + Arrays . toString ( result ) + " ) " ) ; } return result ; } 
private void releaseCatch ( ) { if ( since > = latchThreshold ) { logger . debug ( " caught up to threshold of " + latchThreshold ) ; 
private static Server jetty ( final Lucene lucene , final int port ) { Configure Jetty. final Server server = new Server(Integer.getInteger("port", port)); server.setStopAtShutdown(true); server.setSendServerVersion(false); final ContextHandlerCollection contexts = new ContextHandlerCollection(); server.setHandler(contexts); final SearchServlet search = new SearchServlet(); search.setLucene(lucene); setupContext(contexts, "/search", search); final InfoServlet info = new InfoServlet(); info.setLucene(lucene); setupContext(contexts, "/info", info); final AdminServlet admin = new AdminServlet(); admin.setLucene(lucene); setupContext(contexts, "/admin", admin); final TestServlet test = new TestServlet(); test.setLucene(lucene); setupContext(contexts, "/test", test); return server; } 
protected void doPost ( final HttpServletRequest req , final HttpServletResponse resp ) throws ServletException , IOException { final Result result = JUnitCore . runClasses ( TestServlet . class ) ; resp . setStatus ( 200 ) ; resp . setContentType ( " text/plain " ) ; final Writer writer = resp . getWriter ( ) ; try { if ( result . wasSuccessful ( ) ) { 
public void setup ( ) throws Exception { final HttpClient client = new DefaultHttpClient ( ) ; final Couch couch = new Couch ( client , " http:localhost:5984 " ) ; db = couch . getDatabase ( " lucenetestdb " ) ; db . delete ( ) ; assertThat ( " couldn't create database " , db . create ( ) , is ( true ) ) ; } 
public void teardown ( ) throws Exception { assertThat ( " couldn't delete database " , db . delete ( ) , is ( true ) ) ; } 
private void releaseCatch ( ) { if ( since > = latchThreshold ) { latch . countDown ( ) ; 
public final boolean delete ( ) throws IOException { return HttpUtils . delete ( httpClient , url ) = = 200 ; } 
public void setup ( ) throws Exception { client = new DefaultHttpClient ( ) ; final Couch couch = new Couch ( client , URL ) ; db = couch . getDatabase ( " lucenetestdb " ) ; db . delete ( ) ; assertThat ( " couldn't create database " , db . create ( ) , is ( true ) ) ; } 
public void teardown ( ) throws Exception { assertThat("couldn't delete database", db.delete(), is(true)); } @Test public void basicIndexing() throws Exception { assertThat("can't save ddoc.", db.saveDocument("_design/ddoc", fix("{'fulltext':{'by_subject':" + "{'index':'function(doc) { var ret = new Document(); ret.add(doc.subject); return ret;}'}}}")), is(true)); assertThat("can't save doc1.", db.saveDocument("doc1", fix("{'subject':'cat dog'}")), is(true)); final HttpGet get = new HttpGet("http:localhost:5985/search/localhost/5984/lucenetestdb/ddoc/by_subject?q=cat"); final String response = client.execute(get, new BasicResponseHandler()); final JSONObject result = JSONObject.fromObject(response); assertThat(result.getLong("total_rows"), is(1L)); } private String fix(final String str) { return str.replaceAll("'", "\""); }} 
public void basicIndexing ( ) throws Exception { assertThat ( " can't save ddoc. " , db . saveDocument ( " _design/ddoc " , fix ( " {'fulltext':{'by_subject': " + " {'index':'function(doc) { var ret = new Document(); ret.add(doc.subject); return ret;}'}}} " ) ) , is ( true ) ) ; assertThat ( " can't save doc1. " , db . saveDocument ( " doc1 " , fix ( " {'subject':'cat dog'} " ) ) , is ( true ) ) ; final HttpGet get = new HttpGet ( " http:localhost:5985/search/localhost/5984/lucenetestdb/ddoc/by_subject?q=cat " ) ; final String response = client . execute ( get , new BasicResponseHandler ( ) ) ; final JSONObject result = JSONObject . fromObject ( response ) ; assertThat ( result . getLong ( " total_rows " ) , is ( 1L ) ) ; } 
private String fix ( final String str ) { return str . replaceAll ( " ' " , " \" " ) ; } 
public void setup ( ) throws Exception { client = new DefaultHttpClient ( ) ; final Couch couch = Couch . getInstance ( client , URL ) ; db = couch . getDatabase ( " lucenetestdb " ) ; db . delete ( ) ; assertThat ( " couldn't create database " , db . create ( ) , is ( true ) ) ; } 
private void setup ( ) throws IOException { logger . info ( " Starting. " ) ; context = Context . enter ( ) ; context . setClassShutter ( new RestrictiveClassShutter ( ) ) ; context . setOptimizationLevel ( 9 ) ; client = HttpClientFactory . getInstance ( ) ; final String url = String . format ( " http:%s:%d/ " , Utils . getHost ( path ) , Utils . getPort ( path ) ) ; final Couch couch = Couch . getInstance ( client , url ) ; database = couch . getDatabase ( Utils . getDatabase ( path ) ) ; } 
public Database getDatabase ( final String dbname ) throws IOException { return new Database ( httpClient , url + dbname ) ; } 
public boolean create ( ) throws IOException { return HttpUtils . put ( httpClient , url , null ) = = 201 ; } 
public boolean delete ( ) throws IOException { return HttpUtils . delete ( httpClient , url ) = = 200 ; } 
public JSONObject getDocument ( final String id ) throws IOException { final String response = HttpUtils . get ( httpClient , url + Utils . urlEncode ( id ) ) ; return JSONObject . fromObject ( response ) ; } 
public JSONObject getDocuments ( final String . . . ids ) throws IOException { final JSONArray keys = new JSONArray ( ) ; for ( final String id : ids ) { keys . add ( id ) ; } final JSONObject req = new JSONObject ( ) ; req . element ( " keys " , keys ) ; final String response = HttpUtils . post ( httpClient , url + " _all_docs?include_docs=true " , req . toString ( ) ) ; return JSONObject . fromObject ( response ) ; } 
public JSONObject getDocuments ( final String startkey , final String endkey ) throws IOException { return JSONObject . fromObject ( HttpUtils . get ( httpClient , String . format ( " %s_all_docs?startkey=%%22%s%%22&endkey=%%22%s%%22&include_docs=true " , url , Utils . urlEncode ( startkey ) , Utils 
public JSONObject getInfo ( ) throws IOException { return JSONObject . fromObject ( HttpUtils . get ( httpClient , url ) ) ; } 
public < T > T handleAttachment ( final String doc , final String att , final ResponseHandler < T > handler ) throws IOException { final HttpGet get = new HttpGet ( url + " / " + Utils . urlEncode ( doc ) + " / " + Utils . urlEncode ( att ) ) ; return httpClient . execute ( get , handler ) ; } 
public boolean saveDocument ( final String id , final String body ) throws IOException { return HttpUtils . put ( httpClient , url + Utils . urlEncode ( id ) , body ) = = 201 ; } 
private void planNumericRangeQuery ( final StringBuilder builder , final NumericRangeQuery < ? > query ) { builder . append ( query . getMin ( ) ) ; builder . append ( " TO " ) ; builder . append ( query . getMax ( ) ) ; builder . append ( " AS " ) ; builder . append ( query . getMin ( ) . getClass ( ) . getSimpleName ( ) ) ; } 
private void toPlan ( final StringBuilder builder , final Query query ) { builder . append ( query . getClass ( ) . getSimpleName ( ) ) ; builder . append ( " ( " ) ; if ( query instanceof TermQuery ) { planTermQuery ( builder , ( TermQuery ) query ) ; } else if ( query instanceof BooleanQuery ) { planBooleanQuery ( builder , ( BooleanQuery ) query ) ; } else if ( query instanceof TermRangeQuery ) { planTermRangeQuery ( builder , ( TermRangeQuery ) query ) ; } else if ( query instanceof PrefixQuery ) { planPrefixQuery ( builder , ( PrefixQuery ) query ) ; } else if ( query instanceof WildcardQuery ) { planWildcardQuery ( builder , ( WildcardQuery ) query ) ; } else if ( query instanceof FuzzyQuery ) { planFuzzyQuery ( builder , ( FuzzyQuery ) query ) ; } else if ( query instanceof NumericRangeQuery < ? > ) { planNumericRangeQuery ( builder , ( NumericRangeQuery < ? > ) query ) ; } builder . append ( " ,boost= " + query . getBoost ( ) + " ) " ) ; } 
public void callback ( final IndexReader reader ) throws IOException { final Map < String , String > commit = reader . getCommitUserData ( ) ; if ( commit ! = null & & commit . containsKey ( " last_seq " ) ) { since = Long . parseLong ( commit . get ( " last_seq " ) ) ; 
public Analyzer newAnalyzer ( ) { return new BrazilianAnalyzer ( VERSION ) ; } 
public Analyzer newAnalyzer ( ) { return new CJKAnalyzer ( VERSION ) ; } 
public Analyzer newAnalyzer ( ) { return new CzechAnalyzer ( VERSION ) ; } 
public Analyzer newAnalyzer ( ) { return new DutchAnalyzer ( VERSION ) ; } 
public Analyzer newAnalyzer ( ) { return new StandardAnalyzer ( VERSION ) ; } 
public Analyzer newAnalyzer ( ) { return new FrenchAnalyzer ( VERSION ) ; } 
public Analyzer newAnalyzer ( ) { return new GermanAnalyzer ( VERSION ) ; } 
public Analyzer newAnalyzer ( ) { return new RussianAnalyzer ( VERSION ) ; } 
public Analyzer newAnalyzer ( ) { return new ThaiAnalyzer ( VERSION ) ; } 
private void toPlan ( final StringBuilder builder , final Query query ) { builder . append ( query . getClass ( ) . getSimpleName ( ) ) ; builder . append ( " ( " ) ; if ( query instanceof TermQuery ) { planTermQuery ( builder , ( TermQuery ) query ) ; } else if ( query instanceof BooleanQuery ) { planBooleanQuery ( builder , ( BooleanQuery ) query ) ; } else if ( query instanceof TermRangeQuery ) { planTermRangeQuery ( builder , ( TermRangeQuery ) query ) ; } else if ( query instanceof PrefixQuery ) { planPrefixQuery ( builder , ( PrefixQuery ) query ) ; } else if ( query instanceof WildcardQuery ) { planWildcardQuery ( builder , ( WildcardQuery ) query ) ; } else if ( query instanceof FuzzyQuery ) { planFuzzyQuery ( builder , ( FuzzyQuery ) query ) ; } else if ( query instanceof NumericRangeQuery < ? > ) { planNumericRangeQuery ( builder , ( NumericRangeQuery < ? > ) query ) ; } else { builder . append ( query ) ; } builder . append ( " ,boost= " + query . getBoost ( ) + " ) " ) ; } 
public void callback ( final IndexReader reader ) throws IOException ; public void onMissing ( ) throws IOException ; } public interface SearcherCallback { public void callback ( final IndexSearcher searcher , final String version ) throws IOException ; public void onMissing ( ) throws IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) throws IOException ; public void onMissing ( ) throws IOException ; } public Lucene ( final File root ) { this . root = root ; } public void startIndexing ( final String path , final boolean staleOk ) { final ViewIndexer viewIndexer = executor . submit ( path , new ViewIndexer ( this , path , staleOk ) ) ; viewIndexer . awaitInitialIndexing ( ) ; } public void withReader ( final String path , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple ; synchronized ( map ) { tuple = map . get ( path ) ; } if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final String path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final String path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final String path, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }} 
public void onMissing ( ) throws IOException ; } public interface SearcherCallback { public void callback ( final IndexSearcher searcher , final String version ) throws IOException ; public void onMissing ( ) throws IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) throws IOException ; public void onMissing ( ) throws IOException ; } public Lucene ( final File root ) { this . root = root ; } public void startIndexing ( final String path , final boolean staleOk ) { final ViewIndexer viewIndexer = executor . submit ( path , new ViewIndexer ( this , path , staleOk ) ) ; viewIndexer . awaitInitialIndexing ( ) ; } public void withReader ( final String path , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple ; synchronized ( map ) { tuple = map . get ( path ) ; } if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final String path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final String path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final String path, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }} 
public void callback ( final IndexSearcher searcher , final String version ) throws IOException ; public void onMissing ( ) throws IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) throws IOException ; public void onMissing ( ) throws IOException ; } public Lucene ( final File root ) { this . root = root ; } public void startIndexing ( final String path , final boolean staleOk ) { final ViewIndexer viewIndexer = executor . submit ( path , new ViewIndexer ( this , path , staleOk ) ) ; viewIndexer . awaitInitialIndexing ( ) ; } public void withReader ( final String path , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple ; synchronized ( map ) { tuple = map . get ( path ) ; } if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final String path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final String path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final String path, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }} 
public void onMissing ( ) throws IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) throws IOException ; public void onMissing ( ) throws IOException ; } public Lucene ( final File root ) { this . root = root ; } public void startIndexing ( final String path , final boolean staleOk ) { final ViewIndexer viewIndexer = executor . submit ( path , new ViewIndexer ( this , path , staleOk ) ) ; viewIndexer . awaitInitialIndexing ( ) ; } public void withReader ( final String path , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple ; synchronized ( map ) { tuple = map . get ( path ) ; } if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final String path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final String path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final String path, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }} 
public boolean callback ( final IndexWriter writer ) throws IOException ; public void onMissing ( ) throws IOException ; } public Lucene ( final File root ) { this . root = root ; } public void startIndexing ( final String path , final boolean staleOk ) { final ViewIndexer viewIndexer = executor . submit ( path , new ViewIndexer ( this , path , staleOk ) ) ; viewIndexer . awaitInitialIndexing ( ) ; } public void withReader ( final String path , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple ; synchronized ( map ) { tuple = map . get ( path ) ; } if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final String path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final String path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final String path, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }} 
public void onMissing ( ) throws IOException ; } public Lucene ( final File root ) { this . root = root ; } public void startIndexing ( final String path , final boolean staleOk ) { final ViewIndexer viewIndexer = executor . submit ( path , new ViewIndexer ( this , path , staleOk ) ) ; viewIndexer . awaitInitialIndexing ( ) ; } public void withReader ( final String path , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple ; synchronized ( map ) { tuple = map . get ( path ) ; } if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final String path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final String path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final String path, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }} 
public void startIndexing ( final String path , final boolean staleOk ) { final ViewIndexer viewIndexer = executor . submit ( path , new ViewIndexer ( this , path , staleOk ) ) ; viewIndexer . awaitInitialIndexing ( ) ; } 
private void index ( ) throws IOException { final UUID uuid = getDatabaseUuid ( ) ; final JSONObject ddoc = database . getDocument ( " _design/ " + Utils . getDesignDocumentName ( path ) ) ; final JSONObject info = database . getInfo ( ) ; long seqThreshhold = staleOk ? 0 : info . getLong ( " update_seq " ) ; new ViewChangesHandler ( uuid , ddoc , seqThreshhold ) . start ( ) ; } 
public Object get ( String name , Scriptable start ) { if ( name . equals ( " length " ) ) treturn size ; treturn super . get ( name , start ) ; } 
public Object get ( int index , Scriptable start ) { if ( ( index > = 0 ) & & ( index < size ) ) { tObject value = array . get ( index ) ; if ( value instanceof JSONObject ) treturn new JSONDocumentAdapter ( ( JSONObject ) value ) ; if ( value instanceof JSONArray ) treturn new JSONArrayAdapter ( ( JSONArray ) value ) ; treturn value ; } treturn super . get ( index , start ) ; } 
public Object get ( String name , Scriptable start ) { if ( doc . has ( name ) ) { tObject value = doc . get ( name ) ; if ( value instanceof JSONObject ) treturn new JSONDocumentAdapter ( ( JSONObject ) value ) ; if ( value instanceof JSONArray ) treturn new JSONArrayAdapter ( ( JSONArray ) value ) ; treturn value ; } treturn super . get ( name , start ) ; } 
public void onMissing ( ) throws IOException { ServletUtils . sendJSONError ( req , resp , 404 , " Index for " + Utils . getPath ( req ) + " is missing. " ) ; } 
private void index ( ) throws IOException { final UUID uuid = getDatabaseUuid ( ) ; final JSONObject ddoc = database . getDocument ( " _design/ " + Utils . getDesignDocumentName ( path ) ) ; final JSONObject view = extractView ( ddoc ) ; if ( view = = null ) return ; final JSONObject info = database . getInfo ( ) ; final long seqThreshhold = staleOk ? 0 : info . getLong ( " update_seq " ) ; new ViewChangesHandler ( uuid , view , seqThreshhold ) . start ( ) ; } 
private JSONObject extractView ( final JSONObject ddoc ) { if ( ! ddoc . has ( " fulltext " ) ) return null ; final JSONObject fulltext = ddoc . getJSONObject ( " fulltext " ) ; if ( ! fulltext . has ( Utils . getViewName ( path ) ) ) return null ; return fulltext . getJSONObject ( Utils . getViewName ( path ) ) ; } 
private String extractFunction ( final JSONObject view ) { if ( ! view . has ( " index " ) ) return null ; return StringUtils . trim ( view . getString ( " index " ) ) ; } 
private void commitDocuments ( ) throws IOException { if ( ! hasPendingCommit ( ) ) { return ; } lucene . withWriter ( path , new WriterCallback ( ) { public boolean callback ( final IndexWriter writer ) throws IOException { final Map < String , String > userData = new HashMap < String , String > ( ) ; userData . put ( " last_seq " , Long . toString ( since ) ) ; logger . info ( " Checkpoint at update_seq " + since ) ; writer . commit ( userData ) ; return false ; } public void onMissing ( ) throws IOException { Ignore. } }); setPendingCommit(false); } 
private String extractFunction ( final JSONObject view ) { if ( ! view . has ( " index " ) ) { return null ; } return StringUtils . trim ( view . getString ( " index " ) ) ; } 
private void index ( ) throws IOException { final UUID uuid = getDatabaseUuid ( ) ; final JSONObject ddoc = database . getDocument ( " _design/ " + Utils . getDesignDocumentName ( path ) ) ; final JSONObject view = extractView ( ddoc ) ; if ( view = = null ) { return ; } final JSONObject info = database . getInfo ( ) ; final long seqThreshhold = staleOk ? 0 : info . getLong ( " update_seq " ) ; new ViewChangesHandler ( uuid , view , seqThreshhold ) . start ( ) ; } 
public synchronized V submit ( final K key , final V value ) { cleanup ( ) ; if ( values . containsKey ( key ) ) { LOG . trace ( " Existing view indexer found for " + key ) ; return values . get ( key ) ; } final Thread thread = new Thread ( value , key . toString ( ) ) ; values . put ( key , value ) ; threads . put ( key , thread ) ; thread . start ( ) ; LOG . trace ( " Started new view indexer found for " + key ) ; return value ; } 
public void start ( ) throws IOException { request = database . getChangesRequest ( since ) ; client . execute ( request , this ) ; } 
public HttpUriRequest getChangesRequest ( final long since ) throws IOException { return new HttpGet ( url + " /_changes?feed=continuous&heartbeat=15000&include_docs=true&since= " + since ) ; } 
private void index ( ) throws IOException { final UUID uuid = getDatabaseUuid ( ) ; final JSONObject ddoc = database . getDocument ( " _design/ " + Utils . getDesignDocumentName ( path ) ) ; final JSONObject view = extractView ( ddoc ) ; if ( view = = null ) { return ; } if ( extractFunction ( view ) = = null ) return ; final JSONObject info = database . getInfo ( ) ; final long seqThreshhold = staleOk ? 0 : info . getLong ( " update_seq " ) ; new ViewChangesHandler ( uuid , view , seqThreshhold ) . start ( ) ; } 
public void closeExpiredConnections ( ) { delegate . closeExpiredConnections ( ) ; } 
public void closeIdleConnections ( final long idletime , final TimeUnit tunit ) { delegate . closeIdleConnections ( idletime , tunit ) ; } 
public void releaseConnection ( final ManagedClientConnection conn , final long validDuration , final TimeUnit timeUnit ) { delegate . releaseConnection ( conn , validDuration , timeUnit ) ; } 
public ClientConnectionRequest requestConnection ( final HttpRoute route , final Object state ) { return delegate . requestConnection ( route , state ) ; } 
public static final String execute ( final HttpClient httpClient , final HttpUriRequest request ) throws IOException { return httpClient . execute ( request , new ErrorPreservingResponseHandler ( ) ) ; } 
public void parse ( final InputStream in , final String contentType , final String fieldName , final Document doc ) throws IOException { final Metadata md = new Metadata ( ) ; md . set ( HttpHeaders . CONTENT_TYPE , contentType ) ; final Reader reader = tika . parse ( in , md ) ; final String body ; try { try { body = IOUtils . toString ( reader ) ; } finally { reader . close ( ) ; } } catch ( final IOException e ) { log . warn ( " Failed to index an attachment. " , e ) ; return ; } Add body text. doc.add(text(fieldName, body, false)); Add DC attributes. addDublinCoreAttributes(md, doc); } 
public void parse ( final InputStream in , final String contentType , final String fieldName , final Document doc ) throws IOException { final Metadata md = new Metadata ( ) ; md . set ( HttpHeaders . CONTENT_TYPE , contentType ) ; try { Add body text. doc.add(text(fieldName, tika.parseToString(in, md), false)); } catch (final IOException e) { log.warn("Failed to index an attachment.", e); return; } catch (final TikaException e) { log.warn("Failed to parse an attachment.", e); return; } Add DC attributes. addDublinCoreAttributes(md, doc); } 
public static void jsFunction_add ( final Context cx , final Scriptable thisObj , final Object [ ] args , final Function funObj ) { final RhinoDocument doc = checkInstance ( thisObj ) ; if ( args . length < 1 | | args . length > 2 ) { throw Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } if ( args [ 0 ] = = null ) { throw Context . reportRuntimeError ( " first argument must be non-null. " ) ; } if ( args [ 0 ] instanceof Undefined ) { Ignore return; } if (args.length == 2 && (args[1] == null || args[1] instanceof NativeObject == false)) { throw Context.reportRuntimeError("second argument must be an object."); } final RhinoField field = new RhinoField(); field.value = args[0]; if (args.length == 2) { field.settings = (NativeObject) args[1]; } doc.fields.add(field); } 
private void addAttachment ( final RhinoAttachment attachment , final String id , final Database database , final Document out ) throws IOException { final ResponseHandler < Void > handler = new ResponseHandler < Void > ( ) { public Void handleResponse ( final HttpResponse response ) throws ClientProtocolException , IOException { final HttpEntity entity = response . getEntity ( ) ; Tika . INSTANCE . parse ( entity . getContent ( ) , entity . getContentType ( ) . getValue ( ) , attachment . fieldName , out ) ; return null ; } } ; database . handleAttachment ( id , attachment . attachmentName , handler ) ; } 
public Void handleResponse ( final HttpResponse response ) throws ClientProtocolException , IOException { final HttpEntity entity = response . getEntity ( ) ; Tika . INSTANCE . parse ( entity . getContent ( ) , entity . getContentType ( ) . getValue ( ) , attachment . fieldName , out ) ; return null ; } 
protected void doPost ( final HttpServletRequest req , final HttpServletResponse resp ) throws ServletException , IOException { final String command = req . getParameter ( " cmd " ) ; final IndexPath path = IndexPath . parse ( req ) ; if ( path = = null ) { ServletUtils . sendJSONError ( req , resp , 400 , " Bad path " ) ; return ; } if ( " expunge " . equals ( command ) ) { lucene . withWriter ( path , new WriterCallback ( ) { public boolean callback ( final IndexWriter writer ) throws IOException { writer . expungeDeletes ( false ) ; return false ; } public void onMissing ( ) throws IOException { resp . sendError ( 404 ) ; } } ) ; resp . setStatus ( 202 ) ; return ; } if ( " optimize " . equals ( command ) ) { lucene . withWriter ( path , new WriterCallback ( ) { public boolean callback ( final IndexWriter writer ) throws IOException { writer . optimize ( false ) ; return false ; } public void onMissing ( ) throws IOException { resp . sendError ( 404 ) ; } } ) ; resp . setStatus ( 202 ) ; return ; } resp . sendError ( 400 , " Bad request " ) ; } 
public void callback ( final IndexReader reader ) throws IOException ; public void onMissing ( ) throws IOException ; } public interface SearcherCallback { public void callback ( final IndexSearcher searcher , final String version ) throws IOException ; public void onMissing ( ) throws IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) throws IOException ; public void onMissing ( ) throws IOException ; } public Lucene ( final File root ) { this . root = root ; } public void startIndexing ( final IndexPath path , final boolean staleOk ) { final ViewIndexer viewIndexer = executor . submit ( path , new ViewIndexer ( this , path , staleOk ) ) ; viewIndexer . awaitInitialIndexing ( ) ; } public void withReader ( final IndexPath path , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple ; synchronized ( map ) { tuple = map . get ( path ) ; } if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexPath path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexPath path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final IndexPath path, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }} 
public void onMissing ( ) throws IOException ; } public interface SearcherCallback { public void callback ( final IndexSearcher searcher , final String version ) throws IOException ; public void onMissing ( ) throws IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) throws IOException ; public void onMissing ( ) throws IOException ; } public Lucene ( final File root ) { this . root = root ; } public void startIndexing ( final IndexPath path , final boolean staleOk ) { final ViewIndexer viewIndexer = executor . submit ( path , new ViewIndexer ( this , path , staleOk ) ) ; viewIndexer . awaitInitialIndexing ( ) ; } public void withReader ( final IndexPath path , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple ; synchronized ( map ) { tuple = map . get ( path ) ; } if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexPath path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexPath path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final IndexPath path, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }} 
public void callback ( final IndexSearcher searcher , final String version ) throws IOException ; public void onMissing ( ) throws IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) throws IOException ; public void onMissing ( ) throws IOException ; } public Lucene ( final File root ) { this . root = root ; } public void startIndexing ( final IndexPath path , final boolean staleOk ) { final ViewIndexer viewIndexer = executor . submit ( path , new ViewIndexer ( this , path , staleOk ) ) ; viewIndexer . awaitInitialIndexing ( ) ; } public void withReader ( final IndexPath path , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple ; synchronized ( map ) { tuple = map . get ( path ) ; } if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexPath path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexPath path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final IndexPath path, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }} 
public void onMissing ( ) throws IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) throws IOException ; public void onMissing ( ) throws IOException ; } public Lucene ( final File root ) { this . root = root ; } public void startIndexing ( final IndexPath path , final boolean staleOk ) { final ViewIndexer viewIndexer = executor . submit ( path , new ViewIndexer ( this , path , staleOk ) ) ; viewIndexer . awaitInitialIndexing ( ) ; } public void withReader ( final IndexPath path , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple ; synchronized ( map ) { tuple = map . get ( path ) ; } if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexPath path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexPath path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final IndexPath path, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }} 
public boolean callback ( final IndexWriter writer ) throws IOException ; public void onMissing ( ) throws IOException ; } public Lucene ( final File root ) { this . root = root ; } public void startIndexing ( final IndexPath path , final boolean staleOk ) { final ViewIndexer viewIndexer = executor . submit ( path , new ViewIndexer ( this , path , staleOk ) ) ; viewIndexer . awaitInitialIndexing ( ) ; } public void withReader ( final IndexPath path , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple ; synchronized ( map ) { tuple = map . get ( path ) ; } if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexPath path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexPath path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final IndexPath path, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }} 
public void onMissing ( ) throws IOException ; } public Lucene ( final File root ) { this . root = root ; } public void startIndexing ( final IndexPath path , final boolean staleOk ) { final ViewIndexer viewIndexer = executor . submit ( path , new ViewIndexer ( this , path , staleOk ) ) ; viewIndexer . awaitInitialIndexing ( ) ; } public void withReader ( final IndexPath path , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple ; synchronized ( map ) { tuple = map . get ( path ) ; } if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexPath path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexPath path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final IndexPath path, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }} 
public void startIndexing ( final IndexPath path , final boolean staleOk ) { final ViewIndexer viewIndexer = executor . submit ( path , new ViewIndexer ( this , path , staleOk ) ) ; viewIndexer . awaitInitialIndexing ( ) ; } 
public void withReader ( final IndexPath path , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple ; synchronized ( map ) { tuple = map . get ( path ) ; } if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); 
public void withSearcher ( final IndexPath path , final boolean staleOk , final SearcherCallback callback ) throws IOException { withReader ( path , staleOk , new ReaderCallback ( ) { 
public void withWriter ( final IndexPath path , final WriterCallback callback ) throws IOException { final Tuple tuple ; synchronized ( map ) { tuple = map . get ( path ) ; } if ( tuple = = null ) { callback . onMissing ( ) ; return ; } try { final boolean dirty = callback . callback ( tuple . writer ) ; 
public void createWriter ( final IndexPath path , final UUID uuid , final String function ) throws IOException { final String digest = digest ( function ) ; final File dir = new File ( new File ( root , uuid . toString ( ) ) , digest ) ; dir . mkdirs ( ) ; synchronized ( map ) { Tuple tuple = map . remove ( path ) ; 
public void onMissing ( ) throws IOException { ServletUtils . sendJSONError ( req , resp , 404 , " Index for " + path + " is missing. " ) ; } 
private void index ( ) throws IOException { final UUID uuid = getDatabaseUuid ( ) ; final JSONObject ddoc = database . getDocument ( " _design/ " + path . getDesignDocumentName ( ) ) ; final JSONObject view = extractView ( ddoc ) ; if ( view = = null ) { return ; } if ( extractFunction ( view ) = = null ) return ; final JSONObject info = database . getInfo ( ) ; final long seqThreshhold = staleOk ? 0 : info . getLong ( " update_seq " ) ; new ViewChangesHandler ( uuid , view , seqThreshhold ) . start ( ) ; } 
private void setup ( ) throws IOException { logger . info ( " Starting. " ) ; context = Context . enter ( ) ; context . setClassShutter ( new RestrictiveClassShutter ( ) ) ; context . setOptimizationLevel ( 9 ) ; client = HttpClientFactory . getInstance ( ) ; final String url = String . format ( " http:%s:%d/ " , path . getHost ( ) , path . getPort ( ) ) ; final Couch couch = Couch . getInstance ( client , url ) ; database = couch . getDatabase ( path . getDatabase ( ) ) ; } 
public static IndexPath parse ( final HttpServletRequest req ) { final String uri = req . getRequestURI ( ) . replaceFirst ( " ^/ \\ w+/ " , " " ) ; final String [ ] parts = uri . split ( " / " ) ; if ( parts . length ! = 5 ) { return null ; } try { return new IndexPath ( parts [ 0 ] , Integer . parseInt ( parts [ 1 ] ) , parts [ 2 ] , parts [ 3 ] , parts [ 4 ] ) ; 
public boolean equals ( final Object obj ) { if ( this = = obj ) { return true ; } if ( obj = = null ) { return false ; } if ( ! ( obj instanceof IndexPath ) ) { return false ; } final IndexPath other = ( IndexPath ) obj ; if ( ! database . equals ( other . database ) ) { return false ; } if ( ! designDocumentName . equals ( other . designDocumentName ) ) { return false ; } if ( ! host . equals ( other . host ) ) { return false ; } if ( port ! = other . port ) { return false ; } if ( ! viewName . equals ( other . viewName ) ) { return false ; } return true ; } 
public int hashCode ( ) { final int prime = 31 ; int result = 1 ; result = prime * result + database . hashCode ( ) ; result = prime * result + designDocumentName . hashCode ( ) ; result = prime * result + host . hashCode ( ) ; result = prime * result + port ; result = prime * result + viewName . hashCode ( ) ; return result ; } 
public String toString ( ) { return " IndexPath [host= " + host + " , port= " + port + " , database= " + database + " , designDocumentName= " + designDocumentName + " , viewName= " + viewName + " ] " ; 
public static void main ( String [ ] args ) throws Exception { final Properties properties = loadProperties ( ) ; final File dir = new File ( properties . getProperty ( " lucene.dir " , " indexes " ) ) ; if ( dir = = null ) { LOG . error ( " lucene.dir not set. " ) ; System . exit ( 1 ) ; } if ( ! dir . exists ( ) & & ! dir . mkdir ( ) ) { LOG . error ( " Could not create " + dir . getCanonicalPath ( ) ) ; System . exit ( 1 ) ; } if ( ! dir . canRead ( ) ) { LOG . error ( dir + " is not readable. " ) ; System . exit ( 1 ) ; } if ( ! dir . canWrite ( ) ) { LOG . error ( dir + " is not writable. " ) ; System . exit ( 1 ) ; } LOG . info ( " Index output goes to: " + dir . getCanonicalPath ( ) ) ; final Lucene lucene = new Lucene ( dir ) ; final String host = properties . getProperty ( " lucene.host " , " localhost " ) ; final int port = Integer . parseInt ( properties . getProperty ( " lucene.port " , " 5985 " ) ) ; final Server jetty = jetty ( lucene , host , port ) ; jetty . start ( ) ; jetty . join ( ) ; } 
private static Server jetty ( final Lucene lucene , final String host , final int port ) { final Server server = new Server ( ) ; final SelectChannelConnector connector = new SelectChannelConnector ( ) ; connector . setHost ( host ) ; connector . setPort ( port ) ; LOG . info ( " Accepting connections with " + connector ) ; server . setConnectors ( new Connector [ ] { connector } ) ; server . setStopAtShutdown ( true ) ; server . setSendServerVersion ( false ) ; final ContextHandlerCollection contexts = new ContextHandlerCollection ( ) ; server . setHandler ( contexts ) ; final SearchServlet search = new SearchServlet ( ) ; search . setLucene ( lucene ) ; setupContext ( contexts , " /search " , search ) ; final InfoServlet info = new InfoServlet ( ) ; info . setLucene ( lucene ) ; setupContext ( contexts , " /info " , info ) ; final AdminServlet admin = new AdminServlet ( ) ; admin . setLucene ( lucene ) ; setupContext ( contexts , " /admin " , admin ) ; final TestServlet test = new TestServlet ( ) ; test . setLucene ( lucene ) ; setupContext ( contexts , " /test " , test ) ; return server ; } 
public boolean callback ( final IndexWriter writer ) throws IOException { writer . deleteDocuments ( new Term ( " _id " , id ) ) ; return true ; } 
public boolean callback ( final IndexWriter writer ) throws IOException { writer . deleteDocuments ( new Term ( " _id " , id ) ) ; for ( final Document doc : docs ) { writer . addDocument ( doc , analyzer ) ; } return true ; } 
public Object get ( String name , Scriptable start ) { if ( name . equals ( " length " ) ) return size ; return super . get ( name , start ) ; } 
public Object get ( int index , Scriptable start ) { if ( ( index > = 0 ) & & ( index < size ) ) { Object value = array . get ( index ) ; if ( value instanceof JSONObject ) { final JSONObject obj = ( JSONObject ) value ; if ( obj . isNullObject ( ) ) return null ; else return new JSONDocumentAdapter ( obj ) ; } if ( value instanceof JSONArray ) return new JSONArrayAdapter ( ( JSONArray ) value ) ; return value ; } return super . get ( index , start ) ; } 
public Object get ( String name , Scriptable start ) { if ( doc . has ( name ) ) { Object value = doc . get ( name ) ; if ( value instanceof JSONObject ) { final JSONObject obj = ( JSONObject ) value ; if ( obj . isNullObject ( ) ) return null ; else return new JSONDocumentAdapter ( obj ) ; } if ( value instanceof JSONArray ) { return new JSONArrayAdapter ( ( JSONArray ) value ) ; } return value ; } return super . get ( name , start ) ; } 
private void commitDocuments ( ) throws IOException { if ( ! hasPendingCommit ( ) ) { return ; } lucene . withWriter ( path , new WriterCallback ( ) { public boolean callback ( final IndexWriter writer ) throws IOException { final Map < String , String > userData = new HashMap < String , String > ( ) ; userData . put ( " last_seq " , Long . toString ( since ) ) ; logger . debug ( " Starting checkpoint at update_seq " + since ) ; writer . commit ( userData ) ; logger . info ( " Committed checkpoint at update_seq " + since ) ; return false ; } public void onMissing ( ) throws IOException { Ignore. } }); setPendingCommit(false); } 
public boolean callback ( final IndexWriter writer ) throws IOException { final Map < String , String > userData = new HashMap < String , String > ( ) ; userData . put ( " last_seq " , Long . toString ( since ) ) ; logger . debug ( " Starting checkpoint at update_seq " + since ) ; writer . commit ( userData ) ; logger . info ( " Committed checkpoint at update_seq " + since ) ; return false ; } 
public String toString ( ) { return host + " / " + port + " / " + database + " / " + designDocumentName + " / " + viewName ; } 
public boolean callback ( final IndexWriter writer ) throws IOException { writer . deleteDocuments ( new Term ( " _id " , id ) ) ; for ( final Document doc : docs ) { if ( logger . isTraceEnabled ( ) ) { logger . trace ( id + " -> " + doc ) ; } writer . addDocument ( doc , analyzer ) ; } return true ; } 
private Object fixup ( final String value ) { if ( value . matches ( " \\ d+ \\ . \\ d+f " ) ) { return Float . parseFloat ( value ) ; } if ( value . matches ( " \\ d+ \\ . \\ d+ " ) ) { return Double . parseDouble ( value ) ; } if ( value . matches ( " \\ d+[lL] " ) ) { return Long . parseLong ( value . substring ( 0 , value . length ( ) - 1 ) ) ; } if ( value . matches ( " \\ d+ " ) ) { return Integer . parseInt ( value ) ; } final DateFormat dateFormat = new SimpleDateFormat ( " yyyy-MM-dd'T'HH:mm:ssZZ " ) ; try { return dateFormat . parse ( value . toUpperCase ( ) ) . getTime ( ) ; } catch ( final java . text . ParseException e ) { Ignore. } return value; } 
public static Object convert ( final Object obj ) { if ( obj instanceof JSONArray ) { return convertArray ( ( JSONArray ) obj ) ; 
public static ScriptableObject convertArray ( final JSONArray array ) { final NativeArray result = new NativeArray ( array . size ( ) ) ; for ( int i = 0 , max = array . size ( ) ; i < max ; i + + ) { ScriptableObject . putProperty ( result , i , convert ( array . get ( i ) ) ) ; } return result ; } 
public static ScriptableObject convertObject ( final JSONObject obj ) { final ScriptableObject result = new ScriptableObjectAdapter ( ) ; for ( final Object key : obj . keySet ( ) ) { final Object value = obj . get ( key ) ; ScriptableObject . putProperty ( result , ( String ) key , convert ( value ) ) ; } return result ; } 
public void testMultipleDocumentReturn ( ) throws Exception { final DocumentConverter converter = new DocumentConverter ( context , " multi " , " function(doc) {var ret = new Array(); ret.push(new Document()); ret.push(new Document()); return ret;} " ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" } " ) , new JSONObject ( ) , null ) ; assertThat ( result . length , is ( 2 ) ) ; assertThat ( result [ 0 ] . get ( " _id " ) , is ( " hello " ) ) ; } 
public void testAdd ( ) throws Exception { final DocumentConverter converter = new DocumentConverter ( context , " single " , " function(doc) {var ret=new Document(); ret.add(doc.key); return ret;} " ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" , key: \" value \" } " ) , new JSONObject ( ) , null ) ; assertThat ( result . length , is ( 1 ) ) ; assertThat ( result [ 0 ] . get ( Constants . DEFAULT_FIELD ) , is ( " value " ) ) ; } 
public void testForLoopOverObject ( ) throws Exception { final DocumentConverter converter = new DocumentConverter ( context , " multi " , " function(doc) {var ret=new Document(); for (var key in doc) { ret.add(doc[key]); } return ret; } " ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" , key: \" value \" } " ) , new JSONObject ( ) , null ) ; assertThat ( result . length , is ( 1 ) ) ; assertThat ( result [ 0 ] . get ( " _id " ) , is ( " hello " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 0 ] , is ( " hello " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 1 ] , is ( " value " ) ) ; } 
public void testForLoopOverArray ( ) throws Exception { final DocumentConverter converter = new DocumentConverter ( context , " multi " , " function(doc) {var ret=new Document(); for (var key in doc.arr) {ret.add(doc.arr[key]); } return ret; } " ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" , arr:[0,1,2,3]} " ) , new JSONObject ( ) , null ) ; assertThat ( result . length , is ( 1 ) ) ; assertThat ( result [ 0 ] . get ( " _id " ) , is ( " hello " ) ) ; System . err . println ( result [ 0 ] ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 0 ] , is ( " 0 " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 1 ] , is ( " 1 " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 2 ] , is ( " 2 " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 3 ] , is ( " 3 " ) ) ; } 
public void testForEverything ( ) throws Exception { final DocumentConverter converter = new DocumentConverter ( context , " multi " , " function(doc) {var ret=new Document(); function idx(obj) {for (var key in obj) {switch (typeof obj[key]) {case 'object':idx(obj[key]); break; case 'function': break; default: ret.add(obj[key]); break;} } }; idx(doc); return ret; } " ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" , l1: { l2: {l3:[ \" v3 \" , \" v4 \" ]}}} " ) , new JSONObject ( ) , null ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 0 ] , is ( " hello " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 1 ] , is ( " v3 " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 2 ] , is ( " v4 " ) ) ; } 
private static Server jetty ( final Lucene lucene , final String host , final int port ) { final Server server = new Server ( ) ; final SelectChannelConnector connector = new SelectChannelConnector ( ) ; connector . setHost ( host ) ; connector . setPort ( port ) ; LOG . info ( " Accepting connections with " + connector ) ; server . setConnectors ( new Connector [ ] { connector } ) ; server . setStopAtShutdown ( true ) ; server . setSendServerVersion ( false ) ; final ContextHandlerCollection contexts = new ContextHandlerCollection ( ) ; server . setHandler ( contexts ) ; final SearchServlet search = new SearchServlet ( ) ; search . setLucene ( lucene ) ; setupContext ( contexts , " /search " , search ) ; final InfoServlet info = new InfoServlet ( ) ; info . setLucene ( lucene ) ; setupContext ( contexts , " /info " , info ) ; final AdminServlet admin = new AdminServlet ( ) ; admin . setLucene ( lucene ) ; setupContext ( contexts , " /admin " , admin ) ; return server ; } 
public void setup ( ) { parser = new CustomQueryParser ( Version . LUCENE_CURRENT , " default " , new StandardAnalyzer ( Version . LUCENE_CURRENT ) ) ; } 
public void integerRangeQuery ( ) throws Exception { final Query q = parser . parse ( " blah:[0 TO 123] " ) ; assertThat ( q , is ( NumericRangeQuery . class ) ) ; assertThat ( ( ( NumericRangeQuery ) q ) . getMin ( ) , is ( Integer . class ) ) ; } 
public void longRangeQuery ( ) throws Exception { final Query q = parser . parse ( " blah:[0L TO 123L] " ) ; assertThat ( q , is ( NumericRangeQuery . class ) ) ; assertThat ( ( ( NumericRangeQuery ) q ) . getMin ( ) , is ( Long . class ) ) ; } 
public void floatRangeQuery ( ) throws Exception { final Query q = parser . parse ( " blah:[0.0f TO 123.5f] " ) ; assertThat ( q , is ( NumericRangeQuery . class ) ) ; assertThat ( ( ( NumericRangeQuery ) q ) . getMin ( ) , is ( Float . class ) ) ; } 
public void doubleRangeQuery ( ) throws Exception { final Query q = parser . parse ( " blah:[0.0 TO 123.0] " ) ; assertThat ( q , is ( NumericRangeQuery . class ) ) ; assertThat ( ( ( NumericRangeQuery ) q ) . getMin ( ) , is ( Double . class ) ) ; } 
private Object fixup ( final String value ) { if ( value . matches ( " \\ d+ \\ . \\ d+f " ) ) { return Float . parseFloat ( value ) ; } if ( value . matches ( " \\ d+ \\ . \\ d+ " ) ) { return Double . parseDouble ( value ) ; } if ( value . matches ( " \\ d+[lL] " ) ) { return Long . parseLong ( value . substring ( 0 , value . length ( ) - 1 ) ) ; } if ( value . matches ( " \\ d+ " ) ) { return Integer . parseInt ( value ) ; } try { return DateUtils . parseDate ( value . toUpperCase ( ) , DATE_PATTERNS ) . getTime ( ) ; } catch ( final DateParseException e ) { Ignore. } return value; } 
public void integerRangeQuery ( ) throws Exception { final Query q = parser . parse ( " blah:[0 TO 123] " ) ; assertRange ( q , Integer . class , 0 , 123 ) ; } 
public void longRangeQuery ( ) throws Exception { final Query q = parser . parse ( " blah:[0L TO 123L] " ) ; assertRange ( q , Long . class , 0 L , 123L ) ; } 
public void floatRangeQuery ( ) throws Exception { final Query q = parser . parse ( " blah:[0.0f TO 123.5f] " ) ; assertRange ( q , Float . class , 0.0f , 123.5f ) ; } 
public void doubleRangeQuery ( ) throws Exception { final Query q = parser . parse ( " blah:[0.0 TO 123.0] " ) ; assertRange ( q , Double . class , 0.0 , 123.0 ) ; } 
public void dateRangeQuery ( ) throws Exception { final Query q = parser . parse ( " blah:[2000-01-01 TO 2010-02-04] " ) ; assertRange ( q , Long . class , 946684800000L , 1265241600000L ) ; } 
public void dateTimeRangeQuery ( ) throws Exception { final Query q = parser . parse ( " blah:[2000-01-01T00:00:01 TO 2010-02-04T00:00:01] " ) ; assertRange ( q , Long . class , 946684801000L , 1265241601000L ) ; } 
public void dateTimeZoneRangeQuery ( ) throws Exception { final Query q = parser . parse ( " blah:[2000-01-01-0100 TO 2010-02-04-0100] " ) ; assertRange ( q , Long . class , 946688400000L , 1265245200000L ) ; } 
public void dateTimeTimeZoneRangeQuery ( ) throws Exception { final Query q = parser . parse ( " blah:[2000-01-01T00:00:00-0100 TO 2010-02-04T00:00:00-0100] " ) ; assertRange ( q , Long . class , 946688400000L , 1265245200000L ) ; } 
private void assertRange ( final Query q , final Class < ? > type , final Number min , final Number max ) { assertThat ( q , is ( NumericRangeQuery . class ) ) ; final NumericRangeQuery nq = ( NumericRangeQuery ) q ; assertThat ( nq . getMin ( ) , is ( type ) ) ; assertThat ( nq . getMax ( ) , is ( type ) ) ; assertThat ( nq . getMin ( ) , is ( min ) ) ; assertThat ( nq . getMax ( ) , is ( max ) ) ; } 
public static void main ( String [ ] args ) throws Exception { final FileConfiguration config = new HierarchicalINIConfiguration ( Main . class . getClassLoader ( ) . getResource ( " couchdb-lucene.properties " ) ) ; config . setReloadingStrategy ( new FileChangedReloadingStrategy ( ) ) ; final File dir = new File ( config . getString ( " lucene.dir " , " indexes " ) ) ; if ( dir = = null ) { LOG . error ( " lucene.dir not set. " ) ; System . exit ( 1 ) ; } if ( ! dir . exists ( ) & & ! dir . mkdir ( ) ) { LOG . error ( " Could not create " + dir . getCanonicalPath ( ) ) ; System . exit ( 1 ) ; } if ( ! dir . canRead ( ) ) { LOG . error ( dir + " is not readable. " ) ; System . exit ( 1 ) ; } if ( ! dir . canWrite ( ) ) { LOG . error ( dir + " is not writable. " ) ; System . exit ( 1 ) ; } LOG . info ( " Index output goes to: " + dir . getCanonicalPath ( ) ) ; final Lucene lucene = new Lucene ( dir ) ; final String host = config . getString ( " lucene.host " , " localhost " ) ; final int port = config . getInt ( " lucene.port " , 5985 ) ; final Server jetty = jetty ( lucene , host , port ) ; jetty . start ( ) ; jetty . join ( ) ; } 
public static void main ( String [ ] args ) throws Exception { final HierarchicalINIConfiguration configuration = new HierarchicalINIConfiguration ( Main . class . getClassLoader ( ) . getResource ( " couchdb-lucene.properties " ) ) ; configuration . setReloadingStrategy ( new FileChangedReloadingStrategy ( ) ) ; final File dir = new File ( configuration . getString ( " lucene.dir " , " indexes " ) ) ; if ( dir = = null ) { LOG . error ( " lucene.dir not set. " ) ; System . exit ( 1 ) ; } if ( ! dir . exists ( ) & & ! dir . mkdir ( ) ) { LOG . error ( " Could not create " + dir . getCanonicalPath ( ) ) ; System . exit ( 1 ) ; } if ( ! dir . canRead ( ) ) { LOG . error ( dir + " is not readable. " ) ; System . exit ( 1 ) ; } if ( ! dir . canWrite ( ) ) { LOG . error ( dir + " is not writable. " ) ; System . exit ( 1 ) ; } LOG . info ( " Index output goes to: " + dir . getCanonicalPath ( ) ) ; final Lucene lucene = new Lucene ( dir ) ; final Server server = new Server ( ) ; final SelectChannelConnector connector = new SelectChannelConnector ( ) ; connector . setHost ( configuration . getString ( " lucene.host " , " localhost " ) ) ; connector . setPort ( configuration . getInt ( " lucene.port " , 5985 ) ) ; LOG . info ( " Accepting connections with " + connector ) ; server . setConnectors ( new Connector [ ] { connector } ) ; server . setStopAtShutdown ( true ) ; server . setSendServerVersion ( false ) ; final ContextHandlerCollection contexts = new ContextHandlerCollection ( ) ; server . setHandler ( contexts ) ; final SearchServlet search = new SearchServlet ( ) ; search . setLucene ( lucene ) ; search . setConfiguration ( configuration ) ; setupContext ( contexts , " /search " , search ) ; final InfoServlet info = new InfoServlet ( ) ; info . setLucene ( lucene ) ; info . setConfiguration ( configuration ) ; setupContext ( contexts , " /info " , info ) ; final AdminServlet admin = new AdminServlet ( ) ; admin . setLucene ( lucene ) ; admin . setConfiguration ( configuration ) ; setupContext ( contexts , " /admin " , admin ) ; server . start ( ) ; server . join ( ) ; } 
private String trim ( final String fun ) { String result = fun ; result = StringUtils . trim ( result ) ; result = StringUtils . removeStart ( result , " \" " ) ; result = StringUtils . removeEnd ( result , " \" " ) ; return result ; } 
private String extractFunction ( final JSONObject view ) { if ( ! view . has ( " index " ) ) { return null ; } return view . getString ( " index " ) ; } 
public void testForLoopOverArray ( ) throws Exception { final DocumentConverter converter = new DocumentConverter ( context , " multi " , " function(doc) {var ret=new Document(); for (var key in doc.arr) {ret.add(doc.arr[key]); } return ret; } " ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" , arr:[0,1,2,3]} " ) , new JSONObject ( ) , null ) ; assertThat ( result . length , is ( 1 ) ) ; assertThat ( result [ 0 ] . get ( " _id " ) , is ( " hello " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 0 ] , is ( " 0 " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 1 ] , is ( " 1 " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 2 ] , is ( " 2 " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 3 ] , is ( " 3 " ) ) ; } 
public void testForEverything ( ) throws Exception { final DocumentConverter converter = new DocumentConverter ( context , " multi " , " function(doc) {var ret=new Document(); function idx(obj) {for (var key in obj) {switch (typeof obj[key]) {case 'object':idx(obj[key]); break; case 'function': break; default: ret.add(obj[key]); break;} } }; idx(doc); return ret; } " ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" , l1: { l2: {l3:[ \" v3 \" , \" v4 \" ]}}} " ) , new JSONObject ( ) , null ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 0 ] , is ( " hello " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 1 ] , is ( " v3 " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 2 ] , is ( " v4 " ) ) ; } 
public void testQuoteRemoval ( ) throws Exception { final DocumentConverter converter = new DocumentConverter ( context , " single " , " \" function(doc) {return new Document();} \" " ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" } " ) , new JSONObject ( ) , null ) ; assertThat ( result . length , is ( 1 ) ) ; assertThat ( result [ 0 ] . get ( " _id " ) , is ( " hello " ) ) ; } 
public static Sort toSort ( final String sort ) { if ( sort = = null ) { return null ; 
public static String toPlan ( final Query query ) { final StringBuilder builder = new StringBuilder ( 300 ) ; toPlan ( builder , query ) ; return builder . toString ( ) ; } 
private static void planFuzzyQuery ( final StringBuilder builder , final FuzzyQuery query ) { builder . append ( query . getTerm ( ) ) ; builder . append ( " ,prefixLength= " ) ; builder . append ( query . getPrefixLength ( ) ) ; builder . append ( " ,minSimilarity= " ) ; builder . append ( query . getMinSimilarity ( ) ) ; } 
private static void planNumericRangeQuery ( final StringBuilder builder , final NumericRangeQuery < ? > query ) { builder . append ( query . getMin ( ) ) ; builder . append ( " TO " ) ; builder . append ( query . getMax ( ) ) ; builder . append ( " AS " ) ; builder . append ( query . getMin ( ) . getClass ( ) . getSimpleName ( ) ) ; } 
private static void planPrefixQuery ( final StringBuilder builder , final PrefixQuery query ) { builder . append ( query . getPrefix ( ) ) ; } 
private static void planTermQuery ( final StringBuilder builder , final TermQuery query ) { builder . append ( query . getTerm ( ) ) ; } 
private static void planTermRangeQuery ( final StringBuilder builder , final TermRangeQuery query ) { builder . append ( query . getLowerTerm ( ) ) ; builder . append ( " TO " ) ; builder . append ( query . getUpperTerm ( ) ) ; } 
private static void planWildcardQuery ( final StringBuilder builder , final WildcardQuery query ) { builder . append ( query . getTerm ( ) ) ; } 
private static void toPlan ( final StringBuilder builder , final Query query ) { builder . append ( query . getClass ( ) . getSimpleName ( ) ) ; builder . append ( " ( " ) ; if ( query instanceof TermQuery ) { planTermQuery ( builder , ( TermQuery ) query ) ; } else if ( query instanceof BooleanQuery ) { planBooleanQuery ( builder , ( BooleanQuery ) query ) ; } else if ( query instanceof TermRangeQuery ) { planTermRangeQuery ( builder , ( TermRangeQuery ) query ) ; } else if ( query instanceof PrefixQuery ) { planPrefixQuery ( builder , ( PrefixQuery ) query ) ; } else if ( query instanceof WildcardQuery ) { planWildcardQuery ( builder , ( WildcardQuery ) query ) ; } else if ( query instanceof FuzzyQuery ) { planFuzzyQuery ( builder , ( FuzzyQuery ) query ) ; } else if ( query instanceof NumericRangeQuery < ? > ) { planNumericRangeQuery ( builder , ( NumericRangeQuery < ? > ) query ) ; } else { builder . append ( query ) ; } builder . append ( " ,boost= " + query . getBoost ( ) + " ) " ) ; } 
public Analyzer newAnalyzer ( final String args ) { return new BrazilianAnalyzer ( VERSION ) ; } 
public Analyzer newAnalyzer ( final String args ) { return new ChineseAnalyzer ( ) ; } 
public Analyzer newAnalyzer ( final String args ) { return new CJKAnalyzer ( VERSION ) ; } 
public Analyzer newAnalyzer ( final String args ) { return new CzechAnalyzer ( VERSION ) ; } 
public Analyzer newAnalyzer ( final String args ) { return new DutchAnalyzer ( VERSION ) ; } 
public Analyzer newAnalyzer ( final String args ) { return new StandardAnalyzer ( VERSION ) ; } 
public Analyzer newAnalyzer ( final String args ) { return new FrenchAnalyzer ( VERSION ) ; } 
public Analyzer newAnalyzer ( final String args ) { return new GermanAnalyzer ( VERSION ) ; } 
public Analyzer newAnalyzer ( final String args ) { return new KeywordAnalyzer ( ) ; } 
public Analyzer newAnalyzer ( final String args ) { final JSONObject json = JSONObject . fromObject ( args ) ; final Analyzer defaultAnalyzer = Analyzers . getAnalyzer ( json . optString ( " _default " , " standard " ) ) ; final PerFieldAnalyzerWrapper result = new PerFieldAnalyzerWrapper ( defaultAnalyzer ) ; for ( final Object obj : json . keySet ( ) ) { final String key = obj . toString ( ) ; if ( " _default " . equals ( key ) ) continue ; result . addAnalyzer ( key , Analyzers . getAnalyzer ( json . getString ( key ) ) ) ; } return result ; } 
public Analyzer newAnalyzer ( final String args ) { return new PorterStemAnalyzer ( ) ; } 
public Analyzer newAnalyzer ( final String args ) { return new RussianAnalyzer ( VERSION ) ; } 
public Analyzer newAnalyzer ( final String args ) { return new SimpleAnalyzer ( ) ; } 
public Analyzer newAnalyzer ( final String args ) { return new StandardAnalyzer ( Version . LUCENE_CURRENT ) ; } 
public Analyzer newAnalyzer ( final String args ) { return new ThaiAnalyzer ( VERSION ) ; } 
public Analyzer newAnalyzer ( final String args ) { final JSONObject json = JSONObject . fromObject ( args = = null ? " {} " : args ) ; final Analyzer defaultAnalyzer = Analyzers . getAnalyzer ( json . optString ( " _default " , " standard " ) ) ; final PerFieldAnalyzerWrapper result = new PerFieldAnalyzerWrapper ( defaultAnalyzer ) ; for ( final Object obj : json . keySet ( ) ) { final String key = obj . toString ( ) ; if ( " _default " . equals ( key ) ) continue ; result . addAnalyzer ( key , Analyzers . getAnalyzer ( json . getString ( key ) ) ) ; } return result ; } 
public Analyzer newAnalyzer ( final String args ) { final JSONObject json = JSONObject . fromObject ( args = = null ? " {} " : args ) ; final Analyzer defaultAnalyzer = Analyzers . getAnalyzer ( json . optString ( Constants . DEFAULT_FIELD , " standard " ) ) ; final PerFieldAnalyzerWrapper result = new PerFieldAnalyzerWrapper ( defaultAnalyzer ) ; for ( final Object obj : json . keySet ( ) ) { final String key = obj . toString ( ) ; if ( Constants . DEFAULT_FIELD . equals ( key ) ) continue ; result . addAnalyzer ( key , Analyzers . getAnalyzer ( json . getString ( key ) ) ) ; } return result ; } 
public static void main ( String [ ] args ) throws Exception { final HierarchicalINIConfiguration configuration = new HierarchicalINIConfiguration ( Main . class . getClassLoader ( ) . getResource ( " couchdb-lucene.ini " ) ) ; configuration . setReloadingStrategy ( new FileChangedReloadingStrategy ( ) ) ; final File dir = new File ( configuration . getString ( " lucene.dir " , " indexes " ) ) ; if ( dir = = null ) { LOG . error ( " lucene.dir not set. " ) ; System . exit ( 1 ) ; } if ( ! dir . exists ( ) & & ! dir . mkdir ( ) ) { LOG . error ( " Could not create " + dir . getCanonicalPath ( ) ) ; System . exit ( 1 ) ; } if ( ! dir . canRead ( ) ) { LOG . error ( dir + " is not readable. " ) ; System . exit ( 1 ) ; } if ( ! dir . canWrite ( ) ) { LOG . error ( dir + " is not writable. " ) ; System . exit ( 1 ) ; } LOG . info ( " Index output goes to: " + dir . getCanonicalPath ( ) ) ; final Lucene lucene = new Lucene ( dir ) ; final Server server = new Server ( ) ; final SelectChannelConnector connector = new SelectChannelConnector ( ) ; connector . setHost ( configuration . getString ( " lucene.host " , " localhost " ) ) ; connector . setPort ( configuration . getInt ( " lucene.port " , 5985 ) ) ; LOG . info ( " Accepting connections with " + connector ) ; server . setConnectors ( new Connector [ ] { connector } ) ; server . setStopAtShutdown ( true ) ; server . setSendServerVersion ( false ) ; final ContextHandlerCollection contexts = new ContextHandlerCollection ( ) ; server . setHandler ( contexts ) ; final SearchServlet search = new SearchServlet ( ) ; search . setLucene ( lucene ) ; search . setConfiguration ( configuration ) ; setupContext ( contexts , " /search " , search ) ; final InfoServlet info = new InfoServlet ( ) ; info . setLucene ( lucene ) ; info . setConfiguration ( configuration ) ; setupContext ( contexts , " /info " , info ) ; final AdminServlet admin = new AdminServlet ( ) ; admin . setLucene ( lucene ) ; admin . setConfiguration ( configuration ) ; setupContext ( contexts , " /admin " , admin ) ; server . start ( ) ; server . join ( ) ; } 
public void testStandard ( ) { assertThat ( Analyzers . getAnalyzer ( " standard " ) , is ( StandardAnalyzer . class ) ) ; } 
public void testFrench ( ) { assertThat ( Analyzers . getAnalyzer ( " french " ) , is ( FrenchAnalyzer . class ) ) ; } 
public void testPerField ( ) { final Analyzer analyzer = Analyzers . getAnalyzer ( " perfield:{name: \" standard \" ,age: \" keyword \" } " ) ; assertThat ( analyzer , is ( PerFieldAnalyzerWrapper . class ) ) ; assertThat ( analyzer . toString ( ) , containsString ( " default=org.apache.lucene.analysis.standard.StandardAnalyzer " ) ) ; assertThat ( analyzer . toString ( ) , containsString ( " name=org.apache.lucene.analysis.standard.StandardAnalyzer " ) ) ; assertThat ( analyzer . toString ( ) , containsString ( " age=org.apache.lucene.analysis.KeywordAnalyzer " ) ) ; } 
public void testPerFieldDefault ( ) { final Analyzer analyzer = Analyzers . getAnalyzer ( " perfield:{default: \" keyword \" } " ) ; assertThat ( analyzer , is ( PerFieldAnalyzerWrapper . class ) ) ; assertThat ( analyzer . toString ( ) , containsString ( " default=org.apache.lucene.analysis.KeywordAnalyzer " ) ) ; } 
public HttpUriRequest getChangesRequest ( final long since ) throws IOException { return new HttpGet ( url + " _changes?feed=continuous&heartbeat=15000&include_docs=true&since= " + since ) ; } 
protected void doPost ( final HttpServletRequest req , final HttpServletResponse resp ) throws ServletException , IOException { final String command = req . getParameter ( " cmd " ) ; final IndexPath path = IndexPath . parse ( configuration , req ) ; if ( path = = null ) { ServletUtils . sendJSONError ( req , resp , 400 , " Bad path " ) ; return ; } if ( " expunge " . equals ( command ) ) { lucene . withWriter ( path , new WriterCallback ( ) { public boolean callback ( final IndexWriter writer ) throws IOException { writer . expungeDeletes ( false ) ; return false ; } public void onMissing ( ) throws IOException { resp . sendError ( 404 ) ; } } ) ; resp . setStatus ( 202 ) ; return ; } if ( " optimize " . equals ( command ) ) { lucene . withWriter ( path , new WriterCallback ( ) { public boolean callback ( final IndexWriter writer ) throws IOException { writer . optimize ( false ) ; return false ; } public void onMissing ( ) throws IOException { resp . sendError ( 404 ) ; } } ) ; resp . setStatus ( 202 ) ; return ; } resp . sendError ( 400 , " Bad request " ) ; } 
private void setup ( ) throws IOException { logger . info ( " Starting. " ) ; context = Context . enter ( ) ; context . setClassShutter ( new RestrictiveClassShutter ( ) ) ; context . setOptimizationLevel ( 9 ) ; client = HttpClientFactory . getInstance ( ) ; final Couch couch = Couch . getInstance ( client , path . getUrl ( ) ) ; database = couch . getDatabase ( path . getDatabase ( ) ) ; } 
public static IndexPath parse ( final HierarchicalINIConfiguration configuration , final HttpServletRequest req ) { final String uri = req . getRequestURI ( ) . replaceFirst ( " ^/ \\ w+/ " , " " ) ; final String [ ] parts = uri . split ( " / " ) ; if ( parts . length ! = 4 ) { return null ; } final Configuration section = configuration . getSection ( parts [ 0 ] ) ; return section . containsKey ( " url " ) ? new IndexPath ( section . getString ( " url " ) , parts [ 1 ] , parts [ 2 ] , parts [ 3 ] ) : null ; } 
public boolean equals ( final Object obj ) { if ( this = = obj ) { return true ; } if ( obj = = null ) { return false ; } if ( ! ( obj instanceof IndexPath ) ) { return false ; } final IndexPath other = ( IndexPath ) obj ; if ( ! database . equals ( other . database ) ) { return false ; } if ( ! designDocumentName . equals ( other . designDocumentName ) ) { return false ; } if ( ! url . equals ( other . url ) ) { return false ; } if ( ! viewName . equals ( other . viewName ) ) { return false ; } return true ; } 
public int hashCode ( ) { final int prime = 31 ; int result = 1 ; result = prime * result + database . hashCode ( ) ; result = prime * result + designDocumentName . hashCode ( ) ; result = prime * result + url . hashCode ( ) ; result = prime * result + viewName . hashCode ( ) ; return result ; } 
public String toString ( ) { return url + " / " + database + " / " + designDocumentName + " / " + viewName ; } 
public void callback ( final IndexReader reader ) throws IOException ; public void onMissing ( ) throws IOException ; } public interface SearcherCallback { public void callback ( final IndexSearcher searcher , final String version ) throws IOException ; public void onMissing ( ) throws IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) throws IOException ; public void onMissing ( ) throws IOException ; } public Lucene ( final File root ) { this . root = root ; } public void startIndexing ( final IndexPath path , final boolean staleOk ) { final ViewIndexer viewIndexer = executor . submit ( path , new ViewIndexer ( this , path , staleOk ) ) ; viewIndexer . awaitInitialIndexing ( ) ; } public void withReader ( final IndexPath path , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple ; synchronized ( map ) { tuple = map . get ( path ) ; } if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexPath path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexPath path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final IndexPath path, final UUID uuid, final JSONObject view) throws IOException { final String digest = digest(view); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final JSONObject view) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(toBytes(view.optString("analyzer"))); md.update(toBytes(view.optString("defaults"))); md.update(toBytes(view.optString("index"))); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } } private static byte[] toBytes(final String str) { if (str == null) { return new byte[0]; } try { return str.getBytes("UTF-8"); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }} 
public void onMissing ( ) throws IOException ; } public interface SearcherCallback { public void callback ( final IndexSearcher searcher , final String version ) throws IOException ; public void onMissing ( ) throws IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) throws IOException ; public void onMissing ( ) throws IOException ; } public Lucene ( final File root ) { this . root = root ; } public void startIndexing ( final IndexPath path , final boolean staleOk ) { final ViewIndexer viewIndexer = executor . submit ( path , new ViewIndexer ( this , path , staleOk ) ) ; viewIndexer . awaitInitialIndexing ( ) ; } public void withReader ( final IndexPath path , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple ; synchronized ( map ) { tuple = map . get ( path ) ; } if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexPath path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexPath path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final IndexPath path, final UUID uuid, final JSONObject view) throws IOException { final String digest = digest(view); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final JSONObject view) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(toBytes(view.optString("analyzer"))); md.update(toBytes(view.optString("defaults"))); md.update(toBytes(view.optString("index"))); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } } private static byte[] toBytes(final String str) { if (str == null) { return new byte[0]; } try { return str.getBytes("UTF-8"); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }} 
public void callback ( final IndexSearcher searcher , final String version ) throws IOException ; public void onMissing ( ) throws IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) throws IOException ; public void onMissing ( ) throws IOException ; } public Lucene ( final File root ) { this . root = root ; } public void startIndexing ( final IndexPath path , final boolean staleOk ) { final ViewIndexer viewIndexer = executor . submit ( path , new ViewIndexer ( this , path , staleOk ) ) ; viewIndexer . awaitInitialIndexing ( ) ; } public void withReader ( final IndexPath path , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple ; synchronized ( map ) { tuple = map . get ( path ) ; } if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexPath path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexPath path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final IndexPath path, final UUID uuid, final JSONObject view) throws IOException { final String digest = digest(view); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final JSONObject view) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(toBytes(view.optString("analyzer"))); md.update(toBytes(view.optString("defaults"))); md.update(toBytes(view.optString("index"))); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } } private static byte[] toBytes(final String str) { if (str == null) { return new byte[0]; } try { return str.getBytes("UTF-8"); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }} 
public void onMissing ( ) throws IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) throws IOException ; public void onMissing ( ) throws IOException ; } public Lucene ( final File root ) { this . root = root ; } public void startIndexing ( final IndexPath path , final boolean staleOk ) { final ViewIndexer viewIndexer = executor . submit ( path , new ViewIndexer ( this , path , staleOk ) ) ; viewIndexer . awaitInitialIndexing ( ) ; } public void withReader ( final IndexPath path , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple ; synchronized ( map ) { tuple = map . get ( path ) ; } if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexPath path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexPath path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final IndexPath path, final UUID uuid, final JSONObject view) throws IOException { final String digest = digest(view); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final JSONObject view) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(toBytes(view.optString("analyzer"))); md.update(toBytes(view.optString("defaults"))); md.update(toBytes(view.optString("index"))); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } } private static byte[] toBytes(final String str) { if (str == null) { return new byte[0]; } try { return str.getBytes("UTF-8"); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }} 
public boolean callback ( final IndexWriter writer ) throws IOException ; public void onMissing ( ) throws IOException ; } public Lucene ( final File root ) { this . root = root ; } public void startIndexing ( final IndexPath path , final boolean staleOk ) { final ViewIndexer viewIndexer = executor . submit ( path , new ViewIndexer ( this , path , staleOk ) ) ; viewIndexer . awaitInitialIndexing ( ) ; } public void withReader ( final IndexPath path , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple ; synchronized ( map ) { tuple = map . get ( path ) ; } if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexPath path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexPath path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final IndexPath path, final UUID uuid, final JSONObject view) throws IOException { final String digest = digest(view); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final JSONObject view) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(toBytes(view.optString("analyzer"))); md.update(toBytes(view.optString("defaults"))); md.update(toBytes(view.optString("index"))); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } } private static byte[] toBytes(final String str) { if (str == null) { return new byte[0]; } try { return str.getBytes("UTF-8"); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }} 
public void onMissing ( ) throws IOException ; } public Lucene ( final File root ) { this . root = root ; } public void startIndexing ( final IndexPath path , final boolean staleOk ) { final ViewIndexer viewIndexer = executor . submit ( path , new ViewIndexer ( this , path , staleOk ) ) ; viewIndexer . awaitInitialIndexing ( ) ; } public void withReader ( final IndexPath path , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple ; synchronized ( map ) { tuple = map . get ( path ) ; } if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexPath path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexPath path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final IndexPath path, final UUID uuid, final JSONObject view) throws IOException { final String digest = digest(view); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final JSONObject view) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(toBytes(view.optString("analyzer"))); md.update(toBytes(view.optString("defaults"))); md.update(toBytes(view.optString("index"))); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } } private static byte[] toBytes(final String str) { if (str == null) { return new byte[0]; } try { return str.getBytes("UTF-8"); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }} 
public void createWriter ( final IndexPath path , final UUID uuid , final JSONObject view ) throws IOException { final String digest = digest ( view ) ; final File dir = new File ( new File ( root , uuid . toString ( ) ) , digest ) ; dir . mkdirs ( ) ; synchronized ( map ) { Tuple tuple = map . remove ( path ) ; 
public static String digest ( final JSONObject view ) { try { final MessageDigest md = MessageDigest . getInstance ( " MD5 " ) ; 
private static byte [ ] toBytes ( final String str ) { if ( str = = null ) { return new byte [ 0 ] ; } try { return str . getBytes ( " UTF-8 " ) ; 
public void callback ( final IndexReader reader ) throws IOException ; public void onMissing ( ) throws IOException ; } public interface SearcherCallback { public void callback ( final IndexSearcher searcher , final String version ) throws IOException ; public void onMissing ( ) throws IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) throws IOException ; public void onMissing ( ) throws IOException ; } public Lucene ( final File root ) { this . root = root ; } public ViewIndexer startIndexing ( final IndexPath path , final boolean staleOk ) { final ViewIndexer result = executor . submit ( path , new ViewIndexer ( this , path , staleOk ) ) ; result . awaitInitialIndexing ( ) ; return result ; } public void withReader ( final IndexPath path , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple ; synchronized ( map ) { tuple = map . get ( path ) ; } if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexPath path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexPath path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final IndexPath path, final UUID uuid, final JSONObject view) throws IOException { final String digest = digest(view); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final JSONObject view) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(toBytes(view.optString("analyzer"))); md.update(toBytes(view.optString("defaults"))); md.update(toBytes(view.optString("index"))); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } } private static byte[] toBytes(final String str) { if (str == null) { return new byte[0]; } try { return str.getBytes("UTF-8"); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }} 
public void onMissing ( ) throws IOException ; } public interface SearcherCallback { public void callback ( final IndexSearcher searcher , final String version ) throws IOException ; public void onMissing ( ) throws IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) throws IOException ; public void onMissing ( ) throws IOException ; } public Lucene ( final File root ) { this . root = root ; } public ViewIndexer startIndexing ( final IndexPath path , final boolean staleOk ) { final ViewIndexer result = executor . submit ( path , new ViewIndexer ( this , path , staleOk ) ) ; result . awaitInitialIndexing ( ) ; return result ; } public void withReader ( final IndexPath path , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple ; synchronized ( map ) { tuple = map . get ( path ) ; } if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexPath path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexPath path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final IndexPath path, final UUID uuid, final JSONObject view) throws IOException { final String digest = digest(view); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final JSONObject view) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(toBytes(view.optString("analyzer"))); md.update(toBytes(view.optString("defaults"))); md.update(toBytes(view.optString("index"))); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } } private static byte[] toBytes(final String str) { if (str == null) { return new byte[0]; } try { return str.getBytes("UTF-8"); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }} 
public void callback ( final IndexSearcher searcher , final String version ) throws IOException ; public void onMissing ( ) throws IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) throws IOException ; public void onMissing ( ) throws IOException ; } public Lucene ( final File root ) { this . root = root ; } public ViewIndexer startIndexing ( final IndexPath path , final boolean staleOk ) { final ViewIndexer result = executor . submit ( path , new ViewIndexer ( this , path , staleOk ) ) ; result . awaitInitialIndexing ( ) ; return result ; } public void withReader ( final IndexPath path , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple ; synchronized ( map ) { tuple = map . get ( path ) ; } if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexPath path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexPath path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final IndexPath path, final UUID uuid, final JSONObject view) throws IOException { final String digest = digest(view); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final JSONObject view) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(toBytes(view.optString("analyzer"))); md.update(toBytes(view.optString("defaults"))); md.update(toBytes(view.optString("index"))); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } } private static byte[] toBytes(final String str) { if (str == null) { return new byte[0]; } try { return str.getBytes("UTF-8"); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }} 
public void onMissing ( ) throws IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) throws IOException ; public void onMissing ( ) throws IOException ; } public Lucene ( final File root ) { this . root = root ; } public ViewIndexer startIndexing ( final IndexPath path , final boolean staleOk ) { final ViewIndexer result = executor . submit ( path , new ViewIndexer ( this , path , staleOk ) ) ; result . awaitInitialIndexing ( ) ; return result ; } public void withReader ( final IndexPath path , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple ; synchronized ( map ) { tuple = map . get ( path ) ; } if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexPath path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexPath path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final IndexPath path, final UUID uuid, final JSONObject view) throws IOException { final String digest = digest(view); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final JSONObject view) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(toBytes(view.optString("analyzer"))); md.update(toBytes(view.optString("defaults"))); md.update(toBytes(view.optString("index"))); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } } private static byte[] toBytes(final String str) { if (str == null) { return new byte[0]; } try { return str.getBytes("UTF-8"); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }} 
public boolean callback ( final IndexWriter writer ) throws IOException ; public void onMissing ( ) throws IOException ; } public Lucene ( final File root ) { this . root = root ; } public ViewIndexer startIndexing ( final IndexPath path , final boolean staleOk ) { final ViewIndexer result = executor . submit ( path , new ViewIndexer ( this , path , staleOk ) ) ; result . awaitInitialIndexing ( ) ; return result ; } public void withReader ( final IndexPath path , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple ; synchronized ( map ) { tuple = map . get ( path ) ; } if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexPath path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexPath path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final IndexPath path, final UUID uuid, final JSONObject view) throws IOException { final String digest = digest(view); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final JSONObject view) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(toBytes(view.optString("analyzer"))); md.update(toBytes(view.optString("defaults"))); md.update(toBytes(view.optString("index"))); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } } private static byte[] toBytes(final String str) { if (str == null) { return new byte[0]; } try { return str.getBytes("UTF-8"); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }} 
public void onMissing ( ) throws IOException ; } public Lucene ( final File root ) { this . root = root ; } public ViewIndexer startIndexing ( final IndexPath path , final boolean staleOk ) { final ViewIndexer result = executor . submit ( path , new ViewIndexer ( this , path , staleOk ) ) ; result . awaitInitialIndexing ( ) ; return result ; } public void withReader ( final IndexPath path , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple ; synchronized ( map ) { tuple = map . get ( path ) ; } if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexPath path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexPath path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final IndexPath path, final UUID uuid, final JSONObject view) throws IOException { final String digest = digest(view); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final JSONObject view) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(toBytes(view.optString("analyzer"))); md.update(toBytes(view.optString("defaults"))); md.update(toBytes(view.optString("index"))); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } } private static byte[] toBytes(final String str) { if (str == null) { return new byte[0]; } try { return str.getBytes("UTF-8"); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }} 
public ViewIndexer startIndexing ( final IndexPath path , final boolean staleOk ) { final ViewIndexer result = executor . submit ( path , new ViewIndexer ( this , path , staleOk ) ) ; result . awaitInitialIndexing ( ) ; return result ; } 
private void index ( ) throws IOException { final UUID uuid = getDatabaseUuid ( ) ; final JSONObject ddoc = database . getDocument ( " _design/ " + path . getDesignDocumentName ( ) ) ; final JSONObject view = extractView ( ddoc ) ; if ( view = = null ) { return ; } if ( extractFunction ( view ) = = null ) return ; final JSONObject info = database . getInfo ( ) ; final long seqThreshhold = staleOk ? 0 : info . getLong ( " update_seq " ) ; this . handler = new ViewChangesHandler ( uuid , view , seqThreshhold ) ; handler . start ( ) ; } 
protected void doPost ( final HttpServletRequest req , final HttpServletResponse resp ) throws ServletException , IOException { final IndexPath path = IndexPath . parse ( configuration , req ) ; if ( path = = null ) { ServletUtils . sendJSONError ( req , resp , 400 , " Bad path " ) ; return ; } lucene . startIndexing ( path , true ) ; String command = req . getPathInfo ( ) ; command = command . substring ( command . lastIndexOf ( " / " ) + 1 ) ; if ( " _expunge " . equals ( command ) ) { lucene . withWriter ( path , new WriterCallback ( ) { public boolean callback ( final IndexWriter writer ) throws IOException { writer . expungeDeletes ( false ) ; return false ; } public void onMissing ( ) throws IOException { resp . sendError ( 404 ) ; } } ) ; Utils . setResponseContentTypeAndEncoding ( req , resp ) ; resp . setStatus ( 202 ) ; sendJSON ( resp , JSON_SUCCESS ) ; return ; } if ( " _optimize " . equals ( command ) ) { lucene . withWriter ( path , new WriterCallback ( ) { public boolean callback ( final IndexWriter writer ) throws IOException { writer . optimize ( false ) ; return false ; } public void onMissing ( ) throws IOException { resp . sendError ( 404 ) ; } } ) ; Utils . setResponseContentTypeAndEncoding ( req , resp ) ; resp . setStatus ( 202 ) ; sendJSON ( resp , JSON_SUCCESS ) ; return ; } resp . sendError ( 400 , " Bad request " ) ; } 
private void sendJSON ( final HttpServletResponse resp , final String json ) throws IOException { final Writer writer = resp . getWriter ( ) ; try { writer . write ( json ) ; 
public static IndexPath parse ( final HierarchicalINIConfiguration configuration , final HttpServletRequest req ) { final String uri = req . getRequestURI ( ) . replaceFirst ( " ^/ \\ w+/ " , " " ) ; final String [ ] parts = uri . split ( " / " ) ; if ( parts . length < 4 ) { return null ; } final Configuration section = configuration . getSection ( parts [ 0 ] ) ; return section . containsKey ( " url " ) ? new IndexPath ( section . getString ( " url " ) , parts [ 1 ] , parts [ 2 ] , parts [ 3 ] ) : null ; } 
protected void doPost ( final HttpServletRequest req , final HttpServletResponse resp ) throws ServletException , IOException { final IndexPath path = IndexPath . parse ( configuration , req ) ; if ( path = = null ) { ServletUtils . sendJSONError ( req , resp , 400 , " Bad path " ) ; return ; } lucene . startIndexing ( path , true ) ; String command = req . getPathInfo ( ) ; command = command . substring ( command . lastIndexOf ( " / " ) + 1 ) ; if ( " _expunge " . equals ( command ) ) { lucene . withWriter ( path , new WriterCallback ( ) { public boolean callback ( final IndexWriter writer ) throws IOException { writer . expungeDeletes ( false ) ; return false ; } public void onMissing ( ) throws IOException { resp . sendError ( 404 ) ; } } ) ; Utils . setResponseContentTypeAndEncoding ( req , resp ) ; resp . setStatus ( 202 ) ; Utils . writeJSON ( resp , JSON_SUCCESS ) ; return ; } if ( " _optimize " . equals ( command ) ) { lucene . withWriter ( path , new WriterCallback ( ) { public boolean callback ( final IndexWriter writer ) throws IOException { writer . optimize ( false ) ; return false ; } public void onMissing ( ) throws IOException { resp . sendError ( 404 ) ; } } ) ; Utils . setResponseContentTypeAndEncoding ( req , resp ) ; resp . setStatus ( 202 ) ; Utils . writeJSON ( resp , JSON_SUCCESS ) ; return ; } resp . sendError ( 400 , " Bad request " ) ; } 
public static void main ( String [ ] args ) throws Exception { final HierarchicalINIConfiguration configuration = new HierarchicalINIConfiguration ( Main . class . getClassLoader ( ) . getResource ( " couchdb-lucene.ini " ) ) ; configuration . setReloadingStrategy ( new FileChangedReloadingStrategy ( ) ) ; final File dir = new File ( configuration . getString ( " lucene.dir " , " indexes " ) ) ; if ( dir = = null ) { LOG . error ( " lucene.dir not set. " ) ; System . exit ( 1 ) ; } if ( ! dir . exists ( ) & & ! dir . mkdir ( ) ) { LOG . error ( " Could not create " + dir . getCanonicalPath ( ) ) ; System . exit ( 1 ) ; } if ( ! dir . canRead ( ) ) { LOG . error ( dir + " is not readable. " ) ; System . exit ( 1 ) ; } if ( ! dir . canWrite ( ) ) { LOG . error ( dir + " is not writable. " ) ; System . exit ( 1 ) ; } LOG . info ( " Index output goes to: " + dir . getCanonicalPath ( ) ) ; final Lucene lucene = new Lucene ( dir ) ; final Server server = new Server ( ) ; final SelectChannelConnector connector = new SelectChannelConnector ( ) ; connector . setHost ( configuration . getString ( " lucene.host " , " localhost " ) ) ; connector . setPort ( configuration . getInt ( " lucene.port " , 5985 ) ) ; LOG . info ( " Accepting connections with " + connector ) ; server . setConnectors ( new Connector [ ] { connector } ) ; server . setStopAtShutdown ( true ) ; server . setSendServerVersion ( false ) ; final ContextHandlerCollection contexts = new ContextHandlerCollection ( ) ; server . setHandler ( contexts ) ; final SearchServlet search = new SearchServlet ( ) ; search . setLucene ( lucene ) ; search . setConfiguration ( configuration ) ; setupContext ( contexts , " /search " , search ) ; final InfoServlet info = new InfoServlet ( ) ; info . setLucene ( lucene ) ; info . setConfiguration ( configuration ) ; setupContext ( contexts , " /info " , info ) ; final AdminServlet admin = new AdminServlet ( ) ; admin . setLucene ( lucene ) ; admin . setConfiguration ( configuration ) ; setupContext ( contexts , " /admin " , admin ) ; setupContext ( contexts , " / " , new WelcomeServlet ( ) ) ; server . start ( ) ; server . join ( ) ; } 
protected void doGet ( final HttpServletRequest req , final HttpServletResponse resp ) throws ServletException , IOException { Utils . setResponseContentTypeAndEncoding ( req , resp ) ; final JSONObject welcome = new JSONObject ( ) ; welcome . put ( " couchdb-lucene " , " Welcome " ) ; welcome . put ( " version " , " 0.5.0 " ) ; Utils . writeJSON ( resp , welcome ) ; } 
public static void writeJSON ( final HttpServletResponse resp , final JSONObject json ) throws IOException { final Writer writer = resp . getWriter ( ) ; try { writer . write ( json . toString ( ) + " r " ) ; 
private void commitDocuments ( ) throws IOException { if ( ! hasPendingCommit ( ) ) { return ; } lucene . withWriter ( path , new WriterCallback ( ) { public boolean callback ( final IndexWriter writer ) throws IOException { final Map < String , String > userData = new HashMap < String , String > ( ) ; userData . put ( " last_seq " , Long . toString ( since ) ) ; logger . debug ( " Starting checkpoint at update_seq " + since ) ; writer . commit ( userData ) ; final long elapsedSeconds = NANOSECONDS . toSeconds ( System . nanoTime ( ) - startNanos ) ; logger . info ( String . format ( " Committed checkpoint at update_seq %,d (%,d updates in %d seconds, %,d updates per minute) " , since , updateCount , elapsedSeconds , 60 * updateCount / elapsedSeconds ) ) ; updateCount = 0 ; startNanos = System . nanoTime ( ) ; return false ; } public void onMissing ( ) throws IOException { Ignore. } }); setPendingCommit(false); } 
public boolean callback ( final IndexWriter writer ) throws IOException { final Map < String , String > userData = new HashMap < String , String > ( ) ; userData . put ( " last_seq " , Long . toString ( since ) ) ; logger . debug ( " Starting checkpoint at update_seq " + since ) ; writer . commit ( userData ) ; final long elapsedSeconds = NANOSECONDS . toSeconds ( System . nanoTime ( ) - startNanos ) ; logger . info ( String . format ( " Committed checkpoint at update_seq %,d (%,d updates in %d seconds, %,d updates per minute) " , since , updateCount , elapsedSeconds , 60 * updateCount / elapsedSeconds ) ) ; updateCount = 0 ; startNanos = System . nanoTime ( ) ; return false ; } 
private Object fixup ( final String value ) { if ( value . matches ( " [-+]? \\ d+ \\ . \\ d+f " ) ) { return Float . parseFloat ( value ) ; } if ( value . matches ( " [-+]? \\ d+ \\ . \\ d+ " ) ) { return Double . parseDouble ( value ) ; } if ( value . matches ( " [-+]? \\ d+[lL] " ) ) { return Long . parseLong ( value . substring ( 0 , value . length ( ) - 1 ) ) ; } if ( value . matches ( " [-+]? \\ d+ " ) ) { return Integer . parseInt ( value ) ; } try { return DateUtils . parseDate ( value . toUpperCase ( ) , DATE_PATTERNS ) . getTime ( ) ; } catch ( final DateParseException e ) { Ignore. } return value; } 
protected Query getRangeQuery ( final String fieldAndType , final String part1 , final String part2 , final boolean inclusive ) throws ParseException { final Matcher matcher = NUMERIC_RANGE_PATTERN . matcher ( fieldAndType ) ; if ( ! matcher . matches ( ) ) { throw new ParseException ( " Field name ' " + fieldAndType + " ' not recognized. " ) ; } final String field = matcher . group ( 1 ) ; final String type = matcher . group ( 2 ) = = null ? " <string> " : matcher . group ( 2 ) ; if ( " <string> " . equals ( type ) ) { return newRangeQuery ( field , part1 , part2 , inclusive ) ; } if ( " <int> " . equals ( type ) ) { return NumericRangeQuery . newIntRange ( field , 4 , Integer . parseInt ( part1 ) , Integer . parseInt ( part2 ) , inclusive , inclusive ) ; } if ( " <long> " . equals ( type ) ) { return NumericRangeQuery . newLongRange ( field , 4 , Long . parseLong ( part1 ) , Long . parseLong ( part2 ) , inclusive , inclusive ) ; } if ( " <float> " . equals ( type ) ) { return NumericRangeQuery . newFloatRange ( field , 4 , Float . parseFloat ( part1 ) , Float . parseFloat ( part2 ) , inclusive , inclusive ) ; } if ( " <double> " . equals ( type ) ) { return NumericRangeQuery . newDoubleRange ( field , 4 , Double . parseDouble ( part1 ) , Double . parseDouble ( part2 ) , inclusive , inclusive ) ; } if ( " <date> " . equals ( type ) ) { return NumericRangeQuery . newLongRange ( field , 8 , date ( part1 ) , date ( part2 ) , inclusive , inclusive ) ; } throw new ParseException ( " Unrecognized type ' " + type + " ' " ) ; } 
private long date ( final String str ) throws ParseException { try { return DateUtils . parseDate ( str . toUpperCase ( ) , DATE_PATTERNS ) . getTime ( ) ; 
public void integerRangeQuery ( ) throws Exception { final Query q = parser . parse ( " blah<int>:[0 TO 123] " ) ; assertRange ( q , Integer . class , 0 , 123 ) ; } 
public void longRangeQuery ( ) throws Exception { final Query q = parser . parse ( " blah<long>:[0 TO 123] " ) ; assertRange ( q , Long . class , 0 L , 123L ) ; } 
public void floatRangeQuery ( ) throws Exception { final Query q = parser . parse ( " blah<float>:[0.0 TO 123.5] " ) ; assertRange ( q , Float . class , 0.0f , 123.5f ) ; } 
public void doubleRangeQuery ( ) throws Exception { final Query q = parser . parse ( " blah<double>:[0.0 TO 123.0] " ) ; assertRange ( q , Double . class , 0.0 , 123.0 ) ; } 
public void dateRangeQuery ( ) throws Exception { final Query q = parser . parse ( " blah<date>:[2000-01-01 TO 2010-02-04] " ) ; assertRange ( q , Long . class , 946684800000L , 1265241600000L ) ; } 
public void dateTimeRangeQuery ( ) throws Exception { final Query q = parser . parse ( " blah<date>:[2000-01-01T00:00:01 TO 2010-02-04T00:00:01] " ) ; assertRange ( q , Long . class , 946684801000L , 1265241601000L ) ; } 
public void dateTimeZoneRangeQuery ( ) throws Exception { final Query q = parser . parse ( " blah<date>:[2000-01-01-0100 TO 2010-02-04-0100] " ) ; assertRange ( q , Long . class , 946688400000L , 1265245200000L ) ; } 
public void dateTimeTimeZoneRangeQuery ( ) throws Exception { final Query q = parser . parse ( " blah<date>:[2000-01-01T00:00:00-0100 TO 2010-02-04T00:00:00-0100] " ) ; assertRange ( q , Long . class , 946688400000L , 1265245200000L ) ; } 
public static Sort toSort ( final String sort ) throws ParseException { if ( sort = = null ) { return null ; 
public String toString ( ) { return String . format ( " %s<%s> " , name , type . toString ( ) . toLowerCase ( ) ) ; } 
private void commitDocuments ( ) throws IOException { if ( ! hasPendingCommit ( ) ) { return ; } lucene . withWriter ( path , new WriterCallback ( ) { public boolean callback ( final IndexWriter writer ) throws IOException { final Map < String , String > userData = new HashMap < String , String > ( ) ; userData . put ( " last_seq " , Long . toString ( since ) ) ; logger . debug ( " Starting checkpoint at update_seq " + since ) ; writer . commit ( userData ) ; final long elapsedNanos = lastUpdate - firstUpdate ; logger . info ( String . format ( " Committed checkpoint at update_seq %,d (%,d updates in %d seconds, %,d updates per minute) " , since , updateCount , NANOSECONDS . toSeconds ( elapsedNanos ) , ( 60000000000L * updateCount ) / elapsedNanos ) ) ; updateCount = 0 ; firstUpdate = - 1 ; return false ; } public void onMissing ( ) throws IOException { Ignore. } }); setPendingCommit(false); } 
public boolean callback ( final IndexWriter writer ) throws IOException { final Map < String , String > userData = new HashMap < String , String > ( ) ; userData . put ( " last_seq " , Long . toString ( since ) ) ; logger . debug ( " Starting checkpoint at update_seq " + since ) ; writer . commit ( userData ) ; final long elapsedNanos = lastUpdate - firstUpdate ; logger . info ( String . format ( " Committed checkpoint at update_seq %,d (%,d updates in %d seconds, %,d updates per minute) " , since , updateCount , NANOSECONDS . toSeconds ( elapsedNanos ) , ( 60000000000L * updateCount ) / elapsedNanos ) ) ; updateCount = 0 ; firstUpdate = - 1 ; return false ; } 
protected void doPost ( final HttpServletRequest req , final HttpServletResponse resp ) throws ServletException , IOException { final IndexPath path = IndexPath . parse ( configuration , req ) ; String command = req . getPathInfo ( ) ; command = command . substring ( command . lastIndexOf ( " / " ) + 1 ) ; if ( path = = null ) { generalize path handling. final String[] parts = IndexPath.parts(req); if (parts.length == 2) { if ("_cleanup".equals(command)) { cleanup(parts[0]); resp.setStatus(202); Utils.writeJSON(resp, JSON_SUCCESS); } } else { ServletUtils.sendJSONError(req, resp, 400, "Bad path"); } return; } lucene.startIndexing(path, true); if ("_expunge".equals(command)) { lucene.withWriter(path, new WriterCallback() { public boolean callback(final IndexWriter writer) throws IOException { writer.expungeDeletes(false); return false; } public void onMissing() throws IOException { resp.sendError(404); } }); Utils.setResponseContentTypeAndEncoding(req, resp); resp.setStatus(202); Utils.writeJSON(resp, JSON_SUCCESS); return; } if ("_optimize".equals(command)) { lucene.withWriter(path, new WriterCallback() { public boolean callback(final IndexWriter writer) throws IOException { writer.optimize(false); return false; } public void onMissing() throws IOException { resp.sendError(404); } }); Utils.setResponseContentTypeAndEncoding(req, resp); resp.setStatus(202); Utils.writeJSON(resp, JSON_SUCCESS); return; } resp.sendError(400, "Bad request"); } 
public void createWriter ( final IndexPath path , final UUID uuid , final JSONObject view ) throws IOException { final String digest = digest ( view ) ; final File dir = new File ( getUuidDir ( uuid ) , digest ) ; dir . mkdirs ( ) ; synchronized ( map ) { Tuple tuple = map . remove ( path ) ; 
private void index ( ) throws IOException { UUID uuid = null ; try { uuid = database . getUuid ( ) ; } catch ( final IOException e ) { database . createUuid ( ) ; uuid = database . getUuid ( ) ; } final JSONObject ddoc = database . getDocument ( " _design/ " + path . getDesignDocumentName ( ) ) ; final JSONObject view = extractView ( ddoc ) ; if ( view = = null ) { return ; } if ( extractFunction ( view ) = = null ) return ; final JSONObject info = database . getInfo ( ) ; final long seqThreshhold = staleOk ? 0 : info . getLong ( " update_seq " ) ; this . handler = new ViewChangesHandler ( uuid , view , seqThreshhold ) ; handler . start ( ) ; } 
public UUID getUuid ( ) throws IOException { final JSONObject local = getDocument ( " _local/lucene " ) ; return UUID . fromString ( local . getString ( " uuid " ) ) ; } 
public void createUuid ( ) throws IOException { final UUID uuid = UUID . randomUUID ( ) ; saveDocument ( " _local/lucene " , String . format ( " { \" uuid \" : \" %s \" } " , uuid ) ) ; } 
public static IndexPath parse ( final HierarchicalINIConfiguration configuration , final HttpServletRequest req ) { final String [ ] parts = parts ( req ) ; if ( parts . length < 4 ) { return null ; } final String url = url ( configuration , parts [ 0 ] ) ; return url = = null ? null : new IndexPath ( url , parts [ 1 ] , parts [ 2 ] , parts [ 3 ] ) ; } 
public static String [ ] parts ( final HttpServletRequest req ) { final String uri = req . getRequestURI ( ) . replaceFirst ( " ^/ \\ w+/ " , " " ) ; return uri . split ( " / " ) ; } 
public static String url ( final HierarchicalINIConfiguration configuration , final String key ) { final Configuration section = configuration . getSection ( key ) ; return section . containsKey ( " url " ) ? section . getString ( " url " ) : null ; } 
public void createWriter ( final IndexPath path , final UUID uuid , final View view ) throws IOException { final File dir = new File ( getUuidDir ( uuid ) , view . getDigest ( ) ) ; dir . mkdirs ( ) ; synchronized ( map ) { Tuple tuple = map . remove ( path ) ; 
public boolean callback ( final IndexWriter writer ) throws IOException { writer . deleteDocuments ( new Term ( " _id " , id ) ) ; for ( final Document doc : docs ) { if ( logger . isTraceEnabled ( ) ) { logger . trace ( id + " -> " + doc ) ; } writer . addDocument ( doc , view . getAnalyzer ( ) ) ; } return true ; } 
private void index ( ) throws IOException { UUID uuid = null ; try { uuid = database . getUuid ( ) ; } catch ( final IOException e ) { database . createUuid ( ) ; uuid = database . getUuid ( ) ; } final DesignDocument ddoc = database . getDesignDocument ( path . getDesignDocumentName ( ) ) ; final View view = ddoc . getView ( path . getViewName ( ) ) ; if ( view = = null ) { return ; } final JSONObject info = database . getInfo ( ) ; final long seqThreshhold = staleOk ? 0 : info . getLong ( " update_seq " ) ; this . handler = new ViewChangesHandler ( uuid , view , seqThreshhold ) ; handler . start ( ) ; } 
public static CouchDocument deletedDocument ( final String id ) { final JSONObject json = new JSONObject ( ) ; json . put ( ID , id ) ; json . put ( DELETED , true ) ; return new CouchDocument ( json ) ; } 
public boolean isDeleted ( ) { return json . optBoolean ( DELETED , false ) ; } 
public List < DesignDocument > getAllDesignDocuments ( ) throws IOException { final String body = HttpUtils . get ( httpClient , url + " _all_docs?startkey=%%22_design%%22&endkey=%%22_design9%%22&include_docs=true " ) ; final JSONObject json = JSONObject . fromObject ( body ) ; return toDesignDocuments ( json ) ; } 
public CouchDocument getDocument ( final String id ) throws IOException { final String response = HttpUtils . get ( httpClient , url + Utils . urlEncode ( id ) ) ; return new CouchDocument ( JSONObject . fromObject ( response ) ) ; } 
public DesignDocument getDesignDocument ( final String id ) throws IOException { final String response = HttpUtils . get ( httpClient , url + " _design/ " + Utils . urlEncode ( id ) ) ; return new DesignDocument ( JSONObject . fromObject ( response ) ) ; } 
public List < CouchDocument > getDocuments ( final String . . . ids ) throws IOException { final JSONArray keys = new JSONArray ( ) ; for ( final String id : ids ) { keys . add ( id ) ; } final JSONObject req = new JSONObject ( ) ; req . element ( " keys " , keys ) ; final String body = HttpUtils . post ( httpClient , url + " _all_docs?include_docs=true " , req . toString ( ) ) ; final JSONObject json = JSONObject . fromObject ( body ) ; return toDocuments ( json ) ; } 
public UUID getUuid ( ) throws IOException { final CouchDocument local = getDocument ( " _local/lucene " ) ; return UUID . fromString ( local . asJson ( ) . getString ( " uuid " ) ) ; } 
private List < DesignDocument > toDesignDocuments ( final JSONObject json ) { final List < DesignDocument > result = new ArrayList < DesignDocument > ( ) ; for ( final JSONObject doc : rows ( json ) ) { result . add ( new DesignDocument ( doc ) ) ; } return result ; } 
private List < CouchDocument > toDocuments ( final JSONObject json ) { final List < CouchDocument > result = new ArrayList < CouchDocument > ( ) ; for ( final JSONObject doc : rows ( json ) ) { result . add ( new CouchDocument ( doc ) ) ; } return result ; } 
private List < JSONObject > rows ( final JSONObject json ) { final List < JSONObject > result = new ArrayList < JSONObject > ( ) ; final JSONArray rows = json . getJSONArray ( " rows " ) ; for ( int i = 0 ; i < rows . size ( ) ; i + + ) { result . add ( rows . getJSONObject ( i ) . getJSONObject ( " doc " ) ) ; } return result ; } 
public NumericField asField ( String name , String value , ViewSettings settings ) { Date date ; try { date = DateUtils . parseDate ( value . toUpperCase ( ) , patterns ) ; } catch ( final DateParseException e ) { throw new NumberFormatException ( ) ; } return field ( name , 8 , settings ) . setLongValue ( date . getTime ( ) ) ; } 
public int asSortField ( ) { return SortField . LONG ; } 
public NumericField asField ( String name , String value , ViewSettings settings ) { return field ( name , 8 , settings ) . setDoubleValue ( Double . parseDouble ( value ) ) ; } 
public int asSortField ( ) { return SortField . DOUBLE ; } 
public NumericField asField ( String name , String value , ViewSettings settings ) { return field ( name , 4 , settings ) . setFloatValue ( Float . parseFloat ( value ) ) ; } 
public int asSortField ( ) { return SortField . FLOAT ; } 
public NumericField asField ( String name , String value , ViewSettings settings ) { return field ( name , 4 , settings ) . setIntValue ( Integer . parseInt ( value ) ) ; } 
public int asSortField ( ) { return SortField . INT ; } 
public NumericField asField ( String name , String value , ViewSettings settings ) { return field ( name , 8 , settings ) . setLongValue ( Long . parseLong ( value ) ) ; } 
public Field asField ( String name , String value , ViewSettings settings ) { return new Field ( name , value , settings . getStore ( ) , settings . getIndex ( ) ) ; } 
public int asSortField ( ) { return SortField . STRING ; } 
public abstract int asSortField ( ) ; public abstract AbstractField asField ( final String name , final String value , final ViewSettings settings ) ; private static NumericField field ( final String name , final int precisionStep , final ViewSettings settings ) { return new NumericField ( name , precisionStep , settings . getStore ( ) , settings . getIndex ( ) . isIndexed ( ) ) ; } } 
public abstract AbstractField asField ( final String name , final String value , final ViewSettings settings ) ; private static NumericField field ( final String name , final int precisionStep , final ViewSettings settings ) { return new NumericField ( name , precisionStep , settings . getStore ( ) , settings . getIndex ( ) . isIndexed ( ) ) ; } } 
private static NumericField field ( final String name , final int precisionStep , final ViewSettings settings ) { return new NumericField ( name , precisionStep , settings . getStore ( ) , settings . getIndex ( ) . isIndexed ( ) ) ; } 
public Function compileFunction ( final Context context , ScriptableObject scope ) { return context . compileFunction ( scope , getFunction ( ) , null , 0 , null ) ; } 
public int hashCode ( ) { final int prime = 31 ; int result = 1 ; result = prime * result + ( ( json = = null ) ? 0 : json . hashCode ( ) ) ; return result ; } 
public boolean equals ( Object obj ) { if ( this = = obj ) { return true ; } if ( obj = = null ) { return false ; } if ( ! ( obj instanceof View ) ) { return false ; } View other = ( View ) obj ; return getDigest ( ) . equals ( other . getDigest ( ) ) ; } 
private static String get ( final NativeObject obj , final String key ) { return obj = = null ? null : obj . has ( key , null ) ? ( String ) obj . get ( key , null ) : null ; } 
public Document toDocument ( final String id , final ViewSettings defaults , final Database database ) throws IOException { final Document result = new Document ( ) ; Add id. result.add(Utils.token("_id", id, true)); Add user-supplied fields. for (final RhinoField field : fields) { addField(field, defaults, result); } Parse user-requested attachments. for (final RhinoAttachment attachment : attachments) { addAttachment(attachment, id, database, result); } return result; } 
private void addField ( final RhinoField field , final ViewSettings defaults , final Document out ) { final ViewSettings settings = new ViewSettings ( field . settings , defaults ) ; final FieldType type = settings . getFieldType ( ) ; out . add ( type . asField ( settings . getField ( ) , field . value . toString ( ) , settings ) ) ; } 
public void testSingleDocumentReturn ( ) throws Exception { final DocumentConverter converter = new DocumentConverter ( context , " single " , " function(doc) {return new Document();} " ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" } " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 1 ) ) ; assertThat ( result [ 0 ] . get ( " _id " ) , is ( " hello " ) ) ; } 
public void testMultipleDocumentReturn ( ) throws Exception { final DocumentConverter converter = new DocumentConverter ( context , " multi " , " function(doc) {var ret = new Array(); ret.push(new Document()); ret.push(new Document()); return ret;} " ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" } " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 2 ) ) ; assertThat ( result [ 0 ] . get ( " _id " ) , is ( " hello " ) ) ; } 
public void testAdd ( ) throws Exception { final DocumentConverter converter = new DocumentConverter ( context , " single " , " function(doc) {var ret=new Document(); ret.add(doc.key); return ret;} " ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" , key: \" value \" } " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 1 ) ) ; assertThat ( result [ 0 ] . get ( Constants . DEFAULT_FIELD ) , is ( " value " ) ) ; } 
public void testForLoopOverObject ( ) throws Exception { final DocumentConverter converter = new DocumentConverter ( context , " multi " , " function(doc) {var ret=new Document(); for (var key in doc) { ret.add(doc[key]); } return ret; } " ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" , key: \" value \" } " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 1 ) ) ; assertThat ( result [ 0 ] . get ( " _id " ) , is ( " hello " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 0 ] , is ( " hello " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 1 ] , is ( " value " ) ) ; } 
public void testForLoopOverArray ( ) throws Exception { final DocumentConverter converter = new DocumentConverter ( context , " multi " , " function(doc) {var ret=new Document(); for (var key in doc.arr) {ret.add(doc.arr[key]); } return ret; } " ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" , arr:[0,1,2,3]} " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 1 ) ) ; assertThat ( result [ 0 ] . get ( " _id " ) , is ( " hello " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 0 ] , is ( " 0 " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 1 ] , is ( " 1 " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 2 ] , is ( " 2 " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 3 ] , is ( " 3 " ) ) ; } 
public void testForEverything ( ) throws Exception { final DocumentConverter converter = new DocumentConverter ( context , " multi " , " function(doc) {var ret=new Document(); function idx(obj) {for (var key in obj) {switch (typeof obj[key]) {case 'object':idx(obj[key]); break; case 'function': break; default: ret.add(obj[key]); break;} } }; idx(doc); return ret; } " ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" , l1: { l2: {l3:[ \" v3 \" , \" v4 \" ]}}} " ) , settings ( ) , null ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 0 ] , is ( " hello " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 1 ] , is ( " v3 " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 2 ] , is ( " v4 " ) ) ; } 
public void testNullReturn ( ) throws Exception { final DocumentConverter converter = new DocumentConverter ( context , " null " , " function(doc) {return null;} " ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" } " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 0 ) ) ; } 
public void testUndefinedReturn ( ) throws Exception { final DocumentConverter converter = new DocumentConverter ( context , " null " , " function(doc) {return doc.nope;} " ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" } " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 0 ) ) ; } 
public void testRuntimeException ( ) throws Exception { final DocumentConverter converter = new DocumentConverter ( context , " null " , " function(doc) {throw {bad : \" stuff \" }} " ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" } " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 0 ) ) ; } 
public void testNullAddsAreIgnored ( ) throws Exception { final DocumentConverter converter = new DocumentConverter ( context , " null " , " function(doc) {var ret=new Document(); ret.add(doc.nope); return ret;} " ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" } " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 1 ) ) ; } 
public void testQuoteRemoval ( ) throws Exception { final DocumentConverter converter = new DocumentConverter ( context , " single " , " \" function(doc) {return new Document();} \" " ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" } " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 1 ) ) ; assertThat ( result [ 0 ] . get ( " _id " ) , is ( " hello " ) ) ; } 
private CouchDocument doc ( final String json ) { return new CouchDocument ( JSONObject . fromObject ( json ) ) ; } 
private ViewSettings settings ( ) { return ViewSettings . getDefaultSettings ( ) ; } 
public void notValidDocument ( ) { new CouchDocument ( JSONObject . fromObject ( " {} " ) ) ; } 
public void validDocument ( ) { final CouchDocument doc = new CouchDocument ( JSONObject . fromObject ( " {_id: \" hello \" } " ) ) ; assertThat ( doc . getId ( ) , is ( " hello " ) ) ; } 
public void asJson ( ) { final JSONObject json = JSONObject . fromObject ( " {_id: \" hello \" } " ) ; final CouchDocument doc = new CouchDocument ( json ) ; assertThat ( doc . asJson ( ) , is ( json ) ) ; } 
public void notDesignDocument ( ) { new DesignDocument ( JSONObject . fromObject ( " {_id: \" hello \" } " ) ) ; } 
public void noViews ( ) { final DesignDocument ddoc = new DesignDocument ( JSONObject . fromObject ( " {_id: \" _design/hello \" } " ) ) ; assertThat ( ddoc . getAllViews ( ) . size ( ) , is ( 0 ) ) ; } 
public void views ( ) { final JSONObject view = new JSONObject ( ) ; view . put ( " index " , " function(doc) { return null; } " ) ; final JSONObject fulltext = new JSONObject ( ) ; fulltext . put ( " foo " , view ) ; final JSONObject json = new JSONObject ( ) ; json . put ( " _id " , " _design/hello " ) ; json . put ( " fulltext " , fulltext ) ; final DesignDocument ddoc = new DesignDocument ( json ) ; assertThat ( ddoc . getView ( " foo " ) , notNullValue ( ) ) ; assertThat ( ddoc . getAllViews ( ) . size ( ) , is ( 1 ) ) ; } 
public void noIndex ( ) { new View ( JSONObject . fromObject ( " {} " ) ) ; } 
public void index ( ) { final JSONObject json = new JSONObject ( ) ; json . put ( " index " , " function(doc) { return null; } " ) ; new View ( json ) ; } 
public void testSingleDocumentReturn ( ) throws Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) {return new Document();} " ) ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" } " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 1 ) ) ; assertThat ( result [ 0 ] . get ( " _id " ) , is ( " hello " ) ) ; } 
public void testMultipleDocumentReturn ( ) throws Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) {var ret = new Array(); ret.push(new Document()); ret.push(new Document()); return ret;} " ) ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" } " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 2 ) ) ; assertThat ( result [ 0 ] . get ( " _id " ) , is ( " hello " ) ) ; } 
public void testAdd ( ) throws Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) {var ret=new Document(); ret.add(doc.key); return ret;} " ) ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" , key: \" value \" } " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 1 ) ) ; assertThat ( result [ 0 ] . get ( Constants . DEFAULT_FIELD ) , is ( " value " ) ) ; } 
public void testForLoopOverObject ( ) throws Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) {var ret=new Document(); for (var key in doc) { ret.add(doc[key]); } return ret; } " ) ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" , key: \" value \" } " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 1 ) ) ; assertThat ( result [ 0 ] . get ( " _id " ) , is ( " hello " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 0 ] , is ( " hello " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 1 ] , is ( " value " ) ) ; } 
public void testForLoopOverArray ( ) throws Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) {var ret=new Document(); for (var key in doc.arr) {ret.add(doc.arr[key]); } return ret; } " ) ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" , arr:[0,1,2,3]} " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 1 ) ) ; assertThat ( result [ 0 ] . get ( " _id " ) , is ( " hello " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 0 ] , is ( " 0 " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 1 ] , is ( " 1 " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 2 ] , is ( " 2 " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 3 ] , is ( " 3 " ) ) ; } 
public void testForEverything ( ) throws Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) {var ret=new Document(); " + " function idx(obj) {for (var key in obj) " + " {switch (typeof obj[key]) {case 'object':idx(obj[key]); break; " + " case 'function': break; default: ret.add(obj[key]); break;} } }; idx(doc); return ret; } " ) ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" , l1: { l2: {l3:[ \" v3 \" , \" v4 \" ]}}} " ) , settings ( ) , null ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 0 ] , is ( " hello " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 1 ] , is ( " v3 " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 2 ] , is ( " v4 " ) ) ; } 
public void testNullReturn ( ) throws Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) {return null;} " ) ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" } " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 0 ) ) ; } 
public void testUndefinedReturn ( ) throws Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) {return doc.nope;} " ) ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" } " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 0 ) ) ; } 
public void testRuntimeException ( ) throws Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) {throw {bad : \" stuff \" }} " ) ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" } " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 0 ) ) ; } 
public void testNullAddsAreIgnored ( ) throws Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) {var ret=new Document(); ret.add(doc.nope); return ret;} " ) ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" } " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 1 ) ) ; } 
public void testQuoteRemoval ( ) throws Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " \" function(doc) {return new Document();} \" " ) ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" } " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 1 ) ) ; assertThat ( result [ 0 ] . get ( " _id " ) , is ( " hello " ) ) ; } 
private View view ( final String fun ) { final JSONObject json = new JSONObject ( ) ; json . put ( " index " , fun ) ; return new View ( json ) ; } 
protected Query getRangeQuery ( final String field , final String lower , final String upper , final boolean inclusive ) throws ParseException { return new TypedField ( field ) . toRangeQuery ( lower , upper , inclusive ) ; } 
public Query toRangeQuery ( final String lower , final String upper , final boolean inclusive ) throws ParseException { return type . toRangeQuery ( name , lower , upper , inclusive ) ; } 
public NumericField toField ( final String name , final String value , final ViewSettings settings ) throws ParseException { return field ( name , precisionStep , settings ) . setLongValue ( toDate ( value ) ) ; } 
public Query toRangeQuery ( final String name , final String lower , final String upper , final boolean inclusive ) throws ParseException { return NumericRangeQuery . newLongRange ( name , precisionStep , toDate ( lower ) , toDate ( upper ) , inclusive , inclusive ) ; } 
private long toDate ( final String str ) throws ParseException { try { return DateUtils . parseDate ( str . toUpperCase ( ) , patterns ) . getTime ( ) ; 
public NumericField toField ( final String name , final String value , final ViewSettings settings ) { return field ( name , precisionStep , settings ) . setDoubleValue ( toDouble ( value ) ) ; } 
public Query toRangeQuery ( final String name , final String lower , final String upper , final boolean inclusive ) { return NumericRangeQuery . newDoubleRange ( name , precisionStep , toDouble ( lower ) , toDouble ( upper ) , inclusive , inclusive ) ; } 
private double toDouble ( final String str ) { return Double . parseDouble ( str ) ; } 
public NumericField toField ( final String name , final String value , final ViewSettings settings ) { return field ( name , 4 , settings ) . setFloatValue ( toFloat ( value ) ) ; } 
public Query toRangeQuery ( final String name , final String lower , final String upper , final boolean inclusive ) { return NumericRangeQuery . newFloatRange ( name , precisionStep , toFloat ( lower ) , toFloat ( upper ) , inclusive , inclusive ) ; } 
private float toFloat ( final String str ) { return Float . parseFloat ( str ) ; } 
public NumericField toField ( final String name , final String value , final ViewSettings settings ) { return field ( name , 4 , settings ) . setIntValue ( toInt ( value ) ) ; } 
public Query toRangeQuery ( final String name , final String lower , final String upper , final boolean inclusive ) { return NumericRangeQuery . newIntRange ( name , precisionStep , toInt ( lower ) , toInt ( upper ) , inclusive , inclusive ) ; } 
private int toInt ( final String str ) { return Integer . parseInt ( str ) ; } 
public NumericField toField ( final String name , final String value , final ViewSettings settings ) { return field ( name , precisionStep , settings ) . setLongValue ( toLong ( value ) ) ; } 
public Query toRangeQuery ( final String name , final String lower , final String upper , final boolean inclusive ) { return NumericRangeQuery . newLongRange ( name , precisionStep , toLong ( lower ) , toLong ( upper ) , inclusive , inclusive ) ; } 
private long toLong ( final String str ) { return Long . parseLong ( str ) ; } 
public Field toField ( final String name , final String value , final ViewSettings settings ) { return new Field ( name , value , settings . getStore ( ) , settings . getIndex ( ) ) ; } 
public Query toRangeQuery ( final String name , final String lower , final String upper , final boolean inclusive ) { final TermRangeQuery result = new TermRangeQuery ( name , lower , upper , inclusive , inclusive ) ; result . setRewriteMethod ( MultiTermQuery . CONSTANT_SCORE_AUTO_REWRITE_DEFAULT ) ; return result ; } 
public abstract AbstractField toField ( final String name , final String value , final ViewSettings settings ) throws ParseException ; public abstract Query toRangeQuery ( final String name , final String lower , final String upper , final boolean inclusive ) throws ParseException ; public final int toSortField ( ) { return sortField ; } } 
public abstract Query toRangeQuery ( final String name , final String lower , final String upper , final boolean inclusive ) throws ParseException ; public final int toSortField ( ) { return sortField ; } } 
public Document toDocument ( final String id , final ViewSettings defaults , final Database database ) throws IOException , ParseException { final Document result = new Document ( ) ; Add id. result.add(Utils.token("_id", id, true)); Add user-supplied fields. for (final RhinoField field : fields) { addField(field, defaults, result); } Parse user-requested attachments. for (final RhinoAttachment attachment : attachments) { addAttachment(attachment, id, database, result); } return result; } 
private void addField ( final RhinoField field , final ViewSettings defaults , final Document out ) throws ParseException { final ViewSettings settings = new ViewSettings ( field . settings , defaults ) ; final FieldType type = settings . getFieldType ( ) ; out . add ( type . toField ( settings . getField ( ) , field . value . toString ( ) , settings ) ) ; } 
protected void doPost ( final HttpServletRequest req , final HttpServletResponse resp ) throws ServletException , IOException { final IndexPath path = IndexPath . parse ( configuration , req ) ; String command = req . getPathInfo ( ) ; command = command . substring ( command . lastIndexOf ( " / " ) + 1 ) ; if ( path = = null ) { final String [ ] parts = IndexPath . parts ( req ) ; if ( parts . length = = 3 ) { if ( " _cleanup " . equals ( command ) ) { cleanup ( parts [ 0 ] ) ; resp . setStatus ( 202 ) ; Utils . writeJSON ( resp , JSON_SUCCESS ) ; } } else { ServletUtils . sendJSONError ( req , resp , 400 , " Bad path " ) ; } return ; } lucene . startIndexing ( path , true ) ; if ( " _expunge " . equals ( command ) ) { LOG . info ( " Expunging deletes from " + path ) ; lucene . withWriter ( path , new WriterCallback ( ) { public boolean callback ( final IndexWriter writer ) throws IOException { writer . expungeDeletes ( false ) ; return false ; } public void onMissing ( ) throws IOException { resp . sendError ( 404 ) ; } } ) ; Utils . setResponseContentTypeAndEncoding ( req , resp ) ; resp . setStatus ( 202 ) ; Utils . writeJSON ( resp , JSON_SUCCESS ) ; return ; } if ( " _optimize " . equals ( command ) ) { LOG . info ( " Optimizing " + path ) ; lucene . withWriter ( path , new WriterCallback ( ) { public boolean callback ( final IndexWriter writer ) throws IOException { writer . optimize ( false ) ; return false ; } public void onMissing ( ) throws IOException { resp . sendError ( 404 ) ; } } ) ; Utils . setResponseContentTypeAndEncoding ( req , resp ) ; resp . setStatus ( 202 ) ; Utils . writeJSON ( resp , JSON_SUCCESS ) ; return ; } resp . sendError ( 400 , " Bad request " ) ; } 
private void index ( ) throws IOException { UUID uuid = database . getUuid ( ) ; if ( uuid = = null ) { database . createUuid ( ) ; uuid = database . getUuid ( ) ; } final DesignDocument ddoc = database . getDesignDocument ( path . getDesignDocumentName ( ) ) ; final View view = ddoc . getView ( path . getViewName ( ) ) ; if ( view = = null ) { return ; } final JSONObject info = database . getInfo ( ) ; final long seqThreshhold = staleOk ? 0 : info . getLong ( " update_seq " ) ; this . handler = new ViewChangesHandler ( uuid , view , seqThreshhold ) ; handler . start ( ) ; } 
public List < DesignDocument > getAllDesignDocuments ( ) throws IOException { final String body = HttpUtils . get ( httpClient , String . format ( " %s_all_docs?startkey=%s&endkey=%s&include_docs=true " , url , Utils . urlEncode ( " \" _design \" " ) , Utils . urlEncode ( " \" _design0 \" " ) ) ) ; final JSONObject json = JSONObject . fromObject ( body ) ; return toDesignDocuments ( json ) ; } 
public UUID getUuid ( ) throws IOException { try { final CouchDocument local = getDocument ( " _local/lucene " ) ; 
public abstract AbstractField toField ( final String name , final String value , final ViewSettings settings ) throws ParseException ; public abstract Query toRangeQuery ( final String name , final String lower , final String upper , final boolean inclusive ) throws ParseException ; public final int toSortField ( ) { return sortField ; } public static long toDate ( final String str ) throws ParseException { try { return DateUtils . parseDate ( str . toUpperCase ( ) , DATE_PATTERNS ) . getTime ( ) ; } catch ( final java . text . ParseException e ) { throw new ParseException ( e . getMessage ( ) ) ; } } } 
public abstract Query toRangeQuery ( final String name , final String lower , final String upper , final boolean inclusive ) throws ParseException ; public final int toSortField ( ) { return sortField ; } public static long toDate ( final String str ) throws ParseException { try { return DateUtils . parseDate ( str . toUpperCase ( ) , DATE_PATTERNS ) . getTime ( ) ; } catch ( final java . text . ParseException e ) { throw new ParseException ( e . getMessage ( ) ) ; } } } 
public static long toDate ( final String str ) throws ParseException { try { return DateUtils . parseDate ( str . toUpperCase ( ) , DATE_PATTERNS ) . getTime ( ) ; 
public void dateRangeQuery ( ) throws Exception { final Query q = parser . parse ( " blah<date>:[2000-01-01 TO 2010-02-04] " ) ; assertRange ( q , Long . class , time ( " 2000-01-01 " ) , time ( " 2010-02-04 " ) ) ; } 
public void dateTimeRangeQuery ( ) throws Exception { final Query q = parser . parse ( " blah<date>:[2000-01-01T00:00:01 TO 2010-02-04T00:00:01] " ) ; assertRange ( q , Long . class , time ( " 2000-01-01T00:00:01 " ) , time ( " 2010-02-04T00:00:01 " ) ) ; } 
public void dateTimeZoneRangeQuery ( ) throws Exception { final Query q = parser . parse ( " blah<date>:[2000-01-01-0100 TO 2010-02-04-0100] " ) ; assertRange ( q , Long . class , time ( " 2000-01-01-0100 " ) , time ( " 2010-02-04-0100 " ) ) ; } 
public void dateTimeTimeZoneRangeQuery ( ) throws Exception { final Query q = parser . parse ( " blah<date>:[2000-01-01T00:00:00-0100 TO 2010-02-04T00:00:00-0100] " ) ; assertRange ( q , Long . class , time ( " 2000-01-01T00:00:00-0100 " ) , time ( " 2010-02-04T00:00:00-0100 " ) ) ; } 
private long time ( final String str ) throws ParseException { return FieldType . toDate ( str ) ; } 
public static Object convert ( final Context context , final ScriptableObject scope , final Object obj ) { if ( obj instanceof JSONArray ) { return convertArray ( context , scope , ( JSONArray ) obj ) ; 
public static Scriptable convertArray ( final Context context , final ScriptableObject scope , final JSONArray array ) { final Scriptable result = context . newArray ( scope , array . size ( ) ) ; for ( int i = 0 , max = array . size ( ) ; i < max ; i + + ) { ScriptableObject . putProperty ( result , i , convert ( context , scope , array . get ( i ) ) ) ; } return result ; } 
public static Scriptable convertObject ( final Context context , final ScriptableObject scope , final JSONObject obj ) { final Scriptable result = context . newObject ( scope ) ; for ( final Object key : obj . keySet ( ) ) { final Object value = obj . get ( key ) ; ScriptableObject . putProperty ( result , ( String ) key , convert ( context , scope , value ) ) ; } return result ; } 
public void testSingleDocumentReturn ( ) throws Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) {return new Document();} " ) ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" } " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 1 ) ) ; assertThat ( result [ 0 ] . get ( " _id " ) , is ( " hello " ) ) ; } 
public void testMultipleDocumentReturn ( ) throws Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) {var ret = new Array(); ret.push(new Document()); ret.push(new Document()); return ret;} " ) ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" } " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 2 ) ) ; assertThat ( result [ 0 ] . get ( " _id " ) , is ( " hello " ) ) ; } 
public void testAdd ( ) throws Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) {var ret=new Document(); ret.add(doc.key); return ret;} " ) ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" , key: \" value \" } " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 1 ) ) ; assertThat ( result [ 0 ] . get ( Constants . DEFAULT_FIELD ) , is ( " value " ) ) ; } 
public void testForLoopOverObject ( ) throws Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) {var ret=new Document(); for (var key in doc) { ret.add(doc[key]); } return ret; } " ) ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" , key: \" value \" } " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 1 ) ) ; assertThat ( result [ 0 ] . get ( " _id " ) , is ( " hello " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 0 ] , is ( " hello " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 1 ] , is ( " value " ) ) ; } 
public void testForLoopOverArray ( ) throws Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) {var ret=new Document(); for (var key in doc.arr) {ret.add(doc.arr[key]); } return ret; } " ) ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" , arr:[0,1,2,3]} " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 1 ) ) ; assertThat ( result [ 0 ] . get ( " _id " ) , is ( " hello " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 0 ] , is ( " 0 " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 1 ] , is ( " 1 " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 2 ] , is ( " 2 " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 3 ] , is ( " 3 " ) ) ; } 
public void testForEverything ( ) throws Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) {var ret=new Document(); " + " function idx(obj) {for (var key in obj) " + " {switch (typeof obj[key]) {case 'object':idx(obj[key]); break; " + " case 'function': break; default: ret.add(obj[key]); break;} } }; idx(doc); return ret; } " ) ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" , l1: { l2: {l3:[ \" v3 \" , \" v4 \" ]}}} " ) , settings ( ) , null ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 0 ] , is ( " hello " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 1 ] , is ( " v3 " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 2 ] , is ( " v4 " ) ) ; } 
public void testNullReturn ( ) throws Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) {return null;} " ) ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" } " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 0 ) ) ; } 
public void testUndefinedReturn ( ) throws Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) {return doc.nope;} " ) ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" } " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 0 ) ) ; } 
public void testRuntimeException ( ) throws Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) {throw {bad : \" stuff \" }} " ) ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" } " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 0 ) ) ; } 
public void testNullAddsAreIgnored ( ) throws Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) {var ret=new Document(); ret.add(doc.nope); return ret;} " ) ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" } " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 1 ) ) ; } 
public void testQuoteRemoval ( ) throws Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " \" function(doc) {return new Document();} \" " ) ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" } " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 1 ) ) ; assertThat ( result [ 0 ] . get ( " _id " ) , is ( " hello " ) ) ; } 
public void testNoReturnValue ( ) throws Exception { final String fun = " function(doc) { } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hi \" } " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 0 ) ) ; } 
public void defaultValue ( ) throws Exception { final String fun = " function(doc) { var ret=new Document(); ret.add(doc['arr'].join(' ')); return ret; } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hi \" , arr:[ \" 1 \" , \" 2 \" ]} " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 1 ) ) ; assertThat ( result [ 0 ] . get ( " default " ) , is ( " 1 2 " ) ) ; } 
private Object convert ( final Object obj ) { if ( obj instanceof JSONArray ) { return convertArray ( ( JSONArray ) obj ) ; 
private Scriptable convertArray ( final JSONArray array ) { final Scriptable result = context . newArray ( scope , array . size ( ) ) ; for ( int i = 0 , max = array . size ( ) ; i < max ; i + + ) { ScriptableObject . putProperty ( result , i , convert ( array . get ( i ) ) ) ; } return result ; } 
private Scriptable convertObject ( final JSONObject obj ) { final Scriptable result = context . newObject ( scope ) ; for ( final Object key : obj . keySet ( ) ) { final Object value = obj . get ( key ) ; ScriptableObject . putProperty ( result , ( String ) key , convert ( value ) ) ; } return result ; } 
public Analyzer newAnalyzer ( final String args ) { return new BrazilianAnalyzer ( Constants . VERSION ) ; } 
public Analyzer newAnalyzer ( final String args ) { return new CJKAnalyzer ( Constants . VERSION ) ; } 
public Analyzer newAnalyzer ( final String args ) { return new CzechAnalyzer ( Constants . VERSION ) ; } 
public Analyzer newAnalyzer ( final String args ) { return new DutchAnalyzer ( Constants . VERSION ) ; } 
public Analyzer newAnalyzer ( final String args ) { return new StandardAnalyzer ( Constants . VERSION ) ; } 
public Analyzer newAnalyzer ( final String args ) { return new FrenchAnalyzer ( Constants . VERSION ) ; } 
public Analyzer newAnalyzer ( final String args ) { return new GermanAnalyzer ( Constants . VERSION ) ; } 
public Analyzer newAnalyzer ( final String args ) { return new RussianAnalyzer ( Constants . VERSION ) ; } 
public Analyzer newAnalyzer ( final String args ) { return new ThaiAnalyzer ( Constants . VERSION ) ; } 
public void setup ( ) { parser = new CustomQueryParser ( Constants . VERSION , " default " , new StandardAnalyzer ( Constants . VERSION ) ) ; } 
protected void doPost ( HttpServletRequest req , HttpServletResponse resp ) tthrows ServletException , IOException { tfinal String [ ] pathParts = IndexPath . parts ( req ) ; tfinal IndexPath path = IndexPath . parse ( ini , req ) ; if ( path ! = null ) { tlucene . startIndexing ( path , true ) ; } tUtils . setResponseContentTypeAndEncoding ( req , resp ) ; tswitch ( pathParts . length ) { tcase 3 : if ( " _cleanup " . equals ( pathParts [ 2 ] ) ) { thandleCleanupReq ( pathParts [ 0 ] , req , resp ) ; treturn ; } tbreak ; tcase 5 : thandleAdminReq ( pathParts [ 4 ] , path , req , resp ) ; treturn ; } tServletUtils . sendJSONError ( req , resp , 400 , " bad_request " ) ; } 
private void handleWelcomeReq ( final HttpServletRequest req , tfinal HttpServletResponse resp ) throws ServletException , tIOException { tfinal JSONObject welcome = new JSONObject ( ) ; twelcome . put ( " couchdb-lucene " , " Welcome " ) ; twelcome . put ( " version " , " 0.5.0 " ) ; tUtils . writeJSON ( resp , welcome ) ; } 
public void onMissing ( ) throws IOException { tServletUtils . sendJSONError ( req , resp , 404 , " Index for " + path + " is missing. " ) ; 
public void onMissing ( ) throws IOException { tresp . sendError ( 404 ) ; } 
private void handleAdminReq ( final String command , final IndexPath path , tfinal HttpServletRequest req , final HttpServletResponse resp ) tthrows ServletException , IOException { if ( " _expunge " . equals ( command ) ) { tLOG . info ( " Expunging deletes from " + path ) ; tlucene . withWriter ( path , new WriterCallback ( ) { public boolean callback ( final IndexWriter writer ) tthrows IOException { twriter . expungeDeletes ( false ) ; treturn false ; } public void onMissing ( ) throws IOException { tresp . sendError ( 404 ) ; } } ) ; tUtils . setResponseContentTypeAndEncoding ( req , resp ) ; tresp . setStatus ( 202 ) ; tUtils . writeJSON ( resp , JSON_SUCCESS ) ; treturn ; } if ( " _optimize " . equals ( command ) ) { tLOG . info ( " Optimizing " + path ) ; 
public boolean callback ( final IndexWriter writer ) tthrows IOException { twriter . expungeDeletes ( false ) ; treturn false ; } 
public void onMissing ( ) throws IOException { tresp . sendError ( 404 ) ; } 
public boolean callback ( final IndexWriter writer ) tthrows IOException { twriter . optimize ( false ) ; treturn false ; } 
public static void main ( String [ ] args ) throws Exception { tfinal HierarchicalINIConfiguration configuration = new HierarchicalINIConfiguration ( tMain . class . getClassLoader ( ) . getResource ( " couchdb-lucene.ini " ) ) ; tconfiguration . setReloadingStrategy ( new FileChangedReloadingStrategy ( ) ) ; tfinal File dir = new File ( configuration . getString ( " lucene.dir " , " indexes " ) ) ; if ( dir = = null ) { tLOG . error ( " lucene.dir not set. " ) ; tSystem . exit ( 1 ) ; } if ( ! dir . exists ( ) & & ! dir . mkdir ( ) ) { tLOG . error ( " Could not create " + dir . getCanonicalPath ( ) ) ; tSystem . exit ( 1 ) ; } if ( ! dir . canRead ( ) ) { tLOG . error ( dir + " is not readable. " ) ; tSystem . exit ( 1 ) ; } if ( ! dir . canWrite ( ) ) { tLOG . error ( dir + " is not writable. " ) ; tSystem . exit ( 1 ) ; } tLOG . info ( " Index output goes to: " + dir . getCanonicalPath ( ) ) ; tfinal Lucene lucene = new Lucene ( dir ) ; tfinal Server server = new Server ( ) ; tfinal SelectChannelConnector connector = new SelectChannelConnector ( ) ; tconnector . setHost ( configuration . getString ( " lucene.host " , " localhost " ) ) ; tconnector . setPort ( configuration . getInt ( " lucene.port " , 5985 ) ) ; tLOG . info ( " Accepting connections with " + connector ) ; tserver . setConnectors ( new Connector [ ] { connector } ) ; tserver . setStopAtShutdown ( true ) ; tserver . setSendServerVersion ( false ) ; tfinal LuceneServlet servlet = new LuceneServlet ( ) ; tservlet . setLucene ( lucene ) ; tservlet . setConfiguration ( configuration ) ; tfinal Context context = new Context ( server , " / " , Context . NO_SESSIONS | Context . NO_SECURITY ) ; tcontext . addServlet ( new ServletHolder ( servlet ) , " /* " ) ; tcontext . addFilter ( new FilterHolder ( new GzipFilter ( ) ) , " /* " , tHandler . DEFAULT ) ; tcontext . setErrorHandler ( new JSONErrorHandler ( ) ) ; tserver . setHandler ( context ) ; tserver . start ( ) ; tserver . join ( ) ; } 
public static String [ ] parts ( final HttpServletRequest req ) { return req . getRequestURI ( ) . replaceFirst ( " / " , " " ) . split ( " / " ) ; } 
protected void doPost ( HttpServletRequest req , HttpServletResponse resp ) tthrows ServletException , IOException { tfinal String [ ] pathParts = IndexPath . parts ( req ) ; tfinal IndexPath path = IndexPath . parse ( ini , req ) ; if ( path ! = null ) { tlucene . startIndexing ( path , true ) ; } tServletUtils . setResponseContentTypeAndEncoding ( req , resp ) ; tswitch ( pathParts . length ) { tcase 3 : if ( " _cleanup " . equals ( pathParts [ 2 ] ) ) { thandleCleanupReq ( pathParts [ 0 ] , req , resp ) ; treturn ; } tbreak ; tcase 5 : thandleAdminReq ( pathParts [ 4 ] , path , req , resp ) ; treturn ; } tServletUtils . sendJSONError ( req , resp , 400 , " bad_request " ) ; } 
private void handleWelcomeReq ( final HttpServletRequest req , tfinal HttpServletResponse resp ) throws ServletException , tIOException { tfinal JSONObject welcome = new JSONObject ( ) ; twelcome . put ( " couchdb-lucene " , " Welcome " ) ; twelcome . put ( " version " , " 0.5.0 " ) ; tServletUtils . writeJSON ( resp , welcome ) ; } 
private void handleAdminReq ( final String command , final IndexPath path , tfinal HttpServletRequest req , final HttpServletResponse resp ) tthrows ServletException , IOException { if ( " _expunge " . equals ( command ) ) { tLOG . info ( " Expunging deletes from " + path ) ; tlucene . withWriter ( path , new WriterCallback ( ) { public boolean callback ( final IndexWriter writer ) tthrows IOException { twriter . expungeDeletes ( false ) ; treturn false ; } public void onMissing ( ) throws IOException { tresp . sendError ( 404 ) ; } } ) ; tServletUtils . setResponseContentTypeAndEncoding ( req , resp ) ; tresp . setStatus ( 202 ) ; tServletUtils . writeJSON ( resp , JSON_SUCCESS ) ; treturn ; } if ( " _optimize " . equals ( command ) ) { tLOG . info ( " Optimizing " + path ) ; 
public static void sendJSONError ( final HttpServletRequest request , final HttpServletResponse response , final int code , final String reason ) throws IOException { final JSONObject obj = new JSONObject ( ) ; obj . put ( " code " , code ) ; obj . put ( " reason " , reason ) ; setResponseContentTypeAndEncoding ( request , response ) ; response . setHeader ( HttpHeaders . CACHE_CONTROL , " must-revalidate,no-cache,no-store " ) ; response . setStatus ( code ) ; final Writer writer = response . getWriter ( ) ; try { writer . write ( obj . toString ( ) ) ; 
public static void writeJSON ( final HttpServletResponse resp , final JSONObject json ) throws IOException { final Writer writer = resp . getWriter ( ) ; try { writer . write ( json . toString ( ) + " r " ) ; 
public void withReader ( final IndexPath path , final boolean staleOk , final ReaderCallback callback ) throws IOException { final Tuple tuple = getTuple ( path ) ; if ( tuple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( tuple ) { if ( tuple . reader = = null ) { tuple . reader = tuple . writer . getReader ( ) ; tuple . version = newVersion ( ) ; tuple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); 
public void callback ( final IndexReader reader ) throws IOException { callback . callback ( new IndexSearcher ( reader ) , getTuple ( path ) . version ) ; } 
public void withWriter ( final IndexPath path , final WriterCallback callback ) throws IOException { final Tuple tuple = getTuple ( path ) ; if ( tuple = = null ) { callback . onMissing ( ) ; return ; } try { final boolean dirty = callback . callback ( tuple . writer ) ; 
public void createWriter ( final IndexPath path , final UUID uuid , final View view ) throws IOException { final File dir = new File ( getUuidDir ( uuid ) , view . getDigest ( ) ) ; dir . mkdirs ( ) ; Tuple tuple = removeTuple ( path ) ; if ( tuple ! = null ) { tuple . close ( ) ; } final Directory d = FSDirectory . open ( dir ) ; tuple = new Tuple ( ) ; tuple . writer = newWriter ( d ) ; putTuple ( path , tuple ) ; } 
private Tuple removeTuple ( final IndexPath path ) { tsynchronized ( map ) { treturn map . remove ( path ) ; 
private Tuple putTuple ( final IndexPath path , final Tuple tuple ) { tsynchronized ( map ) { treturn map . put ( path , tuple ) ; 
public void callback ( final IndexReader reader ) throws IOException { tfinal Tuple tuple = getTuple ( path ) ; callback . callback ( new IndexSearcher ( reader ) , tuple . parser , tuple . version ) ; } 
public void createWriter ( final IndexPath path , final UUID uuid , tfinal View view ) throws IOException { tfinal File dir = new File ( getUuidDir ( uuid ) , view . getDigest ( ) ) ; tdir . mkdirs ( ) ; tTuple tuple = removeTuple ( path ) ; if ( tuple ! = null ) { ttuple . close ( ) ; } tfinal Directory d = FSDirectory . open ( dir ) ; ttuple = new Tuple ( ) ; ttuple . writer = newWriter ( d ) ; ttuple . parser = new CustomQueryParser ( Constants . VERSION , tConstants . DEFAULT_FIELD , view . getAnalyzer ( ) ) ; tputTuple ( path , tuple ) ; } 
public ViewIndexer startIndexing ( final IndexPath path , final boolean staleOk ) throws IOException { tfinal ViewKey viewKey = getViewKey ( path ) ; final ViewIndexer result = executor . submit ( viewKey , new ViewIndexer ( this , path , staleOk ) ) ; result . awaitInitialIndexing ( ) ; return result ; } 
private Tuple getTuple ( final IndexPath path ) throws IOException { tfinal ViewKey viewKey = getViewKey ( path ) ; tsynchronized ( tuples ) { treturn tuples . get ( viewKey ) ; 
private Tuple removeTuple ( final IndexPath path ) throws IOException { tfinal ViewKey viewKey = getViewKey ( path ) ; tsynchronized ( tuples ) { treturn tuples . remove ( viewKey ) ; 
private Tuple putTuple ( final IndexPath path , final Tuple tuple ) throws IOException { tfinal ViewKey viewKey = getViewKey ( path ) ; tsynchronized ( tuples ) { treturn tuples . put ( viewKey , tuple ) ; 
private ViewKey getViewKey ( final IndexPath path ) throws IOException { tViewKey result ; tsynchronized ( keys ) { tresult = keys . get ( path ) ; } if ( result ! = null ) { treturn result ; } final Couch couch = Couch . getInstance ( client , path . getUrl ( ) ) ; final Database database = couch . getDatabase ( path . getDatabase ( ) ) ; tfinal DesignDocument ddoc = database . getDesignDocument ( path . getDesignDocumentName ( ) ) ; final View view = ddoc . getView ( path . getViewName ( ) ) ; result = new ViewKey ( newOrCurrentUuid ( database ) , view ) ; synchronized ( keys ) { tkeys . put ( path , result ) ; } return result ; } 
private UUID newOrCurrentUuid ( final Database database ) throws IOException { UUID result = database . getUuid ( ) ; if ( result = = null ) { database . createUuid ( ) ; result = database . getUuid ( ) ; } return result ; } 
public int hashCode ( ) { tfinal int prime = 31 ; tint result = 1 ; tresult = prime * result + ( uuid . hashCode ( ) ) ; tresult = prime * result + ( view . hashCode ( ) ) ; treturn result ; } 
public boolean equals ( Object obj ) { if ( this = = obj ) treturn true ; if ( obj = = null ) treturn false ; if ( getClass ( ) ! = obj . getClass ( ) ) treturn false ; tViewKey other = ( ViewKey ) obj ; if ( ! uuid . equals ( other . uuid ) ) treturn false ; if ( ! view . equals ( other . view ) ) treturn false ; treturn true ; } 
public String toString ( ) { treturn String . format ( " ViewKey[uuid=%s,digest=%s] " , uuid , view . getDigest ( ) ) ; } 
public DatabaseInfo getInfo ( ) throws IOException { return new DatabaseInfo ( JSONObject . fromObject ( HttpUtils . get ( httpClient , url ) ) ) ; } 
public static void main ( String [ ] args ) throws Exception { tfinal HttpClient client = HttpClientFactory . getInstance ( ) ; tfinal Couch couch = Couch . getInstance ( client , " http:localhost:5984 " ) ; tfinal Database db = couch . getDatabase ( " db1 " ) ; tfinal DatabaseIndexer indexer = new DatabaseIndexer ( client , new File ( " target/tmp " ) , db ) ; tindexer . index ( ) ; } 
public void index ( ) throws IOException { tthis . logger = Logger . getLogger ( DatabaseIndexer . class . getName ( ) + " . " + database . getInfo ( ) . getName ( ) ) ; tthis . uuid = database . getOrCreateUuid ( ) ; trefresh ( ) ; tfinal HttpUriRequest req = database . getChangesRequest ( since ) ; tlogger . info ( " Indexing from update_seq " + since ) ; tclient . execute ( req , this ) ; } 
private void maybeCommit ( ) { } private void refresh ( ) throws IOException { tsince = 0 ; tfinal Set < View > currentViews = getCurrentViews ( ) ; }} 
private void refresh ( ) throws IOException { tsince = 0 ; tfinal Set < View > currentViews = getCurrentViews ( ) ; final Directory dir = viewDir(view); 
private Directory viewDir ( final View view ) throws IOException { tfinal File uuidDir = new File ( root , uuid . toString ( ) ) ; tfinal File viewDir = new File ( uuidDir , view . getDigest ( ) ) ; tviewDir . mkdirs ( ) ; treturn FSDirectory . open ( viewDir ) ; } 
private long getUpdateSequence ( final Directory dir ) throws IOException { if ( ! IndexReader . indexExists ( dir ) ) { treturn 0 L ; } tfinal Map < String , String > userData = IndexReader . getCommitUserData ( dir ) ; if ( userData ! = null & & userData . containsKey ( " last_seq " ) ) { treturn Long . parseLong ( userData . get ( " last_seq " ) ) ; } treturn 0 L ; } 
private IndexWriter newWriter ( final Directory dir ) throws IOException { tfinal IndexWriter result = new IndexWriter ( dir , Constants . ANALYZER , tMaxFieldLength . UNLIMITED ) ; tresult . setMergeFactor ( 5 ) ; tresult . setUseCompoundFile ( false ) ; treturn result ; } 
private void index ( ) throws IOException { UUID uuid = database . getUuid ( ) ; if ( uuid = = null ) { database . createUuid ( ) ; uuid = database . getUuid ( ) ; } final DesignDocument ddoc = database . getDesignDocument ( path . getDesignDocumentName ( ) ) ; final View view = ddoc . getView ( path . getViewName ( ) ) ; if ( view = = null ) { return ; } final DatabaseInfo info = database . getInfo ( ) ; final long seqThreshhold = staleOk ? 0 : info . getUpdateSequence ( ) ; this . handler = new ViewChangesHandler ( uuid , view , seqThreshhold ) ; handler . start ( ) ; } 
public UUID getOrCreateUuid ( ) throws IOException { tfinal UUID result = getUuid ( ) ; if ( result ! = null ) { treturn result ; } tcreateUuid ( ) ; treturn getUuid ( ) ; } 
public Function compileFunction ( final Context context , tScriptableObject scope ) { treturn context . compileFunction ( scope , getFunction ( ) , null , 0 , null ) ; } 
private String trim ( final String fun ) { tString result = fun ; tresult = StringUtils . trim ( result ) ; tresult = StringUtils . removeStart ( result , " \" " ) ; tresult = StringUtils . removeEnd ( result , " \" " ) ; treturn result ; } 
public boolean equals ( Object obj ) { if ( this = = obj ) { treturn true ; } if ( obj = = null ) { treturn false ; } if ( ! ( obj instanceof View ) ) { treturn false ; } tView other = ( View ) obj ; treturn getDigest ( ) . equals ( other . getDigest ( ) ) ; } 
public String toString ( ) { treturn String . format ( " View[digest=%s] " , getDigest ( ) ) ; } 
public boolean visibleToScripts ( final String fullClassName ) { treturn false ; } 
private void close ( ) throws IOException { if ( reader ! = null ) treader . close ( ) ; if ( writer ! = null ) twriter . rollback ( ) ; 
public void index ( ) throws IOException { tinit ( ) ; ttry { tfinal HttpUriRequest req = database . getChangesRequest ( since ) ; 
private void close ( ) throws IOException { tfor ( IndexState state : states . values ( ) ) { tstate . close ( ) ; } tstates . clear ( ) ; tContext . exit ( ) ; } 
private void maybeCommit ( ) throws IOException { if ( now ( ) - lastCommit > = COMMIT_INTERVAL ) { tcommitAll ( ) ; 
private long getUpdateSequence ( final Directory dir ) throws IOException { if ( ! IndexReader . indexExists ( dir ) ) { treturn 0 L ; } treturn getUpdateSequence ( IndexReader . getCommitUserData ( dir ) ) ; } 
private long getUpdateSequence ( final IndexWriter writer ) throws IOException { treturn getUpdateSequence ( writer . getDirectory ( ) ) ; } 
public static void main ( String [ ] args ) throws Exception { tfinal HttpClient client = HttpClientFactory . getInstance ( ) ; tfinal Couch couch = Couch . getInstance ( client , " http:localhost:5984 " ) ; tfinal Database db = couch . getDatabase ( " db1 " ) ; tfinal DatabaseIndexer indexer = new DatabaseIndexer ( client , new File ( " target/tmp " ) , db ) ; tnew Thread ( new Runnable ( ) { public void run ( ) { ttry { tindexer . index ( ) ; } catch ( IOException e ) { te . printStackTrace ( ) ; } } } ) . start ( ) ; tThread . sleep ( 5000 ) ; tfinal IndexSearcher searcher = indexer . borrowSearcher ( indexer . states . keySet ( ) . iterator ( ) . next ( ) , false ) ; tSystem . out . println ( searcher . search ( new MatchAllDocsQuery ( ) , 50 ) . totalHits ) ; tindexer . returnSearcher ( searcher ) ; } 
public IndexSearcher borrowSearcher ( final View view , final boolean staleOk ) tthrows IOException { tfinal IndexState state = states . get ( view ) ; if ( state . reader = = null ) { tstate . reader = state . writer . getReader ( ) ; tstate . readerEtag = newVersion ( ) ; tstate . reader . incRef ( ) ; } if ( ! staleOk ) { tfinal IndexReader newReader = state . reader . reopen ( ) ; if ( newReader ! = state . reader ) { tstate . reader . decRef ( ) ; tstate . reader = newReader ; tstate . readerEtag = newVersion ( ) ; } } tstate . reader . incRef ( ) ; treturn new IndexSearcher ( state . reader ) ; } 
public void returnSearcher ( final IndexSearcher searcher ) throws IOException { tsearcher . getIndexReader ( ) . decRef ( ) ; } 
public static void main ( String [ ] args ) throws Exception { tfinal HttpClient client = HttpClientFactory . getInstance ( ) ; tfinal Couch couch = Couch . getInstance ( client , " http:localhost:5984 " ) ; tfinal Database db = couch . getDatabase ( " db1 " ) ; tfinal DatabaseIndexer indexer = new DatabaseIndexer ( client , new File ( " target/tmp " ) , db ) ; tindexer . init ( ) ; } 
public synchronized boolean notModified ( final HttpServletRequest req ) { treturn etag . equals ( req . getHeader ( " If-None-Match " ) ) ; } 
private synchronized void close ( ) throws IOException { if ( reader ! = null ) treader . close ( ) ; if ( writer ! = null ) twriter . rollback ( ) ; 
public synchronized IndexSearcher borrowSearcher ( final boolean staleOk ) tthrows IOException { if ( reader = = null ) { treader = writer . getReader ( ) ; tetag = newEtag ( ) ; treader . incRef ( ) ; } if ( ! staleOk ) { tfinal IndexReader newReader = reader . reopen ( ) ; if ( newReader ! = reader ) { treader . decRef ( ) ; treader = newReader ; tetag = newEtag ( ) ; } } treader . incRef ( ) ; treturn new IndexSearcher ( reader ) ; } 
public void returnSearcher ( final IndexSearcher searcher ) tthrows IOException { tsearcher . getIndexReader ( ) . decRef ( ) ; } 
public void run ( ) { if ( ! initialized ) { tthrow new IllegalStateException ( " not initialized. " ) ; } if ( closed ) { tthrow new IllegalStateException ( " closed! " ) ; } ttry { ttry { 
public IndexState getState ( final String ddocName , final String viewName ) tthrows IOException { tfinal String path = ddocName + " / " + viewName ; tfinal View view = paths . get ( path ) ; if ( view = = null ) { treturn null ; } treturn states . get ( view ) ; } 
private void close ( ) throws IOException { tthis . closed = true ; tfor ( IndexState state : states . values ( ) ) { tstate . close ( ) ; } tstates . clear ( ) ; tContext . exit ( ) ; } 
public static IndexKey parse ( final HttpServletRequest req ) { tfinal String [ ] parts = req . getRequestURI ( ) . replaceFirst ( " / " , " " ) . split ( " / " ) ; if ( parts . length < 4 ) { treturn null ; } treturn new IndexKey ( parts [ 0 ] , parts [ 1 ] , parts [ 2 ] , parts [ 3 ] ) ; } 
public int hashCode ( ) { tfinal int prime = 31 ; tint result = 1 ; tresult = prime * result + ( ( database = = null ) ? 0 : database . hashCode ( ) ) ; tresult = prime * result + ( ( ddoc = = null ) ? 0 : ddoc . hashCode ( ) ) ; tresult = prime * result + ( ( key = = null ) ? 0 : key . hashCode ( ) ) ; tresult = prime * result + ( ( view = = null ) ? 0 : view . hashCode ( ) ) ; treturn result ; } 
public boolean equals ( Object obj ) { if ( this = = obj ) treturn true ; if ( obj = = null ) treturn false ; if ( getClass ( ) ! = obj . getClass ( ) ) treturn false ; tIndexKey other = ( IndexKey ) obj ; if ( database = = null ) { if ( other . database ! = null ) treturn false ; } else if ( ! database . equals ( other . database ) ) treturn false ; if ( ddoc = = null ) { if ( other . ddoc ! = null ) treturn false ; } else if ( ! ddoc . equals ( other . ddoc ) ) treturn false ; if ( key = = null ) { if ( other . key ! = null ) treturn false ; } else if ( ! key . equals ( other . key ) ) treturn false ; if ( view = = null ) { if ( other . view ! = null ) treturn false ; } else if ( ! view . equals ( other . view ) ) treturn false ; treturn true ; } 
public IndexState getState ( final HttpServletRequest req ) tthrows IOException { tfinal String [ ] parts = req . getRequestURI ( ) . replaceFirst ( " / " , " " ) . split ( " / " ) ; if ( parts . length ! = 4 ) { treturn null ; } tfinal Configuration section = ini . getSection ( parts [ 0 ] ) ; tfinal String url = section . containsKey ( " url " ) ? section . getString ( " url " ) : null ; tfinal Couch couch = Couch . getInstance ( client , url ) ; tfinal Database database = couch . getDatabase ( parts [ 1 ] ) ; tfinal DatabaseIndexer indexer = getIndexer ( database ) ; tensureRunning ( database , indexer ) ; treturn indexer . getState ( parts [ 2 ] , parts [ 3 ] ) ; } 
private synchronized DatabaseIndexer getIndexer ( final Database database ) tthrows IOException { tDatabaseIndexer result = indexers . get ( database ) ; if ( result = = null ) { tresult = new DatabaseIndexer ( client , root , database ) ; tresult . init ( ) ; } tindexers . put ( database , result ) ; treturn result ; } 
private synchronized void ensureRunning ( final Database database , tfinal DatabaseIndexer indexer ) { tThread thread = threads . get ( database ) ; if ( thread = = null | | ! thread . isAlive ( ) ) { tthread = new Thread ( indexer ) ; 
protected void doPost ( HttpServletRequest req , HttpServletResponse resp ) tthrows ServletException , IOException { tServletUtils . setResponseContentTypeAndEncoding ( req , resp ) ; tswitch ( pathParts . length ) { tcase 3 : if ( " _cleanup " . equals ( pathParts [ 2 ] ) ) { thandleCleanupReq ( pathParts [ 0 ] , req , resp ) ; treturn ; } tbreak ; tcase 5 : thandleAdminReq ( pathParts [ 4 ] , path , req , resp ) ; treturn ; } tServletUtils . sendJSONError ( req , resp , 400 , " bad_request " ) ; } 
private void handleSearchReq ( final HttpServletRequest req , tfinal HttpServletResponse resp ) throws ServletException , tIOException { tfinal boolean debug = getBooleanParameter ( req , " debug " ) ; tfinal boolean staleOk = Utils . getStaleOk ( req ) ; tfinal IndexState state = lucene2 . getState ( req ) ; tfinal IndexSearcher searcher = state . borrowSearcher ( staleOk ) ; ttry { Check for 304 - Not Modified. 
public boolean create ( ) throws IOException { treturn HttpUtils . put ( httpClient , url , null ) = = 201 ; } 
public boolean delete ( ) throws IOException { treturn HttpUtils . delete ( httpClient , url ) = = 200 ; } 
public List < DesignDocument > getAllDesignDocuments ( ) throws IOException { tfinal String body = HttpUtils . get ( httpClient , String . format ( " %s_all_docs?startkey=%s&endkey=%s&include_docs=true " , turl , Utils . urlEncode ( " \" _design \" " ) , Utils . urlEncode ( " \" _design0 \" " ) ) ) ; tfinal JSONObject json = JSONObject . fromObject ( body ) ; treturn toDesignDocuments ( json ) ; } 
public CouchDocument getDocument ( final String id ) throws IOException { tfinal String response = HttpUtils . get ( httpClient , url + Utils . urlEncode ( id ) ) ; treturn new CouchDocument ( JSONObject . fromObject ( response ) ) ; } 
public DesignDocument getDesignDocument ( final String id ) throws IOException { tfinal String response = HttpUtils . get ( httpClient , url + " _design/ " + Utils . urlEncode ( id ) ) ; treturn new DesignDocument ( JSONObject . fromObject ( response ) ) ; } 
public List < CouchDocument > getDocuments ( final String . . . ids ) tthrows IOException { if ( ids . length = = 0 ) { treturn Collections . emptyList ( ) ; } tfinal JSONArray keys = new JSONArray ( ) ; tfor ( final String id : ids ) { tkeys . add ( id ) ; } tfinal JSONObject req = new JSONObject ( ) ; treq . element ( " keys " , keys ) ; tfinal String body = HttpUtils . post ( httpClient , url + " _all_docs?include_docs=true " , req . toString ( ) ) ; tfinal JSONObject json = JSONObject . fromObject ( body ) ; treturn toDocuments ( json ) ; } 
public DatabaseInfo getInfo ( ) throws IOException { treturn new DatabaseInfo ( JSONObject . fromObject ( HttpUtils . get ( httpClient , turl ) ) ) ; 
public < T > T handleAttachment ( final String doc , final String att , tfinal ResponseHandler < T > handler ) throws IOException { tfinal HttpGet get = new HttpGet ( url + " / " + Utils . urlEncode ( doc ) + " / " + Utils . urlEncode ( att ) ) ; treturn httpClient . execute ( get , handler ) ; } 
public HttpUriRequest getChangesRequest ( final long since ) tthrows IOException { treturn new HttpGet ( turl 
public boolean saveDocument ( final String id , final String body ) tthrows IOException { treturn HttpUtils . put ( httpClient , url + Utils . urlEncode ( id ) , body ) = = 201 ; } 
public UUID getUuid ( ) throws IOException { ttry { tfinal CouchDocument local = getDocument ( " _local/lucene " ) ; 
public void createUuid ( ) throws IOException { tfinal UUID uuid = UUID . randomUUID ( ) ; tsaveDocument ( " _local/lucene " , String . format ( " { \" uuid \" : \" %s \" } " , uuid ) ) ; } 
public UUID getOrCreateUuid ( ) throws IOException { tfinal UUID result = getUuid ( ) ; if ( result ! = null ) { treturn result ; } tcreateUuid ( ) ; treturn getUuid ( ) ; } 
private List < DesignDocument > toDesignDocuments ( final JSONObject json ) { tfinal List < DesignDocument > result = new ArrayList < DesignDocument > ( ) ; tfor ( final JSONObject doc : rows ( json ) ) { tresult . add ( new DesignDocument ( doc ) ) ; } treturn result ; } 
private List < CouchDocument > toDocuments ( final JSONObject json ) { tfinal List < CouchDocument > result = new ArrayList < CouchDocument > ( ) ; tfor ( final JSONObject doc : rows ( json ) ) { tresult . add ( new CouchDocument ( doc ) ) ; } treturn result ; } 
private List < JSONObject > rows ( final JSONObject json ) { tfinal List < JSONObject > result = new ArrayList < JSONObject > ( ) ; tfinal JSONArray rows = json . getJSONArray ( " rows " ) ; tfor ( int i = 0 ; i < rows . size ( ) ; i + + ) { tresult . add ( rows . getJSONObject ( i ) . getJSONObject ( " doc " ) ) ; } treturn result ; } 
public int hashCode ( ) { tfinal int prime = 31 ; tint result = 1 ; tresult = prime * result + ( ( url = = null ) ? 0 : url . hashCode ( ) ) ; treturn result ; } 
public boolean equals ( Object obj ) { if ( this = = obj ) treturn true ; if ( obj = = null ) treturn false ; if ( getClass ( ) ! = obj . getClass ( ) ) treturn false ; tDatabase other = ( Database ) obj ; if ( url = = null ) { if ( other . url ! = null ) treturn false ; } else if ( ! url . equals ( other . url ) ) treturn false ; treturn true ; } 
private static byte [ ] toBytes ( final String str ) { if ( str = = null ) { treturn new byte [ 0 ] ; } ttry { treturn str . getBytes ( " UTF-8 " ) ; 
public static void main ( String [ ] args ) throws Exception { tfinal HierarchicalINIConfiguration configuration = new HierarchicalINIConfiguration ( tMain . class . getClassLoader ( ) . getResource ( " couchdb-lucene.ini " ) ) ; tconfiguration . setReloadingStrategy ( new FileChangedReloadingStrategy ( ) ) ; tfinal File dir = new File ( configuration . getString ( " lucene.dir " , " indexes " ) ) ; if ( dir = = null ) { tLOG . error ( " lucene.dir not set. " ) ; tSystem . exit ( 1 ) ; } if ( ! dir . exists ( ) & & ! dir . mkdir ( ) ) { tLOG . error ( " Could not create " + dir . getCanonicalPath ( ) ) ; tSystem . exit ( 1 ) ; } if ( ! dir . canRead ( ) ) { tLOG . error ( dir + " is not readable. " ) ; tSystem . exit ( 1 ) ; } if ( ! dir . canWrite ( ) ) { tLOG . error ( dir + " is not writable. " ) ; tSystem . exit ( 1 ) ; } tLOG . info ( " Index output goes to: " + dir . getCanonicalPath ( ) ) ; tfinal Server server = new Server ( ) ; tfinal SelectChannelConnector connector = new SelectChannelConnector ( ) ; tconnector . setHost ( configuration . getString ( " lucene.host " , " localhost " ) ) ; tconnector . setPort ( configuration . getInt ( " lucene.port " , 5985 ) ) ; tLOG . info ( " Accepting connections with " + connector ) ; tserver . setConnectors ( new Connector [ ] { connector } ) ; tserver . setStopAtShutdown ( true ) ; tserver . setSendServerVersion ( false ) ; tfinal LuceneServlet servlet = new LuceneServlet ( ) ; tservlet . setLucene ( new Lucene ( HttpClientFactory . getInstance ( ) , dir , configuration ) ) ; tservlet . setConfiguration ( configuration ) ; tfinal Context context = new Context ( server , " / " , Context . NO_SESSIONS | Context . NO_SECURITY ) ; tcontext . addServlet ( new ServletHolder ( servlet ) , " /* " ) ; tcontext . addFilter ( new FilterHolder ( new GzipFilter ( ) ) , " /* " , tHandler . DEFAULT ) ; tcontext . setErrorHandler ( new JSONErrorHandler ( ) ) ; tserver . setHandler ( context ) ; tserver . start ( ) ; tserver . join ( ) ; } 
private synchronized boolean notModified ( final HttpServletRequest req ) { treturn etag . equals ( req . getHeader ( " If-None-Match " ) ) ; } 
public IndexSearcher borrowSearcher ( final boolean staleOk ) tthrows IOException { treturn new IndexSearcher ( borrowReader ( staleOk ) ) ; } 
public void returnSearcher ( final IndexSearcher searcher ) tthrows IOException { treturnReader ( searcher . getIndexReader ( ) ) ; } 
public synchronized IndexReader borrowReader ( final boolean staleOk ) tthrows IOException { if ( reader = = null ) { treader = writer . getReader ( ) ; tetag = newEtag ( ) ; treader . incRef ( ) ; } if ( ! staleOk ) { tfinal IndexReader newReader = reader . reopen ( ) ; if ( newReader ! = reader ) { treader . decRef ( ) ; treader = newReader ; tetag = newEtag ( ) ; } } treader . incRef ( ) ; treturn reader ; } 
public void returnReader ( final IndexReader reader ) throws IOException { treader . decRef ( ) ; } 
public void info ( final HttpServletRequest req , tfinal HttpServletResponse resp ) throws IOException { tfinal IndexState state = getState ( req ) ; tfinal IndexReader reader = state . borrowReader ( isStaleOk ( req ) ) ; ttry { tfinal JSONObject result = new JSONObject ( ) ; 
private IndexState getState ( final HttpServletRequest req ) tthrows IOException { tfinal String path = pathParts ( req ) [ 2 ] + " / " + pathParts ( req ) [ 3 ] ; tfinal View view = paths . get ( path ) ; if ( view = = null ) { treturn null ; } treturn states . get ( view ) ; } 
private boolean getBooleanParameter ( final HttpServletRequest req , tfinal String parameterName ) { treturn Boolean . parseBoolean ( req . getParameter ( parameterName ) ) ; } 
private int getIntParameter ( final HttpServletRequest req , tfinal String parameterName , final int defaultValue ) { tfinal String result = req . getParameter ( parameterName ) ; treturn result ! = null ? Integer . parseInt ( result ) : defaultValue ; } 
private String [ ] pathParts ( final HttpServletRequest req ) { treturn req . getRequestURI ( ) . replaceFirst ( " / " , " " ) . split ( " / " ) ; } 
private boolean isStaleOk ( final HttpServletRequest req ) { treturn " ok " . equals ( req . getParameter ( " stale " ) ) ; } 
protected void doPost ( HttpServletRequest req , HttpServletResponse resp ) tthrows ServletException , IOException { tfinal String [ ] pathParts = pathParts ( req ) ; tswitch ( pathParts . length ) { tcase 3 : if ( " _cleanup " . equals ( pathParts [ 2 ] ) ) { } 
private void negotiateContentType ( final HttpServletRequest req , tfinal HttpServletResponse resp ) { tfinal String accept = req . getHeader ( " Accept " ) ; if ( getBooleanParameter ( req , " force_json " ) | | ( accept ! = null & & accept . contains ( " application/json " ) ) ) { tresp . setContentType ( " application/json " ) ; } else { tresp . setContentType ( " text/plain " ) ; } if ( ! resp . containsHeader ( " Vary " ) ) { tresp . addHeader ( " Vary " , " Accept " ) ; } tresp . setCharacterEncoding ( " utf-8 " ) ; } 
private void writeJSON ( final HttpServletResponse resp , final JSONObject json ) tthrows IOException { tfinal Writer writer = resp . getWriter ( ) ; ttry { twriter . write ( json . toString ( ) + " r " ) ; 
private DatabaseIndexer getIndexer ( final HttpServletRequest req ) tthrows IOException { tfinal Configuration section = ini . getSection ( pathParts ( req ) [ 0 ] ) ; tfinal String url = section . containsKey ( " url " ) ? section . getString ( " url " ) : null ; tfinal Couch couch = new Couch ( client , url ) ; tfinal Database database = couch . getDatabase ( pathParts ( req ) [ 1 ] ) ; tfinal DatabaseIndexer indexer = getIndexer ( database ) ; tensureRunning ( database , indexer ) ; treturn indexer ; } 
public static void main ( String [ ] args ) throws Exception { tfinal HierarchicalINIConfiguration configuration = new HierarchicalINIConfiguration ( tMain . class . getClassLoader ( ) . getResource ( " couchdb-lucene.ini " ) ) ; tconfiguration . setReloadingStrategy ( new FileChangedReloadingStrategy ( ) ) ; tfinal File dir = new File ( configuration . getString ( " lucene.dir " , " indexes " ) ) ; if ( dir = = null ) { tLOG . error ( " lucene.dir not set. " ) ; tSystem . exit ( 1 ) ; } if ( ! dir . exists ( ) & & ! dir . mkdir ( ) ) { tLOG . error ( " Could not create " + dir . getCanonicalPath ( ) ) ; tSystem . exit ( 1 ) ; } if ( ! dir . canRead ( ) ) { tLOG . error ( dir + " is not readable. " ) ; tSystem . exit ( 1 ) ; } if ( ! dir . canWrite ( ) ) { tLOG . error ( dir + " is not writable. " ) ; tSystem . exit ( 1 ) ; } tLOG . info ( " Index output goes to: " + dir . getCanonicalPath ( ) ) ; tfinal Server server = new Server ( ) ; tfinal SelectChannelConnector connector = new SelectChannelConnector ( ) ; tconnector . setHost ( configuration . getString ( " lucene.host " , " localhost " ) ) ; tconnector . setPort ( configuration . getInt ( " lucene.port " , 5985 ) ) ; tLOG . info ( " Accepting connections with " + connector ) ; tserver . setConnectors ( new Connector [ ] { connector } ) ; tserver . setStopAtShutdown ( true ) ; tserver . setSendServerVersion ( false ) ; tfinal LuceneServlet servlet = new LuceneServlet ( HttpClientFactory . getInstance ( ) , dir , configuration ) ; tfinal Context context = new Context ( server , " / " , Context . NO_SESSIONS | Context . NO_SECURITY ) ; tcontext . addServlet ( new ServletHolder ( servlet ) , " /* " ) ; tcontext . addFilter ( new FilterHolder ( new GzipFilter ( ) ) , " /* " , tHandler . DEFAULT ) ; tcontext . setErrorHandler ( new JSONErrorHandler ( ) ) ; tserver . setHandler ( context ) ; tserver . start ( ) ; tserver . join ( ) ; } 
public final String [ ] getAllDatabases ( ) throws IOException { tfinal String response = HttpUtils . get ( httpClient , url + " _all_dbs " ) ; tfinal JSONArray arr = JSONArray . fromObject ( response ) ; treturn ( String [ ] ) arr . toArray ( new String [ 0 ] ) ; } 
public final JSONObject getInfo ( ) throws IOException { treturn JSONObject . fromObject ( HttpUtils . get ( httpClient , url ) ) ; } 
public Database getDatabase ( final String dbname ) throws IOException { treturn new Database ( httpClient , url + dbname ) ; } 
private synchronized boolean notModified ( final HttpServletRequest req ) { treturn etag ! = null & & etag . equals ( req . getHeader ( " If-None-Match " ) ) ; } 
public void run ( ) { if ( closed ) { tthrow new IllegalStateException ( " closed! " ) ; } ttry { tinit ( ) ; } catch ( final IOException e ) { tlogger . warn ( " Exiting after init() raised I/O exception. " , e ) ; treturn ; } ttry { ttry { 
private DatabaseIndexer getIndexer ( final HttpServletRequest req ) tthrows IOException { tfinal Configuration section = ini . getSection ( pathParts ( req ) [ 0 ] ) ; tfinal String url = section . containsKey ( " url " ) ? section . getString ( " url " ) : null ; tfinal Couch couch = new Couch ( client , url ) ; tfinal Database database = couch . getDatabase ( pathParts ( req ) [ 1 ] ) ; treturn getIndexer ( database ) ; } 
private synchronized DatabaseIndexer getIndexer ( final Database database ) tthrows IOException { tDatabaseIndexer result = indexers . get ( database ) ; tThread thread = threads . get ( database ) ; if ( result = = null | | thread = = null | | ! thread . isAlive ( ) ) { tresult = new DatabaseIndexer ( client , root , database ) ; tindexers . put ( database , result ) ; tthread = new Thread ( result ) ; tthreads . put ( database , thread ) ; tthread . start ( ) ; } treturn result ; } 
public synchronized IndexReader borrowReader ( final boolean staleOk ) tthrows IOException { if ( reader = = null ) { treader = writer . getReader ( ) ; tetag = newEtag ( ) ; treader . incRef ( ) ; } if ( ! staleOk ) { treader . decRef ( ) ; treader = writer . getReader ( ) ; if ( dirty ) { tetag = newEtag ( ) ; tdirty = false ; } } treader . incRef ( ) ; treturn reader ; } 
public synchronized IndexReader borrowReader ( final boolean staleOk ) tthrows IOException { ttry { tlatch . await ( ) ; } catch ( final InterruptedException e ) { } 
private void releaseLatches ( ) { tfor ( final IndexState state : states . values ( ) ) { if ( state . pending_seq > = ddoc_seq ) { 
private synchronized DatabaseIndexer getIndexer ( final Database database ) tthrows IOException { tDatabaseIndexer result = indexers . get ( database ) ; tThread thread = threads . get ( database ) ; if ( result = = null | | thread = = null | | ! thread . isAlive ( ) ) { tresult = new DatabaseIndexer ( client , root , database ) ; tindexers . put ( database , result ) ; tthread = new Thread ( result ) ; tthreads . put ( database , thread ) ; tthread . start ( ) ; tresult . awaitInitialization ( ) ; } treturn result ; } 
public static File uuidDir ( final File root , final UUID uuid ) { treturn new File ( root , uuid . toString ( ) ) ; } 
public static File viewDir ( final File root , final UUID uuid , tfinal String digest , final boolean mkdirs ) throws IOException { tfinal File uuidDir = uuidDir ( root , uuid ) ; tfinal File viewDir = new File ( uuidDir , digest ) ; if ( mkdirs ) { tviewDir . mkdirs ( ) ; } treturn viewDir ; } 
public void admin ( final HttpServletRequest req , tfinal HttpServletResponse resp ) throws IOException { tfinal IndexState state = getState ( req ) ; tfinal String command = pathParts ( req ) [ 4 ] ; if ( " _expunge " . equals ( command ) ) { tlogger . info ( " Expunging deletes from " + state ) ; tstate . writer . expungeDeletes ( false ) ; tServletUtils . setResponseContentTypeAndEncoding ( req , resp ) ; tresp . setStatus ( 202 ) ; tServletUtils . writeJSON ( resp , JSON_SUCCESS ) ; treturn ; } if ( " _optimize " . equals ( command ) ) { tlogger . info ( " Optimizing " + state ) ; 
private void close ( ) throws IOException { tthis . closed = true ; tfor ( final IndexState state : states . values ( ) ) { tstate . close ( ) ; } tstates . clear ( ) ; tContext . exit ( ) ; } 
private File viewDir ( final View view , final boolean mkdirs ) tthrows IOException { treturn viewDir ( root , uuid , view . getDigest ( ) , mkdirs ) ; } 
private Couch getCouch ( final HttpServletRequest req ) throws IOException { tfinal Configuration section = ini . getSection ( pathParts ( req ) [ 0 ] ) ; tfinal String url = section . containsKey ( " url " ) ? section . getString ( " url " ) : null ; treturn new Couch ( client , url ) ; } 
private synchronized DatabaseIndexer getIndexer ( final Database database ) tthrows IOException { tDatabaseIndexer result = indexers . get ( database ) ; tThread thread = threads . get ( database ) ; if ( result = = null | | thread = = null | | ! thread . isAlive ( ) ) { tresult = new DatabaseIndexer ( client , root , database ) ; tindexers . put ( database , result ) ; tthread = new Thread ( result ) ; tthreads . put ( database , thread ) ; tthread . start ( ) ; tresult . awaitInitialization ( ) ; } treturn result ; } 
private DatabaseIndexer getIndexer ( final HttpServletRequest req ) tthrows IOException { tfinal Couch couch = getCouch ( req ) ; tfinal Database database = couch . getDatabase ( pathParts ( req ) [ 1 ] ) ; treturn getIndexer ( database ) ; } 
public synchronized IndexReader borrowReader ( final boolean staleOk ) tthrows IOException { tblockForLatest ( staleOk ) ; if ( reader = = null ) { treader = writer . getReader ( ) ; tetag = newEtag ( ) ; treader . incRef ( ) ; } if ( ! staleOk ) { treader . decRef ( ) ; treader = writer . getReader ( ) ; if ( dirty ) { tetag = newEtag ( ) ; tdirty = false ; } } treader . incRef ( ) ; treturn reader ; } 
private void blockForLatest ( final boolean staleOk ) throws IOException { if ( staleOk ) { treturn ; } tfinal long latest = database . getInfo ( ) . getUpdateSequence ( ) ; tsynchronized ( this ) { twhile ( pending_seq < latest ) { 
public void admin ( final HttpServletRequest req , tfinal HttpServletResponse resp ) throws IOException { tfinal IndexState state = getState ( req ) ; tfinal String command = pathParts ( req ) [ 4 ] ; if ( " _expunge " . equals ( command ) ) { tlogger . info ( " Expunging deletes from " + state ) ; tstate . writer . expungeDeletes ( false ) ; tServletUtils . setResponseContentTypeAndEncoding ( req , resp ) ; tresp . setStatus ( 202 ) ; tServletUtils . writeJSON ( resp , JSON_SUCCESS ) ; treturn ; } if ( " _optimize " . equals ( command ) ) { tlogger . info ( " Optimizing " + state ) ; 
public void admin ( final HttpServletRequest req , tfinal HttpServletResponse resp ) throws IOException { tfinal IndexState state = getState ( req , resp ) ; if ( state = = null ) treturn ; tfinal String command = pathParts ( req ) [ 4 ] ; if ( " _expunge " . equals ( command ) ) { tlogger . info ( " Expunging deletes from " + state ) ; tstate . writer . expungeDeletes ( false ) ; tServletUtils . setResponseContentTypeAndEncoding ( req , resp ) ; tresp . setStatus ( 202 ) ; tServletUtils . writeJSON ( resp , JSON_SUCCESS ) ; treturn ; } if ( " _optimize " . equals ( command ) ) { tlogger . info ( " Optimizing " + state ) ; 
public void info ( final HttpServletRequest req , tfinal HttpServletResponse resp ) throws IOException { tfinal IndexState state = getState ( req , resp ) ; if ( state = = null ) treturn ; tfinal IndexReader reader = state . borrowReader ( isStaleOk ( req ) ) ; ttry { tfinal JSONObject result = new JSONObject ( ) ; 
private IndexState getState ( final HttpServletRequest req , tfinal HttpServletResponse resp ) throws IOException { tfinal String path = pathParts ( req ) [ 2 ] + " / " + pathParts ( req ) [ 3 ] ; tfinal View view = paths . get ( path ) ; if ( view = = null ) { tServletUtils . sendJSONError ( req , resp , 400 , " no_such_view " ) ; treturn null ; } tfinal IndexState result = states . get ( view ) ; if ( result = = null ) { tServletUtils . sendJSONError ( req , resp , 400 , " no_such_state " ) ; } treturn result ; } 
private synchronized DatabaseIndexer getIndexer ( final Database database ) tthrows IOException { tDatabaseIndexer result = indexers . get ( database ) ; tThread thread = threads . get ( database ) ; if ( result = = null | | thread = = null | | ! thread . isAlive ( ) ) { tresult = new DatabaseIndexer ( client , root , database , tini . getLong ( " lucene.timeout " , 5000 ) ) ; tindexers . put ( database , result ) ; tthread = new Thread ( result ) ; tthreads . put ( database , thread ) ; tthread . start ( ) ; tresult . awaitInitialization ( ) ; } treturn result ; } 
private synchronized DatabaseIndexer getIndexer ( final Database database ) tthrows IOException { tDatabaseIndexer result = indexers . get ( database ) ; tThread thread = threads . get ( database ) ; if ( result = = null | | thread = = null | | ! thread . isAlive ( ) ) { tresult = new DatabaseIndexer ( client , root , database , ini ) ; tindexers . put ( database , result ) ; tthread = new Thread ( result ) ; tthreads . put ( database , thread ) ; tthread . start ( ) ; tresult . awaitInitialization ( ) ; } treturn result ; } 
private IndexWriter newWriter ( final Directory dir ) throws IOException { tfinal IndexWriter result = new IndexWriter ( dir , Constants . ANALYZER , tMaxFieldLength . UNLIMITED ) ; tresult . setMergeFactor ( ini . getInt ( " lucene.mergeFactor " , 5 ) ) ; tresult . setUseCompoundFile ( ini . getBoolean ( " lucene.useCompoundFile " , false ) ) ; tresult . setRAMBufferSizeMB ( ini . getDouble ( " lucene.ramBufferSizeMB " , IndexWriter . DEFAULT_RAM_BUFFER_SIZE_MB ) ) ; treturn result ; } 
public void testDefaultValue ( ) throws Exception { final String fun = " function(doc) { var ret=new Document(); ret.add(doc['arr'].join(' ')); return ret; } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hi \" , arr:[ \" 1 \" , \" 2 \" ]} " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 1 ) ) ; assertThat ( result [ 0 ] . get ( " default " ) , is ( " 1 2 " ) ) ; } 
public void testNullValue ( ) throws Exception { final String fun = " function(doc) { var ret=new Document(); ret.add(doc.foo); return ret; } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hi \" , foo:null} " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 1 ) ) ; assertThat ( result [ 0 ] . get ( " foo " ) , is ( nullValue ( ) ) ) ; } 
private File viewDir ( final View view , final boolean mkdirs ) tthrows IOException { tassert root ! = null ; tassert uuid ! = null ; tassert view ! = null ; treturn viewDir ( root , uuid , view . getDigest ( ) , mkdirs ) ; } 
public static void jsFunction_add ( final Context cx , final Scriptable thisObj , final Object [ ] args , final Function funObj ) { final RhinoDocument doc = checkInstance ( thisObj ) ; if ( args . length < 1 | | args . length > 2 ) { throw Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } if ( args [ 0 ] = = null ) { throw Context . reportRuntimeError ( " first argument must be non-null. " ) ; } if ( args [ 0 ] instanceof Undefined ) { hrow Context.reportRuntimeError(className + " is not supported."); } if (args.length == 2 && (args[1] == null || args[1] instanceof NativeObject == false)) { throw Context.reportRuntimeError("second argument must be an object."); } final RhinoField field = new RhinoField(); field.value = args[0]; if (args.length == 2) { field.settings = (NativeObject) args[1]; } doc.fields.add(field); } 
public void testLongValue ( ) throws Exception { final String fun = " function(doc) { var ret=new Document(); ret.add(12, {type: \" long \" , field: \" num \" }); return ret; } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hi \" } " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 1 ) ) ; assertThat ( result [ 0 ] . getFieldable ( " num " ) , is ( NumericField . class ) ) ; } 
public void testDateString ( ) throws Exception { final String fun = " function(doc) { var ret=new Document(); ret.add( \" 2009-01-01 \" , {type: \" date \" , field: \" num \" }); return ret; } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hi \" } " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 1 ) ) ; assertThat ( result [ 0 ] . getFieldable ( " num " ) , is ( NumericField . class ) ) ; } 
public void testDateObject ( ) throws Exception { final String fun = " function(doc) { var ret=new Document(); ret.add(new Date(), {type: \" date \" , field: \" num \" }); return ret; } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hi \" } " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 1 ) ) ; assertThat ( result [ 0 ] . getFieldable ( " num " ) , is ( NumericField . class ) ) ; } 
public static void jsFunction_add ( final Context cx , final Scriptable thisObj , final Object [ ] args , final Function funObj ) { final RhinoDocument doc = checkInstance ( thisObj ) ; if ( args . length < 1 | | args . length > 2 ) { throw Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } if ( args [ 0 ] = = null ) { throw Context . reportRuntimeError ( " first argument must be non-null. " ) ; } if ( args [ 0 ] instanceof Undefined ) { hrow Context.reportRuntimeError(className + " is not supported."); } if (args.length == 2 && (args[1] == null || args[1] instanceof NativeObject == false)) { throw Context.reportRuntimeError("second argument must be an object."); } final RhinoField field = new RhinoField(); field.value = args[0]; if (args.length == 2) { field.settings = (NativeObject) args[1]; } doc.fields.add(field); } 
public synchronized IndexReader borrowReader ( final boolean staleOk ) tthrows IOException { tblockForLatest ( staleOk ) ; if ( reader = = null ) { tetag = newEtag ( ) ; } if ( reader ! = null ) { treader . decRef ( ) ; } treader = writer . getReader ( ) ; if ( dirty ) { tetag = newEtag ( ) ; tdirty = false ; } treader . incRef ( ) ; treturn reader ; } 
private IndexWriter newWriter ( final Directory dir ) throws IOException { tfinal IndexWriter result = new IndexWriter ( dir , Constants . ANALYZER , tMaxFieldLength . UNLIMITED ) ; tresult . setMergeFactor ( ini . getInt ( " lucene.mergeFactor " , 5 ) ) ; tresult . setUseCompoundFile ( ini . getBoolean ( " lucene.useCompoundFile " , tfalse ) ) ; tresult . setRAMBufferSizeMB ( ini . getDouble ( " lucene.ramBufferSizeMB " , tIndexWriter . DEFAULT_RAM_BUFFER_SIZE_MB ) ) ; treturn result ; } 
private IndexWriter newWriter ( final Directory dir ) throws IOException { tfinal IndexWriter result = new IndexWriter ( dir , Constants . ANALYZER , tMaxFieldLength . UNLIMITED ) ; tresult . setMergeFactor ( ini . getInt ( " lucene.mergeFactor " , 10 ) ) ; tresult . setUseCompoundFile ( ini . getBoolean ( " lucene.useCompoundFile " , tfalse ) ) ; tresult . setRAMBufferSizeMB ( ini . getDouble ( " lucene.ramBufferSizeMB " , tIndexWriter . DEFAULT_RAM_BUFFER_SIZE_MB ) ) ; treturn result ; } 
public void testWord ( ) throws IOException { parse ( " example.doc " , " application/msword " , " bar " ) ; assertThat ( doc . getField ( " bar " ) , not ( nullValue ( ) ) ) ; assertThat ( doc . get ( " bar " ) , containsString ( " 576 dsf45 d56 dsgh " ) ) ; } 
public List < CouchDocument > getDocuments ( final String . . . ids ) tthrows IOException { if ( ids . length = = 0 ) { treturn Collections . emptyList ( ) ; } tfinal JSONArray keys = new JSONArray ( ) ; tfor ( final String id : ids ) { tassert id ! = null ; tkeys . add ( id ) ; } tfinal JSONObject req = new JSONObject ( ) ; treq . element ( " keys " , keys ) ; tfinal String body = HttpUtils . post ( httpClient , url + " _all_docs?include_docs=true " , req . toString ( ) ) ; tfinal JSONObject json = JSONObject . fromObject ( body ) ; treturn toDocuments ( json ) ; } 
public void testSearchPath ( ) { tfinal PathParts parts = new PathParts ( " /local/db1/_design/foo/by_subject " ) ; tassertThat ( parts . getKey ( ) , is ( " local " ) ) ; tassertThat ( parts . getDatabaseName ( ) , is ( " db1 " ) ) ; tassertThat ( parts . getDesignDocumentName ( ) , is ( " _design/foo " ) ) ; tassertThat ( parts . getViewName ( ) , is ( " by_subject " ) ) ; } 
public void admin ( final HttpServletRequest req , tfinal HttpServletResponse resp ) throws IOException { tfinal IndexState state = getState ( req , resp ) ; if ( state = = null ) treturn ; tfinal String command = new PathParts ( req ) . getCommand ( ) ; if ( " _expunge " . equals ( command ) ) { tlogger . info ( " Expunging deletes from " + state ) ; tstate . writer . expungeDeletes ( false ) ; tServletUtils . setResponseContentTypeAndEncoding ( req , resp ) ; tresp . setStatus ( 202 ) ; tServletUtils . writeJSON ( resp , JSON_SUCCESS ) ; treturn ; } if ( " _optimize " . equals ( command ) ) { tlogger . info ( " Optimizing " + state ) ; 
private IndexState getState ( final HttpServletRequest req , tfinal HttpServletResponse resp ) throws IOException { tfinal View view = paths . get ( toPath ( req ) ) ; if ( view = = null ) { tServletUtils . sendJSONError ( req , resp , 400 , " no_such_view " ) ; treturn null ; } tfinal IndexState result = states . get ( view ) ; if ( result = = null ) { tServletUtils . sendJSONError ( req , resp , 400 , " no_such_state " ) ; } treturn result ; } 
private String toPath ( final HttpServletRequest req ) { tfinal PathParts parts = new PathParts ( req ) ; treturn toPath ( parts . getDesignDocumentName ( ) , parts . getViewName ( ) ) ; } 
private String toPath ( final String ddoc , final String view ) { treturn ddoc + " / " + view ; } 
private Couch getCouch ( final HttpServletRequest req ) throws IOException { tfinal Configuration section = ini . getSection ( new PathParts ( req ) . getKey ( ) ) ; tfinal String url = section . containsKey ( " url " ) ? section . getString ( " url " ) : null ; treturn new Couch ( client , url ) ; } 
private DatabaseIndexer getIndexer ( final HttpServletRequest req ) tthrows IOException { tfinal Couch couch = getCouch ( req ) ; tfinal Database database = couch . getDatabase ( new PathParts ( req ) . getDatabaseName ( ) ) ; treturn getIndexer ( database ) ; } 
public String toString ( ) { treturn " PathParts [getCommand()= " + getCommand ( ) + " , getDatabaseName()= " + getDatabaseName ( ) 
public DesignDocument getDesignDocument ( final String id ) throws IOException { tfinal String response = HttpUtils . get ( httpClient , url + Utils . urlEncode ( id ) ) ; treturn new DesignDocument ( JSONObject . fromObject ( response ) ) ; } 
public void testSearchPath ( ) { tfinal PathParts parts = new PathParts ( " /local/db1/_design/foo/by_subject " ) ; tassertThat ( parts . getKey ( ) , is ( " local " ) ) ; tassertThat ( parts . getDatabaseName ( ) , is ( " db1 " ) ) ; tassertThat ( parts . getDesignDocumentName ( ) , is ( " _design/foo " ) ) ; tassertThat ( parts . getViewName ( ) , is ( " by_subject " ) ) ; tassertThat ( parts . getCommand ( ) , is ( nullValue ( ) ) ) ; } 
public void testCommandPath ( ) { tfinal PathParts parts = new PathParts ( " /local/db1/_design/foo/by_subject/_expunge " ) ; tassertThat ( parts . getKey ( ) , is ( " local " ) ) ; tassertThat ( parts . getDatabaseName ( ) , is ( " db1 " ) ) ; tassertThat ( parts . getDesignDocumentName ( ) , is ( " _design/foo " ) ) ; tassertThat ( parts . getViewName ( ) , is ( " by_subject " ) ) ; tassertThat ( parts . getCommand ( ) , is ( " _expunge " ) ) ; } 
public void testCleanupPath ( ) { tfinal PathParts parts = new PathParts ( " /local/db1/_cleanup " ) ; tassertThat ( parts . getKey ( ) , is ( " local " ) ) ; tassertThat ( parts . getDatabaseName ( ) , is ( " db1 " ) ) ; tassertThat ( parts . getCommand ( ) , is ( " _cleanup " ) ) ; } 
private Document forceDocument ( ) { tfinal Document result = new Document ( ) ; tresult . add ( new Field ( " _id " , uuid . toString ( ) , Store . NO , tIndex . NOT_ANALYZED_NO_NORMS ) ) ; treturn result ; } 
public void forceCommit ( ) throws Exception { tfinal Directory dir = new RAMDirectory ( ) ; tfinal IndexWriter writer = new IndexWriter ( dir , new StandardAnalyzer ( tVersion . LUCENE_30 ) , MaxFieldLength . UNLIMITED ) ; twriter . commit ( Collections . singletonMap ( " foo " , " bar " ) ) ; tassertThat ( IndexReader . getCommitUserData ( dir ) . get ( " foo " ) , tis ( nullValue ( ) ) ) ; tfinal Document doc = new Document ( ) ; tdoc . add ( new Field ( " foo " , " bar " , Store . NO , Index . NOT_ANALYZED_NO_NORMS ) ) ; tfinal Term term = new Term ( " foo " , " bar " ) ; twriter . updateDocument ( term , doc ) ; twriter . commit ( Collections . singletonMap ( " foo " , " bar " ) ) ; tassertThat ( IndexReader . getCommitUserData ( dir ) . get ( " foo " ) , is ( " bar " ) ) ; tassertThat ( writer . numDocs ( ) , is ( 1 ) ) ; twriter . deleteDocuments ( term ) ; twriter . commit ( ) ; tassertThat ( writer . numDocs ( ) , is ( 0 ) ) ; } 
private Document forceDocument ( ) { tfinal Document result = new Document ( ) ; tresult . add ( new Field ( " _cl " , uuid . toString ( ) , Store . NO , tIndex . NOT_ANALYZED_NO_NORMS ) ) ; treturn result ; } 
public synchronized IndexReader borrowReader ( final boolean staleOk ) tthrows IOException { tblockForLatest ( staleOk ) ; if ( reader = = null ) { tetag = newEtag ( ) ; } if ( reader ! = null ) { treader . decRef ( ) ; } treader = writer . getReader ( ) ; if ( readerDirty ) { tetag = newEtag ( ) ; treaderDirty = false ; } treader . incRef ( ) ; treturn reader ; } 
public NumericField toField ( final String name , final Object value , final ViewSettings settings ) throws ParseException { return field ( name , precisionStep , settings ) . setLongValue ( toDate ( value ) ) ; } 
public NumericField toField ( final String name , final Object value , final ViewSettings settings ) { return field ( name , precisionStep , settings ) . setDoubleValue ( toDouble ( value ) ) ; } 
private double toDouble ( final Object obj ) { if ( obj instanceof Number ) { treturn ( ( Number ) obj ) . doubleValue ( ) ; } return Double . parseDouble ( obj . toString ( ) ) ; } 
public NumericField toField ( final String name , final Object value , final ViewSettings settings ) { return field ( name , 4 , settings ) . setFloatValue ( toFloat ( value ) ) ; } 
private float toFloat ( final Object obj ) { if ( obj instanceof Number ) { treturn ( ( Number ) obj ) . floatValue ( ) ; } return Float . parseFloat ( obj . toString ( ) ) ; } 
public NumericField toField ( final String name , final Object value , final ViewSettings settings ) { return field ( name , 4 , settings ) . setIntValue ( toInt ( value ) ) ; } 
private int toInt ( final Object obj ) { if ( obj instanceof Number ) { treturn ( ( Number ) obj ) . intValue ( ) ; } return Integer . parseInt ( obj . toString ( ) ) ; } 
public NumericField toField ( final String name , final Object value , final ViewSettings settings ) { return field ( name , precisionStep , settings ) . setLongValue ( toLong ( value ) ) ; } 
private long toLong ( final Object obj ) { if ( obj instanceof Number ) { treturn ( ( Number ) obj ) . longValue ( ) ; } return Long . parseLong ( obj . toString ( ) ) ; } 
public Field toField ( final String name , final Object value , final ViewSettings settings ) { return new Field ( name , value . toString ( ) , settings . getStore ( ) , settings . getIndex ( ) ) ; } 
public abstract AbstractField toField ( final String name , final Object value , final ViewSettings settings ) throws ParseException ; public abstract Query toRangeQuery ( final String name , final String lower , final String upper , final boolean inclusive ) throws ParseException ; public final int toSortField ( ) { return sortField ; } public static long toDate ( final Object obj ) throws ParseException { if ( obj instanceof Date ) { treturn ( ( Date ) obj ) . getTime ( ) ; } try { return DateUtils . parseDate ( obj . toString ( ) . toUpperCase ( ) , DATE_PATTERNS ) . getTime ( ) ; } catch ( final java . text . ParseException e ) { throw new ParseException ( e . getMessage ( ) ) ; } } } 
public abstract Query toRangeQuery ( final String name , final String lower , final String upper , final boolean inclusive ) throws ParseException ; public final int toSortField ( ) { return sortField ; } public static long toDate ( final Object obj ) throws ParseException { if ( obj instanceof Date ) { treturn ( ( Date ) obj ) . getTime ( ) ; } try { return DateUtils . parseDate ( obj . toString ( ) . toUpperCase ( ) , DATE_PATTERNS ) . getTime ( ) ; } catch ( final java . text . ParseException e ) { throw new ParseException ( e . getMessage ( ) ) ; } } } 
public static long toDate ( final Object obj ) throws ParseException { if ( obj instanceof Date ) { treturn ( ( Date ) obj ) . getTime ( ) ; } try { return DateUtils . parseDate ( obj . toString ( ) . toUpperCase ( ) , DATE_PATTERNS ) . getTime ( ) ; 
public static void jsFunction_add ( final Context cx , final Scriptable thisObj , final Object [ ] args , final Function funObj ) { final RhinoDocument doc = checkInstance ( thisObj ) ; if ( args . length < 1 | | args . length > 2 ) { throw Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } if ( args [ 0 ] = = null ) { throw Context . reportRuntimeError ( " first argument must be non-null. " ) ; } if ( args [ 0 ] instanceof Undefined ) { hrow Context.reportRuntimeError(className + " is not supported."); } if (args.length == 2 && (args[1] == null || args[1] instanceof NativeObject == false)) { throw Context.reportRuntimeError("second argument must be an object."); } final RhinoField field = new RhinoField(); field.value = args[0]; if (args.length == 2) { field.settings = (NativeObject) args[1]; } doc.fields.add(field); } 
private void addField ( final RhinoField field , final ViewSettings defaults , final Document out ) throws ParseException { final ViewSettings settings = new ViewSettings ( field . settings , defaults ) ; final FieldType type = settings . getFieldType ( ) ; out . add ( type . toField ( settings . getField ( ) , field . value , settings ) ) ; } 
public void testParseInt ( ) throws Exception { final String fun = " function(doc) { var ret=new Document(); ret.add(parseInt( \" 12.5 \" ), {type: \" int \" , field: \" num \" }); return ret; } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hi \" } " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 1 ) ) ; assertThat ( result [ 0 ] . getFieldable ( " num " ) , is ( NumericField . class ) ) ; } 
public static Sort toSort ( final String sort ) throws ParseException { if ( sort = = null ) { treturn null ; 
private Scriptable convertObject ( final JSONObject obj ) { if ( obj . isNullObject ( ) ) { treturn null ; } final Scriptable result = context . newObject ( scope ) ; for ( final Object key : obj . keySet ( ) ) { final Object value = obj . get ( key ) ; ScriptableObject . putProperty ( result , ( String ) key , convert ( value ) ) ; } return result ; } 
public static void jsFunction_add ( final Context cx , final Scriptable thisObj , final Object [ ] args , final Function funObj ) { final RhinoDocument doc = checkInstance ( thisObj ) ; if ( args . length < 1 | | args . length > 2 ) { throw Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } if ( args [ 0 ] = = null ) { hrow Context.reportRuntimeError(className + " is not supported."); } if (args.length == 2 && (args[1] == null || args[1] instanceof NativeObject == false)) { throw Context.reportRuntimeError("second argument must be an object."); } final RhinoField field = new RhinoField(); field.value = args[0]; if (args.length == 2) { field.settings = (NativeObject) args[1]; } doc.fields.add(field); } 
public void testConditionalOnNulls ( ) throws Exception { tfinal String fun = " function(doc) { if (doc.foo && doc.bar) { return new Document(); }; return null; } " ; tfinal DocumentConverter converter = new DocumentConverter ( context , tview ( fun ) ) ; tfinal Document [ ] result = converter . convert ( tdoc ( " {_id: \" hi \" , foo: null, bar: null} " ) , settings ( ) , null ) ; tassertThat ( result . length , is ( 0 ) ) ; } 
public Field toField ( final String name , final Object value , final ViewSettings settings ) { return field ( name , value , settings ) ; } 
private static NumericField field ( final String name , final int precisionStep , final ViewSettings settings ) { return boost ( new NumericField ( name , precisionStep , settings . getStore ( ) , settings . getIndex ( ) . isIndexed ( ) ) , settings ) ; } 
private static Field field ( final String name , final Object value , final ViewSettings settings ) { return boost ( new Field ( name , value . toString ( ) , settings . getStore ( ) , settings . getIndex ( ) ) , settings ) ; } 
private static < T extends AbstractField > T boost ( final T field , final ViewSettings settings ) { field . setBoost ( settings . getBoost ( ) ) ; return field ; } 
private static String get ( final NativeObject obj , final String key ) { return obj = = null ? null : obj . has ( key , null ) ? obj . get ( key , null ) . toString ( ) : null ; } 
private void handleWelcomeReq ( final HttpServletRequest req , tfinal HttpServletResponse resp ) throws ServletException , tIOException { tfinal JSONObject welcome = new JSONObject ( ) ; twelcome . put ( " couchdb-lucene " , " Welcome " ) ; twelcome . put ( " version " , " 0.6-SNAPSHOT " ) ; tServletUtils . writeJSON ( resp , welcome ) ; } 
private static Field field ( final String name , final Object value , final ViewSettings settings ) { return boost ( new Field ( name , value . toString ( ) , settings . getStore ( ) , settings . getIndex ( ) , settings . getTermVector ( ) ) , settings ) ; } 
public Query parse ( final String query ) throws ParseException { tfinal QueryParser parser = new CustomQueryParser ( Constants . VERSION , tConstants . DEFAULT_FIELD , analyzer ) ; treturn parser . parse ( query ) ; } 
protected Query getFieldQuery ( final String field , final String queryText ) throws ParseException { return new TypedField ( field ) . toTermQuery ( queryText ) ; } 
public Query toTermQuery ( final String text ) throws ParseException { return type . toTermQuery ( name , text ) ; } 
public Query toTermQuery ( final String name , final String text ) throws ParseException { final long date = toDate ( text ) ; return new TermQuery ( new Term ( name , NumericUtils . longToPrefixCoded ( date ) ) ) ; } 
public Query toTermQuery ( final String name , final String text ) { return new TermQuery ( new Term ( name , NumericUtils . doubleToPrefixCoded ( toDouble ( text ) ) ) ) ; } 
public Query toTermQuery ( final String name , final String text ) { return new TermQuery ( new Term ( name , NumericUtils . floatToPrefixCoded ( toFloat ( text ) ) ) ) ; } 
public Query toTermQuery ( final String name , final String text ) { return new TermQuery ( new Term ( name , NumericUtils . intToPrefixCoded ( toInt ( text ) ) ) ) ; } 
public Query toTermQuery ( final String name , final String text ) { return new TermQuery ( new Term ( name , NumericUtils . longToPrefixCoded ( toLong ( text ) ) ) ) ; } 
public Query toTermQuery ( String name , String text ) { return new TermQuery ( new Term ( name , text ) ) ; } 
public abstract AbstractField toField ( final String name , final Object value , final ViewSettings settings ) throws ParseException ; public abstract Query toRangeQuery ( final String name , final String lower , final String upper , final boolean inclusive ) throws ParseException ; public abstract Query toTermQuery ( final String name , final String text ) throws ParseException ; public final int toSortField ( ) { return sortField ; } public static long toDate ( final Object obj ) throws ParseException { if ( obj instanceof Date ) { treturn ( ( Date ) obj ) . getTime ( ) ; } try { return DateUtils . parseDate ( obj . toString ( ) . toUpperCase ( ) , DATE_PATTERNS ) . getTime ( ) ; } catch ( final java . text . ParseException e ) { throw new ParseException ( e . getMessage ( ) ) ; } } } 
public abstract Query toRangeQuery ( final String name , final String lower , final String upper , final boolean inclusive ) throws ParseException ; public abstract Query toTermQuery ( final String name , final String text ) throws ParseException ; public final int toSortField ( ) { return sortField ; } public static long toDate ( final Object obj ) throws ParseException { if ( obj instanceof Date ) { treturn ( ( Date ) obj ) . getTime ( ) ; } try { return DateUtils . parseDate ( obj . toString ( ) . toUpperCase ( ) , DATE_PATTERNS ) . getTime ( ) ; } catch ( final java . text . ParseException e ) { throw new ParseException ( e . getMessage ( ) ) ; } } } 
public abstract Query toTermQuery ( final String name , final String text ) throws ParseException ; public final int toSortField ( ) { return sortField ; } public static long toDate ( final Object obj ) throws ParseException { if ( obj instanceof Date ) { treturn ( ( Date ) obj ) . getTime ( ) ; } try { return DateUtils . parseDate ( obj . toString ( ) . toUpperCase ( ) , DATE_PATTERNS ) . getTime ( ) ; } catch ( final java . text . ParseException e ) { throw new ParseException ( e . getMessage ( ) ) ; } } } 
private void handleWelcomeReq ( final HttpServletRequest req , tfinal HttpServletResponse resp ) throws ServletException , tIOException { final Package p = this . getClass ( ) . getPackage ( ) ; tfinal JSONObject welcome = new JSONObject ( ) ; twelcome . put ( " couchdb-lucene " , " Welcome " ) ; twelcome . put ( " version " , p . getImplementationVersion ( ) ) ; tServletUtils . writeJSON ( resp , welcome ) ; } 
public void handle ( String target , HttpServletRequest request , HttpServletResponse response , int dispatch ) throws IOException { HttpConnection connection = HttpConnection . getCurrentConnection ( ) ; connection . getRequest ( ) . setHandled ( true ) ; ServletUtils . sendJSONError ( request , response , connection . getResponse ( ) . getStatus ( ) , JSONObject . fromObject ( connection . getResponse ( ) . getReason ( ) ) ) ; 
public static void sendJSONError ( final HttpServletRequest request , final HttpServletResponse response , final int code , final String reason ) throws IOException { final JSONObject obj = new JSONObject ( ) ; obj . put ( " reason " , reason ) ; sendJSONError ( request , response , code , obj ) ; } 
public static void sendJSONError ( final HttpServletRequest request , final HttpServletResponse response , final int code , final JSONObject error ) throws IOException { error . put ( " code " , code ) ; setResponseContentTypeAndEncoding ( request , response ) ; response . setHeader ( HttpHeaders . CACHE_CONTROL , " must-revalidate,no-cache,no-store " ) ; response . setStatus ( code ) ; final Writer writer = response . getWriter ( ) ; try { writer . write ( error . toString ( ) ) ; 
public void releaseConnection ( final ManagedClientConnection conn , final long validDuration , final TimeUnit timeUnit ) { delegate . releaseConnection ( conn , validDuration , timeUnit ) ; } 
public static synchronized HttpClient getInstance ( ) throws MalformedURLException { if ( instance = = null ) { final HttpParams params = new BasicHttpParams ( ) ; protocol params. HttpProtocolParams.setVersion(params, HttpVersion.HTTP_1_1); HttpProtocolParams.setUseExpectContinue(params, false); connection params. HttpConnectionParams.setTcpNoDelay(params, true); HttpConnectionParams.setStaleCheckingEnabled(params, false); ConnManagerParams.setMaxTotalConnections(params, 1000); ConnManagerParams.setMaxConnectionsPerRoute(params, new ConnPerRouteBean(1000)); final SchemeRegistry schemeRegistry = new SchemeRegistry(); schemeRegistry .register(new Scheme("http", PlainSocketFactory.getSocketFactory(), 5984)); final ClientConnectionManager cm = new ShieldedClientConnManager( new ThreadSafeClientConnManager(params, schemeRegistry)); instance = new DefaultHttpClient(cm, params); if (INI != null) { final CredentialsProvider credsProvider = new BasicCredentialsProvider(); final Iterator<?> it = INI.getKeys(); while (it.hasNext()) { final String key = (String) it.next(); if (!key.startsWith("lucene.") && key.endsWith(".url")) { final URL url = new URL(INI.getString(key)); credsProvider.setCredentials( new AuthScope(url.getHost(), url.getPort()), new UsernamePasswordCredentials(url.getUserInfo())); } } instance.setCredentialsProvider(credsProvider); instance.addRequestInterceptor(new PreemptiveAuthenticationRequestInterceptor(), 0); } } return instance; } 
public static void main ( String [ ] args ) throws Exception { final HierarchicalINIConfiguration configuration = new HierarchicalINIConfiguration ( Main . class . getClassLoader ( ) . getResource ( " couchdb-lucene.ini " ) ) ; configuration . setReloadingStrategy ( new FileChangedReloadingStrategy ( ) ) ; final File dir = new File ( configuration . getString ( " lucene.dir " , " indexes " ) ) ; if ( dir = = null ) { LOG . error ( " lucene.dir not set. " ) ; System . exit ( 1 ) ; } if ( ! dir . exists ( ) & & ! dir . mkdir ( ) ) { LOG . error ( " Could not create " + dir . getCanonicalPath ( ) ) ; System . exit ( 1 ) ; } if ( ! dir . canRead ( ) ) { LOG . error ( dir + " is not readable. " ) ; System . exit ( 1 ) ; } if ( ! dir . canWrite ( ) ) { LOG . error ( dir + " is not writable. " ) ; System . exit ( 1 ) ; } LOG . info ( " Index output goes to: " + dir . getCanonicalPath ( ) ) ; final Server server = new Server ( ) ; final SelectChannelConnector connector = new SelectChannelConnector ( ) ; connector . setHost ( configuration . getString ( " lucene.host " , " localhost " ) ) ; connector . setPort ( configuration . getInt ( " lucene.port " , 5985 ) ) ; LOG . info ( " Accepting connections with " + connector ) ; server . setConnectors ( new Connector [ ] { connector } ) ; server . setStopAtShutdown ( true ) ; server . setSendServerVersion ( false ) ; HttpClientFactory . setIni ( configuration ) ; final HttpClient httpClient = HttpClientFactory . getInstance ( ) ; final LuceneServlet servlet = new LuceneServlet ( httpClient , dir , configuration ) ; final Context context = new Context ( server , " / " , Context . NO_SESSIONS | Context . NO_SECURITY ) ; context . addServlet ( new ServletHolder ( servlet ) , " /* " ) ; context . addFilter ( new FilterHolder ( new GzipFilter ( ) ) , " /* " , Handler . DEFAULT ) ; context . setErrorHandler ( new JSONErrorHandler ( ) ) ; server . setHandler ( context ) ; server . start ( ) ; server . join ( ) ; } 
public void handle ( String target , HttpServletRequest request , HttpServletResponse response , int dispatch ) throws IOException { HttpConnection connection = HttpConnection . getCurrentConnection ( ) ; connection . getRequest ( ) . setHandled ( true ) ; final String reason = connection . getResponse ( ) . getReason ( ) ; if ( reason . startsWith ( " { " ) ) { ServletUtils . sendJSONError ( request , response , connection . getResponse ( ) . getStatus ( ) , 
private void blockForLatest ( final boolean staleOk ) throws IOException { if ( staleOk ) { treturn ; } tfinal long latest = database . getInfo ( ) . getUpdateSequence ( ) ; tsynchronized ( this ) { long imeout = getSearchTimeout ( ) ; 
public Query toTermQuery ( String name , String text ) { throw new UnsupportedOperationException ( " toTermQuery is not supported for FieldType.String. " ) ; } 
private void assertRange ( final Query q , final Class < ? > type , final Number min , final Number max ) { assertThat ( q , is ( NumericRangeQuery . class ) ) ; final NumericRangeQuery < ? > nq = ( NumericRangeQuery < ? > ) q ; assertThat ( nq . getMin ( ) , is ( type ) ) ; assertThat ( nq . getMax ( ) , is ( type ) ) ; assertThat ( nq . getMin ( ) , is ( min ) ) ; assertThat ( nq . getMax ( ) , is ( max ) ) ; } 
public void admin ( final HttpServletRequest req , tfinal HttpServletResponse resp ) throws IOException { tfinal IndexState state = getState ( req , resp ) ; if ( state = = null ) treturn ; tfinal String command = new PathParts ( req ) . getCommand ( ) ; if ( " _expunge " . equals ( command ) ) { tlogger . info ( " Expunging deletes from " + state ) ; tstate . writer . expungeDeletes ( false ) ; tServletUtils . setResponseContentTypeAndEncoding ( req , resp ) ; tresp . setStatus ( 202 ) ; tServletUtils . writeJSON ( resp , JSON_SUCCESS ) ; treturn ; } if ( " _optimize " . equals ( command ) ) { tlogger . info ( " Optimizing " + state ) ; tstate . writer . optimize ( false ) ; tServletUtils . setResponseContentTypeAndEncoding ( req , resp ) ; tresp . setStatus ( 202 ) ; tServletUtils . writeJSON ( resp , JSON_SUCCESS ) ; treturn ; } tServletUtils . sendJSONError ( req , resp , 400 , " bad_request " ) ; } 
public void testDateObject ( ) throws Exception { final String fun = " function(doc) { var ret=new Document(); ret.add(new Date(2010,8,13), {type: \" date \" , field: \" num \" }); return ret; } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hi \" } " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 1 ) ) ; assertThat ( result [ 0 ] . getFieldable ( " num " ) , is ( NumericField . class ) ) ; assertThat ( ( Long ) ( ( NumericField ) result [ 0 ] . getFieldable ( " num " ) ) . getNumericValue ( ) , is ( 1284332400000L ) ) ; } 
public void testDateObject2 ( ) throws Exception { final String fun = " function(doc) { var ret=new Document(); ret.add(new Date( \" January 6, 1972 16:05:00 \" ), {type: \" date \" , field: \" num \" }); return ret; } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hi \" } " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 1 ) ) ; assertThat ( result [ 0 ] . getFieldable ( " num " ) , is ( NumericField . class ) ) ; assertThat ( ( Long ) ( ( NumericField ) result [ 0 ] . getFieldable ( " num " ) ) . getNumericValue ( ) , is ( 63561900000L ) ) ; } 
public void setup ( ) { context = Context . enter ( ) ; tz = TimeZone . getDefault ( ) ; TimeZone . setDefault ( TimeZone . getTimeZone ( " Europe/London " ) ) ; } 
public void teardown ( ) { TimeZone . setDefault ( tz ) ; Context . exit ( ) ; } 
public void admin ( final HttpServletRequest req , tfinal HttpServletResponse resp ) throws IOException { tfinal IndexState state = getState ( req , resp ) ; if ( state = = null ) treturn ; tfinal String command = new PathParts ( req ) . getCommand ( ) ; if ( " _expunge " . equals ( command ) ) { tlogger . info ( " Expunging deletes from " + state ) ; tstate . writer . expungeDeletes ( false ) ; tresp . setStatus ( 202 ) ; tServletUtils . writeJSON ( req , resp , JSON_SUCCESS ) ; treturn ; } if ( " _optimize " . equals ( command ) ) { tlogger . info ( " Optimizing " + state ) ; tstate . writer . optimize ( false ) ; tresp . setStatus ( 202 ) ; tServletUtils . writeJSON ( req , resp , JSON_SUCCESS ) ; treturn ; } tServletUtils . sendJSONError ( req , resp , 400 , " bad_request " ) ; } 
private void handleWelcomeReq ( final HttpServletRequest req , tfinal HttpServletResponse resp ) throws ServletException , tIOException { final Package p = this . getClass ( ) . getPackage ( ) ; tfinal JSONObject welcome = new JSONObject ( ) ; twelcome . put ( " couchdb-lucene " , " Welcome " ) ; twelcome . put ( " version " , p . getImplementationVersion ( ) ) ; tServletUtils . writeJSON ( req , resp , welcome ) ; } 
public static void writeJSON ( final HttpServletRequest req , final HttpServletResponse resp , final JSONObject json ) throws IOException { setResponseContentTypeAndEncoding ( req , resp ) ; final Writer writer = resp . getWriter ( ) ; try { writer . write ( json . toString ( ) + " r " ) ; 
public void testBadCode ( ) throws Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) { if (doc.) return null; } " ) ) ; converter . convert ( doc ( " {_id: \" hello \" } " ) , settings ( ) , null ) ; } 
public void run ( ) { if ( closed ) { tthrow new IllegalStateException ( " closed! " ) ; } ttry { tinit ( ) ; } catch ( final Exception e ) { tlogger . warn ( " Exiting after init() raised exception. " , e ) ; tlatch . countDown ( ) ; treturn ; } ttry { ttry { 
public void run ( ) { if ( closed ) { tthrow new IllegalStateException ( " closed! " ) ; } ttry { tinit ( ) ; } catch ( final Exception e ) { tlogger . warn ( " Exiting after init() raised exception. " , e ) ; tclose ( ) ; treturn ; } ttry { ttry { 
private void close ( ) { tthis . closed = true ; tfor ( final IndexState state : states . values ( ) ) { ttry { state . close ( ) ; } catch ( final IOException e ) { logger . warn ( " Error while closing. " , e ) ; } } tstates . clear ( ) ; tContext . exit ( ) ; tlatch . countDown ( ) ; } 
private synchronized DatabaseIndexer getIndexer ( final Database database ) tthrows IOException { tDatabaseIndexer result = indexers . get ( database ) ; tThread thread = threads . get ( database ) ; if ( result = = null | | thread = = null | | ! thread . isAlive ( ) ) { tresult = new DatabaseIndexer ( client , root , database , ini ) ; tthread = new Thread ( result ) ; tthread . start ( ) ; tresult . awaitInitialization ( ) ; if ( result . isClosed ( ) ) { return null ; } else { indexers . put ( database , result ) ; threads . put ( database , thread ) ; } } treturn result ; } 
public static String [ ] splitOnCommas ( final String str ) { return str . split ( " ,(?=([^ \" ]* \" [^ \" ]* \" )*[^ \" ]*$) " ) ; } 
public void testSplitOnCommas ( ) { assertArrayEquals ( new String [ ] { " foo " , " bar " } , Utils . splitOnCommas ( " foo,bar " ) ) ; } 
public void testSplitOnCommasWithEmbeddedCommas ( ) { assertArrayEquals ( new String [ ] { " \" fo,o \" " , " bar " } , Utils . splitOnCommas ( " \" fo,o \" ,bar " ) ) ; } 
public Analyzer newAnalyzer ( final String args ) { return new WhitespaceAnalyzer ( ) ; } 
public void testWhitespace ( ) { assertThat ( Analyzers . getAnalyzer ( " whitespace " ) , is ( WhitespaceAnalyzer . class ) ) ; } 
public void testEscapedChars ( ) throws Exception { final String str = " { \" seq \" :1503, \" id \" : \" 11dca825e8b19e40bd675345e05afa24 \" , \" changes \" :[{ \" rev \" : \" 2-bb1fba3e33ed2e8b78412fe27c8c6474 \" }], \" doc \" :{ \" _id \" : \" 11dca825e8b19e40bd675345e05afa24 \" , \" _rev \" : \" 2-bb1fba3e33ed2e8b78412fe27c8c6474 \" , \" query_params \" :{ \" { \\ \" action \\ \" : \\ \" answer \\ \" , \\ \" session-id \\ \" :41, \\ \" answer \\ \" :5} \" : \" \" }, \" stack_trace \" : \" File \\ \" /usr/local/lib/python2.6/dist-packages/Django-1.2.1-py2.6.egg/django/core/handlers/base.py \\ \" , line 95, in get_response \\ n response = middleware_method(request, callback, callback_args, callback_kwargs) \\ n File \\ \" /var/src/bhoma/bhoma/middleware.py \\ \" , line 37, in process_view \\ n return login_required(view_func)(request, *view_args, **view_kwargs) \\ n File \\ \" /usr/local/lib/python2.6/dist-packages/Django-1.2.1-py2.6.egg/django/contrib/auth/decorators.py \\ \" , line 25, in _wrapped_view \\ n return view_func(request, *args, **kwargs) \\ n File \\ \" /var/src/bhoma/bhoma/apps/xforms/views.py \\ \" , line 74, in player_proxy \\ n response, errors = post_data(data, settings.XFORMS_PLAYER_URL, content_type= \\ \" text/json \\ \" ) \\ n File \\ \" /var/src/bhoma/bhoma/utils/post.py \\ \" , line 34, in post_data \\ \" , \" doc_type \" : \" ExceptionRecord \" , \" url \" : \" http:10.10.10.10/xforms/player_proxy \" , \" clinic_id \" : \" 5010110 \" , \" date \" : \" 2010-09-08T14:39:11Z \" , \" message \" : \" [Errno 24] Too many open files: '/tmp/tmp8xIQb7' \" , \" type \" : \" <type 'exceptions.IOError'> \" }} " ; assertThat ( JSONObject . fromObject ( str ) , is ( notNullValue ( ) ) ) ; } 
public synchronized IndexReader borrowReader ( final boolean staleOk ) tthrows IOException , JSONException { tblockForLatest ( staleOk ) ; if ( reader = = null ) { tetag = newEtag ( ) ; } if ( reader ! = null ) { treader . decRef ( ) ; } treader = writer . getReader ( ) ; if ( readerDirty ) { tetag = newEtag ( ) ; treaderDirty = false ; } treader . incRef ( ) ; treturn reader ; } 
public IndexSearcher borrowSearcher ( final boolean staleOk ) tthrows IOException , JSONException { treturn new IndexSearcher ( borrowReader ( staleOk ) ) ; } 
private void blockForLatest ( final boolean staleOk ) throws IOException , JSONException { if ( staleOk ) { treturn ; } tfinal long latest = database . getInfo ( ) . getUpdateSequence ( ) ; tsynchronized ( this ) { long imeout = getSearchTimeout ( ) ; 
public void admin ( final HttpServletRequest req , tfinal HttpServletResponse resp ) throws IOException , JSONException { tfinal IndexState state = getState ( req , resp ) ; if ( state = = null ) treturn ; tfinal String command = new PathParts ( req ) . getCommand ( ) ; if ( " _expunge " . equals ( command ) ) { tlogger . info ( " Expunging deletes from " + state ) ; tstate . writer . expungeDeletes ( false ) ; tresp . setStatus ( 202 ) ; tServletUtils . writeJsonSuccess ( req , resp ) ; treturn ; } if ( " _optimize " . equals ( command ) ) { tlogger . info ( " Optimizing " + state ) ; tstate . writer . optimize ( false ) ; tresp . setStatus ( 202 ) ; tServletUtils . writeJsonSuccess ( req , resp ) ; treturn ; } tServletUtils . sendJSONError ( req , resp , 400 , " bad_request " ) ; } 
public void info ( final HttpServletRequest req , tfinal HttpServletResponse resp ) throws IOException , JSONException { tfinal IndexState state = getState ( req , resp ) ; if ( state = = null ) treturn ; tfinal IndexReader reader = state . borrowReader ( isStaleOk ( req ) ) ; ttry { tfinal JSONObject result = new JSONObject ( ) ; 
private IndexState getState ( final HttpServletRequest req , tfinal HttpServletResponse resp ) throws IOException , JSONException { tfinal View view = paths . get ( toPath ( req ) ) ; if ( view = = null ) { tServletUtils . sendJSONError ( req , resp , 400 , " no_such_view " ) ; treturn null ; } tfinal IndexState result = states . get ( view ) ; if ( result = = null ) { tServletUtils . sendJSONError ( req , resp , 400 , " no_such_state " ) ; } treturn result ; } 
private Object convert ( final Object obj ) throws JSONException { if ( obj instanceof JSONArray ) { return convertArray ( ( JSONArray ) obj ) ; 
private Scriptable convertArray ( final JSONArray array ) throws JSONException { final Scriptable result = context . newArray ( scope , array . length ( ) ) ; for ( int i = 0 , max = array . length ( ) ; i < max ; i + + ) { ScriptableObject . putProperty ( result , i , convert ( array . get ( i ) ) ) ; } return result ; } 
private Scriptable convertObject ( final JSONObject obj ) throws JSONException { if ( obj = = null ) { treturn null ; } final Scriptable result = context . newObject ( scope ) ; final Iterator < ? > it = obj . keys ( ) ; while ( it . hasNext ( ) ) { final String key = ( String ) it . next ( ) ; final Object value = obj . get ( key ) ; ScriptableObject . putProperty ( result , key , convert ( value ) ) ; } return result ; } 
public void handle ( String target , HttpServletRequest request , HttpServletResponse response , int dispatch ) throws IOException { HttpConnection connection = HttpConnection . getCurrentConnection ( ) ; connection . getRequest ( ) . setHandled ( true ) ; final String reason = connection . getResponse ( ) . getReason ( ) ; try { if ( reason . startsWith ( " { " ) ) { 
private synchronized DatabaseIndexer getIndexer ( final Database database ) tthrows IOException , JSONException { tDatabaseIndexer result = indexers . get ( database ) ; tThread thread = threads . get ( database ) ; if ( result = = null | | thread = = null | | ! thread . isAlive ( ) ) { tresult = new DatabaseIndexer ( client , root , database , ini ) ; tthread = new Thread ( result ) ; tthread . start ( ) ; tresult . awaitInitialization ( ) ; if ( result . isClosed ( ) ) { return null ; } else { indexers . put ( database , result ) ; threads . put ( database , thread ) ; } } treturn result ; } 
private DatabaseIndexer getIndexer ( final HttpServletRequest req ) tthrows IOException , JSONException { tfinal Couch couch = getCouch ( req ) ; tfinal Database database = couch . getDatabase ( new PathParts ( req ) . getDatabaseName ( ) ) ; treturn getIndexer ( database ) ; } 
private void handleWelcomeReq ( final HttpServletRequest req , tfinal HttpServletResponse resp ) throws ServletException , tIOException , JSONException { final Package p = this . getClass ( ) . getPackage ( ) ; tfinal JSONObject welcome = new JSONObject ( ) ; twelcome . put ( " couchdb-lucene " , " Welcome " ) ; twelcome . put ( " version " , p . getImplementationVersion ( ) ) ; tServletUtils . writeJson ( req , resp , welcome ) ; } 
protected void doGet ( final HttpServletRequest req , tfinal HttpServletResponse resp ) throws ServletException , tIOException { ttry { doGetInternal ( req , resp ) ; 
protected void doPost ( final HttpServletRequest req , tfinal HttpServletResponse resp ) throws ServletException , tIOException { ttry { doPostInternal ( req , resp ) ; 
public final JSONArray getAllDatabases ( ) throws IOException , JSONException { tfinal String response = HttpUtils . get ( httpClient , url + " _all_dbs " ) ; treturn new JSONArray ( response ) ; } 
public final JSONObject getInfo ( ) throws IOException , JSONException { treturn new JSONObject ( HttpUtils . get ( httpClient , url ) ) ; } 
public static CouchDocument deletedDocument ( final String id ) throws JSONException { final JSONObject json = new JSONObject ( ) ; json . put ( ID , id ) ; json . put ( DELETED , true ) ; return new CouchDocument ( json ) ; } 
public String getId ( ) throws JSONException { return json . getString ( ID ) ; } 
public List < DesignDocument > getAllDesignDocuments ( ) throws IOException , JSONException { tfinal String body = HttpUtils . get ( httpClient , String . format ( " %s_all_docs?startkey=%s&endkey=%s&include_docs=true " , turl , Utils . urlEncode ( " \" _design \" " ) , Utils . urlEncode ( " \" _design0 \" " ) ) ) ; tfinal JSONObject json = new JSONObject ( body ) ; treturn toDesignDocuments ( json ) ; } 
public CouchDocument getDocument ( final String id ) throws IOException , JSONException { tfinal String response = HttpUtils . get ( httpClient , url + Utils . urlEncode ( id ) ) ; treturn new CouchDocument ( new JSONObject ( response ) ) ; } 
public DesignDocument getDesignDocument ( final String id ) throws IOException , JSONException { tfinal String response = HttpUtils . get ( httpClient , url + Utils . urlEncode ( id ) ) ; treturn new DesignDocument ( new JSONObject ( response ) ) ; } 
public List < CouchDocument > getDocuments ( final String . . . ids ) tthrows IOException , JSONException { if ( ids . length = = 0 ) { treturn Collections . emptyList ( ) ; } tfinal JSONArray keys = new JSONArray ( ) ; tfor ( final String id : ids ) { tassert id ! = null ; tkeys . put ( id ) ; } tfinal JSONObject req = new JSONObject ( ) ; treq . put ( " keys " , keys ) ; tfinal String body = HttpUtils . post ( httpClient , url + " _all_docs?include_docs=true " , req . toString ( ) ) ; treturn toDocuments ( new JSONObject ( body ) ) ; } 
public DatabaseInfo getInfo ( ) throws IOException , JSONException { treturn new DatabaseInfo ( new JSONObject ( HttpUtils . get ( httpClient , turl ) ) ) ; 
public UUID getUuid ( ) throws IOException , JSONException { ttry { tfinal CouchDocument local = getDocument ( " _local/lucene " ) ; 
public UUID getOrCreateUuid ( ) throws IOException , JSONException { tfinal UUID result = getUuid ( ) ; if ( result ! = null ) { treturn result ; } tcreateUuid ( ) ; treturn getUuid ( ) ; } 
private List < DesignDocument > toDesignDocuments ( final JSONObject json ) throws JSONException { tfinal List < DesignDocument > result = new ArrayList < DesignDocument > ( ) ; tfor ( final JSONObject doc : rows ( json ) ) { tresult . add ( new DesignDocument ( doc ) ) ; } treturn result ; } 
private List < CouchDocument > toDocuments ( final JSONObject json ) throws JSONException { tfinal List < CouchDocument > result = new ArrayList < CouchDocument > ( ) ; tfor ( final JSONObject doc : rows ( json ) ) { tresult . add ( new CouchDocument ( doc ) ) ; } treturn result ; } 
private List < JSONObject > rows ( final JSONObject json ) throws JSONException { tfinal List < JSONObject > result = new ArrayList < JSONObject > ( ) ; tfinal JSONArray rows = json . getJSONArray ( " rows " ) ; tfor ( int i = 0 ; i < rows . length ( ) ; i + + ) { tresult . add ( rows . getJSONObject ( i ) . getJSONObject ( " doc " ) ) ; } treturn result ; } 
public long getUpdateSequence ( ) throws JSONException { treturn json . getLong ( " update_seq " ) ; } 
public String getName ( ) throws JSONException { treturn json . getString ( " db_name " ) ; } 
public Analyzer getAnalyzer ( ) throws JSONException { treturn Analyzers . getAnalyzer ( json . optString ( ANALYZER , DEFAULT_ANALYZER ) ) ; 
public ViewSettings getDefaultSettings ( ) throws JSONException { treturn json . has ( DEFAULTS ) ? new ViewSettings ( json . getJSONObject ( DEFAULTS ) ) : ViewSettings . getDefaultSettings ( ) ; 
public String getFunction ( ) throws JSONException { treturn trim ( json . getString ( INDEX ) ) ; } 
public Function compileFunction ( final Context context , tScriptableObject scope ) throws JSONException { treturn context . compileFunction ( scope , getFunction ( ) , null , 0 , null ) ; } 
public Analyzer newAnalyzer ( final String args ) throws JSONException { final JSONObject json = new JSONObject ( args = = null ? " {} " : args ) ; final Analyzer defaultAnalyzer = Analyzers . getAnalyzer ( json . optString ( Constants . DEFAULT_FIELD , " standard " ) ) ; final PerFieldAnalyzerWrapper result = new PerFieldAnalyzerWrapper ( defaultAnalyzer ) ; final Iterator < ? > it = json . keys ( ) ; while ( it . hasNext ( ) ) { final String key = it . next ( ) . toString ( ) ; if ( Constants . DEFAULT_FIELD . equals ( key ) ) continue ; result . addAnalyzer ( key , Analyzers . getAnalyzer ( json . getString ( key ) ) ) ; } return result ; } 
public static Analyzer getAnalyzer ( final String str ) throws JSONException { final String [ ] parts = str . split ( " : " , 2 ) ; final String name = parts [ 0 ] . toUpperCase ( ) ; final String args = parts . length = = 2 ? parts [ 1 ] : null ; return Analyzers . valueOf ( name ) . newAnalyzer ( args ) ; } 
public abstract Analyzer newAnalyzer ( final String args ) throws JSONException ; } 
public static void sendJSONError ( final HttpServletRequest request , final HttpServletResponse response , final int code , final String reason ) throws IOException , JSONException { final JSONObject obj = new JSONObject ( ) ; obj . put ( " reason " , reason ) ; sendJSONError ( request , response , code , obj ) ; } 
public static void sendJSONError ( final HttpServletRequest request , final HttpServletResponse response , final int code , final JSONObject error ) throws IOException , JSONException { error . put ( " code " , code ) ; setResponseContentTypeAndEncoding ( request , response ) ; response . setHeader ( HttpHeaders . CACHE_CONTROL , " must-revalidate,no-cache,no-store " ) ; response . setStatus ( code ) ; final Writer writer = response . getWriter ( ) ; try { writer . write ( error . toString ( ) ) ; 
public static void writeJson ( final HttpServletRequest req , final HttpServletResponse resp , final JSONObject json ) throws IOException { setResponseContentTypeAndEncoding ( req , resp ) ; final Writer writer = resp . getWriter ( ) ; try { writer . write ( json . toString ( ) + " r " ) ; 
public static void writeJsonSuccess ( final HttpServletRequest req , final HttpServletResponse resp ) throws IOException { setResponseContentTypeAndEncoding ( req , resp ) ; final Writer writer = resp . getWriter ( ) ; try { writer . write ( " { \" ok \" , true} r " ) ; 
public static Field token ( final String name , final String value , final boolean store ) { return new Field ( name , 
private CouchDocument doc ( final String json ) throws JSONException { return new CouchDocument ( new JSONObject ( json ) ) ; } 
private View view ( final String fun ) throws JSONException { final JSONObject json = new JSONObject ( ) ; json . put ( " index " , fun ) ; return new View ( json ) ; } 
public void testEscapedChars ( ) throws Exception { final String str = " { \" seq \" :1503, \" id \" : \" 11dca825e8b19e40bd675345e05afa24 \" , \" changes \" :[{ \" rev \" : \" 2-bb1fba3e33ed2e8b78412fe27c8c6474 \" }], \" doc \" :{ \" _id \" : \" 11dca825e8b19e40bd675345e05afa24 \" , \" _rev \" : \" 2-bb1fba3e33ed2e8b78412fe27c8c6474 \" , \" query_params \" :{ \" { \\ \" action \\ \" : \\ \" answer \\ \" , \\ \" session-id \\ \" :41, \\ \" answer \\ \" :5} \" : \" \" }, \" stack_trace \" : \" File \\ \" /usr/local/lib/python2.6/dist-packages/Django-1.2.1-py2.6.egg/django/core/handlers/base.py \\ \" , line 95, in get_response \\ n response = middleware_method(request, callback, callback_args, callback_kwargs) \\ n File \\ \" /var/src/bhoma/bhoma/middleware.py \\ \" , line 37, in process_view \\ n return login_required(view_func)(request, *view_args, **view_kwargs) \\ n File \\ \" /usr/local/lib/python2.6/dist-packages/Django-1.2.1-py2.6.egg/django/contrib/auth/decorators.py \\ \" , line 25, in _wrapped_view \\ n return view_func(request, *args, **kwargs) \\ n File \\ \" /var/src/bhoma/bhoma/apps/xforms/views.py \\ \" , line 74, in player_proxy \\ n response, errors = post_data(data, settings.XFORMS_PLAYER_URL, content_type= \\ \" text/json \\ \" ) \\ n File \\ \" /var/src/bhoma/bhoma/utils/post.py \\ \" , line 34, in post_data \\ \" , \" doc_type \" : \" ExceptionRecord \" , \" url \" : \" http:10.10.10.10/xforms/player_proxy \" , \" clinic_id \" : \" 5010110 \" , \" date \" : \" 2010-09-08T14:39:11Z \" , \" message \" : \" [Errno 24] Too many open files: '/tmp/tmp8xIQb7' \" , \" type \" : \" <type 'exceptions.IOError'> \" }} " ; new JSONObject ( str ) ; } 
public void notValidDocument ( ) throws Exception { new CouchDocument ( new JSONObject ( " {} " ) ) ; } 
public void validDocument ( ) throws Exception { final CouchDocument doc = new CouchDocument ( new JSONObject ( " {_id: \" hello \" } " ) ) ; assertThat ( doc . getId ( ) , is ( " hello " ) ) ; } 
public void asJson ( ) throws Exception { final JSONObject json = new JSONObject ( " {_id: \" hello \" } " ) ; final CouchDocument doc = new CouchDocument ( json ) ; assertThat ( doc . asJson ( ) , is ( json ) ) ; } 
public void notDesignDocument ( ) throws Exception { new DesignDocument ( new JSONObject ( " {_id: \" hello \" } " ) ) ; } 
public void noViews ( ) throws Exception { final DesignDocument ddoc = new DesignDocument ( new JSONObject ( " {_id: \" _design/hello \" } " ) ) ; assertThat ( ddoc . getAllViews ( ) . size ( ) , is ( 0 ) ) ; } 
public void views ( ) throws Exception { final JSONObject view = new JSONObject ( ) ; view . put ( " index " , " function(doc) { return null; } " ) ; final JSONObject fulltext = new JSONObject ( ) ; fulltext . put ( " foo " , view ) ; final JSONObject json = new JSONObject ( ) ; json . put ( " _id " , " _design/hello " ) ; json . put ( " fulltext " , fulltext ) ; final DesignDocument ddoc = new DesignDocument ( json ) ; assertThat ( ddoc . getView ( " foo " ) , notNullValue ( ) ) ; assertThat ( ddoc . getAllViews ( ) . size ( ) , is ( 1 ) ) ; } 
public void noIndex ( ) throws Exception { new View ( new JSONObject ( " {} " ) ) ; } 
public void index ( ) throws Exception { final JSONObject json = new JSONObject ( ) ; json . put ( " index " , " function(doc) { return null; } " ) ; new View ( json ) ; } 
public void testStandard ( ) throws Exception { assertThat ( Analyzers . getAnalyzer ( " standard " ) , is ( StandardAnalyzer . class ) ) ; } 
public void testFrench ( ) throws Exception { assertThat ( Analyzers . getAnalyzer ( " french " ) , is ( FrenchAnalyzer . class ) ) ; } 
public void testWhitespace ( ) throws Exception { assertThat ( Analyzers . getAnalyzer ( " whitespace " ) , is ( WhitespaceAnalyzer . class ) ) ; } 
public void testPerField ( ) throws Exception { final Analyzer analyzer = Analyzers . getAnalyzer ( " perfield:{name: \" standard \" ,age: \" keyword \" } " ) ; assertThat ( analyzer , is ( PerFieldAnalyzerWrapper . class ) ) ; assertThat ( analyzer . toString ( ) , containsString ( " default=org.apache.lucene.analysis.standard.StandardAnalyzer " ) ) ; assertThat ( analyzer . toString ( ) , containsString ( " name=org.apache.lucene.analysis.standard.StandardAnalyzer " ) ) ; assertThat ( analyzer . toString ( ) , containsString ( " age=org.apache.lucene.analysis.KeywordAnalyzer " ) ) ; } 
public void testPerFieldDefault ( ) throws Exception { final Analyzer analyzer = Analyzers . getAnalyzer ( " perfield:{default: \" keyword \" } " ) ; assertThat ( analyzer , is ( PerFieldAnalyzerWrapper . class ) ) ; assertThat ( analyzer . toString ( ) , containsString ( " default=org.apache.lucene.analysis.KeywordAnalyzer " ) ) ; } 
public void admin ( final HttpServletRequest req , tfinal HttpServletResponse resp ) throws IOException , JSONException { tfinal IndexState state = getState ( req , resp ) ; if ( state = = null ) treturn ; tfinal String command = new PathParts ( req ) . getCommand ( ) ; if ( " _expunge " . equals ( command ) ) { tlogger . info ( " Expunging deletes from " + state ) ; tstate . writer . expungeDeletes ( false ) ; tresp . setStatus ( 202 ) ; tServletUtils . sendJsonSuccess ( req , resp ) ; treturn ; } if ( " _optimize " . equals ( command ) ) { tlogger . info ( " Optimizing " + state ) ; tstate . writer . optimize ( false ) ; tresp . setStatus ( 202 ) ; tServletUtils . sendJsonSuccess ( req , resp ) ; treturn ; } tServletUtils . sendJsonError ( req , resp , 400 , " bad_request " ) ; } 
private IndexState getState ( final HttpServletRequest req , tfinal HttpServletResponse resp ) throws IOException , JSONException { tfinal View view = paths . get ( toPath ( req ) ) ; if ( view = = null ) { tServletUtils . sendJsonError ( req , resp , 400 , " no_such_view " ) ; treturn null ; } tfinal IndexState result = states . get ( view ) ; if ( result = = null ) { tServletUtils . sendJsonError ( req , resp , 400 , " no_such_state " ) ; } treturn result ; } 
private void handleWelcomeReq ( final HttpServletRequest req , tfinal HttpServletResponse resp ) throws ServletException , tIOException , JSONException { final Package p = this . getClass ( ) . getPackage ( ) ; tfinal JSONObject welcome = new JSONObject ( ) ; twelcome . put ( " couchdb-lucene " , " Welcome " ) ; twelcome . put ( " version " , p . getImplementationVersion ( ) ) ; tServletUtils . sendJson ( req , resp , welcome ) ; } 
public static void sendJsonError ( final HttpServletRequest request , final HttpServletResponse response , final int code , final String reason ) throws IOException , JSONException { final JSONObject obj = new JSONObject ( ) ; obj . put ( " reason " , reason ) ; sendJsonError ( request , response , code , obj ) ; } 
public static void sendJsonError ( final HttpServletRequest request , final HttpServletResponse response , final int code , final JSONObject error ) throws IOException , JSONException { setResponseContentTypeAndEncoding ( request , response ) ; response . setHeader ( HttpHeaders . CACHE_CONTROL , " must-revalidate,no-cache,no-store " ) ; response . setStatus ( code ) ; error . put ( " code " , code ) ; final Writer writer = response . getWriter ( ) ; try { writer . write ( error . toString ( ) ) ; 
public static void sendJson ( final HttpServletRequest req , final HttpServletResponse resp , final JSONObject json ) throws IOException { setResponseContentTypeAndEncoding ( req , resp ) ; final Writer writer = resp . getWriter ( ) ; try { writer . write ( json . toString ( ) + " r " ) ; 
public static void sendJsonSuccess ( final HttpServletRequest req , final HttpServletResponse resp ) throws IOException { setResponseContentTypeAndEncoding ( req , resp ) ; final Writer writer = resp . getWriter ( ) ; try { writer . write ( " { \" ok \" , true} r " ) ; 
private Scriptable convertObject ( final JSONObject obj ) throws JSONException { if ( obj = = JSONObject . NULL ) { treturn null ; } final Scriptable result = context . newObject ( scope ) ; final Iterator < ? > it = obj . keys ( ) ; while ( it . hasNext ( ) ) { final String key = ( String ) it . next ( ) ; final Object value = obj . get ( key ) ; ScriptableObject . putProperty ( result , key , convert ( value ) ) ; } return result ; } 
public static void main ( String [ ] args ) throws Exception { final HierarchicalINIConfiguration configuration = new HierarchicalINIConfiguration ( Main . class . getClassLoader ( ) . getResource ( " couchdb-lucene.ini " ) ) ; configuration . setReloadingStrategy ( new FileChangedReloadingStrategy ( ) ) ; final File dir = new File ( configuration . getString ( " lucene.dir " , " indexes " ) ) ; if ( ! dir . exists ( ) & & ! dir . mkdir ( ) ) { LOG . error ( " Could not create " + dir . getCanonicalPath ( ) ) ; System . exit ( 1 ) ; } if ( ! dir . canRead ( ) ) { LOG . error ( dir + " is not readable. " ) ; System . exit ( 1 ) ; } if ( ! dir . canWrite ( ) ) { LOG . error ( dir + " is not writable. " ) ; System . exit ( 1 ) ; } LOG . info ( " Index output goes to: " + dir . getCanonicalPath ( ) ) ; final Server server = new Server ( ) ; final SelectChannelConnector connector = new SelectChannelConnector ( ) ; connector . setHost ( configuration . getString ( " lucene.host " , " localhost " ) ) ; connector . setPort ( configuration . getInt ( " lucene.port " , 5985 ) ) ; LOG . info ( " Accepting connections with " + connector ) ; server . setConnectors ( new Connector [ ] { connector } ) ; server . setStopAtShutdown ( true ) ; server . setSendServerVersion ( false ) ; HttpClientFactory . setIni ( configuration ) ; final HttpClient httpClient = HttpClientFactory . getInstance ( ) ; final LuceneServlet servlet = new LuceneServlet ( httpClient , dir , configuration ) ; final Context context = new Context ( server , " / " , Context . NO_SESSIONS | Context . NO_SECURITY ) ; context . addServlet ( new ServletHolder ( servlet ) , " /* " ) ; context . addFilter ( new FilterHolder ( new GzipFilter ( ) ) , " /* " , Handler . DEFAULT ) ; context . setErrorHandler ( new JSONErrorHandler ( ) ) ; server . setHandler ( context ) ; server . start ( ) ; server . join ( ) ; } 
public Query parse ( final String query , final Analyzer analyzer ) throws ParseException { tfinal QueryParser parser = new CustomQueryParser ( Constants . VERSION , tConstants . DEFAULT_FIELD , analyzer ) ; treturn parser . parse ( query ) ; } 
private Analyzer getAnalyzer ( final HttpServletRequest req , final Analyzer defaultAnalyzer ) throws JSONException { tfinal String analyzer = req . getParameter ( " analyzer " ) ; treturn analyzer = = null ? defaultAnalyzer : Analyzers . getAnalyzer ( analyzer ) ; } 
public Query parse ( final String query , final Analyzer analyzer ) throws ParseException , JSONException { tfinal QueryParser parser = new CustomQueryParser ( Constants . VERSION , tConstants . DEFAULT_FIELD , analyzer ) ; treturn parser . parse ( query ) ; } 
public Analyzer analyzer ( final String analyzerName ) throws JSONException { return analyzerName = = null ? this . analyzer : Analyzers . getAnalyzer ( analyzerName ) ; } 
public static void sendJsonSuccess ( final HttpServletRequest req , final HttpServletResponse resp ) throws IOException { setResponseContentTypeAndEncoding ( req , resp ) ; final Writer writer = resp . getWriter ( ) ; try { writer . write ( " { \" ok \" : true} r " ) ; 
private void addAttribute ( final String namespace , final Property property , final Metadata md , final Document doc ) { if ( md . get ( property ) ! = null ) { doc . add ( text ( namespace + property . getName ( ) , md . get ( property ) , false ) ) ; 
public List < CouchDocument > getDocuments ( final String . . . ids ) tthrows IOException , JSONException { if ( ids . length = = 0 ) { treturn Collections . emptyList ( ) ; } tfinal JSONArray keys = new JSONArray ( ) ; tfor ( final String id : ids ) { tassert id ! = null ; tkeys . put ( id ) ; } tfinal JSONObject req = new JSONObject ( ) ; treq . put ( " keys " , keys ) ; tfinal String body = HttpUtils . post ( httpClient , url + " _all_docs?include_docs=true " , req ) ; treturn toDocuments ( new JSONObject ( body ) ) ; } 
public static final String post ( final HttpClient httpClient , final String url , final JSONObject body ) throws IOException { final HttpPost post = new HttpPost ( url ) ; post . setHeader ( " Content-Type " , " application/json " ) ; post . setEntity ( new StringEntity ( body . toString ( ) ) ) ; return execute ( httpClient , post ) ; } 
public Query parse ( final String query , final Operator operator , final Analyzer analyzer ) throws ParseException , JSONException { tfinal QueryParser parser = new CustomQueryParser ( Constants . VERSION , tConstants . DEFAULT_FIELD , analyzer ) ; tparser . setDefaultOperator ( operator ) ; treturn parser . parse ( query ) ; } 
public Analyzer newAnalyzer ( final String args ) { return new SnowballAnalyzer ( Constants . VERSION , args ) ; } 
public void testWord ( ) throws IOException { parse ( " example.doc " , " application/msword " , " bar " ) ; assertThat ( doc . getField ( " bar " ) , not ( nullValue ( ) ) ) ; assertThat ( doc . get ( " bar " ) , containsString ( " 576 dsf45 d56 dsgh " ) ) ; } 
public static void main ( String [ ] args ) throws Exception { final HierarchicalINIConfiguration configuration = new HierarchicalINIConfiguration ( Main . class . getClassLoader ( ) . getResource ( " couchdb-lucene.ini " ) ) ; configuration . setReloadingStrategy ( new FileChangedReloadingStrategy ( ) ) ; final File dir = new File ( configuration . getString ( " lucene.dir " , " indexes " ) ) ; cleanLocks ( dir ) ; if ( ! dir . exists ( ) & & ! dir . mkdir ( ) ) { LOG . error ( " Could not create " + dir . getCanonicalPath ( ) ) ; System . exit ( 1 ) ; } if ( ! dir . canRead ( ) ) { LOG . error ( dir + " is not readable. " ) ; System . exit ( 1 ) ; } if ( ! dir . canWrite ( ) ) { LOG . error ( dir + " is not writable. " ) ; System . exit ( 1 ) ; } LOG . info ( " Index output goes to: " + dir . getCanonicalPath ( ) ) ; final Server server = new Server ( ) ; final SelectChannelConnector connector = new SelectChannelConnector ( ) ; connector . setHost ( configuration . getString ( " lucene.host " , " localhost " ) ) ; connector . setPort ( configuration . getInt ( " lucene.port " , 5985 ) ) ; LOG . info ( " Accepting connections with " + connector ) ; server . setConnectors ( new Connector [ ] { connector } ) ; server . setStopAtShutdown ( true ) ; server . setSendServerVersion ( false ) ; HttpClientFactory . setIni ( configuration ) ; final HttpClient httpClient = HttpClientFactory . getInstance ( ) ; final LuceneServlet servlet = new LuceneServlet ( httpClient , dir , configuration ) ; final Context context = new Context ( server , " / " , Context . NO_SESSIONS | Context . NO_SECURITY ) ; context . addServlet ( new ServletHolder ( servlet ) , " /* " ) ; context . addFilter ( new FilterHolder ( new GzipFilter ( ) ) , " /* " , Handler . DEFAULT ) ; context . setErrorHandler ( new JSONErrorHandler ( ) ) ; server . setHandler ( context ) ; server . start ( ) ; server . join ( ) ; } 
private static void cleanLocks ( final File root ) throws IOException { tfinal Iterator it = FileUtils . iterateFiles ( root , tnew String [ ] { " lock " } , true ) ; twhile ( it . hasNext ( ) ) { tfinal File lock = ( File ) it . next ( ) ; 
public static void main ( String [ ] args ) throws Exception { final HierarchicalINIConfiguration configuration = new HierarchicalINIConfiguration ( Main . class . getClassLoader ( ) . getResource ( " couchdb-lucene.ini " ) ) ; configuration . setReloadingStrategy ( new FileChangedReloadingStrategy ( ) ) ; final File dir = new File ( configuration . getString ( " lucene.dir " , " indexes " ) ) ; if ( ! dir . exists ( ) & & ! dir . mkdir ( ) ) { LOG . error ( " Could not create " + dir . getCanonicalPath ( ) ) ; System . exit ( 1 ) ; } if ( ! dir . canRead ( ) ) { LOG . error ( dir + " is not readable. " ) ; System . exit ( 1 ) ; } if ( ! dir . canWrite ( ) ) { LOG . error ( dir + " is not writable. " ) ; System . exit ( 1 ) ; } LOG . info ( " Index output goes to: " + dir . getCanonicalPath ( ) ) ; cleanLocks ( dir ) ; final Server server = new Server ( ) ; final SelectChannelConnector connector = new SelectChannelConnector ( ) ; connector . setHost ( configuration . getString ( " lucene.host " , " localhost " ) ) ; connector . setPort ( configuration . getInt ( " lucene.port " , 5985 ) ) ; LOG . info ( " Accepting connections with " + connector ) ; server . setConnectors ( new Connector [ ] { connector } ) ; server . setStopAtShutdown ( true ) ; server . setSendServerVersion ( false ) ; HttpClientFactory . setIni ( configuration ) ; final HttpClient httpClient = HttpClientFactory . getInstance ( ) ; final LuceneServlet servlet = new LuceneServlet ( httpClient , dir , configuration ) ; final Context context = new Context ( server , " / " , Context . NO_SESSIONS | Context . NO_SECURITY ) ; context . addServlet ( new ServletHolder ( servlet ) , " /* " ) ; context . addFilter ( new FilterHolder ( new GzipFilter ( ) ) , " /* " , Handler . DEFAULT ) ; context . setErrorHandler ( new JSONErrorHandler ( ) ) ; server . setHandler ( context ) ; server . start ( ) ; server . join ( ) ; } 
public synchronized IndexReader borrowReader ( final boolean staleOk ) tthrows IOException , JSONException { tblockForLatest ( staleOk ) ; if ( reader = = null ) { tetag = newEtag ( ) ; } if ( reader ! = null ) { treader . decRef ( ) ; } treader = IndexReader . open ( writer , ! staleOk ) ; if ( readerDirty ) { tetag = newEtag ( ) ; treaderDirty = false ; } treader . incRef ( ) ; treturn reader ; } 
private IndexWriter newWriter ( final Directory dir ) throws IOException { tfinal IndexWriterConfig config = new IndexWriterConfig ( tVersion . LUCENE_30 , Constants . ANALYZER ) ; tfinal LogByteSizeMergePolicy mergePolicy = new LogByteSizeMergePolicy ( ) ; tmergePolicy . setMergeFactor ( ini . getInt ( " lucene.mergeFactor " , 10 ) ) ; tmergePolicy . setUseCompoundFile ( ini . getBoolean ( " lucene.useCompoundFile " , tfalse ) ) ; tconfig . setMergePolicy ( mergePolicy ) ; tconfig . setRAMBufferSizeMB ( ini . getDouble ( " lucene.ramBufferSizeMB " , tIndexWriterConfig . DEFAULT_RAM_BUFFER_SIZE_MB ) ) ; treturn new IndexWriter ( dir , config ) ; } 
public Analyzer newAnalyzer ( final String args ) { return new SimpleAnalyzer ( Constants . VERSION ) ; } 
public Analyzer newAnalyzer ( final String args ) { return new WhitespaceAnalyzer ( Constants . VERSION ) ; } 
public TokenStream tokenStream ( final String fieldName , final Reader reader ) { return new PorterStemFilter ( new LowerCaseTokenizer ( Constants . VERSION , reader ) ) ; } 
public void parse ( final InputStream in , final String contentType , final String fieldName , final Document doc ) throws IOException { final Metadata md = new Metadata ( ) ; md . set ( HttpHeaders . CONTENT_TYPE , contentType ) ; try { Add body text. doc.add(new Field(fieldName, tika.parse(in, md))); } catch (final IOException e) { log.warn("Failed to index an attachment.", e); return; } Add DC attributes. addDublinCoreAttributes(md, doc); } 
public void testWord ( ) throws IOException { parse ( " example.doc " , " application/msword " , " bar " ) ; assertThat ( doc . getField ( " bar " ) , not ( nullValue ( ) ) ) ; } 
private void blockForLatest ( final boolean staleOk ) throws IOException , JSONException { if ( staleOk ) { treturn ; } tfinal UpdateSequence latest = database . getInfo ( ) . getUpdateSequence ( ) ; tsynchronized ( this ) { long imeout = getSearchTimeout ( ) ; 
private UpdateSequence getUpdateSequence ( final Directory dir ) throws IOException { if ( ! IndexReader . indexExists ( dir ) ) { treturn UpdateSequence . BOTTOM ; } treturn getUpdateSequence ( IndexReader . getCommitUserData ( dir ) ) ; } 
private UpdateSequence getUpdateSequence ( final IndexWriter writer ) throws IOException { treturn getUpdateSequence ( writer . getDirectory ( ) ) ; } 
public HttpUriRequest getChangesRequest ( final UpdateSequence since ) tthrows IOException { treturn new HttpGet ( turl 
public UpdateSequence getUpdateSequence ( ) throws JSONException { treturn new UpdateSequence ( json . getString ( " update_seq " ) ) ; } 
private void close ( ) { tthis . closed = true ; tfor ( final IndexState state : states . values ( ) ) { ttry { state . close ( ) ; } catch ( final IOException e ) { logger . warn ( " Error while closing. " , e ) ; } } tstates . clear ( ) ; if ( context ! = null ) { tContext . exit ( ) ; } tlatch . countDown ( ) ; } 
private Couch getCouch ( final HttpServletRequest req ) throws IOException { final Configuration section = ini . getSection ( new PathParts ( req ) . getKey ( ) ) ; final String url = section . containsKey ( " url " ) ? section . getString ( " url " ) : null ; return new Couch ( client , url ) ; } 
private synchronized DatabaseIndexer getIndexer ( final Database database ) throws IOException , JSONException { DatabaseIndexer result = indexers . get ( database ) ; Thread thread = threads . get ( database ) ; if ( result = = null | | thread = = null | | ! thread . isAlive ( ) ) { result = new DatabaseIndexer ( client , root , database , ini ) ; thread = new Thread ( result ) ; thread . start ( ) ; result . awaitInitialization ( ) ; if ( result . isClosed ( ) ) { return null ; } else { indexers . put ( database , result ) ; threads . put ( database , thread ) ; } } return result ; } 
private DatabaseIndexer getIndexer ( final HttpServletRequest req ) throws IOException , JSONException { final Couch couch = getCouch ( req ) ; final Database database = couch . getDatabase ( new PathParts ( req ) . getDatabaseName ( ) ) ; return getIndexer ( database ) ; } 
private void handleWelcomeReq ( final HttpServletRequest req , final HttpServletResponse resp ) throws ServletException , IOException , JSONException { final Package p = this . getClass ( ) . getPackage ( ) ; final JSONObject welcome = new JSONObject ( ) ; welcome . put ( " couchdb-lucene " , " Welcome " ) ; welcome . put ( " version " , p . getImplementationVersion ( ) ) ; ServletUtils . sendJson ( req , resp , welcome ) ; } 
protected void doGet ( final HttpServletRequest req , final HttpServletResponse resp ) throws ServletException , IOException { try { doGetInternal ( req , resp ) ; 
protected void doPost ( final HttpServletRequest req , final HttpServletResponse resp ) throws ServletException , IOException { try { doPostInternal ( req , resp ) ; 
public static void main ( String [ ] args ) throws Exception { final Config config = new Config ( ) ; final File dir = config . getDir ( ) ; final Server server = new Server ( ) ; final SelectChannelConnector connector = new SelectChannelConnector ( ) ; connector . setHost ( config . getConfiguration ( ) . getString ( " lucene.host " , " localhost " ) ) ; connector . setPort ( config . getConfiguration ( ) . getInt ( " lucene.port " , 5985 ) ) ; LOG . info ( " Accepting connections with " + connector ) ; server . setConnectors ( new Connector [ ] { connector } ) ; server . setStopAtShutdown ( true ) ; server . setSendServerVersion ( false ) ; final LuceneServlet servlet = new LuceneServlet ( config . getClient ( ) , dir , config . getConfiguration ( ) ) ; final Context context = new Context ( server , " / " , Context . NO_SESSIONS | Context . NO_SECURITY ) ; context . addServlet ( new ServletHolder ( servlet ) , " /* " ) ; context . addFilter ( new FilterHolder ( new GzipFilter ( ) ) , " /* " , Handler . DEFAULT ) ; context . setErrorHandler ( new JSONErrorHandler ( ) ) ; server . setHandler ( context ) ; server . start ( ) ; server . join ( ) ; } 
public final File getDir ( ) throws IOException { final File dir = new File ( this . configuration . getString ( LUCENE_DIR , DEFAULT_DIR ) ) ; if ( ! dir . exists ( ) & & ! dir . mkdir ( ) ) { throw new IOException ( " Could not create " + dir . getCanonicalPath ( ) ) ; } if ( ! dir . canRead ( ) ) { throw new IOException ( dir + " is not readable. " ) ; } if ( ! dir . canWrite ( ) ) { throw new IOException ( dir + " is not writable. " ) ; } LOG . info ( " Index output goes to: " + dir . getCanonicalPath ( ) ) ; return dir ; } 
public final HttpClient getClient ( ) throws MalformedURLException { HttpClientFactory . setIni ( this . configuration ) ; return HttpClientFactory . getInstance ( ) ; } 
public void testGetConfiguration ( ) { try { final Config config = new Config ( ) ; 
public void testGetDir ( ) { try { final Config config = new Config ( ) ; 
public void testGetClient ( ) { try { final Config config = new Config ( ) ; 
public void handle ( String target , HttpServletRequest request , HttpServletResponse response , int dispatch ) throws IOException { HttpConnection connection = HttpConnection . getCurrentConnection ( ) ; connection . getRequest ( ) . setHandled ( true ) ; final String reason = connection . getResponse ( ) . getReason ( ) ; try { if ( reason ! = null & & reason . startsWith ( " { " ) ) { 
private List < CouchDocument > toDocuments ( final JSONObject json ) throws JSONException { tfinal List < CouchDocument > result = new ArrayList < CouchDocument > ( ) ; tfor ( final JSONObject doc : rows ( json ) ) { tresult . add ( doc = = null ? null : new CouchDocument ( doc ) ) ; } treturn result ; } 
private List < JSONObject > rows ( final JSONObject json ) throws JSONException { tfinal List < JSONObject > result = new ArrayList < JSONObject > ( ) ; tfinal JSONArray rows = json . getJSONArray ( " rows " ) ; tfor ( int i = 0 ; i < rows . length ( ) ; i + + ) { tresult . add ( rows . getJSONObject ( i ) . optJSONObject ( " doc " ) ) ; } treturn result ; } 
public static final String post ( final HttpClient httpClient , final String url , final JSONObject body ) throws IOException { final HttpPost post = new HttpPost ( url ) ; post . setHeader ( " Content-Type " , " application/json " ) ; post . setEntity ( new StringEntity ( body . toString ( ) , " UTF-8 " ) ) ; return execute ( httpClient , post ) ; } 
public static final int put ( final HttpClient httpClient , final String url , final String body ) throws IOException { final HttpPut put = new HttpPut ( url ) ; if ( body ! = null ) { put . setHeader ( " Content-Type " , Constants . CONTENT_TYPE ) ; put . setEntity ( new StringEntity ( body , " UTF-8 " ) ) ; } return httpClient . execute ( put , new StatusCodeResponseHandler ( ) ) ; } 
public static final String post ( final HttpClient httpClient , final String url , final JSONObject body ) throws IOException { final HttpPost post = new HttpPost ( url ) ; post . setHeader ( " Content-Type " , Constants . APPLICATION_JSON ) ; post . setEntity ( new StringEntity ( body . toString ( ) , " UTF-8 " ) ) ; return execute ( httpClient , post ) ; } 
public static final int put ( final HttpClient httpClient , final String url , final String body ) throws IOException { final HttpPut put = new HttpPut ( url ) ; if ( body ! = null ) { put . setHeader ( " Content-Type " , Constants . APPLICATION_JSON ) ; put . setEntity ( new StringEntity ( body , " UTF-8 " ) ) ; } return httpClient . execute ( put , new StatusCodeResponseHandler ( ) ) ; } 
private UpdateSequence getUpdateSequence ( final Directory dir ) throws IOException { if ( ! IndexReader . indexExists ( dir ) ) { treturn UpdateSequence . START ; } treturn getUpdateSequence ( IndexReader . getCommitUserData ( dir ) ) ; } 
public HttpUriRequest getChangesRequest ( final UpdateSequence since ) tthrows IOException { tfinal String uri = url + " _changes?feed=continuous&heartbeat=15000&include_docs=true " ; treturn new HttpGet ( since . appendSince ( uri ) ) ; } 
public UpdateSequence getUpdateSequence ( ) throws JSONException { treturn UpdateSequence . parseUpdateSequence ( json . getString ( " update_seq " ) ) ; } 
public String appendSince ( final String url ) { treturn url + " ?since= " + since ; } 
public String appendSince ( final String url ) { treturn url + " ?since= " + seq ; } 
public boolean isEarlierThan ( final UpdateSequence other ) { if ( other = = START ) { treturn false ; } if ( other instanceof CouchDbUpdateSequence ) { treturn this . seq < ( ( CouchDbUpdateSequence ) other ) . seq ; } tthrow new IllegalArgumentException ( other + " is not compatible. " ) ; } 
public boolean isLaterThan ( final UpdateSequence other ) { if ( other = = START ) { treturn true ; } if ( other instanceof CouchDbUpdateSequence ) { treturn this . seq > ( ( CouchDbUpdateSequence ) other ) . seq ; } tthrow new IllegalArgumentException ( other + " is not compatible. " ) ; } 
public boolean isEarlierThan ( final UpdateSequence other ) { treturn true ; } 
public boolean isLaterThan ( final UpdateSequence other ) { treturn false ; } 
public static UpdateSequence parseUpdateSequence ( final String str ) { if ( str . matches ( " [0-9]+ " ) ) { treturn new CouchDbUpdateSequence ( str ) ; } if ( str . matches ( " [0-9]+-[0-9a-zA-Z_-]+ " ) ) { treturn new BigCouchUpdateSequence ( str ) ; } tthrow new IllegalArgumentException ( str + " not recognized. " ) ; } 
public abstract String appendSince ( final String url ) ; public abstract boolean isEarlierThan ( final UpdateSequence other ) ; public abstract boolean isLaterThan ( final UpdateSequence other ) ; } 
public abstract boolean isEarlierThan ( final UpdateSequence other ) ; public abstract boolean isLaterThan ( final UpdateSequence other ) ; } 
private void close ( ) { tthis . closed = true ; tfor ( final IndexState state : states . values ( ) ) { ttry { state . close ( ) ; } catch ( final IOException e ) { logger . warn ( " Error while closing. " , e ) ; } } tstates . clear ( ) ; if ( context ! = null ) { tContext . exit ( ) ; tcontext = null ; } tlatch . countDown ( ) ; } 
private Couch getCouch ( final HttpServletRequest req ) throws IOException { tfinal String sectionName = new PathParts ( req ) . getKey ( ) ; tfinal Configuration section = ini . getSection ( sectionName ) ; if ( ! section . containsKey ( " url " ) ) { tthrow new FileNotFoundException ( sectionName + " is missing or has no url parameter. " ) ; } treturn new Couch ( client , section . getString ( " url " ) ) ; } 
private void addAttachment ( final RhinoAttachment attachment , final String id , final Database database , final Document out ) throws IOException { final ResponseHandler < Void > handler = new ResponseHandler < Void > ( ) { public Void handleResponse ( final HttpResponse response ) throws ClientProtocolException , IOException { final HttpEntity entity = response . getEntity ( ) ; try { tTika . INSTANCE . parse ( entity . getContent ( ) , entity . getContentType ( ) . getValue ( ) , attachment . fieldName , out ) ; } finally { tentity . consumeContent ( ) ; } return null ; } } ; database . handleAttachment ( id , attachment . attachmentName , handler ) ; } 
public Void handleResponse ( final HttpResponse response ) throws ClientProtocolException , IOException { final HttpEntity entity = response . getEntity ( ) ; try { tTika . INSTANCE . parse ( entity . getContent ( ) , entity . getContentType ( ) . getValue ( ) , attachment . fieldName , out ) ; } finally { tentity . consumeContent ( ) ; } return null ; } 
public String appendSince ( final String url ) { treturn url + " &since= " + since ; } 
public String appendSince ( final String url ) { treturn url + " &since= " + seq ; } 
public void testSingleDocumentReturn ( ) throws Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) {return new Document();} " ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hello \" } " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 1 ) ) ; assertThat ( result . iterator ( ) . next ( ) . get ( " _id " ) , is ( " hello " ) ) ; } 
public void testMultipleDocumentReturn ( ) throws Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) {var ret = new Array(); ret.push(new Document()); ret.push(new Document()); return ret;} " ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hello \" } " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 2 ) ) ; assertThat ( result . iterator ( ) . next ( ) . get ( " _id " ) , is ( " hello " ) ) ; } 
public void testAdd ( ) throws Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) {var ret=new Document(); ret.add(doc.key); return ret;} " ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hello \" , key: \" value \" } " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 1 ) ) ; assertThat ( result . iterator ( ) . next ( ) . get ( Constants . DEFAULT_FIELD ) , is ( " value " ) ) ; } 
public void testForLoopOverObject ( ) throws Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) {var ret=new Document(); for (var key in doc) { ret.add(doc[key]); } return ret; } " ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hello \" , key: \" value \" } " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 1 ) ) ; assertThat ( result . iterator ( ) . next ( ) . get ( " _id " ) , is ( " hello " ) ) ; assertThat ( result . iterator ( ) . next ( ) . getValues ( Constants . DEFAULT_FIELD ) [ 0 ] , is ( " hello " ) ) ; assertThat ( result . iterator ( ) . next ( ) . getValues ( Constants . DEFAULT_FIELD ) [ 1 ] , is ( " value " ) ) ; } 
public void testForLoopOverArray ( ) throws Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) {var ret=new Document(); for (var key in doc.arr) {ret.add(doc.arr[key]); } return ret; } " ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hello \" , arr:[0,1,2,3]} " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 1 ) ) ; assertThat ( result . iterator ( ) . next ( ) . get ( " _id " ) , is ( " hello " ) ) ; assertThat ( result . iterator ( ) . next ( ) . getValues ( Constants . DEFAULT_FIELD ) [ 0 ] , is ( " 0 " ) ) ; assertThat ( result . iterator ( ) . next ( ) . getValues ( Constants . DEFAULT_FIELD ) [ 1 ] , is ( " 1 " ) ) ; assertThat ( result . iterator ( ) . next ( ) . getValues ( Constants . DEFAULT_FIELD ) [ 2 ] , is ( " 2 " ) ) ; assertThat ( result . iterator ( ) . next ( ) . getValues ( Constants . DEFAULT_FIELD ) [ 3 ] , is ( " 3 " ) ) ; } 
public void testForEverything ( ) throws Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) {var ret=new Document(); " + " function idx(obj) {for (var key in obj) " + " {switch (typeof obj[key]) {case 'object':idx(obj[key]); break; " + " case 'function': break; default: ret.add(obj[key]); break;} } }; idx(doc); return ret; } " ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hello \" , l1: { l2: {l3:[ \" v3 \" , \" v4 \" ]}}} " ) , settings ( ) , null ) ; assertThat ( result . iterator ( ) . next ( ) . getValues ( Constants . DEFAULT_FIELD ) [ 0 ] , is ( " hello " ) ) ; assertThat ( result . iterator ( ) . next ( ) . getValues ( Constants . DEFAULT_FIELD ) [ 1 ] , is ( " v3 " ) ) ; assertThat ( result . iterator ( ) . next ( ) . getValues ( Constants . DEFAULT_FIELD ) [ 2 ] , is ( " v4 " ) ) ; } 
public void testNullReturn ( ) throws Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) {return null;} " ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hello \" } " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 0 ) ) ; } 
public void testUndefinedReturn ( ) throws Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) {return doc.nope;} " ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hello \" } " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 0 ) ) ; } 
public void testRuntimeException ( ) throws Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) {throw {bad : \" stuff \" }} " ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hello \" } " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 0 ) ) ; } 
public void testNullAddsAreIgnored ( ) throws Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) {var ret=new Document(); ret.add(doc.nope); return ret;} " ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hello \" } " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 1 ) ) ; } 
public void testQuoteRemoval ( ) throws Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " \" function(doc) {return new Document();} \" " ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hello \" } " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 1 ) ) ; assertThat ( result . iterator ( ) . next ( ) . get ( " _id " ) , is ( " hello " ) ) ; } 
public void testNoReturnValue ( ) throws Exception { final String fun = " function(doc) { } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hi \" } " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 0 ) ) ; } 
public void testDefaultValue ( ) throws Exception { final String fun = " function(doc) { var ret=new Document(); ret.add(doc['arr'].join(' ')); return ret; } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hi \" , arr:[ \" 1 \" , \" 2 \" ]} " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 1 ) ) ; assertThat ( result . iterator ( ) . next ( ) . get ( " default " ) , is ( " 1 2 " ) ) ; } 
public void testNullValue ( ) throws Exception { final String fun = " function(doc) { var ret=new Document(); ret.add(doc.foo); return ret; } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hi \" , foo:null} " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 1 ) ) ; assertThat ( result . iterator ( ) . next ( ) . get ( " foo " ) , is ( nullValue ( ) ) ) ; } 
public void testLongValue ( ) throws Exception { final String fun = " function(doc) { var ret=new Document(); ret.add(12, {type: \" long \" , field: \" num \" }); return ret; } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hi \" } " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 1 ) ) ; assertThat ( result . iterator ( ) . next ( ) . getFieldable ( " num " ) , is ( NumericField . class ) ) ; } 
public void testDateString ( ) throws Exception { final String fun = " function(doc) { var ret=new Document(); ret.add( \" 2009-01-01 \" , {type: \" date \" , field: \" num \" }); return ret; } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hi \" } " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 1 ) ) ; assertThat ( result . iterator ( ) . next ( ) . getFieldable ( " num " ) , is ( NumericField . class ) ) ; } 
public void testDateObject ( ) throws Exception { final String fun = " function(doc) { var ret=new Document(); ret.add(new Date(2010,8,13), {type: \" date \" , field: \" num \" }); return ret; } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hi \" } " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 1 ) ) ; assertThat ( result . iterator ( ) . next ( ) . getFieldable ( " num " ) , is ( NumericField . class ) ) ; assertThat ( ( Long ) ( ( NumericField ) result . iterator ( ) . next ( ) . getFieldable ( " num " ) ) . getNumericValue ( ) , is ( 1284332400000L ) ) ; } 
public void testDateObject2 ( ) throws Exception { final String fun = " function(doc) { var ret=new Document(); ret.add(new Date( \" January 6, 1972 16:05:00 \" ), {type: \" date \" , field: \" num \" }); return ret; } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hi \" } " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 1 ) ) ; assertThat ( result . iterator ( ) . next ( ) . getFieldable ( " num " ) , is ( NumericField . class ) ) ; assertThat ( ( Long ) ( ( NumericField ) result . iterator ( ) . next ( ) . getFieldable ( " num " ) ) . getNumericValue ( ) , is ( 63561900000L ) ) ; } 
public void testParseInt ( ) throws Exception { final String fun = " function(doc) { var ret=new Document(); ret.add(parseInt( \" 12.5 \" ), {type: \" int \" , field: \" num \" }); return ret; } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hi \" } " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 1 ) ) ; assertThat ( result . iterator ( ) . next ( ) . getFieldable ( " num " ) , is ( NumericField . class ) ) ; } 
public void testConditionalOnNulls ( ) throws Exception { tfinal String fun = " function(doc) { if (doc.foo && doc.bar) { return new Document(); }; return null; } " ; tfinal DocumentConverter converter = new DocumentConverter ( context , tview ( fun ) ) ; tfinal Collection < Document > result = converter . convert ( tdoc ( " {_id: \" hi \" , foo: null, bar: null} " ) , settings ( ) , null ) ; tassertThat ( result . size ( ) , is ( 0 ) ) ; } 
private IndexWriter newWriter ( final Directory dir ) throws IOException { tfinal IndexWriterConfig config = new IndexWriterConfig ( tConstants . VERSION , Constants . ANALYZER ) ; tfinal LogByteSizeMergePolicy mergePolicy = new LogByteSizeMergePolicy ( ) ; tmergePolicy . setMergeFactor ( ini . getInt ( " lucene.mergeFactor " , 10 ) ) ; tmergePolicy . setUseCompoundFile ( ini . getBoolean ( " lucene.useCompoundFile " , tfalse ) ) ; tconfig . setMergePolicy ( mergePolicy ) ; tconfig . setRAMBufferSizeMB ( ini . getDouble ( " lucene.ramBufferSizeMB " , tIndexWriterConfig . DEFAULT_RAM_BUFFER_SIZE_MB ) ) ; treturn new IndexWriter ( dir , config ) ; } 
public UUID getUuid ( ) throws JSONException , IOException { return database . getUuid ( ) ; } 
public void testWord ( ) throws IOException { parse ( " example.doc " , " application/msword " , " bar " ) ; assertThat ( doc . getField ( " bar " ) , not ( nullValue ( ) ) ) ; assertThat ( doc . get ( " bar " ) , containsString ( " The express mission of the organization " ) ) ; } 
public Analyzer newAnalyzer ( final String args ) { return new ClassicAnalyzer ( Constants . VERSION ) ; } 
public void testEmailAddresses ( ) throws Exception { assertThat ( analyze ( " standard " , " foo@bar.com " ) , is ( new String [ ] { " foo " , " bar.com " } ) ) ; assertThat ( analyze ( " classic " , " foo@bar.com " ) , is ( new String [ ] { " foo@bar.com " } ) ) ; } 
private String [ ] analyze ( final String analyzerName , final String text ) throws Exception { final Analyzer analyzer = Analyzers . getAnalyzer ( analyzerName ) ; final TokenStream stream = analyzer . tokenStream ( " default " , new StringReader ( text ) ) ; stream . reset ( ) ; final List < String > result = new ArrayList < String > ( ) ; while ( stream . incrementToken ( ) ) { final CharTermAttribute c = stream . getAttribute ( CharTermAttribute . class ) ; result . add ( c . toString ( ) ) ; } return result . toArray ( new String [ 0 ] ) ; } 
public Query parse ( final String query , final Operator operator , final Analyzer analyzer ) throws ParseException , JSONException { tfinal QueryParser parser = new CustomQueryParser ( Constants . VERSION , tConstants . DEFAULT_FIELD , analyzer ) ; tparser . setDefaultOperator ( operator ) ; tparser . setAllowLeadingWildcard ( ini . getBoolean ( " lucene.allowLeadingWildcard " , false ) ) ; treturn parser . parse ( query ) ; } 
public Query parse ( final String query , final Operator operator , final Analyzer analyzer ) throws ParseException , JSONException { tfinal QueryParser parser = new CustomQueryParser ( Constants . VERSION , tConstants . DEFAULT_FIELD , analyzer ) ; tparser . setDefaultOperator ( operator ) ; tparser . setAllowLeadingWildcard ( ini . getBoolean ( " lucene.allowLeadingWildcard " , false ) ) ; tparser . setLowercaseExpandedTerms ( ini . getBoolean ( " lucene.lowercaseExpandedTerms " , true ) ) ; treturn parser . parse ( query ) ; } 
private void blockForLatest ( final boolean staleOk ) throws IOException , JSONException { if ( staleOk ) { treturn ; } tfinal UpdateSequence latest = database . getLastSequence ( ) ; tsynchronized ( this ) { long imeout = getSearchTimeout ( ) ; 
public UpdateSequence getLastSequence ( ) throws IOException , JSONException { final JSONObject result = new JSONObject ( HttpUtils . get ( httpClient , url + " _changes?limit=0&descending=true " ) ) ; return UpdateSequence . parseUpdateSequence ( result . getString ( " last_seq " ) ) ; } 
public View getView ( final String name ) throws JSONException { if ( fulltext = = null ) treturn null ; tfinal JSONObject json = fulltext . optJSONObject ( name ) ; treturn json = = null ? null : new View ( getId ( ) + " / " + name , json ) ; } 
public Map < String , View > getAllViews ( ) throws JSONException { if ( fulltext = = null ) treturn Collections . emptyMap ( ) ; tfinal Map < String , View > result = new HashMap < String , View > ( ) ; tfinal Iterator < ? > it = fulltext . keys ( ) ; twhile ( it . hasNext ( ) ) { final Object key = it . next ( ) ; tfinal String name = ( String ) key ; tfinal View view = getView ( name ) ; if ( view ! = null ) { tresult . put ( name , view ) ; } } treturn result ; } 
public String toString ( ) { treturn String . format ( " View[name=%s, digest=%s] " , name , getDigest ( ) ) ; } 
private View view ( final String fun ) throws JSONException { final JSONObject json = new JSONObject ( ) ; json . put ( " index " , fun ) ; return new View ( null , json ) ; } 
public void noIndex ( ) throws Exception { new View ( null , new JSONObject ( " {} " ) ) ; } 
public void index ( ) throws Exception { final JSONObject json = new JSONObject ( ) ; json . put ( " index " , " function(doc) { return null; } " ) ; new View ( null , json ) ; } 
public void estJSONStringify ( ) throws Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) {var ret=new Document(); " + " ret.add(JSON.stringify({ \" foo \" : \" bar \" }), { \" field \" : \" s \" , \" store \" : \" yes \" }); return ret;} " ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hello \" } " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 1 ) ) ; assertThat ( result . iterator ( ) . next ( ) . getValues ( " s " ) [ 0 ] , is ( " { \" foo \" : \" bar \" } " ) ) ; } 
public void fieldNameWithDashes ( ) throws Exception { final Query q = parser . parse ( " foo-bar:baz " ) ; assertThat ( q , is ( TermQuery . class ) ) ; } 
public void setExpectations ( String field , int numTerms , tboolean storeOffsets , boolean storePositions ) { tcurrentObj = new JSONObject ( ) ; ttry { tresult . put ( field , currentObj ) ; 
public void map ( String term , int frequency , TermVectorOffsetInfo [ ] offsets , tint [ ] positions ) { ttry { tfinal JSONObject field = new JSONObject ( ) ; 
public void admin ( final HttpServletRequest req , tfinal HttpServletResponse resp ) throws IOException , JSONException { tfinal IndexState state = getState ( req , resp ) ; if ( state = = null ) treturn ; tfinal String command = new PathParts ( req ) . getCommand ( ) ; if ( " _expunge " . equals ( command ) ) { tlogger . info ( " Expunging deletes from " + state ) ; tstate . writer . forceMergeDeletes ( false ) ; tresp . setStatus ( 202 ) ; tServletUtils . sendJsonSuccess ( req , resp ) ; treturn ; } if ( " _optimize " . equals ( command ) ) { tlogger . info ( " Optimizing " + state ) ; tstate . writer . forceMerge ( 1 , false ) ; tresp . setStatus ( 202 ) ; tServletUtils . sendJsonSuccess ( req , resp ) ; treturn ; } tServletUtils . sendJsonError ( req , resp , 400 , " bad_request " ) ; } 
public void testPDF ( ) throws IOException { parse ( " paxos-simple.pdf " , " application/pdf " , " foo " ) ; assertThat ( doc . getFieldable ( " foo " ) , not ( nullValue ( ) ) ) ; } 
public void testXML ( ) throws IOException { parse ( " example.xml " , " text/xml " , " bar " ) ; assertThat ( doc . getFieldable ( " bar " ) , not ( nullValue ( ) ) ) ; } 
public void testWord ( ) throws IOException { parse ( " example.doc " , " application/msword " , " bar " ) ; assertThat ( doc . getFieldable ( " bar " ) , not ( nullValue ( ) ) ) ; assertThat ( doc . get ( " bar " ) , containsString ( " The express mission of the organization " ) ) ; } 
public static UpdateSequence parseUpdateSequence ( final String str ) { if ( str . matches ( " [0-9]+ " ) ) { treturn new CouchDbUpdateSequence ( str ) ; } tString packedSeqs ; if ( ( packedSeqs = extractPackedSeqs ( BC3 , str ) ) ! = null ) { treturn new BigCouchUpdateSequence ( str , packedSeqs ) ; } if ( ( packedSeqs = extractPackedSeqs ( BC4 , str ) ) ! = null ) { treturn new BigCouchUpdateSequence ( str , packedSeqs ) ; } tthrow new IllegalArgumentException ( str + " not recognized. " ) ; } 
private static String extractPackedSeqs ( final Pattern p , final String str ) { tfinal Matcher m = p . matcher ( str ) ; if ( m . matches ( ) ) { treturn m . group ( 1 ) ; } treturn null ; } 
public void couchdbSequence ( ) { tassertThat ( UpdateSequence . parseUpdateSequence ( " 1234 " ) , notNullValue ( ) ) ; } 
public String appendSince ( final String url ) { ttry { treturn url + " &since= " + URLEncoder . encode ( since , " US-ASCII " ) ; 
private static < T extends AbstractField > T boost ( final T field , final ViewSettings settings ) { field . setOmitNorms ( false ) ; field . setBoost ( settings . getBoost ( ) ) ; return field ; } 
public void fieldNameWithEscapedSpaces ( ) throws Exception { final Query q = parser . parse ( " foo \\ bar:baz " ) ; assertThat ( q , is ( TermQuery . class ) ) ; } 
public void handle ( String target , Request baseRequest , HttpServletRequest request , HttpServletResponse response ) throws IOException { final String reason = baseRequest . getResponse ( ) . getReason ( ) ; try { if ( reason ! = null & & reason . startsWith ( " { " ) ) { 
public static void main ( String [ ] args ) throws Exception { final Config config = new Config ( ) ; final File dir = config . getDir ( ) ; final Server server = new Server ( ) ; final SelectChannelConnector connector = new SelectChannelConnector ( ) ; connector . setHost ( config . getConfiguration ( ) . getString ( " lucene.host " , " localhost " ) ) ; connector . setPort ( config . getConfiguration ( ) . getInt ( " lucene.port " , 5985 ) ) ; LOG . info ( " Accepting connections with " + connector ) ; server . addConnector ( connector ) ; server . setStopAtShutdown ( true ) ; final LuceneServlet servlet = new LuceneServlet ( config . getClient ( ) , dir , config . getConfiguration ( ) ) ; final ServletContextHandler context = new ServletContextHandler ( server , " / " , ServletContextHandler . NO_SESSIONS | ServletContextHandler . NO_SECURITY ) ; context . addServlet ( new ServletHolder ( servlet ) , " /* " ) ; context . addFilter ( new FilterHolder ( new GzipFilter ( ) ) , " /* " , EnumSet . of ( DispatcherType . REQUEST ) ) ; context . setErrorHandler ( new JSONErrorHandler ( ) ) ; server . setHandler ( context ) ; server . start ( ) ; server . join ( ) ; } 
public synchronized IndexReader borrowReader ( final boolean staleOk ) throws IOException , JSONException { blockForLatest ( staleOk ) ; if ( reader = = null ) { etag = newEtag ( ) ; } if ( reader ! = null ) { reader . decRef ( ) ; } reader = IndexReader . open ( writer , ! staleOk ) ; if ( readerDirty ) { etag = newEtag ( ) ; readerDirty = false ; } reader . incRef ( ) ; return reader ; } 
public IndexSearcher borrowSearcher ( final boolean staleOk ) throws IOException , JSONException { return new IndexSearcher ( borrowReader ( staleOk ) ) ; } 
public void returnReader ( final IndexReader reader ) throws IOException { reader . decRef ( ) ; } 
public void returnSearcher ( final IndexSearcher searcher ) throws IOException { returnReader ( searcher . getIndexReader ( ) ) ; } 
public Query parse ( final String query , final Operator operator , final Analyzer analyzer ) throws ParseException , JSONException { final QueryParser parser = new CustomQueryParser ( Constants . VERSION , Constants . DEFAULT_FIELD , analyzer ) ; parser . setDefaultOperator ( operator ) ; parser . setAllowLeadingWildcard ( ini . getBoolean ( " lucene.allowLeadingWildcard " , false ) ) ; parser . setLowercaseExpandedTerms ( ini . getBoolean ( " lucene.lowercaseExpandedTerms " , true ) ) ; return parser . parse ( query ) ; } 
public Analyzer analyzer ( final String analyzerName ) throws JSONException { return analyzerName = = null ? this . analyzer : Analyzers . getAnalyzer ( analyzerName ) ; } 
private synchronized void close ( ) throws IOException { if ( reader ! = null ) reader . close ( ) ; if ( writer ! = null ) writer . rollback ( ) ; 
public UUID getUuid ( ) throws JSONException , IOException { return database . getUuid ( ) ; } 
private String newEtag ( ) { return Long . toHexString ( now ( ) ) ; } 
private synchronized boolean notModified ( final HttpServletRequest req ) { return etag ! = null & & etag . equals ( req . getHeader ( " If-None-Match " ) ) ; } 
private void blockForLatest ( final boolean staleOk ) throws IOException , JSONException { if ( staleOk ) { return ; } final UpdateSequence latest = database . getLastSequence ( ) ; synchronized ( this ) { long imeout = getSearchTimeout ( ) ; 
public String toString ( ) { return writer . getDirectory ( ) . toString ( ) ; } 
public static File uuidDir ( final File root , final UUID uuid ) { return new File ( root , uuid . toString ( ) ) ; } 
public static File viewDir ( final File root , final UUID uuid , final String digest , final boolean mkdirs ) throws IOException { final File uuidDir = uuidDir ( root , uuid ) ; final File viewDir = new File ( uuidDir , digest ) ; if ( mkdirs ) { viewDir . mkdirs ( ) ; } return viewDir ; } 
public void admin ( final HttpServletRequest req , final HttpServletResponse resp ) throws IOException , JSONException { final IndexState state = getState ( req , resp ) ; if ( state = = null ) return ; final String command = new PathParts ( req ) . getCommand ( ) ; if ( " _expunge " . equals ( command ) ) { logger . info ( " Expunging deletes from " + state ) ; state . writer . forceMergeDeletes ( false ) ; resp . setStatus ( 202 ) ; ServletUtils . sendJsonSuccess ( req , resp ) ; return ; } if ( " _optimize " . equals ( command ) ) { logger . info ( " Optimizing " + state ) ; state . writer . forceMerge ( 1 , false ) ; resp . setStatus ( 202 ) ; ServletUtils . sendJsonSuccess ( req , resp ) ; return ; } ServletUtils . sendJsonError ( req , resp , 400 , " bad_request " ) ; } 
public void awaitInitialization ( ) { try { latch . await ( ) ; 
public void info ( final HttpServletRequest req , final HttpServletResponse resp ) throws IOException , JSONException { final IndexState state = getState ( req , resp ) ; if ( state = = null ) return ; final IndexReader reader = state . borrowReader ( isStaleOk ( req ) ) ; try { final JSONObject result = new JSONObject ( ) ; 
public void run ( ) { if ( closed ) { throw new IllegalStateException ( " closed! " ) ; } try { init ( ) ; } catch ( final Exception e ) { logger . warn ( " Exiting after init() raised exception. " , e ) ; close ( ) ; return ; } try { try { 
private void close ( ) { this . closed = true ; for ( final IndexState state : states . values ( ) ) { try { state . close ( ) ; } catch ( final IOException e ) { logger . warn ( " Error while closing. " , e ) ; } } states . clear ( ) ; if ( context ! = null ) { Context . exit ( ) ; context = null ; } latch . countDown ( ) ; } 
private boolean getBooleanParameter ( final HttpServletRequest req , final String parameterName ) { return Boolean . parseBoolean ( req . getParameter ( parameterName ) ) ; } 
private int getIntParameter ( final HttpServletRequest req , final String parameterName , final int defaultValue ) { final String result = req . getParameter ( parameterName ) ; return result ! = null ? Integer . parseInt ( result ) : defaultValue ; } 
private IndexState getState ( final HttpServletRequest req , final HttpServletResponse resp ) throws IOException , JSONException { final View view = paths . get ( toPath ( req ) ) ; if ( view = = null ) { ServletUtils . sendJsonError ( req , resp , 400 , " no_such_view " ) ; return null ; } final IndexState result = states . get ( view ) ; if ( result = = null ) { ServletUtils . sendJsonError ( req , resp , 400 , " no_such_state " ) ; } return result ; } 
private UpdateSequence getUpdateSequence ( final Directory dir ) throws IOException { if ( ! IndexReader . indexExists ( dir ) ) { return UpdateSequence . START ; } return getUpdateSequence ( IndexReader . getCommitUserData ( dir ) ) ; } 
private UpdateSequence getUpdateSequence ( final IndexWriter writer ) throws IOException { return getUpdateSequence ( writer . getDirectory ( ) ) ; } 
private boolean isStaleOk ( final HttpServletRequest req ) { return " ok " . equals ( req . getParameter ( " stale " ) ) ; } 
private IndexWriter newWriter ( final Directory dir ) throws IOException { final IndexWriterConfig config = new IndexWriterConfig ( Constants . VERSION , Constants . ANALYZER ) ; final LogByteSizeMergePolicy mergePolicy = new LogByteSizeMergePolicy ( ) ; mergePolicy . setMergeFactor ( ini . getInt ( " lucene.mergeFactor " , 10 ) ) ; mergePolicy . setUseCompoundFile ( ini . getBoolean ( " lucene.useCompoundFile " , false ) ) ; config . setMergePolicy ( mergePolicy ) ; config . setRAMBufferSizeMB ( ini . getDouble ( " lucene.ramBufferSizeMB " , IndexWriterConfig . DEFAULT_RAM_BUFFER_SIZE_MB ) ) ; return new IndexWriter ( dir , config ) ; } 
private File viewDir ( final View view , final boolean mkdirs ) throws IOException { return viewDir ( root , uuid , view . getDigest ( ) , mkdirs ) ; } 
private String toPath ( final HttpServletRequest req ) { final PathParts parts = new PathParts ( req ) ; return toPath ( parts . getDesignDocumentName ( ) , parts . getViewName ( ) ) ; } 
private String toPath ( final String ddoc , final String view ) { return ddoc + " / " + view ; } 
private Scriptable convertObject ( final JSONObject obj ) throws JSONException { if ( obj = = JSONObject . NULL ) { return null ; } final Scriptable result = context . newObject ( scope ) ; final Iterator < ? > it = obj . keys ( ) ; while ( it . hasNext ( ) ) { final String key = ( String ) it . next ( ) ; final Object value = obj . get ( key ) ; ScriptableObject . putProperty ( result , key , convert ( value ) ) ; } return result ; } 
public static IndexKey parse ( final HttpServletRequest req ) { final String [ ] parts = req . getRequestURI ( ) . replaceFirst ( " / " , " " ) . split ( " / " ) ; if ( parts . length < 4 ) { return null ; } return new IndexKey ( parts [ 0 ] , parts [ 1 ] , parts [ 2 ] , parts [ 3 ] ) ; } 
public int hashCode ( ) { final int prime = 31 ; int result = 1 ; result = prime * result + ( ( database = = null ) ? 0 : database . hashCode ( ) ) ; result = prime * result + ( ( ddoc = = null ) ? 0 : ddoc . hashCode ( ) ) ; result = prime * result + ( ( key = = null ) ? 0 : key . hashCode ( ) ) ; result = prime * result + ( ( view = = null ) ? 0 : view . hashCode ( ) ) ; return result ; } 
public boolean equals ( Object obj ) { if ( this = = obj ) return true ; if ( obj = = null ) return false ; if ( getClass ( ) ! = obj . getClass ( ) ) return false ; IndexKey other = ( IndexKey ) obj ; if ( database = = null ) { if ( other . database ! = null ) return false ; } else if ( ! database . equals ( other . database ) ) return false ; if ( ddoc = = null ) { if ( other . ddoc ! = null ) return false ; } else if ( ! ddoc . equals ( other . ddoc ) ) return false ; if ( key = = null ) { if ( other . key ! = null ) return false ; } else if ( ! key . equals ( other . key ) ) return false ; if ( view = = null ) { if ( other . view ! = null ) return false ; } else if ( ! view . equals ( other . view ) ) return false ; return true ; } 
public void setExpectations ( String field , int numTerms , boolean storeOffsets , boolean storePositions ) { currentObj = new JSONObject ( ) ; try { result . put ( field , currentObj ) ; 
public void map ( String term , int frequency , TermVectorOffsetInfo [ ] offsets , int [ ] positions ) { try { final JSONObject field = new JSONObject ( ) ; 
private Couch getCouch ( final HttpServletRequest req ) throws IOException { final String sectionName = new PathParts ( req ) . getKey ( ) ; final Configuration section = ini . getSection ( sectionName ) ; if ( ! section . containsKey ( " url " ) ) { throw new FileNotFoundException ( sectionName + " is missing or has no url parameter. " ) ; } return new Couch ( client , section . getString ( " url " ) ) ; } 
private synchronized DatabaseIndexer getIndexer ( final Database database ) throws IOException , JSONException { DatabaseIndexer result = indexers . get ( database ) ; Thread thread = threads . get ( database ) ; if ( result = = null | | thread = = null | | ! thread . isAlive ( ) ) { result = new DatabaseIndexer ( client , root , database , ini ) ; thread = new Thread ( result ) ; thread . start ( ) ; result . awaitInitialization ( ) ; if ( result . isClosed ( ) ) { return null ; } else { indexers . put ( database , result ) ; threads . put ( database , thread ) ; } } return result ; } 
private void handleWelcomeReq ( final HttpServletRequest req , final HttpServletResponse resp ) throws ServletException , IOException , JSONException { final Package p = this . getClass ( ) . getPackage ( ) ; final JSONObject welcome = new JSONObject ( ) ; welcome . put ( " couchdb-lucene " , " Welcome " ) ; welcome . put ( " version " , p . getImplementationVersion ( ) ) ; ServletUtils . sendJson ( req , resp , welcome ) ; } 
protected void doGet ( final HttpServletRequest req , final HttpServletResponse resp ) throws ServletException , IOException { try { doGetInternal ( req , resp ) ; 
protected void doPost ( final HttpServletRequest req , final HttpServletResponse resp ) throws ServletException , IOException { try { doPostInternal ( req , resp ) ; 
public String toString ( ) { return " PathParts [getCommand()= " + getCommand ( ) + " , getDatabaseName()= " + getDatabaseName ( ) 
public final JSONArray getAllDatabases ( ) throws IOException , JSONException { final String response = HttpUtils . get ( httpClient , url + " _all_dbs " ) ; return new JSONArray ( response ) ; } 
public final JSONObject getInfo ( ) throws IOException , JSONException { return new JSONObject ( HttpUtils . get ( httpClient , url ) ) ; } 
public List < DesignDocument > getAllDesignDocuments ( ) throws IOException , JSONException { final String body = HttpUtils . get ( httpClient , String . format ( " %s_all_docs?startkey=%s&endkey=%s&include_docs=true " , url , Utils . urlEncode ( " \" _design \" " ) , Utils . urlEncode ( " \" _design0 \" " ) ) ) ; final JSONObject json = new JSONObject ( body ) ; return toDesignDocuments ( json ) ; } 
public CouchDocument getDocument ( final String id ) throws IOException , JSONException { final String response = HttpUtils . get ( httpClient , url + Utils . urlEncode ( id ) ) ; return new CouchDocument ( new JSONObject ( response ) ) ; } 
public DesignDocument getDesignDocument ( final String id ) throws IOException , JSONException { final String response = HttpUtils . get ( httpClient , url + Utils . urlEncode ( id ) ) ; return new DesignDocument ( new JSONObject ( response ) ) ; } 
public List < CouchDocument > getDocuments ( final String . . . ids ) throws IOException , JSONException { if ( ids . length = = 0 ) { return Collections . emptyList ( ) ; } final JSONArray keys = new JSONArray ( ) ; for ( final String id : ids ) { assert id ! = null ; keys . put ( id ) ; } final JSONObject req = new JSONObject ( ) ; req . put ( " keys " , keys ) ; final String body = HttpUtils . post ( httpClient , url + " _all_docs?include_docs=true " , req ) ; return toDocuments ( new JSONObject ( body ) ) ; } 
public DatabaseInfo getInfo ( ) throws IOException , JSONException { return new DatabaseInfo ( new JSONObject ( HttpUtils . get ( httpClient , url ) ) ) ; 
public < T > T handleAttachment ( final String doc , final String att , final ResponseHandler < T > handler ) throws IOException { final HttpGet get = new HttpGet ( url + " / " + Utils . urlEncode ( doc ) + " / " + Utils . urlEncode ( att ) ) ; return httpClient . execute ( get , handler ) ; } 
public HttpUriRequest getChangesRequest ( final UpdateSequence since ) throws IOException { final String uri = url + " _changes?feed=continuous&heartbeat=15000&include_docs=true " ; return new HttpGet ( since . appendSince ( uri ) ) ; } 
public boolean saveDocument ( final String id , final String body ) throws IOException { return HttpUtils . put ( httpClient , url + Utils . urlEncode ( id ) , body ) = = 201 ; } 
public UUID getUuid ( ) throws IOException , JSONException { try { final CouchDocument local = getDocument ( " _local/lucene " ) ; 
public UUID getOrCreateUuid ( ) throws IOException , JSONException { final UUID result = getUuid ( ) ; if ( result ! = null ) { return result ; } createUuid ( ) ; return getUuid ( ) ; } 
private List < DesignDocument > toDesignDocuments ( final JSONObject json ) throws JSONException { final List < DesignDocument > result = new ArrayList < DesignDocument > ( ) ; for ( final JSONObject doc : rows ( json ) ) { result . add ( new DesignDocument ( doc ) ) ; } return result ; } 
private List < CouchDocument > toDocuments ( final JSONObject json ) throws JSONException { final List < CouchDocument > result = new ArrayList < CouchDocument > ( ) ; for ( final JSONObject doc : rows ( json ) ) { result . add ( doc = = null ? null : new CouchDocument ( doc ) ) ; } return result ; } 
private List < JSONObject > rows ( final JSONObject json ) throws JSONException { final List < JSONObject > result = new ArrayList < JSONObject > ( ) ; final JSONArray rows = json . getJSONArray ( " rows " ) ; for ( int i = 0 ; i < rows . length ( ) ; i + + ) { result . add ( rows . getJSONObject ( i ) . optJSONObject ( " doc " ) ) ; } return result ; } 
public int hashCode ( ) { final int prime = 31 ; int result = 1 ; result = prime * result + ( ( url = = null ) ? 0 : url . hashCode ( ) ) ; return result ; } 
public boolean equals ( Object obj ) { if ( this = = obj ) return true ; if ( obj = = null ) return false ; if ( getClass ( ) ! = obj . getClass ( ) ) return false ; Database other = ( Database ) obj ; if ( url = = null ) { if ( other . url ! = null ) return false ; } else if ( ! url . equals ( other . url ) ) return false ; return true ; } 
public String toString ( ) { return " Database [url= " + url + " ] " ; } 
public UpdateSequence getUpdateSequence ( ) throws JSONException { return UpdateSequence . parseUpdateSequence ( json . getString ( " update_seq " ) ) ; } 
public String getName ( ) throws JSONException { return json . getString ( " db_name " ) ; } 
public View getView ( final String name ) throws JSONException { if ( fulltext = = null ) return null ; final JSONObject json = fulltext . optJSONObject ( name ) ; return json = = null ? null : new View ( getId ( ) + " / " + name , json ) ; } 
public Map < String , View > getAllViews ( ) throws JSONException { if ( fulltext = = null ) return Collections . emptyMap ( ) ; final Map < String , View > result = new HashMap < String , View > ( ) ; final Iterator < ? > it = fulltext . keys ( ) ; while ( it . hasNext ( ) ) { final Object key = it . next ( ) ; final String name = ( String ) key ; final View view = getView ( name ) ; if ( view ! = null ) { result . put ( name , view ) ; } } return result ; } 
private double toDouble ( final Object obj ) { if ( obj instanceof Number ) { return ( ( Number ) obj ) . doubleValue ( ) ; } return Double . parseDouble ( obj . toString ( ) ) ; } 
private float toFloat ( final Object obj ) { if ( obj instanceof Number ) { return ( ( Number ) obj ) . floatValue ( ) ; } return Float . parseFloat ( obj . toString ( ) ) ; } 
private int toInt ( final Object obj ) { if ( obj instanceof Number ) { return ( ( Number ) obj ) . intValue ( ) ; } return Integer . parseInt ( obj . toString ( ) ) ; } 
private long toLong ( final Object obj ) { if ( obj instanceof Number ) { return ( ( Number ) obj ) . longValue ( ) ; } return Long . parseLong ( obj . toString ( ) ) ; } 
public abstract AbstractField toField ( final String name , final Object value , final ViewSettings settings ) throws ParseException ; public abstract Query toRangeQuery ( final String name , final String lower , final String upper , final boolean inclusive ) throws ParseException ; public abstract Query toTermQuery ( final String name , final String text ) throws ParseException ; public final int toSortField ( ) { return sortField ; } public static long toDate ( final Object obj ) throws ParseException { if ( obj instanceof Date ) { return ( ( Date ) obj ) . getTime ( ) ; } try { return DateUtils . parseDate ( obj . toString ( ) . toUpperCase ( ) , DATE_PATTERNS ) . getTime ( ) ; } catch ( final java . text . ParseException e ) { throw new ParseException ( e . getMessage ( ) ) ; } } } 
public abstract Query toRangeQuery ( final String name , final String lower , final String upper , final boolean inclusive ) throws ParseException ; public abstract Query toTermQuery ( final String name , final String text ) throws ParseException ; public final int toSortField ( ) { return sortField ; } public static long toDate ( final Object obj ) throws ParseException { if ( obj instanceof Date ) { return ( ( Date ) obj ) . getTime ( ) ; } try { return DateUtils . parseDate ( obj . toString ( ) . toUpperCase ( ) , DATE_PATTERNS ) . getTime ( ) ; } catch ( final java . text . ParseException e ) { throw new ParseException ( e . getMessage ( ) ) ; } } } 
public abstract Query toTermQuery ( final String name , final String text ) throws ParseException ; public final int toSortField ( ) { return sortField ; } public static long toDate ( final Object obj ) throws ParseException { if ( obj instanceof Date ) { return ( ( Date ) obj ) . getTime ( ) ; } try { return DateUtils . parseDate ( obj . toString ( ) . toUpperCase ( ) , DATE_PATTERNS ) . getTime ( ) ; } catch ( final java . text . ParseException e ) { throw new ParseException ( e . getMessage ( ) ) ; } } } 
public static long toDate ( final Object obj ) throws ParseException { if ( obj instanceof Date ) { return ( ( Date ) obj ) . getTime ( ) ; } try { return DateUtils . parseDate ( obj . toString ( ) . toUpperCase ( ) , DATE_PATTERNS ) . getTime ( ) ; 
public String appendSince ( final String url ) { try { return url + " &since= " + URLEncoder . encode ( since , " US-ASCII " ) ; 
public String appendSince ( final String url ) { return url + " &since= " + seq ; } 
public boolean isEarlierThan ( final UpdateSequence other ) { if ( other = = START ) { return false ; } if ( other instanceof CouchDbUpdateSequence ) { return this . seq < ( ( CouchDbUpdateSequence ) other ) . seq ; } throw new IllegalArgumentException ( other + " is not compatible. " ) ; } 
public boolean isLaterThan ( final UpdateSequence other ) { if ( other = = START ) { return true ; } if ( other instanceof CouchDbUpdateSequence ) { return this . seq > ( ( CouchDbUpdateSequence ) other ) . seq ; } throw new IllegalArgumentException ( other + " is not compatible. " ) ; } 
public String toString ( ) { return Long . toString ( seq ) ; } 
public String appendSince ( final String url ) { return url ; } 
public boolean isEarlierThan ( final UpdateSequence other ) { return true ; } 
public boolean isLaterThan ( final UpdateSequence other ) { return false ; } 
public static UpdateSequence parseUpdateSequence ( final String str ) { if ( str . matches ( " [0-9]+ " ) ) { return new CouchDbUpdateSequence ( str ) ; } String packedSeqs ; if ( ( packedSeqs = extractPackedSeqs ( BC3 , str ) ) ! = null ) { return new BigCouchUpdateSequence ( str , packedSeqs ) ; } if ( ( packedSeqs = extractPackedSeqs ( BC4 , str ) ) ! = null ) { return new BigCouchUpdateSequence ( str , packedSeqs ) ; } throw new IllegalArgumentException ( str + " not recognized. " ) ; } 
private static String extractPackedSeqs ( final Pattern p , final String str ) { final Matcher m = p . matcher ( str ) ; if ( m . matches ( ) ) { return m . group ( 1 ) ; } return null ; } 
public abstract String appendSince ( final String url ) ; public abstract boolean isEarlierThan ( final UpdateSequence other ) ; public abstract boolean isLaterThan ( final UpdateSequence other ) ; } 
public abstract boolean isEarlierThan ( final UpdateSequence other ) ; public abstract boolean isLaterThan ( final UpdateSequence other ) ; } 
public Analyzer getAnalyzer ( ) throws JSONException { return Analyzers . getAnalyzer ( json . optString ( ANALYZER , DEFAULT_ANALYZER ) ) ; 
public ViewSettings getDefaultSettings ( ) throws JSONException { return json . has ( DEFAULTS ) ? new ViewSettings ( json . getJSONObject ( DEFAULTS ) ) : ViewSettings . getDefaultSettings ( ) ; 
public String getFunction ( ) throws JSONException { return trim ( json . getString ( INDEX ) ) ; } 
public Function compileFunction ( final Context context , ScriptableObject scope ) throws JSONException { return context . compileFunction ( scope , getFunction ( ) , null , 0 , null ) ; } 
public String toString ( ) { return String . format ( " View[name=%s, digest=%s] " , name , getDigest ( ) ) ; } 
public static void jsFunction_add ( final Context cx , final Scriptable thisObj , final Object [ ] args , final Function funObj ) { final RhinoDocument doc = checkInstance ( thisObj ) ; if ( args . length < 1 | | args . length > 2 ) { throw Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } if ( args [ 0 ] = = null ) { Ignore. return; } if (args[0] instanceof Undefined) { Ignore return; } final String className = args[0].getClass().getName(); if (className.equals("org.mozilla.javascript.NativeDate")) { args[0] = (Date) Context.jsToJava(args[0], Date.class); } if (!className.startsWith("java.lang.") && !className.equals("org.mozilla.javascript.NativeObject") && !className.equals("org.mozilla.javascript.NativeDate")) { throw Context.reportRuntimeError(className + " is not supported."); } if (args.length == 2 && (args[1] == null || args[1] instanceof NativeObject == false)) { throw Context.reportRuntimeError("second argument must be an object."); } final RhinoField field = new RhinoField(); field.value = args[0]; if (args.length == 2) { field.settings = (NativeObject) args[1]; } doc.fields.add(field); } 
private void addAttachment ( final RhinoAttachment attachment , final String id , final Database database , final Document out ) throws IOException { final ResponseHandler < Void > handler = new ResponseHandler < Void > ( ) { public Void handleResponse ( final HttpResponse response ) throws ClientProtocolException , IOException { final HttpEntity entity = response . getEntity ( ) ; try { Tika . INSTANCE . parse ( entity . getContent ( ) , entity . getContentType ( ) . getValue ( ) , attachment . fieldName , out ) ; } finally { entity . consumeContent ( ) ; } return null ; } } ; database . handleAttachment ( id , attachment . attachmentName , handler ) ; } 
public Void handleResponse ( final HttpResponse response ) throws ClientProtocolException , IOException { final HttpEntity entity = response . getEntity ( ) ; try { Tika . INSTANCE . parse ( entity . getContent ( ) , entity . getContentType ( ) . getValue ( ) , attachment . fieldName , out ) ; } finally { entity . consumeContent ( ) ; } return null ; } 
public static void sendJsonError ( final HttpServletRequest request , final HttpServletResponse response , final int code , final String reason ) throws IOException , JSONException { final JSONObject obj = new JSONObject ( ) ; obj . put ( " reason " , reason ) ; sendJsonError ( request , response , code , obj ) ; } 
public static void sendJsonError ( final HttpServletRequest request , final HttpServletResponse response , final int code , final JSONObject error ) throws IOException , JSONException { setResponseContentTypeAndEncoding ( request , response ) ; response . setHeader ( HttpHeaders . CACHE_CONTROL , " must-revalidate,no-cache,no-store " ) ; response . setStatus ( code ) ; error . put ( " code " , code ) ; final Writer writer = response . getWriter ( ) ; try { writer . write ( error . toString ( ) ) ; 
public static void sendJson ( final HttpServletRequest req , final HttpServletResponse resp , final JSONObject json ) throws IOException { setResponseContentTypeAndEncoding ( req , resp ) ; final Writer writer = resp . getWriter ( ) ; try { writer . write ( json . toString ( ) + " r " ) ; 
public static void sendJsonSuccess ( final HttpServletRequest req , final HttpServletResponse resp ) throws IOException { setResponseContentTypeAndEncoding ( req , resp ) ; final Writer writer = resp . getWriter ( ) ; try { writer . write ( " { \" ok \" : true} r " ) ; 
public void testForEverything ( ) throws Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) {var ret=new Document(); " + " function idx(obj) {for (var key in obj) " + " {switch (typeof obj[key]) {case 'object':idx(obj[key]); break; " + " case 'function': break; default: ret.add(obj[key]); break;} } }; idx(doc); return ret; } " ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hello \" , l1: { l2: {l3:[ \" v3 \" , \" v4 \" ]}}} " ) , settings ( ) , null ) ; assertThat ( result . iterator ( ) . next ( ) . getValues ( Constants . DEFAULT_FIELD ) [ 0 ] , is ( " hello " ) ) ; assertThat ( result . iterator ( ) . next ( ) . getValues ( Constants . DEFAULT_FIELD ) [ 1 ] , is ( " v3 " ) ) ; assertThat ( result . iterator ( ) . next ( ) . getValues ( Constants . DEFAULT_FIELD ) [ 2 ] , is ( " v4 " ) ) ; } 
public void testNullValue ( ) throws Exception { final String fun = " function(doc) { var ret=new Document(); ret.add(doc.foo); return ret; } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hi \" , foo:null} " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 1 ) ) ; assertThat ( result . iterator ( ) . next ( ) . get ( " foo " ) , is ( nullValue ( ) ) ) ; } 
public void testLongValue ( ) throws Exception { final String fun = " function(doc) { var ret=new Document(); ret.add(12, {type: \" long \" , field: \" num \" }); return ret; } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hi \" } " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 1 ) ) ; assertThat ( result . iterator ( ) . next ( ) . getFieldable ( " num " ) , is ( NumericField . class ) ) ; } 
public void testDateString ( ) throws Exception { final String fun = " function(doc) { var ret=new Document(); ret.add( \" 2009-01-01 \" , {type: \" date \" , field: \" num \" }); return ret; } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hi \" } " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 1 ) ) ; assertThat ( result . iterator ( ) . next ( ) . getFieldable ( " num " ) , is ( NumericField . class ) ) ; } 
public void testDateObject ( ) throws Exception { final String fun = " function(doc) { var ret=new Document(); ret.add(new Date(2010,8,13), {type: \" date \" , field: \" num \" }); return ret; } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hi \" } " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 1 ) ) ; assertThat ( result . iterator ( ) . next ( ) . getFieldable ( " num " ) , is ( NumericField . class ) ) ; assertThat ( ( Long ) ( ( NumericField ) result . iterator ( ) . next ( ) . getFieldable ( " num " ) ) . getNumericValue ( ) , is ( 1284332400000L ) ) ; } 
public void testDateObject2 ( ) throws Exception { final String fun = " function(doc) { var ret=new Document(); ret.add(new Date( \" January 6, 1972 16:05:00 \" ), {type: \" date \" , field: \" num \" }); return ret; } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hi \" } " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 1 ) ) ; assertThat ( result . iterator ( ) . next ( ) . getFieldable ( " num " ) , is ( NumericField . class ) ) ; assertThat ( ( Long ) ( ( NumericField ) result . iterator ( ) . next ( ) . getFieldable ( " num " ) ) . getNumericValue ( ) , is ( 63561900000L ) ) ; } 
public void testParseInt ( ) throws Exception { final String fun = " function(doc) { var ret=new Document(); ret.add(parseInt( \" 12.5 \" ), {type: \" int \" , field: \" num \" }); return ret; } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hi \" } " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 1 ) ) ; assertThat ( result . iterator ( ) . next ( ) . getFieldable ( " num " ) , is ( NumericField . class ) ) ; } 
public void testConditionalOnNulls ( ) throws Exception { final String fun = " function(doc) { if (doc.foo && doc.bar) { return new Document(); }; return null; } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hi \" , foo: null, bar: null} " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 0 ) ) ; } 
public void testSearchPath ( ) { final PathParts parts = new PathParts ( " /local/db1/_design/foo/by_subject " ) ; assertThat ( parts . getKey ( ) , is ( " local " ) ) ; assertThat ( parts . getDatabaseName ( ) , is ( " db1 " ) ) ; assertThat ( parts . getDesignDocumentName ( ) , is ( " _design/foo " ) ) ; assertThat ( parts . getViewName ( ) , is ( " by_subject " ) ) ; assertThat ( parts . getCommand ( ) , is ( nullValue ( ) ) ) ; } 
public void testCommandPath ( ) { final PathParts parts = new PathParts ( " /local/db1/_design/foo/by_subject/_expunge " ) ; assertThat ( parts . getKey ( ) , is ( " local " ) ) ; assertThat ( parts . getDatabaseName ( ) , is ( " db1 " ) ) ; assertThat ( parts . getDesignDocumentName ( ) , is ( " _design/foo " ) ) ; assertThat ( parts . getViewName ( ) , is ( " by_subject " ) ) ; assertThat ( parts . getCommand ( ) , is ( " _expunge " ) ) ; } 
public void testCleanupPath ( ) { final PathParts parts = new PathParts ( " /local/db1/_cleanup " ) ; assertThat ( parts . getKey ( ) , is ( " local " ) ) ; assertThat ( parts . getDatabaseName ( ) , is ( " db1 " ) ) ; assertThat ( parts . getCommand ( ) , is ( " _cleanup " ) ) ; } 
public void couchdbSequence ( ) { assertThat ( UpdateSequence . parseUpdateSequence ( " 1234 " ) , notNullValue ( ) ) ; } 
public void bigcouch3Sequence ( ) { assertThat ( UpdateSequence 
public void bigcouch4Sequence ( ) { assertThat ( UpdateSequence 
public void testEmailAddresses ( ) throws Exception { assertThat ( analyze ( " standard " , " foo@bar.com " ) , is ( new String [ ] { " foo " , " bar.com " } ) ) ; assertThat ( analyze ( " classic " , " foo@bar.com " ) , is ( new String [ ] { " foo@bar.com " } ) ) ; } 
protected Query getRangeQuery ( final String field , final String lower , final String upper , final boolean lowerInclusive , final boolean upperInclusive ) throws ParseException { return new TypedField ( field ) . toRangeQuery ( lower , upper , lowerInclusive , upperInclusive ) ; } 
public synchronized DirectoryReader borrowReader ( final boolean staleOk ) throws IOException , JSONException { blockForLatest ( staleOk ) ; if ( reader = = null ) { etag = newEtag ( ) ; } if ( reader ! = null ) { reader . decRef ( ) ; } reader = DirectoryReader . open ( writer , ! staleOk ) ; if ( readerDirty ) { etag = newEtag ( ) ; readerDirty = false ; } reader . incRef ( ) ; return reader ; } 
public void info ( final HttpServletRequest req , final HttpServletResponse resp ) throws IOException , JSONException { final IndexState state = getState ( req , resp ) ; if ( state = = null ) return ; final DirectoryReader reader = state . borrowReader ( isStaleOk ( req ) ) ; try { final JSONObject result = new JSONObject ( ) ; 
private UpdateSequence getUpdateSequence ( final Directory dir ) throws IOException { if ( ! DirectoryReader . indexExists ( dir ) ) { return UpdateSequence . START ; } final List < IndexCommit > commits = DirectoryReader . listCommits ( dir ) ; final IndexCommit latest = commits . get ( commits . size ( ) - 1 ) ; return getUpdateSequence ( latest . getUserData ( ) ) ; } 
private IndexWriter newWriter ( final Directory dir ) throws IOException { final IndexWriterConfig config = new IndexWriterConfig ( Constants . VERSION , Constants . ANALYZER ) ; config . setUseCompoundFile ( ini . getBoolean ( " lucene.useCompoundFile " , false ) ) ; config . setRAMBufferSizeMB ( ini . getDouble ( " lucene.ramBufferSizeMB " , IndexWriterConfig . DEFAULT_RAM_BUFFER_SIZE_MB ) ) ; return new IndexWriter ( dir , config ) ; } 
private static void planFuzzyQuery ( final StringBuilder builder , final FuzzyQuery query ) { builder . append ( query . getTerm ( ) ) ; builder . append ( " ,prefixLength= " ) ; builder . append ( query . getPrefixLength ( ) ) ; builder . append ( " ,maxEdits= " ) ; builder . append ( query . getMaxEdits ( ) ) ; } 
private static void planTermRangeQuery ( final StringBuilder builder , final TermRangeQuery query ) { builder . append ( query . getLowerTerm ( ) . utf8ToString ( ) ) ; builder . append ( " TO " ) ; builder . append ( query . getUpperTerm ( ) . utf8ToString ( ) ) ; } 
public SortField . Type toSortField ( ) { return type . toType ( ) ; } 
public Query toRangeQuery ( final String lower , final String upper , final boolean lowerInclusive , final boolean upperInclusive ) throws ParseException { return type . toRangeQuery ( name , lower , upper , lowerInclusive , upperInclusive ) ; } 
public LongField toField ( final String name , final Object value , final ViewSettings settings ) throws ParseException { return boost ( new LongField ( name , toDate ( value ) , settings . getStore ( ) ) , settings ) ; } 
public Query toRangeQuery ( final String name , final String lower , final String upper , final boolean lowerInclusive , final boolean upperInclusive ) throws ParseException { return NumericRangeQuery . newLongRange ( name , precisionStep , toDate ( lower ) , toDate ( upper ) , lowerInclusive , upperInclusive ) ; 
public Query toTermQuery ( final String name , final String text ) throws ParseException { final long date = toDate ( text ) ; final BytesRef ref = new BytesRef ( ) ; NumericUtils . longToPrefixCoded ( date , 0 , ref ) ; return new TermQuery ( new Term ( name , ref ) ) ; } 
public DoubleField toField ( final String name , final Object value , final ViewSettings settings ) { return boost ( new DoubleField ( name , toDouble ( value ) , settings . getStore ( ) ) , settings ) ; } 
public Query toRangeQuery ( final String name , final String lower , final String upper , final boolean lowerInclusive , final boolean upperInclusive ) { return NumericRangeQuery . newDoubleRange ( name , precisionStep , toDouble ( lower ) , toDouble ( upper ) , lowerInclusive , upperInclusive ) ; 
public Query toTermQuery ( final String name , final String text ) { final long asLong = NumericUtils . doubleToSortableLong ( toDouble ( text ) ) ; final BytesRef ref = new BytesRef ( ) ; NumericUtils . longToPrefixCoded ( asLong , 0 , ref ) ; return new TermQuery ( new Term ( name , ref ) ) ; } 
public FloatField toField ( final String name , final Object value , final ViewSettings settings ) { return boost ( new FloatField ( name , toFloat ( value ) , settings . getStore ( ) ) , settings ) ; } 
public Query toRangeQuery ( final String name , final String lower , final String upper , final boolean lowerInclusive , final boolean upperInclusive ) { return NumericRangeQuery . newFloatRange ( name , precisionStep , toFloat ( lower ) , toFloat ( upper ) , lowerInclusive , upperInclusive ) ; 
public Query toTermQuery ( final String name , final String text ) { final int asInt = NumericUtils . floatToSortableInt ( toFloat ( text ) ) ; final BytesRef ref = new BytesRef ( ) ; NumericUtils . intToPrefixCoded ( asInt , 0 , ref ) ; return new TermQuery ( new Term ( name , ref ) ) ; } 
public IntField toField ( final String name , final Object value , final ViewSettings settings ) { return boost ( new IntField ( name , toInt ( value ) , settings . getStore ( ) ) , settings ) ; } 
public Query toRangeQuery ( final String name , final String lower , final String upper , final boolean lowerInclusive , final boolean upperInclusive ) { return NumericRangeQuery . newIntRange ( name , precisionStep , toInt ( lower ) , toInt ( upper ) , lowerInclusive , upperInclusive ) ; 
public Query toTermQuery ( final String name , final String text ) { final BytesRef ref = new BytesRef ( ) ; NumericUtils . intToPrefixCoded ( toInt ( text ) , 0 , ref ) ; return new TermQuery ( new Term ( name , ref ) ) ; } 
public LongField toField ( final String name , final Object value , final ViewSettings settings ) { return boost ( new LongField ( name , toLong ( value ) , settings . getStore ( ) ) , settings ) ; } 
public Query toRangeQuery ( final String name , final String lower , final String upper , final boolean lowerInclusive , final boolean upperInclusive ) { return NumericRangeQuery . newLongRange ( name , precisionStep , toLong ( lower ) , toLong ( upper ) , lowerInclusive , upperInclusive ) ; 
public Query toTermQuery ( final String name , final String text ) { final BytesRef ref = new BytesRef ( ) ; NumericUtils . longToPrefixCoded ( toLong ( text ) , 0 , ref ) ; return new TermQuery ( new Term ( name , ref ) ) ; } 
public TextField toField ( final String name , final Object value , final ViewSettings settings ) { return boost ( new TextField ( name , value . toString ( ) , settings . getStore ( ) ) , settings ) ; } 
public Query toRangeQuery ( final String name , final String lower , final String upper , final boolean lowerInclusive , final boolean upperInclusive ) { final TermRangeQuery result = TermRangeQuery . newStringRange ( name , lower , upper , lowerInclusive , upperInclusive ) ; result . setRewriteMethod ( MultiTermQuery . CONSTANT_SCORE_AUTO_REWRITE_DEFAULT ) ; return result ; } 
private static < T extends Field > T boost ( final T field , final ViewSettings settings ) { field . setBoost ( settings . getBoost ( ) ) ; return field ; } 
public abstract Field toField ( final String name , final Object value , final ViewSettings settings ) throws ParseException ; public abstract Query toRangeQuery ( final String name , final String lower , final String upper , final boolean lowerInclusive , final boolean upperInclusive ) throws ParseException ; public abstract Query toTermQuery ( final String name , final String text ) throws ParseException ; public final SortField . Type toType ( ) { return type ; } public static long toDate ( final Object obj ) throws ParseException { if ( obj instanceof Date ) { return ( ( Date ) obj ) . getTime ( ) ; } try { return DateUtils . parseDate ( obj . toString ( ) . toUpperCase ( ) , DATE_PATTERNS ) . getTime ( ) ; } catch ( final java . text . ParseException e ) { throw new ParseException ( e . getMessage ( ) ) ; } } } 
public abstract Query toRangeQuery ( final String name , final String lower , final String upper , final boolean lowerInclusive , final boolean upperInclusive ) throws ParseException ; public abstract Query toTermQuery ( final String name , final String text ) throws ParseException ; public final SortField . Type toType ( ) { return type ; } public static long toDate ( final Object obj ) throws ParseException { if ( obj instanceof Date ) { return ( ( Date ) obj ) . getTime ( ) ; } try { return DateUtils . parseDate ( obj . toString ( ) . toUpperCase ( ) , DATE_PATTERNS ) . getTime ( ) ; } catch ( final java . text . ParseException e ) { throw new ParseException ( e . getMessage ( ) ) ; } } } 
public abstract Query toTermQuery ( final String name , final String text ) throws ParseException ; public final SortField . Type toType ( ) { return type ; } public static long toDate ( final Object obj ) throws ParseException { if ( obj instanceof Date ) { return ( ( Date ) obj ) . getTime ( ) ; } try { return DateUtils . parseDate ( obj . toString ( ) . toUpperCase ( ) , DATE_PATTERNS ) . getTime ( ) ; } catch ( final java . text . ParseException e ) { throw new ParseException ( e . getMessage ( ) ) ; } } } 
public Analyzer newAnalyzer ( final String args ) throws JSONException { final JSONObject json = new JSONObject ( args = = null ? " {} " : args ) ; final Analyzer defaultAnalyzer = Analyzers . getAnalyzer ( json . optString ( Constants . DEFAULT_FIELD , " standard " ) ) ; final Map < String , Analyzer > analyzers = new HashMap < String , Analyzer > ( ) ; final Iterator < ? > it = json . keys ( ) ; while ( it . hasNext ( ) ) { final String key = it . next ( ) . toString ( ) ; if ( Constants . DEFAULT_FIELD . equals ( key ) ) continue ; analyzers . put ( key , Analyzers . getAnalyzer ( json . getString ( key ) ) ) ; } return new PerFieldAnalyzerWrapper ( defaultAnalyzer , analyzers ) ; } 
protected TokenStreamComponents createComponents ( String fieldName , Reader reader ) { Tokenizer source = new LowerCaseTokenizer ( Constants . VERSION , reader ) ; return new TokenStreamComponents ( source , new PorterStemFilter ( source ) ) ; } 
public void testLongValue ( ) throws Exception { final String fun = " function(doc) { var ret=new Document(); ret.add(12, {type: \" long \" , field: \" num \" }); return ret; } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hi \" } " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 1 ) ) ; assertThat ( result . iterator ( ) . next ( ) . getField ( " num " ) , is ( LongField . class ) ) ; } 
public void testDateString ( ) throws Exception { final String fun = " function(doc) { var ret=new Document(); ret.add( \" 2009-01-01 \" , {type: \" date \" , field: \" num \" }); return ret; } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hi \" } " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 1 ) ) ; assertThat ( result . iterator ( ) . next ( ) . getField ( " num " ) , is ( LongField . class ) ) ; } 
public void testDateObject ( ) throws Exception { final String fun = " function(doc) { var ret=new Document(); ret.add(new Date(2010,8,13), {type: \" date \" , field: \" num \" }); return ret; } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hi \" } " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 1 ) ) ; assertThat ( result . iterator ( ) . next ( ) . getField ( " num " ) , is ( LongField . class ) ) ; assertThat ( ( Long ) ( result . iterator ( ) . next ( ) . getField ( " num " ) ) . numericValue ( ) , is ( 1284332400000L ) ) ; } 
public void testDateObject2 ( ) throws Exception { final String fun = " function(doc) { var ret=new Document(); ret.add(new Date( \" January 6, 1972 16:05:00 \" ), {type: \" date \" , field: \" num \" }); return ret; } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hi \" } " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 1 ) ) ; assertThat ( result . iterator ( ) . next ( ) . getField ( " num " ) , is ( LongField . class ) ) ; assertThat ( ( Long ) ( result . iterator ( ) . next ( ) . getField ( " num " ) ) . numericValue ( ) , is ( 63561900000L ) ) ; } 
public void testParseInt ( ) throws Exception { final String fun = " function(doc) { var ret=new Document(); ret.add(parseInt( \" 12.5 \" ), {type: \" int \" , field: \" num \" }); return ret; } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hi \" } " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 1 ) ) ; assertThat ( result . iterator ( ) . next ( ) . getField ( " num " ) , is ( IntField . class ) ) ; } 
public void testPerField ( ) throws Exception { final Analyzer analyzer = Analyzers . getAnalyzer ( " perfield:{name: \" standard \" ,age: \" keyword \" } " ) ; assertThat ( analyzer , is ( PerFieldAnalyzerWrapper . class ) ) ; assertThat ( analyzer . toString ( ) , containsString ( " default=org.apache.lucene.analysis.standard.StandardAnalyzer " ) ) ; assertThat ( analyzer . toString ( ) , containsString ( " name=org.apache.lucene.analysis.standard.StandardAnalyzer " ) ) ; assertThat ( analyzer . toString ( ) , containsString ( " age=org.apache.lucene.analysis.core.KeywordAnalyzer " ) ) ; } 
public void testPerFieldDefault ( ) throws Exception { final Analyzer analyzer = Analyzers . getAnalyzer ( " perfield:{default: \" keyword \" } " ) ; assertThat ( analyzer , is ( PerFieldAnalyzerWrapper . class ) ) ; assertThat ( analyzer . toString ( ) , containsString ( " default=org.apache.lucene.analysis.core.KeywordAnalyzer " ) ) ; } 
public HttpUriRequest getChangesRequest ( final UpdateSequence since , final long imeout ) throws IOException { final String uri ; if ( imeout > - 1 ) { uri = url + " _changes?feed=continuous&timeout= " + imeout + " &include_docs=true " ; } else { uri = url + " _changes?feed=continuous&heartbeat=15000&include_docs=true " ; } return new HttpGet ( since . appendSince ( uri ) ) ; } 
public void info ( final HttpServletRequest req , final HttpServletResponse resp ) throws IOException , JSONException { final IndexState state = getState ( req , resp ) ; if ( state = = null ) return ; final DirectoryReader reader = state . borrowReader ( true ) ; try { final JSONObject result = new JSONObject ( ) ; 
public void testForEverything ( ) throws Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) {var ret=new Document(); " + " function idx(obj) {for (var key in obj) " + " {switch (typeof obj[key]) {case 'object':idx(obj[key]); break; " + " case 'function': break; default: ret.add(obj[key]); break;} } }; idx(doc); return ret; } " ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hello \" , l1: { l2: {l3:[ \" v3 \" , \" v4 \" ]}}} " ) , settings ( ) , null ) ; assertThat ( result . iterator ( ) . next ( ) . getValues ( Constants . DEFAULT_FIELD ) , hasItemInArray ( " hello " ) ) ; assertThat ( result . iterator ( ) . next ( ) . getValues ( Constants . DEFAULT_FIELD ) , hasItemInArray ( " v3 " ) ) ; assertThat ( result . iterator ( ) . next ( ) . getValues ( Constants . DEFAULT_FIELD ) , hasItemInArray ( " v4 " ) ) ; } 
public Field toField ( final String name , final Object value , final ViewSettings settings ) { return boost ( new Field ( name , value . toString ( ) , settings . getStore ( ) , settings . getIndex ( ) , settings . getTermVector ( ) ) , settings ) ; 
public Query toRangeQuery ( final String name , final String lower , final String upper , final boolean lowerInclusive , final boolean upperInclusive ) throws ParseException { return NumericRangeQuery . newLongRange ( name , toDate ( lower ) , toDate ( upper ) , lowerInclusive , upperInclusive ) ; 
public Query toRangeQuery ( final String name , final String lower , final String upper , final boolean lowerInclusive , final boolean upperInclusive ) { return NumericRangeQuery . newDoubleRange ( name , toDouble ( lower ) , toDouble ( upper ) , lowerInclusive , upperInclusive ) ; 
public Query toRangeQuery ( final String name , final String lower , final String upper , final boolean lowerInclusive , final boolean upperInclusive ) { return NumericRangeQuery . newFloatRange ( name , toFloat ( lower ) , toFloat ( upper ) , lowerInclusive , upperInclusive ) ; 
public Query toRangeQuery ( final String name , final String lower , final String upper , final boolean lowerInclusive , final boolean upperInclusive ) { return NumericRangeQuery . newIntRange ( name , toInt ( lower ) , toInt ( upper ) , lowerInclusive , upperInclusive ) ; 
public Query toRangeQuery ( final String name , final String lower , final String upper , final boolean lowerInclusive , final boolean upperInclusive ) { return NumericRangeQuery . newLongRange ( name , toLong ( lower ) , toLong ( upper ) , lowerInclusive , upperInclusive ) ; 
public void testRuntimeException ( ) throws Exception { LOG . warn ( " You can ignore the following exception stack trace. " ) ; final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) {throw {bad : \" stuff \" }} " ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hello \" } " ) , settings ( ) , null ) ; LOG . warn ( " You can ignore the preceding exception stack trace. " ) ; assertThat ( result . size ( ) , is ( 0 ) ) ; } 
public Analyzer newAnalyzer ( final String args ) throws JSONException { final JSONObject json = new JSONObject ( args = = null ? " {} " : args ) ; int min = json . optInt ( " min " , NGramTokenizer . DEFAULT_MIN_NGRAM_SIZE ) ; int max = json . optInt ( " max " , NGramTokenizer . DEFAULT_MAX_NGRAM_SIZE ) ; return new NGramAnalyzer ( min , max ) ; } 
protected TokenStreamComponents createComponents ( String fieldName , Reader reader ) { Tokenizer source = new NGramTokenizer ( Constants . VERSION , reader , this . min , this . max ) ; return new TokenStreamComponents ( source ) ; } 
public void testNGramInstance ( ) throws Exception { final Analyzer analyzer = Analyzers . getAnalyzer ( " ngram " ) ; assertThat ( analyzer . toString ( ) , containsString ( " NGramAnalyzer " ) ) ; } 
public void testNGramTokens ( ) throws Exception { assertThat ( analyze ( " ngram " , " hey there " ) , is ( new String [ ] { " h " , " he " , " e " , " ey " , " y " , " y " , " " , " t " , " " , " th " , " h " , " he " , " e " , " er " , " r " , " re " , " e " } ) ) ; } 
public void testNGramMinMax ( ) throws Exception { assertThat ( analyze ( " ngram:{ \" min \" :2, \" max \" :3} " , " hello there " ) , is ( new String [ ] { " he " , " hel " , " el " , " ell " , " ll " , " llo " , " lo " , " lo " , " o " , " o t " , " t " , " th " , " th " , " the " , " he " , " her " , " er " , " ere " , " re " } ) ) ; } 
public Analyzer newAnalyzer ( final String args ) throws JSONException { final JSONObject json = new JSONObject ( args = = null ? " {} " : args ) ; final Analyzer analyzer = Analyzers . getAnalyzer ( json . optString ( " analyzer " , " standard " ) ) ; int min = json . optInt ( " min " , NGramTokenFilter . DEFAULT_MIN_NGRAM_SIZE ) ; int max = json . optInt ( " max " , NGramTokenFilter . DEFAULT_MAX_NGRAM_SIZE ) ; return new NGramAnalyzer ( analyzer , min , max ) ; } 
protected TokenStreamComponents wrapComponents ( String fieldName , TokenStreamComponents components ) { return new TokenStreamComponents ( components . getTokenizer ( ) , new NGramTokenFilter ( Constants . VERSION , components . getTokenStream ( ) , 
public void testNGramTokens ( ) throws Exception { assertThat ( analyze ( " ngram:{ \" analyzer \" : \" simple \" } " , " hey there " ) , is ( new String [ ] { " h " , " he " , " e " , " ey " , " y " , " " , " th " , " h " , " he " , " e " , " er " , " r " , " re " , " e " } ) ) ; } 
public void testNGramMinMax ( ) throws Exception { assertThat ( analyze ( " ngram:{ \" analyzer \" : \" simple \" , \" min \" :2, \" max \" :3} " , " hello there " ) , is ( new String [ ] { " he " , " hel " , " el " , " ell " , " ll " , " llo " , " lo " , " th " , " the " , " he " , " her " , " er " , " ere " , " re " } ) ) ; } 
public Query toTermQuery ( final String name , final String text ) throws ParseException { final long date = toDate ( text ) ; final BytesRefBuilder builder = new BytesRefBuilder ( ) ; NumericUtils . longToPrefixCoded ( date , 0 , builder ) ; return new TermQuery ( new Term ( name , builder . toBytesRef ( ) ) ) ; } 
public Query toTermQuery ( final String name , final String text ) { final long asLong = NumericUtils . doubleToSortableLong ( toDouble ( text ) ) ; final BytesRefBuilder builder = new BytesRefBuilder ( ) ; NumericUtils . longToPrefixCoded ( asLong , 0 , builder ) ; return new TermQuery ( new Term ( name , builder . toBytesRef ( ) ) ) ; } 
public Query toTermQuery ( final String name , final String text ) { final int asInt = NumericUtils . floatToSortableInt ( toFloat ( text ) ) ; final BytesRefBuilder builder = new BytesRefBuilder ( ) ; NumericUtils . intToPrefixCoded ( asInt , 0 , builder ) ; return new TermQuery ( new Term ( name , builder . toBytesRef ( ) ) ) ; } 
public Query toTermQuery ( final String name , final String text ) { final BytesRefBuilder builder = new BytesRefBuilder ( ) ; NumericUtils . intToPrefixCoded ( toInt ( text ) , 0 , builder ) ; return new TermQuery ( new Term ( name , builder . toBytesRef ( ) ) ) ; } 
public Query toTermQuery ( final String name , final String text ) { final BytesRefBuilder builder = new BytesRefBuilder ( ) ; NumericUtils . longToPrefixCoded ( toLong ( text ) , 0 , builder ) ; return new TermQuery ( new Term ( name , builder . toBytesRef ( ) ) ) ; } 
private List < DesignDocument > toDesignDocuments ( final JSONObject json ) throws JSONException { final List < DesignDocument > result = new ArrayList < > ( ) ; for ( final JSONObject doc : rows ( json ) ) { result . add ( new DesignDocument ( doc ) ) ; } return result ; } 
private List < CouchDocument > toDocuments ( final JSONObject json ) throws JSONException { final List < CouchDocument > result = new ArrayList < > ( ) ; for ( final JSONObject doc : rows ( json ) ) { result . add ( doc = = null ? null : new CouchDocument ( doc ) ) ; } return result ; } 
private List < JSONObject > rows ( final JSONObject json ) throws JSONException { final List < JSONObject > result = new ArrayList < > ( ) ; final JSONArray rows = json . getJSONArray ( " rows " ) ; for ( int i = 0 ; i < rows . length ( ) ; i + + ) { result . add ( rows . getJSONObject ( i ) . optJSONObject ( " doc " ) ) ; } return result ; } 
public Map < String , View > getAllViews ( ) throws JSONException { if ( fulltext = = null ) return Collections . emptyMap ( ) ; final Map < String , View > result = new HashMap < > ( ) ; final Iterator < ? > it = fulltext . keys ( ) ; while ( it . hasNext ( ) ) { final Object key = it . next ( ) ; final String name = ( String ) key ; final View view = getView ( name ) ; if ( view ! = null ) { result . put ( name , view ) ; } } return result ; } 
public Analyzer newAnalyzer ( final String args ) throws JSONException { final JSONObject json = new JSONObject ( args = = null ? " {} " : args ) ; final Analyzer defaultAnalyzer = Analyzers . getAnalyzer ( json . optString ( Constants . DEFAULT_FIELD , " standard " ) ) ; final Map < String , Analyzer > analyzers = new HashMap < > ( ) ; final Iterator < ? > it = json . keys ( ) ; while ( it . hasNext ( ) ) { final String key = it . next ( ) . toString ( ) ; if ( Constants . DEFAULT_FIELD . equals ( key ) ) continue ; analyzers . put ( key , Analyzers . getAnalyzer ( json . getString ( key ) ) ) ; } return new PerFieldAnalyzerWrapper ( defaultAnalyzer , analyzers ) ; } 
private static boolean getBooleanParameter ( final HttpServletRequest req , final String parameterName ) { return Boolean . parseBoolean ( req . getParameter ( parameterName ) ) ; } 
private static int getIntParameter ( final HttpServletRequest req , final String parameterName , final int defaultValue ) { final String result = req . getParameter ( parameterName ) ; return result ! = null ? Integer . parseInt ( result ) : defaultValue ; } 
private static boolean isStaleOk ( final HttpServletRequest req ) { return " ok " . equals ( req . getParameter ( " stale " ) ) ; } 
private static String toPath ( final String ddoc , final String view ) { return ddoc + " / " + view ; } 
private static String trim ( final String fun ) { String result = fun ; result = StringUtils . trim ( result ) ; result = StringUtils . removeStart ( result , " \" " ) ; result = StringUtils . removeEnd ( result , " \" " ) ; return result ; } 
public static void main ( String [ ] args ) throws Exception { final Config config = new Config ( ) ; final File dir = config . getDir ( ) ; final Server server = new Server ( ) ; final ServerConnector connector = new ServerConnector ( server ) ; connector . setHost ( config . getConfiguration ( ) . getString ( " lucene.host " , " localhost " ) ) ; connector . setPort ( config . getConfiguration ( ) . getInt ( " lucene.port " , 5985 ) ) ; LOG . info ( " Accepting connections with " + connector ) ; server . addConnector ( connector ) ; server . setStopAtShutdown ( true ) ; final LuceneServlet servlet = new LuceneServlet ( config . getClient ( ) , dir , config . getConfiguration ( ) ) ; final ServletContextHandler context = new ServletContextHandler ( server , " / " , ServletContextHandler . NO_SESSIONS | ServletContextHandler . NO_SECURITY ) ; context . addServlet ( new ServletHolder ( servlet ) , " /* " ) ; context . setErrorHandler ( new JSONErrorHandler ( ) ) ; context . setGzipHandler ( new GzipHandler ( ) ) ; server . setHandler ( context ) ; server . start ( ) ; server . join ( ) ; } 
public static void sendJsonError ( final HttpServletRequest request , final HttpServletResponse response , final int code , final JSONObject error ) throws IOException , JSONException { setResponseContentTypeAndEncoding ( request , response ) ; response . setHeader ( " Cache-Control " , " must-revalidate,no-cache,no-store " ) ; response . setStatus ( code ) ; error . put ( " code " , code ) ; final Writer writer = response . getWriter ( ) ; try { writer . write ( error . toString ( ) ) ; 
public Query parse ( final String query , final Operator operator , final Analyzer analyzer ) throws ParseException , JSONException { final QueryParser parser = new CustomQueryParser ( Constants . DEFAULT_FIELD , analyzer ) ; parser . setDefaultOperator ( operator ) ; parser . setAllowLeadingWildcard ( ini . getBoolean ( " lucene.allowLeadingWildcard " , false ) ) ; parser . setLowercaseExpandedTerms ( ini . getBoolean ( " lucene.lowercaseExpandedTerms " , true ) ) ; return parser . parse ( query ) ; } 
private IndexWriter newWriter ( final Directory dir , final Analyzer analyzer ) throws IOException { final IndexWriterConfig config = new IndexWriterConfig ( analyzer ) ; config . setUseCompoundFile ( ini . getBoolean ( " lucene.useCompoundFile " , false ) ) ; config . setRAMBufferSizeMB ( ini . getDouble ( " lucene.ramBufferSizeMB " , IndexWriterConfig . DEFAULT_RAM_BUFFER_SIZE_MB ) ) ; return new IndexWriter ( dir , config ) ; } 
public Query toRangeQuery ( final String name , final String lower , final String upper , final boolean lowerInclusive , final boolean upperInclusive ) { return TermRangeQuery . newStringRange ( name , lower , upper , lowerInclusive , upperInclusive ) ; 
public Analyzer newAnalyzer ( final String args ) { return new BrazilianAnalyzer ( ) ; } 
public Analyzer newAnalyzer ( final String args ) { return new SmartChineseAnalyzer ( ) ; } 
public Analyzer newAnalyzer ( final String args ) { return new CJKAnalyzer ( ) ; } 
public Analyzer newAnalyzer ( final String args ) { return new ClassicAnalyzer ( ) ; } 
public Analyzer newAnalyzer ( final String args ) { return new CzechAnalyzer ( ) ; } 
public Analyzer newAnalyzer ( final String args ) { return new DutchAnalyzer ( ) ; } 
public Analyzer newAnalyzer ( final String args ) { return new StandardAnalyzer ( ) ; } 
public Analyzer newAnalyzer ( final String args ) { return new FrenchAnalyzer ( ) ; } 
public Analyzer newAnalyzer ( final String args ) { return new GermanAnalyzer ( ) ; } 
public Analyzer newAnalyzer ( final String args ) { return new RussianAnalyzer ( ) ; } 
public Analyzer newAnalyzer ( final String args ) { return new ThaiAnalyzer ( ) ; } 
protected TokenStreamComponents wrapComponents ( String fieldName , TokenStreamComponents components ) { return new TokenStreamComponents ( components . getTokenizer ( ) , new NGramTokenFilter ( components . getTokenStream ( ) , 
public void setup ( ) { parser = new CustomQueryParser ( " default " , new StandardAnalyzer ( ) ) ; } 
public synchronized DirectoryReader borrowReader ( final boolean staleOk ) throws IOException , JSONException { blockForLatest ( staleOk ) ; if ( reader = = null ) { etag = newEtag ( ) ; } if ( reader ! = null ) { reader . decRef ( ) ; } reader = DirectoryReader . open ( writer , ! staleOk , false ) ; if ( readerDirty ) { etag = newEtag ( ) ; readerDirty = false ; } reader . incRef ( ) ; return reader ; } 
private static void planBooleanQuery ( final StringBuilder builder , final BooleanQuery query ) { for ( final BooleanClause clause : query . clauses ( ) ) { builder . append ( clause . getOccur ( ) ) ; 
private static void planBoostQuery ( final StringBuilder builder , final BoostQuery query ) { toPlan ( builder , query . getQuery ( ) ) ; builder . append ( " ,boost= " + query . getBoost ( ) + " ) " ) ; } 
private static void toPlan ( final StringBuilder builder , final Query query ) { builder . append ( query . getClass ( ) . getSimpleName ( ) ) ; builder . append ( " ( " ) ; if ( query instanceof TermQuery ) { planTermQuery ( builder , ( TermQuery ) query ) ; } else if ( query instanceof BooleanQuery ) { planBooleanQuery ( builder , ( BooleanQuery ) query ) ; } else if ( query instanceof TermRangeQuery ) { planTermRangeQuery ( builder , ( TermRangeQuery ) query ) ; } else if ( query instanceof PrefixQuery ) { planPrefixQuery ( builder , ( PrefixQuery ) query ) ; } else if ( query instanceof WildcardQuery ) { planWildcardQuery ( builder , ( WildcardQuery ) query ) ; } else if ( query instanceof FuzzyQuery ) { planFuzzyQuery ( builder , ( FuzzyQuery ) query ) ; } else if ( query instanceof BoostQuery ) { planBoostQuery ( builder , ( BoostQuery ) query ) ; } else { builder . append ( query . getClass ( ) ) ; builder . append ( " @ " ) ; builder . append ( query ) ; } builder . append ( " ) " ) ; } 
public LongPoint toField ( final String name , final Object value , final ViewSettings settings ) throws ParseException { return boost ( new LongPoint ( name , toDate ( value ) ) , settings ) ; } 
public Query toRangeQuery ( final String name , final String lower , final String upper , final boolean lowerInclusive , final boolean upperInclusive ) throws ParseException { return LongPoint . newRangeQuery ( name , lowerInclusive ? toDate ( lower ) : Math . addExact ( toDate ( lower ) , 1 ) , 
public Query toTermQuery ( final String name , final String text ) throws ParseException { return LongPoint . newExactQuery ( name , toDate ( text ) ) ; } 
public DoublePoint toField ( final String name , final Object value , final ViewSettings settings ) { return boost ( new DoublePoint ( name , toDouble ( value ) ) , settings ) ; } 
public Query toRangeQuery ( final String name , final String lower , final String upper , final boolean lowerInclusive , final boolean upperInclusive ) { return DoublePoint . newRangeQuery ( name , lowerInclusive ? toDouble ( lower ) : Math . nextUp ( toDouble ( lower ) ) , 
public Query toTermQuery ( final String name , final String text ) { return DoublePoint . newExactQuery ( name , toDouble ( text ) ) ; } 
public FloatPoint toField ( final String name , final Object value , final ViewSettings settings ) { return boost ( new FloatPoint ( name , toFloat ( value ) ) , settings ) ; } 
public Query toRangeQuery ( final String name , final String lower , final String upper , final boolean lowerInclusive , final boolean upperInclusive ) { return FloatPoint . newRangeQuery ( name , lowerInclusive ? toFloat ( lower ) : Math . nextUp ( toFloat ( lower ) ) , 
public Query toTermQuery ( final String name , final String text ) { return FloatPoint . newExactQuery ( name , toFloat ( text ) ) ; } 
public IntPoint toField ( final String name , final Object value , final ViewSettings settings ) { return boost ( new IntPoint ( name , toInt ( value ) ) , settings ) ; } 
public Query toRangeQuery ( final String name , final String lower , final String upper , final boolean lowerInclusive , final boolean upperInclusive ) { return IntPoint . newRangeQuery ( name , lowerInclusive ? toInt ( lower ) : Math . addExact ( toInt ( lower ) , 1 ) , 
public Query toTermQuery ( final String name , final String text ) { return IntPoint . newExactQuery ( name , toInt ( text ) ) ; } 
public LongPoint toField ( final String name , final Object value , final ViewSettings settings ) { return boost ( new LongPoint ( name , toLong ( value ) ) , settings ) ; } 
public Query toRangeQuery ( final String name , final String lower , final String upper , final boolean lowerInclusive , final boolean upperInclusive ) { return LongPoint . newRangeQuery ( name , lowerInclusive ? toLong ( lower ) : Math . addExact ( toLong ( lower ) , 1 ) , 
public Query toTermQuery ( final String name , final String text ) { return LongPoint . newExactQuery ( name , toLong ( text ) ) ; } 
public Field toField ( final String name , final Object value , final ViewSettings settings ) { return boost ( new StringField ( name , value . toString ( ) , settings . getStore ( ) ) , settings ) ; } 
public Field toField ( final String name , final Object value , final ViewSettings settings ) { return boost ( new TextField ( name , value . toString ( ) , settings . getStore ( ) ) , settings ) ; } 
public Query toRangeQuery ( final String name , final String lower , final String upper , final boolean lowerInclusive , final boolean upperInclusive ) { throw new UnsupportedOperationException ( " toRangeQuery is not supported for TEXT " ) ; } 
public Query toTermQuery ( String name , String text ) { throw new UnsupportedOperationException ( " toTermQuery is not supported for TEXT " ) ; } 
public static Field text ( final String name , final String value , final boolean store ) { return new TextField ( name , value , store ? Store . YES : Store . NO ) ; } 
public static Field token ( final String name , final String value , final boolean store ) { return new StringField ( name , value , store ? Store . YES : Store . NO ) ; } 
private void assertRange ( final Query q , final Class < ? > type , final Number min , final Number max ) { assertThat ( q , is ( PointRangeQuery . class ) ) ; } 
public void testLongValue ( ) throws Exception { final String fun = " function(doc) { var ret=new Document(); ret.add(12, {type: \" long \" , field: \" num \" }); return ret; } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hi \" } " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 1 ) ) ; assertThat ( result . iterator ( ) . next ( ) . getField ( " num " ) , is ( LongPoint . class ) ) ; } 
public void testDateString ( ) throws Exception { final String fun = " function(doc) { var ret=new Document(); ret.add( \" 2009-01-01 \" , {type: \" date \" , field: \" num \" }); return ret; } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hi \" } " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 1 ) ) ; assertThat ( result . iterator ( ) . next ( ) . getField ( " num " ) , is ( LongPoint . class ) ) ; } 
public void testDateObject ( ) throws Exception { final String fun = " function(doc) { var ret=new Document(); ret.add(new Date(2010,8,13), {type: \" date \" , field: \" num \" }); return ret; } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hi \" } " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 1 ) ) ; assertThat ( result . iterator ( ) . next ( ) . getField ( " num " ) , is ( LongPoint . class ) ) ; assertThat ( ( Long ) ( result . iterator ( ) . next ( ) . getField ( " num " ) ) . numericValue ( ) , is ( 1284332400000L ) ) ; } 
public void testDateObject2 ( ) throws Exception { final String fun = " function(doc) { var ret=new Document(); ret.add(new Date( \" January 6, 1972 16:05:00 \" ), {type: \" date \" , field: \" num \" }); return ret; } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hi \" } " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 1 ) ) ; assertThat ( result . iterator ( ) . next ( ) . getField ( " num " ) , is ( LongPoint . class ) ) ; assertThat ( ( Long ) ( result . iterator ( ) . next ( ) . getField ( " num " ) ) . numericValue ( ) , is ( 63561900000L ) ) ; } 
public void testParseInt ( ) throws Exception { final String fun = " function(doc) { var ret=new Document(); ret.add(parseInt( \" 12.5 \" ), {type: \" int \" , field: \" num \" }); return ret; } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hi \" } " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 1 ) ) ; assertThat ( result . iterator ( ) . next ( ) . getField ( " num " ) , is ( IntPoint . class ) ) ; } 
public void addFields ( final String name , final Object value , final ViewSettings settings , final Document to ) throws ParseException { to . add ( boost ( new LongPoint ( name , toDate ( value ) ) , settings ) ) ; } 
public void addFields ( final String name , final Object value , final ViewSettings settings , final Document to ) { to . add ( boost ( new DoublePoint ( name , toDouble ( value ) ) , settings ) ) ; } 
public void addFields ( final String name , final Object value , final ViewSettings settings , final Document to ) { to . add ( boost ( new FloatPoint ( name , toFloat ( value ) ) , settings ) ) ; } 
public void addFields ( final String name , final Object value , final ViewSettings settings , final Document to ) { to . add ( boost ( new IntPoint ( name , toInt ( value ) ) , settings ) ) ; } 
public void addFields ( final String name , final Object value , final ViewSettings settings , final Document to ) { to . add ( boost ( new LongPoint ( name , toLong ( value ) ) , settings ) ) ; } 
public void addFields ( final String name , final Object value , final ViewSettings settings , final Document to ) { to . add ( boost ( new StringField ( name , value . toString ( ) , settings . getStore ( ) ) , settings ) ) ; } 
public void addFields ( final String name , final Object value , final ViewSettings settings , final Document to ) { to . add ( boost ( new TextField ( name , value . toString ( ) , settings . getStore ( ) ) , settings ) ) ; } 
public abstract void addFields ( final String name , final Object value , final ViewSettings settings , final Document to ) throws ParseException ; public abstract Query toRangeQuery ( final String name , final String lower , final String upper , final boolean lowerInclusive , final boolean upperInclusive ) throws ParseException ; public abstract Query toTermQuery ( final String name , final String text ) throws ParseException ; public final SortField . Type toType ( ) { return type ; } public static long toDate ( final Object obj ) throws ParseException { if ( obj instanceof Date ) { return ( ( Date ) obj ) . getTime ( ) ; } try { return DateUtils . parseDate ( obj . toString ( ) . toUpperCase ( ) , DATE_PATTERNS ) . getTime ( ) ; } catch ( final java . text . ParseException e ) { throw new ParseException ( e . getMessage ( ) ) ; } } } 
private void addField ( final RhinoField field , final ViewSettings defaults , final Document out ) throws ParseException { final ViewSettings settings = new ViewSettings ( field . settings , defaults ) ; final FieldType type = settings . getFieldType ( ) ; type . addFields ( settings . getField ( ) , field . value , settings , out ) ; } 
public void addFields ( final String name , final Object value , final ViewSettings settings , final Document to ) throws ParseException { to . add ( boost ( new LongPoint ( name , toDate ( value ) ) , settings ) ) ; to . add ( new NumericDocValuesField ( name , toDate ( value ) ) ) ; } 
public void addFields ( final String name , final Object value , final ViewSettings settings , final Document to ) { to . add ( boost ( new DoublePoint ( name , toDouble ( value ) ) , settings ) ) ; to . add ( new DoubleDocValuesField ( name , toDouble ( value ) ) ) ; } 
public void addFields ( final String name , final Object value , final ViewSettings settings , final Document to ) { to . add ( boost ( new FloatPoint ( name , toFloat ( value ) ) , settings ) ) ; to . add ( new FloatDocValuesField ( name , toFloat ( value ) ) ) ; } 
public void addFields ( final String name , final Object value , final ViewSettings settings , final Document to ) { to . add ( boost ( new IntPoint ( name , toInt ( value ) ) , settings ) ) ; to . add ( new NumericDocValuesField ( name , toInt ( value ) ) ) ; } 
public void addFields ( final String name , final Object value , final ViewSettings settings , final Document to ) { to . add ( boost ( new LongPoint ( name , toLong ( value ) ) , settings ) ) ; to . add ( new NumericDocValuesField ( name , toLong ( value ) ) ) ; } 
public void addFields ( final String name , final Object value , final ViewSettings settings , final Document to ) { to . add ( boost ( new StringField ( name , value . toString ( ) , settings . getStore ( ) ) , settings ) ) ; to . add ( new SortedDocValuesField ( name , new BytesRef ( value . toString ( ) ) ) ) ; } 
public Analyzer analyzer ( final String spec ) throws JSONException { return spec = = null ? this . analyzer : Analyzers . fromSpec ( spec ) ; } 
public Analyzer getAnalyzer ( ) throws JSONException { return Analyzers . fromSpec ( json ) ; } 
public ViewSettings getDefaultSettings ( ) throws JSONException { return json . has ( Constants . DEFAULTS ) ? new ViewSettings ( json . getJSONObject ( Constants . DEFAULTS ) ) : ViewSettings . getDefaultSettings ( ) ; 
public String getFunction ( ) throws JSONException { return trim ( json . getString ( Constants . INDEX ) ) ; } 
public Analyzer newAnalyzer ( final JSONObject args ) { return new BrazilianAnalyzer ( ) ; } 
public Analyzer newAnalyzer ( final JSONObject args ) { return new SmartChineseAnalyzer ( ) ; } 
public Analyzer newAnalyzer ( final JSONObject args ) { return new CJKAnalyzer ( ) ; } 
public Analyzer newAnalyzer ( final JSONObject args ) { return new ClassicAnalyzer ( ) ; } 
public Analyzer newAnalyzer ( final JSONObject args ) { return new CzechAnalyzer ( ) ; } 
public Analyzer newAnalyzer ( final JSONObject args ) { return new DutchAnalyzer ( ) ; } 
public Analyzer newAnalyzer ( final JSONObject args ) { return new StandardAnalyzer ( ) ; } 
public Analyzer newAnalyzer ( final JSONObject args ) { return new FrenchAnalyzer ( ) ; } 
public Analyzer newAnalyzer ( final JSONObject args ) { return new GermanAnalyzer ( ) ; } 
public Analyzer newAnalyzer ( final JSONObject args ) { return new KeywordAnalyzer ( ) ; } 
public Analyzer newAnalyzer ( final String args ) throws JSONException { final JSONObject json = new JSONObject ( args = = null ? " {} " : args ) ; return PERFIELD . newAnalyzer ( json ) ; } 
public Analyzer newAnalyzer ( final JSONObject json ) throws JSONException { final Analyzer defaultAnalyzer = fromSpec ( json , Constants . DEFAULT_FIELD ) ; final Map < String , Analyzer > analyzers = new HashMap < > ( ) ; final Iterator < ? > it = json . keys ( ) ; while ( it . hasNext ( ) ) { final String key = it . next ( ) . toString ( ) ; if ( Constants . DEFAULT_FIELD . equals ( key ) ) continue ; analyzers . put ( key , fromSpec ( json , key ) ) ; } return new PerFieldAnalyzerWrapper ( defaultAnalyzer , analyzers ) ; } 
public Analyzer newAnalyzer ( final JSONObject args ) { return new RussianAnalyzer ( ) ; } 
public Analyzer newAnalyzer ( final JSONObject args ) { return new SimpleAnalyzer ( ) ; } 
public Analyzer newAnalyzer ( final JSONObject args ) { return new ThaiAnalyzer ( ) ; } 
public Analyzer newAnalyzer ( final JSONObject args ) { return new WhitespaceAnalyzer ( ) ; } 
public Analyzer newAnalyzer ( final String args ) throws JSONException { final JSONObject json = new JSONObject ( args = = null ? " {} " : args ) ; return NGRAM . newAnalyzer ( json ) ; } 
public Analyzer newAnalyzer ( final JSONObject json ) throws JSONException { Analyzer analyzer = fromSpec ( json ) ; int min = json . optInt ( " min " , NGramTokenFilter . DEFAULT_MIN_NGRAM_SIZE ) ; int max = json . optInt ( " max " , NGramTokenFilter . DEFAULT_MAX_NGRAM_SIZE ) ; return new NGramAnalyzer ( analyzer , min , max ) ; } 
public static Analyzer fromSpec ( final JSONObject json , final String analyzerKey ) throws JSONException { JSONObject spec = json . optJSONObject ( analyzerKey ) ; if ( spec ! = null ) { return getAnalyzer ( spec ) ; 
public static Analyzer fromSpec ( final JSONObject json ) throws JSONException { return fromSpec ( json , Constants . ANALYZER ) ; } 
public static Analyzer fromSpec ( String str ) throws JSONException { if ( str = = null ) { return getAnalyzer ( Constants . DEFAULT_ANALYZER ) ; } if ( str . startsWith ( " { " ) ) { try { return getAnalyzer ( new JSONObject ( str ) ) ; } catch ( JSONException ex ) { logger . error ( " Analyzer spec is not well-formed json. Using default analyzer! " , ex ) ; return getAnalyzer ( Constants . DEFAULT_ANALYZER ) ; } } return getAnalyzer ( str ) ; } 
public static Analyzer getAnalyzer ( final JSONObject json ) throws JSONException { String className = json . optString ( Constants . CLASS ) ; JSONArray params = json . optJSONArray ( Constants . PARAMS ) ; if ( className = = null | | className . isEmpty ( ) ) { Iterator < ? > it = json . keys ( ) ; if ( it . hasNext ( ) ) { String key = ( String ) it . next ( ) ; String args = json . optString ( key ) ; JSONObject obj = json . optJSONObject ( key ) ; if ( obj ! = null ) { return Analyzers . valueOf ( key . toUpperCase ( ) ) . newAnalyzer ( obj ) ; } else { return Analyzers . valueOf ( key . toUpperCase ( ) ) . newAnalyzer ( args ) ; } } logger . error ( " No analyzer class name defined in " + json ) ; return null ; } is the class accessible? Class<?> clazz = null; try { clazz = Class.forName(className); } catch (ClassNotFoundException e) { logger.error("Analyzer class " + className + " not found. " + e.getMessage(), e); return null; } Is the class an Analyzer? if (!Analyzer.class.isAssignableFrom(clazz)) { logger.error(clazz.getName() + " has to be a subclass of " + Analyzer.class.getName()); return null; } Get list of parameters List<ParamSpec> paramSpecs; try { paramSpecs = getParamSpecs(params); } catch (ParameterException | JSONException ex) { logger.error("Unable to parse parameter specs for " + className + ". " + ex.getMessage(), ex); return null; } split param specs into classes and values for constructor lookup final Class<?> paramClasses[] = new Class<?>[paramSpecs.size()]; final Object paramValues[] = new Object[paramSpecs.size()]; for (int i = 0; i < paramSpecs.size(); i++) { ParamSpec spec = paramSpecs.get(i); paramClasses[i] = spec.getValueClass(); paramValues[i] = spec.getValue(); } Create new analyzer return newAnalyzer(clazz, paramClasses, paramValues); } 
private static Analyzer newAnalyzer ( Class < ? > clazz , Class < ? > [ ] paramClasses , Object [ ] paramValues ) { String className = clazz . getName ( ) ; try { final Constructor < ? > cstr = clazz . getDeclaredConstructor ( paramClasses ) ; return ( Analyzer ) cstr . newInstance ( paramValues ) ; } catch ( IllegalArgumentException | IllegalAccessException | InstantiationException | InvocationTargetException | SecurityException e ) { logger . error ( " Exception while instantiating analyzer class " + className + " . " + e . getMessage ( ) , e ) ; } catch ( NoSuchMethodException ex ) { logger . error ( " Could not find matching analyzer class constructor for " + className + " " + ex . getMessage ( ) , ex ) ; } return null ; } 
private static List < ParamSpec > getParamSpecs ( JSONArray jsonParams ) throws ParameterException , JSONException { final List < ParamSpec > paramSpecs = new ArrayList < > ( ) ; if ( jsonParams ! = null ) { for ( int i = 0 ; i < jsonParams . length ( ) ; i + + ) { paramSpecs . add ( getParamSpec ( jsonParams . getJSONObject ( i ) ) ) ; } } return paramSpecs ; } 
private static ParamSpec getParamSpec ( JSONObject param ) throws ParameterException , JSONException { final String name = param . optString ( " name " ) ; final String type = param . optString ( " type " , " string " ) ; final String value = param . optString ( " value " ) ; switch ( type ) { String case "string": { if (value == null) { throw new ParameterException("Value for string param: " + name + " is not empty!"); } return new ParamSpec(name, value, String.class); } "java.io.FileReader": case "file": { if (value == null) { throw new ParameterException("The 'value' field of a file param must exist and must contain a file name."); } try { The analyzer is responsible for closing the file Reader fileReader = new java.io.FileReader(value); return new ParamSpec(name, fileReader, Reader.class); } catch (java.io.FileNotFoundException ex) { throw new ParameterException("File " + value + " for param " + name + " not found!"); } } "org.apache.lucene.analysis.util.CharArraySet": case "set": { JSONArray values = param.optJSONArray("value"); if (values == null) { throw new ParameterException("The 'value' field of a set param must exist and must contain a json array of strings."); } final Set<String> set = new HashSet<>(); for (int i = 0; i < values.length(); i++) { set.add(values.getString(i)); } return new ParamSpec(name, CharArraySet.copy(set), CharArraySet.class); } "int": case "int": int n = param.optInt("value"); return new ParamSpec(name, n, int.class); "boolean": case "boolean": boolean b = param.optBoolean("value"); return new ParamSpec(name, b, boolean.class); default: there was no match logger.error("Unknown parameter type: " + type + " for param: " + name + " with value: " + value); break; } return null; } 
public abstract Analyzer newAnalyzer ( final String args ) throws JSONException ; public abstract Analyzer newAnalyzer ( final JSONObject args ) throws JSONException ; static Logger logger = Logger . getLogger ( Analyzers . class . getName ( ) ) ; } 
public abstract Analyzer newAnalyzer ( final JSONObject args ) throws JSONException ; static Logger logger = Logger . getLogger ( Analyzers . class . getName ( ) ) ; } 
public void testClassInstance ( ) throws Exception { tfinal JSONObject obj = new JSONObject ( " { \" class \" : \" org.apache.lucene.analysis.core.KeywordAnalyzer \" } " ) ; tfinal Analyzer analyzer = Analyzers . getAnalyzer ( obj ) ; tassertThat ( analyzer , is ( KeywordAnalyzer . class ) ) ; } 
public void testClassInstance2 ( ) throws Exception { tfinal JSONObject obj = new JSONObject ( " { \" class \" : \" org.apache.lucene.analysis.nl.DutchAnalyzer \" , \" params \" : [] } " ) ; tfinal Analyzer analyzer = Analyzers . getAnalyzer ( obj ) ; tassertThat ( analyzer , is ( org . apache . lucene . analysis . nl . DutchAnalyzer . class ) ) ; } 
public void testClassInstance3 ( ) throws Exception { tfinal JSONObject obj = new JSONObject ( " { \" class \" : \" org.apache.lucene.analysis.cn.smart.SmartChineseAnalyzer \" , \" params \" : [ { \" name \" : \" useDefaultStopWords \" , \" type \" : \" boolean \" , \" value \" : true } ] } " ) ; tfinal Analyzer analyzer = Analyzers . getAnalyzer ( obj ) ; tassertThat ( analyzer , is ( org . apache . lucene . analysis . cn . smart . SmartChineseAnalyzer . class ) ) ; } 
public void testClassInstance4 ( ) throws Exception { tfinal JSONObject obj = new JSONObject ( " { \" german \" : {} } " ) ; tfinal Analyzer analyzer = Analyzers . getAnalyzer ( obj ) ; tassertThat ( analyzer , is ( org . apache . lucene . analysis . de . GermanAnalyzer . class ) ) ; } 
public void testClassInstance5 ( ) throws Exception { tfinal JSONObject obj = new JSONObject ( " { \" cjk \" : \" \" } " ) ; tfinal Analyzer analyzer = Analyzers . getAnalyzer ( obj ) ; tassertThat ( analyzer , is ( org . apache . lucene . analysis . cjk . CJKAnalyzer . class ) ) ; } 
public void testClassInstance6 ( ) throws Exception { tfinal JSONObject obj = new JSONObject ( " { \" ngram \" : { \" analyzer \" : \" simple \" , \" min \" : 2, \" max \" : 3 } } " ) ; tfinal Analyzer analyzer = Analyzers . getAnalyzer ( obj ) ; tassertThat ( analyzer . toString ( ) , containsString ( " NGramAnalyzer " ) ) ; } 
public void testClassInstance7 ( ) throws Exception { final Analyzer analyzer = Analyzers . getAnalyzer ( " perfield:{default: \" keyword \" , lang_bo:{ \" class \" : \" org.apache.lucene.analysis.core.WhitespaceAnalyzer \" }, lang_sa:{ \" class \" : \" org.apache.lucene.analysis.hi.HindiAnalyzer \" }} " ) ; assertThat ( analyzer , is ( PerFieldAnalyzerWrapper . class ) ) ; assertThat ( analyzer . toString ( ) , containsString ( " default=org.apache.lucene.analysis.core.KeywordAnalyzer " ) ) ; assertThat ( analyzer . toString ( ) , containsString ( " lang_bo=org.apache.lucene.analysis.core.WhitespaceAnalyzer " ) ) ; assertThat ( analyzer . toString ( ) , containsString ( " lang_sa=org.apache.lucene.analysis.hi.HindiAnalyzer " ) ) ; } 
public void testClassInstance8 ( ) throws Exception { tfinal Analyzer analyzer = Analyzers . fromSpec ( " { \" perfield \" :{ \" default \" : \" keyword \" , \" lang_bo \" : { \" class \" : \" org.apache.lucene.analysis.core.WhitespaceAnalyzer \" }, \" lang_sa \" : { \" class \" : \" org.apache.lucene.analysis.hi.HindiAnalyzer \" }}} " ) ; assertThat ( analyzer , is ( PerFieldAnalyzerWrapper . class ) ) ; assertThat ( analyzer . toString ( ) , containsString ( " default=org.apache.lucene.analysis.core.KeywordAnalyzer " ) ) ; assertThat ( analyzer . toString ( ) , containsString ( " lang_bo=org.apache.lucene.analysis.core.WhitespaceAnalyzer " ) ) ; assertThat ( analyzer . toString ( ) , containsString ( " lang_sa=org.apache.lucene.analysis.hi.HindiAnalyzer " ) ) ; } 
public abstract Analyzer newAnalyzer ( final String args ) throws JSONException ; public abstract Analyzer newAnalyzer ( final JSONObject args ) throws JSONException ; static Logger logger = LoggerFactory . getLogger ( Analyzers . class . getName ( ) ) ; } 
public abstract Analyzer newAnalyzer ( final JSONObject args ) throws JSONException ; static Logger logger = LoggerFactory . getLogger ( Analyzers . class . getName ( ) ) ; } 
