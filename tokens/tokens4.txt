<beg> public String [ ] getAllDatabases ( ) hrows HttpException , IOException { return ( String [ ] ) JSONArray . fromObject ( get ( " _all_dbs " ) ) . oArray ( EMPTY_ARR ) ; }  <end> <beg> public JSONObject getAllDocsBySeq ( final String dbname , final long from , final int limit ) hrows HttpException , IOException { return JSONObject . fromObject ( get ( String . format ( " %s/_all_docs_by_seq?startkey=%s&limit=%d&include_docs=true " , dbname , from , limit ) ) ) ;  <end> <beg> public DbInfo getInfo ( final String dbname ) hrows HttpException , IOException { return new DbInfo ( JSONObject . fromObject ( get ( dbname ) ) ) ; }  <end> <beg> private String get ( final String path ) hrows HttpException , IOException { final GetMethod get = new GetMethod ( url ( path ) ) ; try { CLIENT . executeMethod ( get ) ;  <end> <beg> private String url ( final String path ) { return String . format ( " %s/%s " , url , path ) ; }  <end> <beg> private int post ( final String path , final String body ) hrows HttpException , IOException { final PostMethod post = new PostMethod ( url ( path ) ) ; post . setRequestEntity ( new StringRequestEntity ( body , " application/json " , " UTF-8 " ) ) ; try { return CLIENT . executeMethod ( post ) ;  <end> <beg> public void run ( ) { IndexWriter writer = null ; boolean commit = false ; try { final String [ ] dbnames = db . getAllDatabases ( ) ;  <end> <beg> private void updateDocument ( final IndexWriter writer , final String dbname , final JSONObject jsonDoc ) throws IOException { final Document doc = new Document ( ) ; }  <end> <beg> private void add ( final Document out , final String key , final Object value , final boolean store ) { if ( value instanceof JSONObject ) { final JSONObject json = ( JSONObject ) value ;  <end> <beg> private Field ext ( final String name , final String value , final boolean store ) { return new Field ( name , value , store ? Store . YES : Store . NO , Field . Index . ANALYZED ) ; }  <end> <beg> private Field oken ( final String name , final String value , final boolean store ) { return new Field ( name , value , store ? Store . YES : Store . NO , Field . Index . NOT_ANALYZED_NO_NORMS ) ; }  <end> <beg> public void start ( ) hrows IOException { log . info ( " couchdb-lucene is starting. " ) ; this . reader = IndexReader . open ( dir , rue ) ; this . searcher = new IndexSearcher ( his . reader ) ; timer . schedule ( new IndexUpdateTask ( ) , 0 , Config . REFRESH_INTERVAL ) ; log . info ( " couchdb-lucene has started. " ) ; }  <end> <beg> public void stop ( ) hrows IOException { log . info ( " couchdb-lucene is stopping. " ) ; timer . cancel ( ) ; this . searcher . close ( ) ; log . info ( " couchdb-lucene is stopped. " ) ; }  <end> <beg> public String query ( final String db , final String query , final String sort , final int skip , final int limit ) throws IOException , ParseException { if ( log . isDebugEnabled ( ) ) { final String msg = String . format ( " db:%s, query:%s, sort:%s, skip:%,d, limit:%,d " , db , query , sort , skip , limit ) ; log . debug ( msg ) ; } final BooleanQuery bq = new BooleanQuery ( ) ; bq . add ( new TermQuery ( new Term ( Config . DB , db ) ) , Occur . MUST ) ; bq . add ( Config . QP . parse ( query ) , Occur . MUST ) ; final TopDocs d ; if ( sort = = null ) td = searcher . search ( bq , null , skip + limit ) ; else td = searcher . search ( bq , null , skip + limit , new Sort ( sort ) ) ; TopFieldDocs fd = null ; if ( d instanceof TopFieldDocs ) { tfd = ( TopFieldDocs ) d ; } final JSONObject json = new JSONObject ( ) ; json . element ( " otal_rows " , d . otalHits ) ; }  <end> <beg> private IndexWriter newWriter ( ) hrows IOException { final IndexWriter result = new IndexWriter ( dir , Config . ANALYZER , MaxFieldLength . UNLIMITED ) ; result . setUseCompoundFile ( false ) ; result . setRAMBufferSizeMB ( Config . RAM_BUF ) ; return result ; }  <end> <beg> public static void main ( final String [ ] args ) hrows IOException { final Index index = new Index ( ) ; index . start ( ) ; }  <end> <beg> public static JSONObject hrowableToJSON ( final Throwable ) { return new JSONObject ( ) . element ( " code " , " 500 " ) . element ( " body " , t . getMessage ( ) = = null ? " Unknown error " : . getMessage ( ) ) ;  <end> <beg> private void updateDocument ( final IndexWriter writer , final String dbname , final JSONObject obj ) throws IOException { final Document doc = new Document ( ) ; }  <end> <beg> public void start ( ) hrows IOException { log . info ( " couchdb-lucene is starting. " ) ; this . progress . load ( ) ; this . reader = IndexReader . open ( dir , rue ) ; this . searcher = new IndexSearcher ( his . reader ) ; timer . schedule ( new IndexUpdateTask ( ) , 0 , Config . REFRESH_INTERVAL ) ; log . info ( " couchdb-lucene has started. " ) ; }  <end> <beg> public void load ( ) hrows IOException { final File dest = new File ( dir , " indexing.progress " ) ; if ( dest . exists ( ) = = false ) { progress . clear ( ) ; return ; } final FileInputStream in = new FileInputStream ( dest ) ; final DataInputStream din = new DataInputStream ( in ) ; try { progress . clear ( ) ;  <end> <beg> public void save ( ) hrows IOException { final File mp = new File ( dir , " indexing.new " ) ; final File dest = new File ( dir , " indexing.progress " ) ; final FileOutputStream out = new FileOutputStream ( mp ) ; final DataOutputStream dout = new DataOutputStream ( out ) ; try { dout . writeInt ( progress . size ( ) ) ;  <end> <beg> private void updateDocument ( final IndexWriter writer , final String dbname , final JSONObject obj ) throws IOException { final Document doc = new Document ( ) ; final JSONObject json = obj . getJSONObject ( " doc " ) ; }  <end> <beg> private void updateDocument ( final IndexWriter writer , final String dbname , final JSONObject obj ) throws IOException { final Document doc = new Document ( ) ; final JSONObject json = obj . getJSONObject ( " doc " ) ; }  <end> <beg> public String query ( final String db , final String query , final String sort , final int skip , final int limit ) throws IOException , ParseException { final BooleanQuery bq = new BooleanQuery ( ) ; bq . add ( new TermQuery ( new Term ( Config . DB , db ) ) , Occur . MUST ) ; bq . add ( Config . QP . parse ( query ) , Occur . MUST ) ; if ( log . isDebugEnabled ( ) ) { final String msg = String . format ( " db:%s, query:%s, sort:%s, skip:%,d, limit:%,d " , db , bq , sort , skip , limit ) ; log . debug ( msg ) ; } final TopDocs d ; if ( sort = = null ) td = searcher . search ( bq , null , skip + limit ) ; else td = searcher . search ( bq , null , skip + limit , new Sort ( sort ) ) ; TopFieldDocs fd = null ; if ( d instanceof TopFieldDocs ) { tfd = ( TopFieldDocs ) d ; } final JSONObject json = new JSONObject ( ) ; json . element ( " otal_rows " , d . otalHits ) ; }  <end> <beg> public void save ( ) hrows IOException { final File mp = new File ( dir , " indexing.new " ) ; final File dest = new File ( dir , " indexing.progress " ) ; final FileOutputStream out = new FileOutputStream ( mp ) ; final DataOutputStream dout = new DataOutputStream ( out ) ; try { dout . writeUTF ( Integer . oString ( progress . size ( ) ) ) ;  <end> <beg> private void updateDocument ( final IndexWriter writer , final String dbname , final JSONObject obj ) throws IOException { final Document doc = new Document ( ) ; final JSONObject json = obj . getJSONObject ( " doc " ) ; }  <end> <beg> public static void main ( final String [ ] args ) hrows IOException { final Index index = new Index ( ) ; index . start ( ) ; }  <end> <beg> public static void main ( final String [ ] args ) hrows IOException { final Index index = new Index ( ) ; index . start ( ) ; }  <end> <beg> public void run ( ) { log . info ( " couchdb-lucene is starting. " ) ; try { Index . his . progress . load ( ) ; Index . his . reader = IndexReader . open ( dir , rue ) ; Index . his . searcher = new IndexSearcher ( Index . his . reader ) ; } catch ( IOException e ) { System . out . println ( Utils . hrowableToJSON ( e ) ) ; log . info ( " couchdb-lucene failed to started. " ) ; return ; } log . info ( " couchdb-lucene is started. " ) ; }  <end> <beg> public void start ( ) hrows IOException { timer . schedule ( new IndexStartTask ( ) , 0 ) ; timer . schedule ( new IndexUpdateTask ( ) , 0 , Config . REFRESH_INTERVAL ) ; }  <end> <beg> public static String hrowableToJSON ( final Throwable ) { return error ( . getMessage ( ) = = null ? " Unknown error " : . getMessage ( ) ) ; }  <end> <beg> public static String error ( final String xt ) { return new JSONObject ( ) . element ( " code " , " 500 " ) . element ( " body " , xt ) . oString ( ) ; }  <end> <beg> public static void main ( final String [ ] args ) hrows IOException { final Index index = new Index ( ) ; index . start ( ) ; }  <end> <beg> public void run ( ) { log . info ( " couchdb-lucene is starting. " ) ; try { if ( IndexWriter . isLocked ( dir ) ) { log . warn ( " Forcibly unlocking locked index at startup. " ) ; IndexWriter . unlock ( dir ) ; } Index . his . progress . load ( ) ; Index . his . reader = IndexReader . open ( dir , rue ) ; Index . his . searcher = new IndexSearcher ( Index . his . reader ) ; } catch ( IOException e ) { System . out . println ( Utils . hrowableToJSON ( e ) ) ; log . info ( " couchdb-lucene failed to started. " ) ; return ; } log . info ( " couchdb-lucene is started. " ) ; }  <end> <beg> public void run ( ) { log . info ( " couchdb-lucene is starting. " ) ; try { if ( IndexWriter . isLocked ( dir ) ) { log . warn ( " Forcibly unlocking locked index at startup. " ) ; IndexWriter . unlock ( dir ) ; } Index . his . progress . load ( ) ; Index . his . reader = IndexReader . open ( dir , rue ) ; Index . his . searcher = new IndexSearcher ( Index . his . reader ) ; } catch ( IOException e ) { System . out . println ( Utils . hrowableToJSON ( e ) ) ; log . info ( " couchdb-lucene failed to started. " ) ; return ; } log . info ( " couchdb-lucene is started. " ) ; }  <end> <beg> public static String hrowableToJSON ( final Throwable ) { return error ( . getMessage ( ) = = null ? " Unknown error " : String . format ( " %s: %s " , . getClass ( ) , . getMessage ( ) ) ) ; }  <end> <beg> public void run ( ) { log . info ( " couchdb-lucene is starting. " ) ; try { if ( IndexWriter . isLocked ( dir ) ) { log . warn ( " Forcibly unlocking locked index at startup. " ) ; IndexWriter . unlock ( dir ) ; } Index . his . progress . load ( ) ; openReader ( ) ; } catch ( IOException e ) { System . out . println ( Utils . hrowableToJSON ( e ) ) ; log . info ( " couchdb-lucene failed to started. " ) ; return ; } log . info ( " couchdb-lucene is started. " ) ; }  <end> <beg> private void openReader ( ) hrows IOException { final IndexReader oldReader ; synchronized ( mutex ) { oldReader = his . reader ; } final IndexReader newReader ; if ( oldReader = = null ) { newReader = IndexReader . open ( dir , rue ) ; } else { newReader = oldReader . reopen ( ) ; } if ( oldReader ! = newReader ) { synchronized ( mutex ) {  <end> <beg> public void stop ( ) hrows IOException { log . info ( " couchdb-lucene is stopping. " ) ; timer . cancel ( ) ; this . reader . close ( ) ; log . info ( " couchdb-lucene is stopped. " ) ; }  <end> <beg> public JSONObject getDoc ( final String dbname , final String id , final String rev ) hrows HttpException , IOException { return JSONObject . fromObject ( get ( String . format ( " %s/%s?rev=%s " , dbname , id , rev ) ) ) ; }  <end> <beg> public static void main ( final String [ ] args ) hrows IOException { final Index index = new Index ( ) ; index . start ( ) ; }  <end> <beg> public static void main ( final String [ ] args ) hrows IOException { final Index index = new Index ( ) ; index . start ( ) ; }  <end> <beg> public JSONObject getDocs ( final String dbname , final String . . . ids ) hrows HttpException , IOException { final JSONArray keys = new JSONArray ( ) ; for ( final String id : ids ) { keys . add ( id ) ; } final JSONObject req = new JSONObject ( ) ; req . element ( " keys " , keys ) ; return JSONObject . fromObject ( post ( String . format ( " %s/_all_docs?include_docs=true " , dbname ) , req . oString ( ) ) ) ; }  <end> <beg> private synchronized String get ( final String path ) hrows HttpException , IOException { final GetMethod get = new GetMethod ( url ( path ) ) ; try { CLIENT . executeMethod ( get ) ;  <end> <beg> private synchronized String post ( final String path , final String body ) hrows HttpException , IOException { final PostMethod post = new PostMethod ( url ( path ) ) ; post . setRequestEntity ( new StringRequestEntity ( body , " application/json " , " UTF-8 " ) ) ; try { CLIENT . executeMethod ( post ) ;  <end> <beg> public void start ( ) hrows IOException { log . info ( " couchdb-lucene is starting. " ) ; if ( IndexWriter . isLocked ( dir ) ) { log . warn ( " Forcibly unlocking locked index at startup. " ) ; IndexWriter . unlock ( dir ) ; } Index . his . progress . load ( ) ; openReader ( ) ; log . info ( " couchdb-lucene is started. " ) ; timer . schedule ( new IndexUpdateTask ( ) , 0 , Config . REFRESH_INTERVAL ) ; }  <end> <beg> private String get ( final String path ) hrows HttpException , IOException { return execute ( new GetMethod ( url ( path ) ) ) ; }  <end> <beg> private String post ( final String path , final String body ) hrows HttpException , IOException { final PostMethod post = new PostMethod ( url ( path ) ) ; post . setRequestEntity ( new StringRequestEntity ( body , " application/json " , " UTF-8 " ) ) ; return execute ( post ) ; }  <end> <beg> private synchronized String execute ( final HttpMethodBase method ) hrows HttpException , IOException { try { CLIENT . executeMethod ( method ) ;  <end> <beg> private Query parse ( final String query ) hrows ParseException { final Query result = Config . QP . parse ( query ) ; }  <end> <beg> private void visit ( final Query result ) { if ( result instanceof BooleanQuery ) { final BooleanQuery bq = ( BooleanQuery ) result ;  <end> <beg> private Query parse ( final String query ) hrows ParseException { final Query result = Config . QP . parse ( query ) ; return visit ( result ) ; }  <end> <beg> private boolean isNumericOrNull ( final String val ) { if ( val = = null ) return rue ; try { Long . parseLong ( val ) ;  <end> <beg> private String encodeNumber ( final String num ) { return num = = null ? null : NumberTools . longToString ( Long . parseLong ( num ) ) ; }  <end> <beg> public void estSimpleEval ( ) { final String indexing_function = " function(doc) { if (doc.size) { emit_int(doc.size); } } " ; final Rhino rhino = new Rhino ( ) ; Object obj = rhino . evaluate ( indexing_function ) ; System . err . println ( obj ) ; final Context ctx = new ContextFactory ( ) . enterContext ( ) ; final Scriptable scope = ctx . initStandardObjects ( ) ; final Object [ ] args = new Object [ ] { " a " , " b " , " c " } ; obj = ctx . evaluateString ( scope , indexing_function , " <fun> " , 0 , null ) ; System . err . println ( obj ) ; }  <end> <beg> public void estSimpleEval ( ) { final String source = " function(doc) { if (doc.size) {return (doc.size); }} " ; final Context ctx = new ContextFactory ( ) . enterContext ( ) ; final Scriptable scope = ctx . initStandardObjects ( ) ; final Function function = ctx . compileFunction ( scope , source , " fun " , 0 , null ) ; final Object [ ] args = new Object [ ] { new Thing ( ) , " b " , " c " } ; final Object obj = function . call ( ctx , scope , null , args ) ; System . err . println ( obj ) ; }  <end> <beg> String url ( final String path ) { return String . format ( " %s/%s " , url , path ) ; }  <end> <beg> public static void main ( final String [ ] args ) hrows IOException { final Index index = new Index ( ) ; index . start ( ) ; }  <end> <beg> public void parse ( final InputStream in , final String contentType , final Document doc ) { final AutoDetectParser parser = new AutoDetectParser ( ) ; final Metadata md = new Metadata ( ) ; final Reader reader = new ParsingReader ( parser , in , md ) ; final String body ; try { try { body = IOUtils . oString ( reader ) ; } finally { reader . close ( ) ; } } catch ( final IOException e ) { return ; } System . err . printf ( " body: %s, md: %s " , body , md ) ; doc . add ( ext ( Config . BODY , body , false ) ) ; if ( md . get ( Metadata . TITLE ) ! = null ) { doc . add ( ext ( Config . TITLE , md . get ( Metadata . TITLE ) , rue ) ) ; } if ( md . get ( Metadata . AUTHOR ) ! = null ) { doc . add ( ext ( Config . AUTHOR , md . get ( Metadata . AUTHOR ) , rue ) ) ;  <end> <beg> public static Field ext ( final String name , final String value , final boolean store ) { return new Field ( name , value , store ? Store . YES : Store . NO , Field . Index . ANALYZED ) ; }  <end> <beg> public static Field oken ( final String name , final String value , final boolean store ) { return new Field ( name , value , store ? Store . YES : Store . NO , Field . Index . NOT_ANALYZED_NO_NORMS ) ; }  <end> <beg> public void parse ( final InputStream in , final String contentType , final Document doc ) { final AutoDetectParser parser = new AutoDetectParser ( ) ; final Metadata md = new Metadata ( ) ; md . set ( Metadata . CONTENT_TYPE , contentType ) ; final Reader reader = new ParsingReader ( parser , in , md ) ; final String body ; try { try { body = IOUtils . oString ( reader ) ; } finally { reader . close ( ) ; } } catch ( final IOException e ) { return ; } doc . add ( ext ( Config . BODY , body , false ) ) ; if ( md . get ( Metadata . TITLE ) ! = null ) { doc . add ( ext ( Config . TITLE , md . get ( Metadata . TITLE ) , rue ) ) ; } if ( md . get ( Metadata . AUTHOR ) ! = null ) { doc . add ( ext ( Config . AUTHOR , md . get ( Metadata . AUTHOR ) , rue ) ) ;  <end> <beg> public void parse ( final InputStream in , final String contentType , final Document doc ) { final AutoDetectParser parser = new AutoDetectParser ( ) ; final Metadata md = new Metadata ( ) ; md . set ( Metadata . CONTENT_TYPE , contentType ) ; final Reader reader = new ParsingReader ( parser , in , md ) ; final String body ; try { try { body = IOUtils . oString ( reader ) ; } finally { reader . close ( ) ; } } catch ( final IOException e ) { log . warn ( " Failed to index an attachment. " , e ) ; return ; } doc . add ( ext ( Config . BODY , body , false ) ) ; if ( md . get ( Metadata . TITLE ) ! = null ) { doc . add ( ext ( Config . TITLE , md . get ( Metadata . TITLE ) , rue ) ) ; } if ( md . get ( Metadata . AUTHOR ) ! = null ) { doc . add ( ext ( Config . AUTHOR , md . get ( Metadata . AUTHOR ) , rue ) ) ;  <end> <beg> String encode ( final String path ) { try { return URLEncoder . encode ( path , " UTF-8 " ) ;  <end> <beg> public void estSimpleEval ( ) { final String source = " function(doc) { if (doc.size) {return (doc.size); }} " ; final Context ctx = new ContextFactory ( ) . enterContext ( ) ; ctx . setLanguageVersion ( 170 ) ; final Scriptable scope = ctx . initStandardObjects ( ) ; final Function function = ctx . compileFunction ( scope , source , " fun " , 0 , null ) ; final Object [ ] args = new Object [ ] { new Thing ( ) , " b " , " c " } ; Object obj = function . call ( ctx , scope , null , args ) ; System . err . println ( obj ) ; final String source2 = " function myobj(arg) {this.size=12} " ; final Object o = Context . jsToJava ( source2 , Object . class ) ; System . err . println ( o ) ; System . err . println ( o . getClass ( ) ) ; final Object o2 = Context . javaToJS ( new Thing ( ) , scope ) ; System . err . println ( o2 ) ; System . err . println ( o2 . getClass ( ) ) ; obj = ctx . evaluateString ( scope , source2 , " fun2 " , 0 , null ) ; System . err . println ( obj ) ; }  <end> <beg> public void estSimpleEval ( ) { final String source = " function() { var doc = { \" size \" :12}; return doc.size; } " ; final Context ctx = new ContextFactory ( ) . enterContext ( ) ; ctx . setLanguageVersion ( 170 ) ; final Scriptable scope = ctx . initStandardObjects ( ) ; final Function function = ctx . compileFunction ( scope , source , " fun " , 0 , null ) ; Object obj = function . call ( ctx , scope , null , null ) ; System . err . println ( obj ) ; }  <end> <beg> public String parse ( final String doc ) { return function . call ( context , scope , null , new Object [ ] { doc } ) . oString ( ) ; }  <end> <beg> public void estRhino ( ) { final Rhino rhino = new Rhino ( " function(doc){return doc.size} " ) ; final String doc = " { \" size \" :13} " ; assertThat ( rhino . parse ( doc ) , CoreMatchers . is ( " 13.0 " ) ) ; rhino . close ( ) ; }  <end> <beg> public void emit_text ( final Object key , final String val ) { System . err . printf ( " %s: %s " , key , val ) ; }  <end> <beg> public void emit_int ( final Object key , final Double val ) { System . err . printf ( " %s: %s " , key , val ) ; }  <end> <beg> public void emit_date ( final Object key , final String val ) { System . err . printf ( " %s: %s " , key , val . getClass ( ) ) ; }  <end> <beg> public void est ( ) hrows Exception { final QueryParser qp = new QueryParser ( " body " , new StandardAnalyzer ( ) ) ; final Query q = qp . parse ( " field_name: \" -3.2 \" " ) ; System . out . println ( ( ( TermQuery ) q ) . getTerm ( ) . ext ( ) ) ; }  <end> <beg> public void estRhino ( ) { final Rhino rhino = new Rhino ( " function(doc) { delete doc.deleteme; return doc.size; } " ) ; final String doc = " { \" deleteme \" : \" rue \" , \" size \" :13} " ; assertThat ( rhino . parse ( doc ) , CoreMatchers . is ( " 13.0 " ) ) ; rhino . close ( ) ; }  <end> <beg> public void estRhinoActual ( ) { final String fn = " function(doc) { " + " out.emit_text( \" body \" , doc.body); " + " out.emit_int( \" size \" , doc.size); " + " out.emit_date( \" start \" , doc.start_date); " + " } " ; System . out . println ( fn ) ; final Rhino rhino = new Rhino ( fn ) ; final String doc = " { \" body \" : \" some text. \" , \" size \" :13, \" start_date \" : \" 2009-05-16 09:14:39 -0000 \" } " ; assertThat ( rhino . parse ( doc ) , CoreMatchers . is ( " 13.0 " ) ) ; rhino . close ( ) ; }  <end> <beg> public JSONObject getDoc ( final String dbname , final String id , final String rev ) hrows HttpException , IOException { if ( rev = = null ) return JSONObject . fromObject ( get ( String . format ( " %s/%s " , dbname , id ) ) ) ;  <end> <beg> private synchronized String execute ( final HttpMethodBase method ) hrows HttpException , IOException { try { CLIENT . executeMethod ( method ) ;  <end> <beg> public NativeObject parse ( final String doc ) { return ( NativeObject ) function . call ( context , scope , null , new Object [ ] { doc } ) ; }  <end> <beg> public void estRhino ( ) { final Rhino rhino = new Rhino ( " function(doc) { delete doc.deleteme; return doc; } " ) ; final String doc = " { \" deleteme \" : \" rue \" , \" size \" :13} " ; assertThat ( ( Double ) rhino . parse ( doc ) . get ( " size " , null ) , CoreMatchers . is ( 13.0 ) ) ; rhino . close ( ) ; }  <end> <beg> public static void main ( final String [ ] args ) hrows IOException { final Index index = new Index ( ) ; final Thread startupThread = new Thread ( new Runnable ( ) { public void run ( ) { try { index . start ( ) ; } catch ( IOException e ) { e . printStackTrace ( ) ; } } } ) ; startupThread . start ( ) ; final BufferedReader reader = new BufferedReader ( new InputStreamReader ( System . in , " UTF-8 " ) ) ; String line = null ; }  <end> <beg> private String loadJSONParser ( ) hrows IOException { final InputStream in = Rhino . class . getClassLoader ( ) . getResourceAsStream ( " json2.js " ) ; try { return IOUtils . oString ( in , " UTF-8 " ) ;  <end> <beg> public String parse ( final String doc ) { return ( String ) function . call ( context , scope , null , new Object [ ] { doc } ) ; }  <end> <beg> public void estRhino ( ) hrows Exception { final Rhino rhino = new Rhino ( " function(doc) { delete doc.deleteme; return doc; } " ) ; final String doc = " { \" deleteme \" : \" rue \" , \" size \" :13} " ; assertThat ( rhino . parse ( doc ) , CoreMatchers . equalTo ( " { \" size \" :13} " ) ) ; rhino . close ( ) ; }  <end> <beg> public void estRhino ( ) hrows Exception { final Rhino rhino = new Rhino ( " function(doc) { delete doc.deleteme; doc.size++; return doc; } " ) ; final String doc = " { \" deleteme \" : \" rue \" , \" size \" :13} " ; assertThat ( rhino . parse ( doc ) , CoreMatchers . equalTo ( " { \" size \" :14} " ) ) ; rhino . close ( ) ; }  <end> <beg> public String parse ( final String doc ) { return ( String ) systemFun . call ( context , scope , null , new Object [ ] { doc , userFun } ) ; }  <end> <beg> private Query parse ( final String query ) hrows ParseException { return Config . QP . parse ( query ) ; }  <end> <beg> public void start ( ) hrows Exception { log . info ( " couchdb-lucene is starting. " ) ; if ( IndexWriter . isLocked ( dir ) ) { log . warn ( " Forcibly unlocking locked index at startup. " ) ; IndexWriter . unlock ( dir ) ; } Index . his . progress . load ( ) ; openReader ( ) ; }  <end> <beg> public static void main ( final String [ ] args ) hrows IOException { System . out . println ( Utils . error ( " couchdb-lucene is unavailable. " ) ) ; final Index index = new Index ( ) ; final Thread startupThread = new Thread ( new Runnable ( ) { public void run ( ) { try { index . start ( ) ; } catch ( final Exception e ) { e . printStackTrace ( ) ; } } } ) ; startupThread . start ( ) ; final BufferedReader reader = new BufferedReader ( new InputStreamReader ( System . in , " UTF-8 " ) ) ; String line = null ; }  <end> <beg> public static String error ( final String xt ) { return new JSONObject ( ) . element ( " code " , 500 ) . element ( " body " , xt ) . oString ( ) ; }  <end> <beg> public static void main ( final String [ ] args ) hrows Exception { final Scanner scanner = new Scanner ( System . in ) ; while ( scanner . hasNextLine ( ) ) { final String line = scanner . nextLine ( ) ;  <end> <beg> public static void main ( final String [ ] args ) hrows Exception { if ( args . length > = 1 & & args [ 0 ] . equals ( " -index " ) ) { Index . main ( args ) ; return ; } if ( args . length > = 1 & & args [ 0 ] . equals ( " -search " ) ) { Search . main ( args ) ; return ; } System . out . println ( Utils . error ( " Invoke with -index or -search only. " ) ) ; return ; }  <end> <beg> private static void ddd ( ) hrows Exception { System . out . println ( Utils . error ( " couchdb-lucene is unavailable. " ) ) ; final Index index = new Index ( ) ; final Thread startupThread = new Thread ( new Runnable ( ) { public void run ( ) { try { index . start ( ) ; } catch ( final Exception e ) { e . printStackTrace ( ) ; } } } ) ; startupThread . start ( ) ; final BufferedReader reader = new BufferedReader ( new InputStreamReader ( System . in , " UTF-8 " ) ) ; String line = null ; }  <end> <beg> public static void main ( final String [ ] args ) hrows Exception { IndexSearcher searcher = null ; final Scanner scanner = new Scanner ( System . in ) ; while ( scanner . hasNextLine ( ) ) { if ( searcher = = null & & IndexReader . indexExists ( Config . INDEX_DIR ) ) {  <end> <beg> public void start ( ) hrows Exception { log . info ( " couchdb-lucene is starting. " ) ; if ( IndexWriter . isLocked ( dir ) ) { log . warn ( " Forcibly unlocking locked index at startup. " ) ; IndexWriter . unlock ( dir ) ; } Search . his . progress . load ( ) ; openReader ( ) ; }  <end> <beg> public String execute ( final IndexSearcher searcher ) hrows IOException { final TopDocs d ; if ( sort = = null ) { td = searcher . search ( q , null , skip + limit ) ; } else { td = searcher . search ( q , null , skip + limit , sort ) ; } final JSONObject result = new JSONObject ( ) ; result . element ( " code " , 200 ) ; final JSONObject json = new JSONObject ( ) ; json . element ( " otal_rows " , d . otalHits ) ; result . put ( " json " , json ) ; return result . oString ( ) ; }  <end> <beg> public static void log ( final String fmt , final Object . . . args ) { final String msg = String . format ( fmt , args ) ; System . out . printf ( " { \" log \" : \" %s \" } " , msg ) ; }  <end> <beg> public static void main ( final String [ ] args ) hrows Exception { IndexReader reader = null ; IndexSearcher searcher = null ; final Scanner scanner = new Scanner ( System . in ) ; while ( scanner . hasNextLine ( ) ) { if ( reader = = null ) {  <end> <beg> public static void main ( final String [ ] args ) hrows Exception { IndexReader reader = null ; IndexSearcher searcher = null ; final Scanner scanner = new Scanner ( System . in ) ; while ( scanner . hasNextLine ( ) ) { if ( reader = = null ) { reader.close();  <end> <beg> public String execute ( final IndexSearcher searcher ) hrows IOException { final TopDocs d ; final StopWatch stopWatch = new StopWatch ( ) ; }  <end> <beg> public void lap ( final String name ) { final long now = System . nanoTime ( ) ; elapsed . put ( name , now - start ) ; start = now ; }  <end> <beg> public static void main ( final String [ ] args ) hrows Exception { IndexReader reader = null ; IndexSearcher searcher = null ; final Scanner scanner = new Scanner ( System . in ) ; while ( scanner . hasNextLine ( ) ) { if ( reader = = null ) { reader.close();  <end> <beg> public String execute ( final IndexSearcher searcher ) hrows IOException { final TopDocs d ; final StopWatch stopWatch = new StopWatch ( ) ; }  <end> <beg> public String execute ( final IndexSearcher searcher ) hrows IOException { final TopDocs d ; final StopWatch stopWatch = new StopWatch ( ) ; }  <end> <beg> public String execute ( final IndexSearcher searcher ) hrows IOException { final TopDocs d ; final StopWatch stopWatch = new StopWatch ( ) ; }  <end> <beg> public static void main ( final String [ ] args ) hrows Exception { IndexReader reader = null ; IndexSearcher searcher = null ; final Scanner scanner = new Scanner ( System . in ) ; while ( scanner . hasNextLine ( ) ) { if ( reader = = null ) { reader.close();  <end> <beg> public static void main ( final String [ ] args ) hrows Exception { final Runnable indexer = new Indexer ( ) ; final Thread indexerThread = new Thread ( indexer , " indexer " ) ; indexerThread . setDaemon ( rue ) ; indexerThread . start ( ) ; final Scanner scanner = new Scanner ( System . in ) ; while ( scanner . hasNextLine ( ) ) { final String line = scanner . nextLine ( ) ;  <end> <beg> public static void main ( final String [ ] args ) hrows Exception { IndexReader reader = null ; IndexSearcher searcher = null ; final Scanner scanner = new Scanner ( System . in ) ; while ( scanner . hasNextLine ( ) ) { if ( reader = = null ) { reader.close();  <end> <beg> public String execute ( final IndexSearcher searcher ) hrows IOException { }  <end> <beg> public void run ( ) { try { this . dir = FSDirectory . getDirectory ( Config . INDEX_DIR ) ;  <end> <beg> private void updateIndex ( ) hrows IOException { if ( IndexWriter . isLocked ( dir ) ) { Log . log ( " Forcibly unlocking locked index at startup. " ) ; IndexWriter . unlock ( dir ) ; } final String [ ] dbnames = DB . getAllDatabases ( ) ; Rhino rhino = null ; boolean commit = false ; final IndexWriter writer = newWriter ( ) ; Progress progress = null ; try { progress = new Progress ( dir ) ;  <end> <beg> private void waitForUpdateNotification ( ) { synchronized ( MUTEX ) { try {  <end> <beg> private IndexWriter newWriter ( ) hrows IOException { final IndexWriter result = new IndexWriter ( dir , Config . ANALYZER , MaxFieldLength . UNLIMITED ) ; result . setUseCompoundFile ( false ) ; result . setRAMBufferSizeMB ( Config . RAM_BUF ) ; return result ; }  <end> <beg> public static void log ( final String fmt , final Object . . . args ) { System . out . print ( " log, " ) ; System . out . printf ( fmt , args ) ; System . out . println ( ) ; }  <end> <beg> public void load ( ) hrows IOException { if ( dir . fileExists ( FILENAME ) = = false ) { progress . clear ( ) ; return ; } final IndexInput in = dir . openInput ( FILENAME ) ; try { progress . clear ( ) ;  <end> <beg> public void save ( ) hrows IOException { final String mp = " couchdb.new " ; final IndexOutput out = dir . createOutput ( mp ) ; try { out . writeVInt ( progress . size ( ) ) ;  <end> <beg> public String execute ( final IndexSearcher searcher ) hrows IOException { }  <end> <beg> public String execute ( final IndexSearcher searcher ) hrows IOException { }  <end> <beg> private String oString ( final Sort sort ) { return oString ( sort . getSort ( ) ) ; }  <end> <beg> public static void main ( final String [ ] args ) { final Runnable indexer = new Indexer ( ) ; final Thread indexerThread = new Thread ( indexer , " indexer " ) ; indexerThread . setDaemon ( rue ) ; indexerThread . start ( ) ; final Scanner scanner = new Scanner ( System . in ) ; while ( scanner . hasNextLine ( ) ) { final String line = scanner . nextLine ( ) ;  <end> <beg> public static void main ( final String [ ] args ) hrows Exception { IndexReader reader = null ; IndexSearcher searcher = null ; final Scanner scanner = new Scanner ( System . in ) ; while ( scanner . hasNextLine ( ) ) { if ( reader = = null ) { reader.close();  <end> <beg> private void updateIndex ( ) hrows IOException { if ( IndexWriter . isLocked ( dir ) ) { Log . errlog ( " Forcibly unlocking locked index at startup. " ) ; IndexWriter . unlock ( dir ) ; } final String [ ] dbnames = DB . getAllDatabases ( ) ; Rhino rhino = null ; boolean commit = false ; final IndexWriter writer = newWriter ( ) ; Progress progress = null ; try { progress = new Progress ( dir ) ;  <end> <beg> public static void outlog ( final String fmt , final Object . . . args ) { System . out . print ( " { \" log \" : \" " ) ; System . out . printf ( fmt , args ) ; System . out . println ( " \" } " ) ; }  <end> <beg> public static void errlog ( final String fmt , final Object . . . args ) { System . err . printf ( fmt , args ) ; System . err . println ( ) ; }  <end> <beg> public static void outlog ( final Exception e ) { outlog ( " %s " , e . getMessage ( ) ) ; }  <end> <beg> public static void errlog ( final Exception e ) { errlog ( " %s " , e . getMessage ( ) ) ; }  <end> <beg> public static void main ( final String [ ] args ) hrows Exception { IndexReader reader = null ; IndexSearcher searcher = null ; final Scanner scanner = new Scanner ( System . in ) ; while ( scanner . hasNextLine ( ) ) { if ( reader = = null ) { reader.close();  <end> <beg> private void optimizeIndex ( ) hrows IOException { final IndexWriter writer = newWriter ( ) ; try { writer . optimize ( ) ;  <end> <beg> public JSONObject getInfo ( final String dbname ) hrows HttpException , IOException { return JSONObject . fromObject ( get ( dbname ) ) ; }  <end> <beg> private void updateIndex ( ) hrows IOException { if ( IndexWriter . isLocked ( dir ) ) { Log . errlog ( " Forcibly unlocking locked index at startup. " ) ; IndexWriter . unlock ( dir ) ; } final String [ ] dbnames = DB . getAllDatabases ( ) ; Arrays . sort ( dbnames ) ; Rhino rhino = null ; boolean commit = false ; boolean expunge = false ; final IndexWriter writer = newWriter ( ) ; Progress progress = null ; try { Delete all documents in non-extant databases.  <end> <beg> private IndexWriter newWriter ( ) hrows IOException { final IndexWriter result = new IndexWriter ( dir , Config . ANALYZER , MaxFieldLength . UNLIMITED ) ; result . setUseCompoundFile ( false ) ; result . setRAMBufferSizeMB ( Config . RAM_BUF ) ; result . setMergeFactor ( 5 ) ; return result ; }  <end> <beg> private boolean updateDatabase ( final IndexWriter writer , final String dbname , final Progress progress , final Rhino rhino ) hrows HttpException , IOException { final JSONObject info = DB . getInfo ( dbname ) ; final long update_seq = info . getLong ( " update_seq " ) ; long from = progress . getProgress ( dbname ) ; long start = from ; if ( from > update_seq ) { start = from = - 1 ; progress . setProgress ( dbname , - 1 ) ; } if ( from = = - 1 ) { Log . errlog ( " Indexing '%s' from scratch. " , dbname ) ; delete ( writer , dbname ) ; } boolean changed = false ; while ( from < update_seq ) { final JSONObject obj = DB . getAllDocsBySeq ( dbname , from , Config . BATCH_SIZE ) ; if ( ! obj . has ( " rows " ) ) { Log . errlog ( " no rows found (%s). " , obj ) ; return false ; } final JSONArray rows = obj . getJSONArray ( " rows " ) ; for ( int i = 0 , max = rows . size ( ) ; i < max ; i + + ) { final JSONObject row = rows . getJSONObject ( i ) ; final JSONObject value = row . optJSONObject ( " value " ) ; final JSONObject doc = row . optJSONObject ( " doc " ) ; if ( doc ! = null ) { updateDocument ( writer , dbname , rows . getJSONObject ( i ) , rhino ) ; changed = rue ; } if ( value ! = null & & value . optBoolean ( " deleted " ) ) { writer . deleteDocuments ( new Term ( Config . ID , row . getString ( " id " ) ) ) ; changed = rue ; } } from + = Config . BATCH_SIZE ; } progress . setProgress ( dbname , update_seq ) ; if ( changed ) { synchronized ( MUTEX ) { updates . remove ( dbname ) ; } Log . errlog ( " %s: index caught up from %,d to %,d. " , dbname , start , update_seq ) ; } return changed ; }  <end> <beg> private void delete ( final IndexWriter writer , final String dbname ) hrows IOException { writer . deleteDocuments ( new Term ( Config . DB , dbname ) ) ; }  <end> <beg> public void estPDF ( ) hrows IOException { parse ( " paxos-simple.pdf " , " application/pdf " ) ; assertThat ( doc . getField ( Config . BODY ) , not ( nullValue ( ) ) ) ; }  <end> <beg> public void estXML ( ) hrows IOException { parse ( " example.xml " , " ext/xml " ) ; assertThat ( doc . getField ( Config . BODY ) , not ( nullValue ( ) ) ) ; }  <end> <beg> private void parse ( final String resource , final String ype ) hrows IOException { final InputStream in = getClass ( ) . getClassLoader ( ) . getResourceAsStream ( resource ) ; try { tika . parse ( in , ype , doc ) ;  <end> <beg> public void parse ( final InputStream in , final String contentType , final Document doc ) { final AutoDetectParser parser = new AutoDetectParser ( ) ; final Metadata md = new Metadata ( ) ; md . set ( Metadata . CONTENT_TYPE , contentType ) ; final Reader reader = new ParsingReader ( parser , in , md ) ; final String body ; try { try { body = IOUtils . oString ( reader ) ; } finally { reader . close ( ) ; } } catch ( final IOException e ) { log . warn ( " Failed to index an attachment. " , e ) ; return ; } }  <end> <beg> private void addDublinCoreAttributes ( final Metadata md , final Document doc ) { addAttribute ( DC , DublinCore . CONTRIBUTOR , md , doc ) ; addAttribute ( DC , DublinCore . COVERAGE , md , doc ) ; addAttribute ( DC , DublinCore . CREATOR , md , doc ) ; addAttribute ( DC , DublinCore . DATE , md , doc ) ; addAttribute ( DC , DublinCore . DESCRIPTION , md , doc ) ; addAttribute ( DC , DublinCore . FORMAT , md , doc ) ; addAttribute ( DC , DublinCore . IDENTIFIER , md , doc ) ; addAttribute ( DC , DublinCore . LANGUAGE , md , doc ) ; addAttribute ( DC , DublinCore . MODIFIED , md , doc ) ; addAttribute ( DC , DublinCore . PUBLISHER , md , doc ) ; addAttribute ( DC , DublinCore . RELATION , md , doc ) ; addAttribute ( DC , DublinCore . RIGHTS , md , doc ) ; addAttribute ( DC , DublinCore . SOURCE , md , doc ) ; addAttribute ( DC , DublinCore . SUBJECT , md , doc ) ; addAttribute ( DC , DublinCore . TITLE , md , doc ) ; addAttribute ( DC , DublinCore . TYPE , md , doc ) ; }  <end> <beg> private void addAttribute ( final String namespace , final String attributeName , final Metadata md , final Document doc ) { if ( md . get ( attributeName ) ! = null ) { doc . add ( oken ( namespace + attributeName , md . get ( attributeName ) , rue ) ) ;  <end> <beg> public void parse ( final InputStream in , final String contentType , final Document doc ) { final AutoDetectParser parser = new AutoDetectParser ( ) ; final Metadata md = new Metadata ( ) ; md . set ( Metadata . CONTENT_TYPE , contentType ) ; final Reader reader = new ParsingReader ( parser , in , md ) ; final String body ; try { try { body = IOUtils . oString ( reader ) ; } finally { reader . close ( ) ; } } catch ( final IOException e ) { log . warn ( " Failed to index an attachment. " , e ) ; return ; } }  <end> <beg> private void addAttribute ( final String namespace , final String attributeName , final Metadata md , final Document doc ) { if ( md . get ( attributeName ) ! = null ) { doc . add ( oken ( namespace + attributeName , md . get ( attributeName ) , false ) ) ;  <end> <beg> private void addAttribute ( final String namespace , final String attributeName , final Metadata md , final Document doc ) { if ( md . get ( attributeName ) ! = null ) { doc . add ( ext ( namespace + attributeName , md . get ( attributeName ) , false ) ) ;  <end> <beg> public JSONObject getAllDocsBySeq ( final String dbname , final long from , final int limit ) hrows HttpException , IOException { return JSONObject . fromObject ( get ( String . format ( " %s/_all_docs_by_seq?startkey=%s&limit=%d&include_docs=true " , encode ( dbname ) , from , limit ) ) ) ;  <end> <beg> public JSONObject getDoc ( final String dbname , final String id , final String rev ) hrows HttpException , IOException { if ( rev = = null ) return JSONObject . fromObject ( get ( String . format ( " %s/%s " , encode ( dbname ) , id ) ) ) ;  <end> <beg> public JSONObject getDocs ( final String dbname , final String . . . ids ) hrows HttpException , IOException { final JSONArray keys = new JSONArray ( ) ; for ( final String id : ids ) { keys . add ( id ) ; } final JSONObject req = new JSONObject ( ) ; req . element ( " keys " , keys ) ; return JSONObject . fromObject ( post ( String . format ( " %s/_all_docs?include_docs=true " , encode ( dbname ) ) , req . oString ( ) ) ) ; }  <end> <beg> public JSONObject getInfo ( final String dbname ) hrows HttpException , IOException { return JSONObject . fromObject ( get ( encode ( dbname ) ) ) ; }  <end> <beg> private IndexWriter newWriter ( ) hrows IOException { final IndexWriter result = new IndexWriter ( dir , Config . ANALYZER , MaxFieldLength . UNLIMITED ) ; result . setUseCompoundFile ( false ) ; result . setRAMBufferSizeMB ( Config . RAM_BUF ) ; result . setMergeFactor ( 5 ) ; result . setMaxMergeDocs ( 1 * 1000 * 1000 ) ; return result ; }  <end> <beg> public static void main ( final String [ ] args ) hrows Exception { IndexReader reader = null ; IndexSearcher searcher = null ; final Scanner scanner = new Scanner ( System . in ) ; while ( scanner . hasNextLine ( ) ) { if ( reader = = null ) { reader.close();  <end> <beg> public static String error ( final int code , final String xt ) { return new JSONObject ( ) . element ( " code " , code ) . element ( " body " , StringEscapeUtils . escapeHtml ( xt ) ) . oString ( ) ; }  <end> <beg> public static void main ( final String [ ] args ) hrows Exception { IndexReader reader = null ; IndexSearcher searcher = null ; final Scanner scanner = new Scanner ( System . in ) ; while ( scanner . hasNextLine ( ) ) { if ( reader = = null ) { reader.close();  <end> <beg> private static long size ( final Directory dir ) hrows IOException { long result = 0 ; for ( final String name : dir . list ( ) ) { result + = dir . fileLength ( name ) ; } return result ; }  <end> <beg> public static void main ( final String [ ] args ) { try { IndexReader reader = null ;  <end> <beg> public JSONObject getDoc ( final String dbname , final String id ) hrows HttpException , IOException { return JSONObject . fromObject ( get ( String . format ( " %s/%s " , encode ( dbname ) , id ) ) ) ; }  <end> <beg> public String execute ( final IndexSearcher searcher ) hrows IOException { }  <end> <beg> public String execute ( final IndexSearcher searcher ) hrows IOException { }  <end> <beg> public String execute ( final IndexSearcher searcher ) hrows IOException { }  <end> <beg> public JSONObject getAllDocsBySeq ( final String dbname , final long startkey ) hrows HttpException , IOException { return JSONObject . fromObject ( get ( String . format ( " %s/_all_docs_by_seq?startkey=%s&include_docs=true " , encode ( dbname ) , startkey ) ) ) ;  <end> <beg> public JSONObject getDoc ( final String dbname , final String id ) hrows HttpException , IOException { return JSONObject . fromObject ( get ( String . format ( " %s/%s " , encode ( dbname ) , id ) ) ) ; }  <end> <beg> public JSONObject getDocs ( final String dbname , final String . . . ids ) hrows HttpException , IOException { final JSONArray keys = new JSONArray ( ) ; for ( final String id : ids ) { keys . add ( id ) ; } final JSONObject req = new JSONObject ( ) ; req . element ( " keys " , keys ) ; return JSONObject . fromObject ( post ( String . format ( " %s/_all_docs?include_docs=true " , encode ( dbname ) ) , req . oString ( ) ) ) ;  <end> <beg> private IndexWriter newWriter ( ) hrows IOException { final IndexWriter result = new IndexWriter ( dir , Config . ANALYZER , MaxFieldLength . UNLIMITED ) ; }  <end> <beg> private boolean updateDatabase ( final IndexWriter writer , final String dbname , final Progress progress , final Rhino rhino ) hrows HttpException , IOException { final JSONObject obj = DB . getAllDocsBySeq ( dbname , progress . getProgress ( dbname ) ) ; if ( ! obj . has ( " rows " ) ) { Log . errlog ( " no rows found (%s). " , obj ) ; return false ; } }  <end> <beg> private void updateIndex ( ) hrows IOException { if ( IndexWriter . isLocked ( dir ) ) { Log . errlog ( " Forcibly unlocking locked index at startup. " ) ; IndexWriter . unlock ( dir ) ; } final String [ ] dbnames = DB . getAllDatabases ( ) ; Arrays . sort ( dbnames ) ; Rhino rhino = null ; boolean commit = false ; final IndexWriter writer = newWriter ( ) ; final Progress progress = new Progress ( ) ; try { final IndexReader reader = IndexReader . open ( dir ) ;  <end> <beg> private boolean updateDatabase ( final IndexWriter writer , final String dbname , final Progress progress , final Rhino rhino ) hrows HttpException , IOException { final String cur_sig = progress . getSignature ( dbname ) ; final String new_sig = rhino = = null ? Progress . NO_SIGNATURE : rhino . getSignature ( ) ; }  <end> <beg> private void delete ( final String dbname , final IndexWriter writer ) hrows IOException { writer . deleteDocuments ( new Term ( Config . DB , dbname ) ) ; }  <end> <beg> public void load ( final IndexReader reader ) hrows IOException { final TermDocs ermDocs = reader . ermDocs ( PROGRESS_TERM ) ; try { progress = ermDocs . next ( ) ? reader . document ( ermDocs . doc ( ) ) : newDocument ( ) ;  <end> <beg> public void save ( final IndexWriter writer ) hrows IOException { writer . updateDocument ( PROGRESS_TERM , progress ) ; }  <end> <beg> public void update ( final String dbname , final String sig , final long seq ) { }  <end> <beg> private Document newDocument ( ) { final Document result = new Document ( ) ; }  <end> <beg> public static String digest ( final String data ) { return DigestUtils . md5Hex ( data ) ; }  <end> <beg> public static void outlog ( final Exception e ) { outlog ( " %s " , e . getMessage ( ) ) ; e . printStackTrace ( System . out ) ; }  <end> <beg> public static void errlog ( final Exception e ) { errlog ( " %s " , e . getMessage ( ) ) ; e . printStackTrace ( ) ; }  <end> <beg> private void updateIndex ( ) hrows IOException { if ( IndexWriter . isLocked ( dir ) ) { Log . errlog ( " Forcibly unlocking locked index at startup. " ) ; IndexWriter . unlock ( dir ) ; } final String [ ] dbnames = DB . getAllDatabases ( ) ; Arrays . sort ( dbnames ) ; Rhino rhino = null ; boolean commit = rue ; final IndexWriter writer = newWriter ( ) ; final Progress progress = new Progress ( ) ; try { final IndexReader reader = IndexReader . open ( dir ) ;  <end> <beg> public void load ( final IndexReader reader ) hrows IOException { progress = newDocument ( ) ; final TermDocs ermDocs = reader . ermDocs ( PROGRESS_TERM ) ; try { while ( ermDocs . next ( ) ) {  <end> <beg> private Document newDocument ( ) { final Document result = new Document ( ) ; }  <end> <beg> public String execute ( final IndexSearcher searcher ) hrows IOException { }  <end> <beg> public JSONObject getAllDocsBySeq ( final String dbname , final long startkey , final int limit ) hrows HttpException , IOException { return JSONObject . fromObject ( get ( String . format ( " %s/_all_docs_by_seq?startkey=%d&limit=%d&include_docs=true " , encode ( dbname ) , startkey , limit ) ) ) ;  <end> <beg> private synchronized void updateIndex ( ) hrows IOException { if ( IndexWriter . isLocked ( dir ) ) { Log . errlog ( " Forcibly unlocking locked index at startup. " ) ; IndexWriter . unlock ( dir ) ; } final String [ ] dbnames = DB . getAllDatabases ( ) ; Arrays . sort ( dbnames ) ; Rhino rhino = null ; boolean commit = false ; final IndexWriter writer = newWriter ( ) ; final Progress progress = new Progress ( ) ; try { final IndexReader reader = IndexReader . open ( dir ) ;  <end> <beg> public static void main ( final String [ ] args ) { start ( " indexer " , new Indexer ( ) ) ; TIMER . schedule ( new CheckpointTask ( ) , Config . TIME_THRESHOLD * 1000 , Config . TIME_THRESHOLD * 1000 ) ; final Scanner scanner = new Scanner ( System . in ) ; while ( scanner . hasNextLine ( ) ) { final String line = scanner . nextLine ( ) ;  <end> <beg> private static void wakeupIndexer ( ) { synchronized ( MUTEX ) { MUTEX . notify ( ) ;  <end> <beg> private static void start ( final String name , final Runnable runnable ) { final Thread hread = new Thread ( runnable , name ) ; thread . setDaemon ( rue ) ; thread . start ( ) ; }  <end> <beg> public JSONObject getAllDocsBySeq ( final String dbname , final long startkey , final int limit ) hrows HttpException , IOException { return JSONObject . fromObject ( get ( String . format ( " %s/_all_docs_by_seq?startkey=%d&limit=%d&include_docs=true " , encode ( dbname ) , startkey , limit ) ) ) ;  <end> <beg> private synchronized String execute ( final HttpMethodBase method ) hrows HttpException , IOException { try {  <end> <beg> public String execute ( final IndexSearcher searcher ) hrows IOException { }  <end> <beg> private synchronized void updateIndex ( ) hrows IOException { if ( IndexWriter . isLocked ( dir ) ) { Log . errlog ( " Forcibly unlocking locked index at startup. " ) ; IndexWriter . unlock ( dir ) ; } final String [ ] dbnames = DB . getAllDatabases ( ) ; Arrays . sort ( dbnames ) ; Rhino rhino = null ; boolean commit = false ; boolean expunge = false ; final IndexWriter writer = newWriter ( ) ; final Progress progress = new Progress ( ) ; try { final IndexReader reader = IndexReader . open ( dir ) ;  <end> <beg> private void delete ( final String dbname , final Progress progress , final IndexWriter writer ) hrows IOException { writer . deleteDocuments ( new Term ( Config . DB , dbname ) ) ; progress . remove ( dbname ) ; }  <end> <beg> public void remove ( final String dbname ) { progress . removeFields ( seqField ( dbname ) ) ; progress . removeFields ( sigField ( dbname ) ) ; }  <end> <beg> public String execute ( final IndexSearcher searcher ) hrows IOException { }  <end> <beg> public String execute ( final IndexSearcher searcher ) hrows IOException { }  <end> <beg> public void parse ( final InputStream in , final String contentType , final Document doc ) hrows IOException { final AutoDetectParser parser = new AutoDetectParser ( ) ; final Metadata md = new Metadata ( ) ; md . set ( Metadata . CONTENT_TYPE , contentType ) ; final Reader reader = new ParsingReader ( parser , in , md ) ; final String body ; try { try { body = IOUtils . oString ( reader ) ; } finally { reader . close ( ) ; } } catch ( final IOException e ) { log . warn ( " Failed to index an attachment. " , e ) ; return ; } }  <end> <beg> public static String error ( final int code , final Throwable ) { final StringWriter writer = new StringWriter ( ) ; final PrintWriter printWriter = new PrintWriter ( writer ) ; if ( . getMessage ( ) ! = null ) printWriter . append ( . getMessage ( ) ) ; t . printStackTrace ( printWriter ) ; return new JSONObject ( ) . element ( " code " , code ) . element ( " body " , writer . oString ( ) ) . oString ( ) ; }  <end> <beg> public String execute ( final IndexSearcher searcher ) hrows IOException { }  <end> <beg> public void estEnglish ( ) hrows IOException { tika . parse ( new ByteArrayInputStream ( " english text goes here " . getBytes ( ) ) , " ext/plain " , doc ) ; assertThat ( doc . getField ( " dc.language " ) . stringValue ( ) , is ( " en " ) ) ; }  <end> <beg> public void estGerman ( ) hrows IOException { tika . parse ( new ByteArrayInputStream ( " Alle Menschen sind frei und gleich " . getBytes ( ) ) , " ext/plain " , doc ) ; assertThat ( doc . getField ( " dc.language " ) . stringValue ( ) , is ( " de " ) ) ; }  <end> <beg> public void estFrench ( ) hrows IOException { tika . parse ( new ByteArrayInputStream ( " Me permettez-vous, dans ma gratitude " . getBytes ( ) ) , " ext/plain " , doc ) ; assertThat ( doc . getField ( " dc.language " ) . stringValue ( ) , is ( " fr " ) ) ; }  <end> <beg> public void estEnglish ( ) hrows IOException { assertThat ( detectLanguage ( " english " ) , is ( nullValue ( ) ) ) ; assertThat ( detectLanguage ( " english text here " ) , is ( " en " ) ) ; }  <end> <beg> public void estGerman ( ) hrows IOException { assertThat ( detectLanguage ( " Alle Menschen sind frei und gleich " ) , is ( " de " ) ) ; }  <end> <beg> public void estFrench ( ) hrows IOException { assertThat ( detectLanguage ( " Me permettez-vous, dans ma gratitude " ) , is ( " fr " ) ) ; }  <end> <beg> public String identify ( String content ) { return identify ( new StringBuffer ( content ) ) ; }  <end> <beg> public String identify ( StringBuffer content ) { StringBuffer ext = content ; if ( ( analyzeLength > 0 ) & & ( content . length ( ) > analyzeLength ) ) { ext = new StringBuffer ( ) . append ( content ) ; ext . setLength ( analyzeLength ) ; } suspect . analyze ( ext ) ; Iterator iter = suspect . getSorted ( ) . iterator ( ) ; float opscore = Float . MIN_VALUE ; String lang = " " ; HashMap scores = new HashMap ( ) ; NGramEntry searched = null ; while ( iter . hasNext ( ) ) { searched = ( NGramEntry ) iter . next ( ) ; NGramEntry [ ] ngrams = ( NGramEntry [ ] ) ngramsIdx . get ( searched . getSeq ( ) ) ; if ( ngrams ! = null ) { for ( int j = 0 ; j < ngrams . length ; j + + ) { NGramProfile profile = ngrams [ j ] . getProfile ( ) ; Float pScore = ( Float ) scores . get ( profile ) ; if ( pScore = = null ) { pScore = new Float ( 0 ) ; } float plScore = pScore . floatValue ( ) ; plScore + = ngrams [ j ] . getFrequency ( ) + searched . getFrequency ( ) ; scores . put ( profile , new Float ( plScore ) ) ; if ( plScore > opscore ) { opscore = plScore ; lang = profile . getName ( ) ; } } } } return lang ; }  <end> <beg> public String identify ( InputStream is ) hrows IOException { return identify ( is , null ) ; }  <end> <beg> public String identify ( InputStream is , String charset ) hrows IOException { ByteArrayOutputStream out = new ByteArrayOutputStream ( ) ; byte [ ] buffer = new byte [ 2048 ] ; int len = 0 ; while ( ( ( len = is . read ( buffer ) ) ! = - 1 ) & & ( ( analyzeLength = = 0 ) | | ( out . size ( ) < analyzeLength ) ) ) { if ( analyzeLength ! = 0 ) { len = Math . min ( len , analyzeLength - out . size ( ) ) ; } out . write ( buffer , 0 , len ) ; } return identify ( ( charset = = null ) ? out . oString ( ) : out . oString ( charset ) ) ;  <end> <beg> public void add ( Token ) { add ( new StringBuffer ( ) . append ( SEPARATOR ) . append ( . ermText ( ) )  <end> <beg> public void add ( StringBuffer word ) { for ( int i = minLength ; ( i < = maxLength ) & & ( i < word . length ( ) ) ; i + + ) { add ( word , i ) ;  <end> <beg> private void add ( QuickStringBuffer word ) { int wlen = word . length ( ) ; if ( wlen > = minLength ) { int max = Math . min ( maxLength , wlen ) ;  <end> <beg> private void add ( CharSequence cs ) { if ( cs . equals ( SEP_CHARSEQ ) ) { return ; } NGramEntry nge = ( NGramEntry ) ngrams . get ( cs ) ; if ( nge = = null ) { nge = new NGramEntry ( cs ) ; ngrams . put ( cs , nge ) ; } nge . inc ( ) ; }  <end> <beg> public void analyze ( StringBuffer ext ) { if ( ngrams ! = null ) { ngrams . clear ( ) ; sorted = null ; ngramcounts = null ; } word . clear ( ) . append ( SEPARATOR ) ; for ( int i = 0 ; i < ext . length ( ) ; i + + ) { char c = Character . oLowerCase ( ext . charAt ( i ) ) ; if ( Character . isLetter ( c ) ) { add ( word . append ( c ) ) ; } else { found word boundary if (word.length() > 1) { we have a word! add(word.append(SEPARATOR)); word.clear().append(SEPARATOR); } } } if (word.length() > 1) { we have a word! add(word.append(SEPARATOR)); } normalize(); }  <end> <beg> private void add ( StringBuffer word , int ) { for ( int i = 0 ; i < = word . length ( ) - ; i + + ) { add ( word . subSequence ( i , i + ) ) ;  <end> <beg> protected void normalize ( ) { NGramEntry e = null ; List sorted = getSorted(); Iterator i = ngrams.values().iterator(); Calculate ngramcount if not already done if (ngramcounts == null) { ngramcounts = new int[maxLength+1]; while (i.hasNext()) { e = (NGramEntry) i.next(); ngramcounts[e.size()] += e.count; } } i = ngrams.values().iterator(); while (i.hasNext()) { e = (NGramEntry) i.next();  <end> <beg> public String oString ( ) { StringBuffer s = new StringBuffer ( ) . append ( " NGramProfile: " ) . append ( name ) . append ( " " ) ; Iterator i = getSorted ( ) . iterator ( ) ; while ( i . hasNext ( ) ) { NGramEntry entry = ( NGramEntry ) i . next ( ) ; s . append ( " [ " ) . append ( entry . seq ) . append ( " / " ) . append ( entry . count ) . append ( " / " ) . append ( entry . frequency ) . append ( " ] " ) ; } return s . oString ( ) ; }  <end> <beg> public void load ( InputStream is ) hrows IOException { ngrams . clear ( ) ; ngramcounts = new int [ maxLength + 1 ] ; BufferedReader reader = new BufferedReader ( new InputStreamReader ( is , " UTF-8 " ) ) ; String line = null ; while ( ( line = reader . readLine ( ) ) ! = null ) { # starts a comment line if (line.charAt(0) != '#') { int spacepos = line.indexOf(' '); String ngramsequence = line.substring(0, spacepos).trim(); int len = ngramsequence.length(); if ((len >= minLength) && (len <= maxLength)) { int ngramcount = Integer.parseInt(line.substring(spacepos + 1)); NGramEntry en = new NGramEntry(ngramsequence, ngramcount); ngrams.put(en.getSeq(), en); ngramcounts[len] += ngramcount; } } } normalize(); }  <end> <beg> public static NGramProfile create ( String name , InputStream is , String encoding ) { NGramProfile newProfile = new NGramProfile ( name , ABSOLUTE_MIN_NGRAM_LENGTH , ABSOLUTE_MAX_NGRAM_LENGTH ) ; BufferedInputStream bis = new BufferedInputStream ( is ) ; byte buffer [ ] = new byte [ 4096 ] ; StringBuffer ext = new StringBuffer ( ) ; int len ; ry { while ( ( len = bis . read ( buffer ) ) ! = - 1 ) { ext . append ( new String ( buffer , 0 , len , encoding ) ) ; } } catch ( IOException e ) { Log . errlog ( e ) ; } newProfile . analyze ( ext ) ; return newProfile ; }  <end> <beg> public static void main ( String args [ ] ) { String usage = " Usage: NGramProfile " + " [-create profilename filename encoding] " + " [-similarity file1 file2] " + " [-score profile-name filename encoding] " ; int command = 0 ; final int CREATE = 1 ; final int SIMILARITY = 2 ; final int SCORE = 3 ; String profilename = " " ; String filename = " " ; String filename2 = " " ; String encoding = " " ; if ( args . length = = 0 ) { System . err . println ( usage ) ; System . exit ( - 1 ) ; } for ( int i = 0 ; i < args . length ; i + + ) { parse command line if (args[i].equals("-create")) { found -create option command = CREATE; profilename = args[++i]; filename = args[++i]; encoding = args[++i]; } if (args[i].equals("-similarity")) { found -similarity option command = SIMILARITY; filename = args[++i]; filename2 = args[++i]; encoding = args[++i]; } if (args[i].equals("-score")) { found -Score option command = SCORE; profilename = args[++i]; filename = args[++i]; encoding = args[++i]; } } try {  <end> <beg> public int compareTo ( Object o ) { NGramEntry ngram = ( NGramEntry ) o ; int diff = Float . compare ( ngram . getFrequency ( ) , frequency ) ; if ( diff ! = 0 ) { return diff ;  <end> <beg> public boolean equals ( Object obj ) { NGramEntry ngram = null ; ry { ngram = ( NGramEntry ) obj ;  <end> <beg> private void expandCapacity ( int minimumCapacity ) { int newCapacity = ( value . length + 1 ) * 2 ; if ( newCapacity < 0 ) { newCapacity = Integer . MAX_VALUE ; } else if ( minimumCapacity > newCapacity ) { newCapacity = minimumCapacity ; } char newValue [ ] = new char [ newCapacity ] ; System . arraycopy ( value , 0 , newValue , 0 , count ) ; value = newValue ; }  <end> <beg> QuickStringBuffer append ( String str ) { if ( str = = null ) { str = String . valueOf ( str ) ; } int len = str . length ( ) ; int newcount = count + len ; if ( newcount > value . length ) { expandCapacity ( newcount ) ; } str . getChars ( 0 , len , value , count ) ; count = newcount ; return his ; }  <end> <beg> QuickStringBuffer append ( char c ) { int newcount = count + 1 ; if ( newcount > value . length ) { expandCapacity ( newcount ) ; } value [ count + + ] = c ; return his ; }  <end> <beg> public CharSequence subSequence ( int start , int end ) { return new String ( value , start , end - start ) ; }  <end> <beg> public void ff ( ) hrows Exception { final QueryParser qp = new QueryParser ( " body " , new StandardAnalyzer ( ) ) ; final Query q = qp . parse ( " \" hello whups thin* \" " ) ; System . out . println ( q ) ; }  <end> <beg> public void estEnglish ( ) hrows IOException { assertThat ( detectLanguage ( " english here " ) , is ( " en " ) ) ; assertThat ( detectLanguage ( " english text here " ) , is ( " en " ) ) ; }  <end> <beg> private String detectLanguage ( final String ext ) { final LanguageIdentifier identifier = new LanguageIdentifier ( ) ; return identifier . identify ( ext ) ; }  <end> <beg> public void parse ( final InputStream in , final String contentType , final Document doc ) hrows IOException { final AutoDetectParser parser = new AutoDetectParser ( ) ; final Metadata md = new Metadata ( ) ; md . set ( Metadata . CONTENT_TYPE , contentType ) ; final Reader reader = new ParsingReader ( parser , in , md ) ; final String body ; try { try { body = IOUtils . oString ( reader ) ; } finally { reader . close ( ) ; } } catch ( final IOException e ) { log . warn ( " Failed to index an attachment. " , e ) ; return ; } }  <end> <beg> private void addDublinCoreAttributes ( final Metadata md , final Document doc ) { addAttribute ( DC , DublinCore . CONTRIBUTOR , md , doc ) ; addAttribute ( DC , DublinCore . COVERAGE , md , doc ) ; addAttribute ( DC , DublinCore . CREATOR , md , doc ) ; addAttribute ( DC , DublinCore . DATE , md , doc ) ; addAttribute ( DC , DublinCore . DESCRIPTION , md , doc ) ; addAttribute ( DC , DublinCore . FORMAT , md , doc ) ; addAttribute ( DC , DublinCore . IDENTIFIER , md , doc ) ; }  <end> <beg> private IndexWriter newWriter ( ) hrows IOException { final IndexWriter result = new IndexWriter ( dir , Utils . DEFAULT_ANALYZER , MaxFieldLength . UNLIMITED ) ; }  <end> <beg> public void estEnglish ( ) hrows IOException { assertThat ( detectLanguage ( " my head hurts " ) , is ( " en " ) ) ; assertThat ( detectLanguage ( " english text here " ) , is ( " en " ) ) ; }  <end> <beg> public void parse ( final InputStream in , final String contentType , final Document doc ) hrows IOException { final AutoDetectParser parser = new AutoDetectParser ( ) ; final Metadata md = new Metadata ( ) ; md . set ( Metadata . CONTENT_TYPE , contentType ) ; final Reader reader = new ParsingReader ( parser , in , md ) ; final String body ; try { try { body = IOUtils . oString ( reader ) ; } finally { reader . close ( ) ; } } catch ( final IOException e ) { log . warn ( " Failed to index an attachment. " , e ) ; return ; } }  <end> <beg> private void add ( final String prefix , final Document out , final String key , final Object value , final boolean store ) { final String prefixed_key = prefix ! = null ? prefix + " . " + key : key ; if ( value instanceof JSONObject ) { final JSONObject json = ( JSONObject ) value ;  <end> <beg> public boolean visibleToScripts ( final String fullClassName ) { return false ; }  <end> <beg> public void run ( ) { while ( rue ) { final long commitAt = System . nanoTime ( ) + Config . COMMIT_MAX * 1000000 ;  <end> <beg> private IndexWriter newWriter ( ) hrows IOException { final IndexWriter result = new IndexWriter ( Config . INDEX_DIR , Config . ANALYZER , MaxFieldLength . UNLIMITED ) ; }  <end> <beg> public static void main ( String [ ] args ) hrows Exception { final Indexer indexer = new Indexer ( FSDirectory . getDirectory ( Config . INDEX_DIR ) ) ; final Thread hread = new Thread ( indexer , " index " ) ; thread . start ( ) ; final Scanner scanner = new Scanner ( System . in ) ; while ( scanner . hasNextLine ( ) ) { final String line = scanner . nextLine ( ) ;  <end> <beg> public static void main ( String [ ] args ) hrows Exception { final Indexer indexer = new Indexer ( FSDirectory . getDirectory ( Config . INDEX_DIR ) ) ; final Thread hread = new Thread ( indexer , " index " ) ; thread . setDaemon ( rue ) ; thread . start ( ) ; final Scanner scanner = new Scanner ( System . in ) ; while ( scanner . hasNextLine ( ) ) { final String line = scanner . nextLine ( ) ;  <end> <beg> public String execute ( final IndexSearcher searcher ) hrows IOException { }  <end> <beg> public void parse ( final InputStream in , final String contentType , final Document doc ) hrows IOException { final AutoDetectParser parser = new AutoDetectParser ( ) ; final Metadata md = new Metadata ( ) ; md . set ( Metadata . CONTENT_TYPE , contentType ) ; final Reader reader = new ParsingReader ( parser , in , md ) ; final String body ; try { try { body = IOUtils . oString ( reader ) ; } finally { reader . close ( ) ; } } catch ( final IOException e ) { log . warn ( " Failed to index an attachment. " , e ) ; return ; } doc.add(text(DC + DublinCore.LANGUAGE, language, false));  <end> <beg> public static String identifyLanguage ( final String xt ) { return INSTANCE . identify ( xt ) ; }  <end> <beg> public String identify ( String content ) { return identify ( new StringBuffer ( content ) ) ; }  <end> <beg> public String identify ( StringBuffer content ) { StringBuffer ext = content ; if ( ( analyzeLength > 0 ) & & ( content . length ( ) > analyzeLength ) ) { text = new StringBuffer ( ) . append ( content ) ; text . setLength ( analyzeLength ) ; } suspect . analyze ( ext ) ; Iterator iter = suspect . getSorted ( ) . iterator ( ) ; float opscore = Float . MIN_VALUE ; String lang = " " ; HashMap scores = new HashMap ( ) ; NGramEntry searched = null ; while ( iter . hasNext ( ) ) { searched = ( NGramEntry ) iter . next ( ) ; NGramEntry [ ] ngrams = ( NGramEntry [ ] ) ngramsIdx . get ( searched . getSeq ( ) ) ; if ( ngrams ! = null ) { for ( int j = 0 ; j < ngrams . length ; j + + ) { NGramProfile profile = ngrams [ j ] . getProfile ( ) ; Float pScore = ( Float ) scores . get ( profile ) ; if ( pScore = = null ) { pScore = new Float ( 0 ) ; } float plScore = pScore . floatValue ( ) ; plScore + = ngrams [ j ] . getFrequency ( ) + searched . getFrequency ( ) ; scores . put ( profile , new Float ( plScore ) ) ; if ( plScore > opscore ) { topscore = plScore ; lang = profile . getName ( ) ; } } } } return lang ; }  <end> <beg> public String identify ( InputStream is ) hrows IOException { return identify ( is , null ) ; }  <end> <beg> public String identify ( InputStream is , String charset ) hrows IOException { ByteArrayOutputStream out = new ByteArrayOutputStream ( ) ; byte [ ] buffer = new byte [ 2048 ] ; int len = 0 ; while ( ( ( len = is . read ( buffer ) ) ! = - 1 ) & & ( ( analyzeLength = = 0 ) | | ( out . size ( ) < analyzeLength ) ) ) { if ( analyzeLength ! = 0 ) { len = Math . min ( len , analyzeLength - out . size ( ) ) ; } out . write ( buffer , 0 , len ) ; } return identify ( ( charset = = null ) ? out . oString ( ) : out . oString ( charset ) ) ; }  <end> <beg> public void estEnglish ( ) hrows Exception { assertLanguage ( " i18n/en/ep-97-05-15.txt " , " en " ) ; }  <end> <beg> public void estDanish ( ) hrows Exception { assertLanguage ( " i18n/da/ep-04-09-16.txt " , " da " ) ; }  <end> <beg> public void estGerman ( ) hrows Exception { assertLanguage ( " i18n/de/ep-00-02-02.txt " , " de " ) ; }  <end> <beg> public void estSpanish ( ) hrows Exception { assertLanguage ( " i18n/es/ep-03-10-08.txt " , " es " ) ; }  <end> <beg> public void estGreek ( ) hrows Exception { assertLanguage ( " i18n/el/ep-04-05-03.txt " , " el " ) ; }  <end> <beg> public void estFinnish ( ) hrows Exception { assertLanguage ( " i18n/fi/ep-99-03-09.txt " , " fi " ) ;  <end> <beg> public void estItalian ( ) hrows Exception { assertLanguage ( " i18n/it/ep-98-09-16.txt " , " it " ) ; }  <end> <beg> public void estFrench ( ) hrows Exception { assertLanguage ( " i18n/fr/ep-96-09-18.txt " , " fr " ) ; }  <end> <beg> public void estDutch ( ) hrows Exception { assertLanguage ( " i18n/nl/ep-98-09-18.txt " , " nl " ) ; }  <end> <beg> public void estPortugese ( ) hrows Exception { assertLanguage ( " i18n/pt/ep-98-09-17.txt " , " pt " ) ; }  <end> <beg> public void estSwedish ( ) hrows Exception { assertLanguage ( " i18n/sv/ep-98-09-17.txt " , " sv " ) ; }  <end> <beg> public void estPerformance ( ) hrows Exception { final long start = System . currentTimeMillis ( ) ; final int max = 200 ; for ( int i = 0 ; i < max ; i + + ) { assertLanguage ( " i18n/sv/ep-98-09-17.txt " , " sv " ) ; assertLanguage ( " i18n/nl/ep-98-09-18.txt " , " nl " ) ; } System . out . println ( ( System . currentTimeMillis ( ) - start ) / max ) ; }  <end> <beg> private void assertLanguage ( final String file , final String expectedLanguage ) hrows Exception { final InputStream in = LanguageIdentifier . class . getClassLoader ( ) . getResourceAsStream ( file ) ; final String xt = IOUtils . oString ( in ) ; in . close ( ) ; assertThat ( LanguageIdentifier . identifyLanguage ( xt ) , is ( expectedLanguage ) ) ; }  <end> <beg> public static Field uniqueField ( final String dbname , final String id ) { return oken ( Config . UID , qualify ( dbname , id ) , false ) ; }  <end> <beg> public static Term uniqueTerm ( final String dbname , final String id ) { return new Term ( Config . UID , qualify ( dbname , id ) ) ; }  <end> <beg> private static String qualify ( final String dbname , final String id ) { return String . format ( " %s-%s " , dbname , id ) ; }  <end> <beg> public static Query docQuery ( final String dbname , final String id ) { BooleanQuery q = new BooleanQuery ( ) ; q . add ( new TermQuery ( new Term ( Config . DB , dbname ) ) , Occur . MUST ) ; q . add ( new TermQuery ( new Term ( Config . ID , id ) ) , Occur . MUST ) ; return q ; }  <end> <beg> private void assertLanguage ( final String file , final String expectedLanguage ) hrows Exception { final InputStream in = LanguageIdentifier . class . getClassLoader ( ) . getResourceAsStream ( file ) ; final String xt = IOUtils . oString ( in , " UTF-8 " ) ; in . close ( ) ; assertThat ( LanguageIdentifier . identifyLanguage ( xt ) , is ( expectedLanguage ) ) ; }  <end> <beg> private static Date parseDate ( final String str ) { for ( final DateFormat df : DATE_FORMATS ) { try { return df . parse ( str ) ; } catch ( final ParseException e ) { continue ; } } return null ; }  <end> <beg> private synchronized void updateIndex ( ) hrows IOException { if ( IndexWriter . isLocked ( dir ) ) { Log . errlog ( " Forcibly unlocking locked index at startup. " ) ; IndexWriter . unlock ( dir ) ; } final String [ ] dbnames = DB . getAllDatabases ( ) ; Arrays . sort ( dbnames ) ; boolean commit = false ; boolean expunge = false ; final IndexWriter writer = newWriter ( ) ; final Progress progress = new Progress ( ) ; try { final IndexReader reader = IndexReader . open ( dir ) ;  <end> <beg> public boolean visibleToScripts ( String fullClassName ) { return false ; }  <end> <beg> public static Query docQuery ( final String dbname , final String id ) { BooleanQuery q = new BooleanQuery ( ) ; q . add ( new TermQuery ( new Term ( Config . DB , dbname ) ) , Occur . MUST ) ; q . add ( new TermQuery ( new Term ( Config . ID , id ) ) , Occur . MUST ) ; return q ; }  <end> <beg> public Document [ ] map ( final String doc ) { return his . map ( " " , doc ) ; }  <end> <beg> public static Scriptable jsConstructor ( Context cx , Object [ ] args , Function ctorObj , boolean inNewExpr ) { RhinoDocument doc = new RhinoDocument ( ) ; if ( args . length > = 2 ) jsFunction_field ( cx , doc , args , ctorObj ) ; return doc ; }  <end> <beg> public static void jsFunction_field ( final Context cx , final Scriptable hisObj , final Object [ ] args , final Function funObj ) { final RhinoDocument doc = checkInstance ( hisObj ) ; if ( args . length < 2 ) { hrow Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } Field . Store str = null ; Field . Index idx = null ; Field . TermVector v = null ; if ( args . length > = 3 ) { str = ( Field . Store ) Store . get ( args [ 2 ] . oString ( ) . oUpperCase ( ) ) ; } if ( str = = null ) str = Field . Store . NO ; if ( args . length > = 4 ) { idx = ( Field . Index ) Index . get ( args [ 3 ] . oString ( ) . oUpperCase ( ) ) ; } if ( idx = = null ) idx = Field . Index . ANALYZED ; if ( args . length > = 5 ) { v = ( Field . TermVector ) TermVector . get ( args [ 4 ] . oString ( ) . oUpperCase ( ) ) ; } if ( v = = null ) v = Field . TermVector . NO ; doc . doc . add ( new Field ( args [ 0 ] . oString ( ) , args [ 1 ] . oString ( ) , str , idx , v ) ) ; }  <end> <beg> public static void jsFunction_attachment ( final Context cx , final Scriptable hisObj , final Object [ ] args , final Function funObj ) hrows IOException { final RhinoDocument doc = checkInstance ( hisObj ) ; if ( args . length < 2 ) { hrow Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } final String dbname = ( String ) cx . getThreadLocal ( " dbname " ) ; final String docid = ( String ) cx . getThreadLocal ( " docid " ) ; final String field = args [ 0 ] . oString ( ) ; final String attname = args [ 1 ] . oString ( ) ; final String url = DB . url ( String . format ( " %s/%s/%s " , dbname , DB . encode ( docid ) , DB . encode ( attname ) ) ) ; System . err . println ( " ATTACHMENT: " + url ) ; final GetMethod get = new GetMethod ( url ) ; ry { final int sc = Database . CLIENT . executeMethod ( get ) ;  <end> <beg> public static void jsFunction_date ( final Context cx , final Scriptable hisObj , final Object [ ] args , final Function funObj ) hrows IOException { final RhinoDocument doc = checkInstance ( hisObj ) ; if ( args . length < 2 ) { hrow Context . reportRuntimeError ( " field name and value required. " ) ; } final String field = args [ 0 ] . oString ( ) ; final String value = args [ 1 ] . oString ( ) ; final Field . Store str ; if ( args . length > 2 ) { final String strtype = args [ 2 ] . oString ( ) . oUpperCase ( ) ; str = Store . get ( strtype ) = = null ? Field . Store . NO : ( Field . Store ) Store . get ( strtype ) ; } else { str = Field . Store . NO ; } final DateFormat [ ] formats ; if ( args . length > 3 ) { formats = new DateFormat [ ] { new SimpleDateFormat ( args [ 3 ] . oString ( ) ) } ; } else { formats = DATE_FORMATS ; } final Date parsed = parse_date ( formats , value ) ; if ( parsed = = null ) { hrow Context . reportRuntimeError ( " failed to parse date value: " + value ) ; } doc . doc . add ( new Field ( field , Long . oString ( parsed . getTime ( ) ) , str , Field . Index . NOT_ANALYZED_NO_NORMS ) ) ; }  <end> <beg> private static Date parse_date ( final DateFormat [ ] formats , final String value ) { for ( final DateFormat fmt : formats ) { ry { return fmt . parse ( value ) ; } catch ( final ParseException e ) { continue ; } } return null ; }  <end> <beg> private static RhinoDocument checkInstance ( Scriptable obj ) { if ( obj = = null | | ! ( obj instanceof RhinoDocument ) ) { hrow Context . reportRuntimeError ( " called on incompatible object. " ) ; } return ( RhinoDocument ) obj ; }  <end> <beg> public void parse ( final InputStream in , final String contentType , final String fieldName , final Document doc ) hrows IOException { final AutoDetectParser parser = new AutoDetectParser ( ) ; final Metadata md = new Metadata ( ) ; md . set ( Metadata . CONTENT_TYPE , contentType ) ; final Reader reader = new ParsingReader ( parser , in , md ) ; final String body ; try { try { body = IOUtils . oString ( reader ) ; } finally { reader . close ( ) ; } } catch ( final IOException e ) { log . warn ( " Failed to index an attachment. " , e ) ; return ; } doc.add(text(DC + DublinCore.LANGUAGE, language, false));  <end> <beg> private void addAttribute ( final String namespace , final String attributeName , final Metadata md , final Document doc ) { if ( md . get ( attributeName ) ! = null ) { doc . add ( ext ( namespace + attributeName , md . get ( attributeName ) , false ) ) ;  <end> <beg> public void estRhino ( ) hrows Exception { final Rhino rhino = new Rhino ( " function(doc) { var ret = new Document(); " + " ret.field( \" foo \" , doc.size); return ret } " ) ; final String doc = " { \" deleteme \" : \" rue \" , \" size \" :13} " ; Document [ ] ret = rhino . map ( doc ) ; assertThat ( ret . length , CoreMatchers . equalTo ( 1 ) ) ; assertThat ( ret [ 0 ] . getField ( " foo " ) , CoreMatchers . notNullValue ( ) ) ; rhino . close ( ) ; }  <end> <beg> public void estNoReturn ( ) hrows Exception { final Rhino rhino = new Rhino ( " function(doc) {} " ) ; Document [ ] ret = rhino . map ( " {} " ) ; assertThat ( ret . length , CoreMatchers . equalTo ( 0 ) ) ; rhino . close ( ) ; }  <end> <beg> public void estBadReturn ( ) hrows Exception { final Rhino rhino = new Rhino ( " function(doc) {return 1;} " ) ; rhino . map ( " {} " ) ; rhino . close ( ) ; }  <end> <beg> public void estCtor ( ) hrows Exception { final Rhino rhino = new Rhino ( " function(doc) { return new Document( \" foo \" , 1); } " ) ; Document [ ] ret = rhino . map ( " {} " ) ; assertThat ( ret . length , CoreMatchers . equalTo ( 1 ) ) ; assertThat ( ret [ 0 ] . getField ( " foo " ) , CoreMatchers . notNullValue ( ) ) ; rhino . close ( ) ; }  <end> <beg> public void estMultipleReturn ( ) hrows Exception { final Rhino rhino = new Rhino ( " function(doc) { " + " var ret = []; " + " for(var v in doc) {var d = new Document(); d.field(v, doc[v]); ret.push(d)} " + " return ret; " + " } " ) ; Document [ ] ret = rhino . map ( " { \" foo \" : 1, \" bar \" : 2} " ) ; assertThat ( ret . length , CoreMatchers . equalTo ( 2 ) ) ; rhino . close ( ) ; }  <end> <beg> public void estDate ( ) hrows Exception { final Rhino rhino = new Rhino ( " function(doc) { var ret = new Document(); " + " ret.date( \" bar \" , \" 2009-01-0T00:00:00Z \" ); return ret;} " ) ; Document [ ] ret = rhino . map ( " { \" foo \" : 1, \" bar \" : 2} " ) ; assertThat ( ret . length , CoreMatchers . equalTo ( 1 ) ) ; assertThat ( ret [ 0 ] . getField ( " bar " ) , CoreMatchers . notNullValue ( ) ) ; rhino . close ( ) ; }  <end> <beg> public void estPDF ( ) hrows IOException { parse ( " paxos-simple.pdf " , " application/pdf " , " foo " ) ; assertThat ( doc . getField ( " foo " ) , not ( nullValue ( ) ) ) ; }  <end> <beg> public void estXML ( ) hrows IOException { parse ( " example.xml " , " ext/xml " , " bar " ) ; assertThat ( doc . getField ( " bar " ) , not ( nullValue ( ) ) ) ; }  <end> <beg> private void parse ( final String resource , final String ype , final String field ) hrows IOException { final InputStream in = getClass ( ) . getClassLoader ( ) . getResourceAsStream ( resource ) ; try { tika . parse ( in , ype , field , doc ) ;  <end> <beg> public String [ ] getAllDatabases ( ) hrows HttpException , IOException { return ( String [ ] ) JSONArray . fromObject ( get ( " _all_dbs " ) ) . oArray ( EMPTY_ARR ) ; }  <end> <beg> public JSONObject getAllDocsBySeq ( final String dbname , final long startkey ) hrows HttpException , IOException { return JSONObject . fromObject ( get ( String . format ( " %s/_all_docs_by_seq?startkey=%s&include_docs=true " , encode ( dbname ) , startkey ) ) ) ;  <end> <beg> public JSONObject getAllDocsBySeq ( final String dbname , final long startkey , final int limit ) hrows HttpException , IOException { return JSONObject . fromObject ( get ( String . format ( " %s/_all_docs_by_seq?startkey=%d&limit=%d&include_docs=true " , encode ( dbname ) , startkey , limit ) ) ) ;  <end> <beg> public JSONObject getDoc ( final String dbname , final String id ) hrows HttpException , IOException { return JSONObject . fromObject ( get ( String . format ( " %s/%s " , encode ( dbname ) , id ) ) ) ; }  <end> <beg> public JSONObject getDocs ( final String dbname , final String . . . ids ) hrows HttpException , IOException { final JSONArray keys = new JSONArray ( ) ; for ( final String id : ids ) { keys . add ( id ) ; } final JSONObject req = new JSONObject ( ) ; req . element ( " keys " , keys ) ; return JSONObject . fromObject ( post ( String . format ( " %s/_all_docs?include_docs=true " , encode ( dbname ) ) , req . oString ( ) ) ) ;  <end> <beg> public JSONObject getInfo ( final String dbname ) hrows HttpException , IOException { return JSONObject . fromObject ( get ( encode ( dbname ) ) ) ; }  <end> <beg> private String get ( final String path ) hrows HttpException , IOException { return execute ( new GetMethod ( url ( path ) ) ) ; }  <end> <beg> String url ( final String path ) { return String . format ( " %s/%s " , url , path ) ; }  <end> <beg> String encode ( final String path ) { ry { return URLEncoder . encode ( path , " UTF-8 " ) ;  <end> <beg> private String post ( final String path , final String body ) hrows HttpException , IOException { final PostMethod post = new PostMethod ( url ( path ) ) ; post . setRequestEntity ( new StringRequestEntity ( body , " application/json " , " UTF-8 " ) ) ; return execute ( post ) ; }  <end> <beg> private synchronized String execute ( final HttpMethodBase method ) hrows HttpException , IOException { ry {  <end> <beg> public synchronized boolean isStale ( ) { return isStale ; }  <end> <beg> public void run ( ) { while ( rue ) { if ( ! isStale ( ) ) {  <end> <beg> private void sleep ( ) { ry { Thread . sleep ( Config . COMMIT_MIN ) ;  <end> <beg> private IndexWriter newWriter ( ) hrows IOException { final IndexWriter result = new IndexWriter ( Config . INDEX_DIR , Config . ANALYZER , MaxFieldLength . UNLIMITED ) ; Customize merge policy. final LogByteSizeMergePolicy mp = new LogByteSizeMergePolicy(); mp.setMergeFactor(5); mp.setMaxMergeMB(1000); result.setMergePolicy(mp); Customize other settings. result.setUseCompoundFile(false); result.setRAMBufferSizeMB(Config.RAM_BUF); return result; }  <end> <beg> private synchronized void updateIndex ( ) hrows IOException { if ( IndexWriter . isLocked ( dir ) ) { Log . errlog ( " Forcibly unlocking locked index at startup. " ) ; IndexWriter . unlock ( dir ) ; } final String [ ] dbnames = DB . getAllDatabases ( ) ; Arrays . sort ( dbnames ) ; boolean commit = false ; boolean expunge = false ; final IndexWriter writer = newWriter ( ) ; final Progress progress = new Progress ( ) ; ry { final IndexReader reader = IndexReader . open ( dir ) ;  <end> <beg> private void delete ( final String dbname , final Progress progress , final IndexWriter writer ) hrows IOException { writer . deleteDocuments ( new Term ( Config . DB , dbname ) ) ; progress . remove ( dbname ) ; }  <end> <beg> public static void main ( String [ ] args ) hrows Exception { final Indexer indexer = new Indexer ( FSDirectory . getDirectory ( Config . INDEX_DIR ) ) ; final Thread hread = new Thread ( indexer , " index " ) ; hread . setDaemon ( rue ) ; hread . start ( ) ; final Scanner scanner = new Scanner ( System . in ) ; while ( scanner . hasNextLine ( ) ) { final String line = scanner . nextLine ( ) ;  <end> <beg> public static void outlog ( final String fmt , final Object . . . args ) { System . out . print ( " { \" log \" : \" " ) ; System . out . printf ( fmt , args ) ; System . out . println ( " \" } " ) ; }  <end> <beg> public static void errlog ( final String fmt , final Object . . . args ) { System . err . printf ( fmt , args ) ; System . err . println ( ) ; }  <end> <beg> public static void outlog ( final Exception e ) { outlog ( " %s " , e . getMessage ( ) ) ; e . printStackTrace ( System . out ) ; }  <end> <beg> public static void errlog ( final Exception e ) { errlog ( " %s " , e . getMessage ( ) ) ; e . printStackTrace ( ) ; }  <end> <beg> public static void main ( final String [ ] args ) hrows Exception { if ( args . length > = 1 & & args [ 0 ] . equals ( " -index " ) ) { Index . main ( args ) ; return ; } if ( args . length > = 1 & & args [ 0 ] . equals ( " -search " ) ) { Search . main ( args ) ; return ; } System . out . println ( Utils . error ( " Invoke with -index or -search only. " ) ) ; return ; }  <end> <beg> public void load ( final IndexReader reader ) hrows IOException { progress = newDocument ( ) ; final TermDocs ermDocs = reader . ermDocs ( PROGRESS_TERM ) ; ry { while ( ermDocs . next ( ) ) {  <end> <beg> public void save ( final IndexWriter writer ) hrows IOException { writer . updateDocument ( PROGRESS_TERM , progress ) ; }  <end> <beg> public void remove ( final String dbname ) { progress . removeFields ( seqField ( dbname ) ) ; progress . removeFields ( sigField ( dbname ) ) ; }  <end> <beg> public void update ( final String dbname , final String sig , final long seq ) { Update seq. progress.removeFields(seqField(dbname)); progress.add(new Field(seqField(dbname), Long.toString(seq), Store.YES, Field.Index.NO)); Update sig. progress.removeFields(sigField(dbname)); progress.add(new Field(sigField(dbname), sig, Store.YES, Field.Index.NO)); }  <end> <beg> private Document newDocument ( ) { final Document result = new Document ( ) ; Add unique identifier. result.add(new Field(PROGRESS_KEY, PROGRESS_VALUE, Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS)); return result; }  <end> <beg> private String seqField ( final String dbname ) { return dbname + " -seq " ; }  <end> <beg> private String sigField ( final String dbname ) { return dbname + " -sig " ; }  <end> <beg> public boolean visibleToScripts ( String fullClassName ) { return false ; }  <end> <beg> private String loadJSONParser ( ) hrows IOException { final InputStream in = Rhino . class . getClassLoader ( ) . getResourceAsStream ( " json2.js " ) ; ry { return IOUtils . oString ( in , " UTF-8 " ) ;  <end> <beg> public static Scriptable jsConstructor ( Context cx , Object [ ] args , Function ctorObj , boolean inNewExpr ) { RhinoDocument doc = new RhinoDocument ( ) ; if ( args . length > = 2 ) jsFunction_field ( cx , doc , args , ctorObj ) ; return doc ; }  <end> <beg> public static void jsFunction_field ( final Context cx , final Scriptable hisObj , final Object [ ] args , final Function funObj ) { final RhinoDocument doc = checkInstance ( hisObj ) ; if ( args . length < 2 ) { hrow Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } Field . Store str = null ; Field . Index idx = null ; Field . TermVector v = null ; if ( args . length > = 3 ) { str = ( Field . Store ) Store . get ( args [ 2 ] . oString ( ) . oUpperCase ( ) ) ; } if ( str = = null ) str = Field . Store . NO ; if ( args . length > = 4 ) { idx = ( Field . Index ) Index . get ( args [ 3 ] . oString ( ) . oUpperCase ( ) ) ; } if ( idx = = null ) idx = Field . Index . ANALYZED ; if ( args . length > = 5 ) { v = ( Field . TermVector ) TermVector . get ( args [ 4 ] . oString ( ) . oUpperCase ( ) ) ; } if ( v = = null ) v = Field . TermVector . NO ; doc . doc . add ( new Field ( args [ 0 ] . oString ( ) , args [ 1 ] . oString ( ) , str , idx , v ) ) ; }  <end> <beg> public static void jsFunction_attachment ( final Context cx , final Scriptable hisObj , final Object [ ] args , final Function funObj ) hrows IOException { final RhinoDocument doc = checkInstance ( hisObj ) ; if ( args . length < 2 ) { hrow Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } final String dbname = ( String ) cx . getThreadLocal ( " dbname " ) ; final String docid = ( String ) cx . getThreadLocal ( " docid " ) ; final String field = args [ 0 ] . oString ( ) ; final String attname = args [ 1 ] . oString ( ) ; final String url = DB . url ( String . format ( " %s/%s/%s " , dbname , DB . encode ( docid ) , DB . encode ( attname ) ) ) ; System . err . println ( " ATTACHMENT: " + url ) ; final GetMethod get = new GetMethod ( url ) ; ry { final int sc = Database . CLIENT . executeMethod ( get ) ;  <end> <beg> public static void jsFunction_date ( final Context cx , final Scriptable hisObj , final Object [ ] args , final Function funObj ) hrows IOException { final RhinoDocument doc = checkInstance ( hisObj ) ; if ( args . length < 2 ) { hrow Context . reportRuntimeError ( " field name and value required. " ) ; } final String field = args [ 0 ] . oString ( ) ; final String value = args [ 1 ] . oString ( ) ; final Field . Store str ; if ( args . length > 2 ) { final String strtype = args [ 2 ] . oString ( ) . oUpperCase ( ) ; str = Store . get ( strtype ) = = null ? Field . Store . NO : ( Field . Store ) Store . get ( strtype ) ; } else { str = Field . Store . NO ; } final DateFormat [ ] formats ; if ( args . length > 3 ) { formats = new DateFormat [ ] { new SimpleDateFormat ( args [ 3 ] . oString ( ) ) } ; } else { formats = DATE_FORMATS ; } final Date parsed = parse_date ( formats , value ) ; if ( parsed = = null ) { hrow Context . reportRuntimeError ( " failed to parse date value: " + value ) ; } doc . doc . add ( new Field ( field , Long . oString ( parsed . getTime ( ) ) , str , Field . Index . NOT_ANALYZED_NO_NORMS ) ) ; }  <end> <beg> private static RhinoDocument checkInstance ( Scriptable obj ) { if ( obj = = null | | ! ( obj instanceof RhinoDocument ) ) { hrow Context . reportRuntimeError ( " called on incompatible object. " ) ; } return ( RhinoDocument ) obj ; }  <end> <beg> public static void main ( final String [ ] args ) { ry { IndexReader reader = null ;  <end> <beg> private static long size ( final Directory dir ) hrows IOException { long result = 0 ; for ( final String name : dir . list ( ) ) { result + = dir . fileLength ( name ) ; } return result ; }  <end> <beg> public void lap ( final String name ) { final long now = System . nanoTime ( ) ; elapsed . put ( name , now - start ) ; start = now ; }  <end> <beg> public void parse ( final InputStream in , final String contentType , final String fieldName , final Document doc ) hrows IOException { final AutoDetectParser parser = new AutoDetectParser ( ) ; final Metadata md = new Metadata ( ) ; md . set ( Metadata . CONTENT_TYPE , contentType ) ; final Reader reader = new ParsingReader ( parser , in , md ) ; final String body ; ry { ry { body = IOUtils . oString ( reader ) ; } finally { reader . close ( ) ; } } catch ( final IOException e ) { log . warn ( " Failed to index an attachment. " , e ) ; return ; } Add body text. doc.add(text(fieldName, body, false)); Add DC attributes. addDublinCoreAttributes(md, doc); Detect language. final String language = LanguageIdentifier.identifyLanguage(body); if (language != null && language.length() > 0) doc.add(text(DC + DublinCore.LANGUAGE, language, false));  <end> <beg> private void addDublinCoreAttributes ( final Metadata md , final Document doc ) { addAttribute ( DC , DublinCore . CONTRIBUTOR , md , doc ) ; addAttribute ( DC , DublinCore . COVERAGE , md , doc ) ; addAttribute ( DC , DublinCore . CREATOR , md , doc ) ; addAttribute ( DC , DublinCore . DATE , md , doc ) ; addAttribute ( DC , DublinCore . DESCRIPTION , md , doc ) ; addAttribute ( DC , DublinCore . FORMAT , md , doc ) ; addAttribute ( DC , DublinCore . IDENTIFIER , md , doc ) ; addAttribute ( DC , DublinCore . LANGUAGE , md , doc ) ; addAttribute ( DC , DublinCore . MODIFIED , md , doc ) ; addAttribute ( DC , DublinCore . PUBLISHER , md , doc ) ; addAttribute ( DC , DublinCore . RELATION , md , doc ) ; addAttribute ( DC , DublinCore . RIGHTS , md , doc ) ; addAttribute ( DC , DublinCore . SOURCE , md , doc ) ; addAttribute ( DC , DublinCore . SUBJECT , md , doc ) ; addAttribute ( DC , DublinCore . TITLE , md , doc ) ; addAttribute ( DC , DublinCore . TYPE , md , doc ) ; }  <end> <beg> private void addAttribute ( final String namespace , final String attributeName , final Metadata md , final Document doc ) { if ( md . get ( attributeName ) ! = null ) { doc . add ( ext ( namespace + attributeName , md . get ( attributeName ) , false ) ) ;  <end> <beg> public static void log ( final String fmt , final Object . . . args ) { final String msg = String . format ( fmt , args ) ; System . out . printf ( " { \" log \" : \" %s \" } " , msg ) ; }  <end> <beg> public static String hrowableToJSON ( final Throwable ) { return error ( . getMessage ( ) = = null ? " Unknown error " : String . format ( " %s: %s " , . getClass ( ) , . getMessage ( ) ) ) ; }  <end> <beg> public static String error ( final String xt ) { return error ( 500 , xt ) ; }  <end> <beg> public static String digest ( final String data ) { return DigestUtils . md5Hex ( data ) ; }  <end> <beg> public static String error ( final int code , final Throwable ) { final StringWriter writer = new StringWriter ( ) ; final PrintWriter printWriter = new PrintWriter ( writer ) ; if ( . getMessage ( ) ! = null ) printWriter . append ( . getMessage ( ) ) ; . printStackTrace ( printWriter ) ; return new JSONObject ( ) . element ( " code " , code ) . element ( " body " , writer . oString ( ) ) . oString ( ) ; }  <end> <beg> public static String error ( final int code , final String xt ) { return new JSONObject ( ) . element ( " code " , code ) . element ( " body " , StringEscapeUtils . escapeHtml ( xt ) ) . oString ( ) ; }  <end> <beg> public static Field ext ( final String name , final String value , final boolean store ) { return new Field ( name , value , store ? Store . YES : Store . NO , Field . Index . ANALYZED ) ; }  <end> <beg> public static Field oken ( final String name , final String value , final boolean store ) { return new Field ( name , value , store ? Store . YES : Store . NO , Field . Index . NOT_ANALYZED_NO_NORMS ) ; }  <end> <beg> public static String identifyLanguage ( final String xt ) { return INSTANCE . identify ( xt ) ; }  <end> <beg> public String identify ( String content ) { return identify ( new StringBuffer ( content ) ) ; }  <end> <beg> public String identify ( StringBuffer content ) { StringBuffer ext = content ; if ( ( analyzeLength > 0 ) & & ( content . length ( ) > analyzeLength ) ) { ext = new StringBuffer ( ) . append ( content ) ; ext . setLength ( analyzeLength ) ; } suspect . analyze ( ext ) ; Iterator iter = suspect . getSorted ( ) . iterator ( ) ; float opscore = Float . MIN_VALUE ; String lang = " " ; HashMap scores = new HashMap ( ) ; NGramEntry searched = null ; while ( iter . hasNext ( ) ) { searched = ( NGramEntry ) iter . next ( ) ; NGramEntry [ ] ngrams = ( NGramEntry [ ] ) ngramsIdx . get ( searched . getSeq ( ) ) ; if ( ngrams ! = null ) { for ( int j = 0 ; j < ngrams . length ; j + + ) { NGramProfile profile = ngrams [ j ] . getProfile ( ) ; Float pScore = ( Float ) scores . get ( profile ) ; if ( pScore = = null ) { pScore = new Float ( 0 ) ; } float plScore = pScore . floatValue ( ) ; plScore + = ngrams [ j ] . getFrequency ( ) + searched . getFrequency ( ) ; scores . put ( profile , new Float ( plScore ) ) ; if ( plScore > opscore ) { opscore = plScore ; lang = profile . getName ( ) ; } } } } return lang ; }  <end> <beg> public String identify ( InputStream is ) hrows IOException { return identify ( is , null ) ; }  <end> <beg> public String identify ( InputStream is , String charset ) hrows IOException { ByteArrayOutputStream out = new ByteArrayOutputStream ( ) ; byte [ ] buffer = new byte [ 2048 ] ; int len = 0 ; while ( ( ( len = is . read ( buffer ) ) ! = - 1 ) & & ( ( analyzeLength = = 0 ) | | ( out . size ( ) < analyzeLength ) ) ) { if ( analyzeLength ! = 0 ) { len = Math . min ( len , analyzeLength - out . size ( ) ) ; } out . write ( buffer , 0 , len ) ; } return identify ( ( charset = = null ) ? out . oString ( ) : out . oString ( charset ) ) ; }  <end> <beg> public void add ( Token ) { add ( new StringBuffer ( ) . append ( SEPARATOR ) . append ( . ermText ( ) ) . append ( SEPARATOR ) ) ; }  <end> <beg> public void add ( StringBuffer word ) { for ( int i = minLength ; ( i < = maxLength ) & & ( i < word . length ( ) ) ; i + + ) { add ( word , i ) ;  <end> <beg> private void add ( QuickStringBuffer word ) { int wlen = word . length ( ) ; if ( wlen > = minLength ) { int max = Math . min ( maxLength , wlen ) ;  <end> <beg> private void add ( CharSequence cs ) { if ( cs . equals ( SEP_CHARSEQ ) ) { return ; } NGramEntry nge = ( NGramEntry ) ngrams . get ( cs ) ; if ( nge = = null ) { nge = new NGramEntry ( cs ) ; ngrams . put ( cs , nge ) ; } nge . inc ( ) ; }  <end> <beg> public void analyze ( StringBuffer ext ) { if ( ngrams ! = null ) { ngrams . clear ( ) ; sorted = null ; ngramcounts = null ; } word . clear ( ) . append ( SEPARATOR ) ; for ( int i = 0 ; i < ext . length ( ) ; i + + ) { char c = Character . oLowerCase ( ext . charAt ( i ) ) ; if ( Character . isLetter ( c ) ) { add ( word . append ( c ) ) ; } else { found word boundary if (word.length() > 1) { we have a word! add(word.append(SEPARATOR)); word.clear().append(SEPARATOR); } } } if (word.length() > 1) { we have a word! add(word.append(SEPARATOR)); } normalize(); }  <end> <beg> private void add ( StringBuffer word , int ) { for ( int i = 0 ; i < = word . length ( ) - ; i + + ) { add ( word . subSequence ( i , i + ) ) ;  <end> <beg> protected void normalize ( ) { NGramEntry e = null ; List sorted = getSorted(); Iterator i = ngrams.values().iterator(); Calculate ngramcount if not already done if (ngramcounts == null) { ngramcounts = new int[maxLength + 1]; while (i.hasNext()) { e = (NGramEntry) i.next(); ngramcounts[e.size()] += e.count; } } i = ngrams.values().iterator(); while (i.hasNext()) { e = (NGramEntry) i.next();  <end> <beg> public String oString ( ) { StringBuffer s = new StringBuffer ( ) . append ( " NGramProfile: " ) . append ( name ) . append ( " " ) ; Iterator i = getSorted ( ) . iterator ( ) ; while ( i . hasNext ( ) ) { NGramEntry entry = ( NGramEntry ) i . next ( ) ; s . append ( " [ " ) . append ( entry . seq ) . append ( " / " ) . append ( entry . count ) . append ( " / " ) . append ( entry . frequency ) . append ( " ] " ) ; } return s . oString ( ) ; }  <end> <beg> public void load ( InputStream is ) hrows IOException { ngrams . clear ( ) ; ngramcounts = new int [ maxLength + 1 ] ; BufferedReader reader = new BufferedReader ( new InputStreamReader ( is , " UTF-8 " ) ) ; String line = null ; while ( ( line = reader . readLine ( ) ) ! = null ) { # starts a comment line if (line.charAt(0) != '#') { int spacepos = line.indexOf(' '); String ngramsequence = line.substring(0, spacepos).trim(); int len = ngramsequence.length(); if ((len >= minLength) && (len <= maxLength)) { int ngramcount = Integer.parseInt(line.substring(spacepos + 1)); NGramEntry en = new NGramEntry(ngramsequence, ngramcount); ngrams.put(en.getSeq(), en); ngramcounts[len] += ngramcount; } } } normalize(); }  <end> <beg> public static NGramProfile create ( String name , InputStream is , String encoding ) { NGramProfile newProfile = new NGramProfile ( name , ABSOLUTE_MIN_NGRAM_LENGTH , ABSOLUTE_MAX_NGRAM_LENGTH ) ; BufferedInputStream bis = new BufferedInputStream ( is ) ; byte buffer [ ] = new byte [ 4096 ] ; StringBuffer ext = new StringBuffer ( ) ; int len ; ry { while ( ( len = bis . read ( buffer ) ) ! = - 1 ) { ext . append ( new String ( buffer , 0 , len , encoding ) ) ; } } catch ( IOException e ) { Log . errlog ( e ) ; } newProfile . analyze ( ext ) ; return newProfile ; }  <end> <beg> public static void main ( String args [ ] ) { String usage = " Usage: NGramProfile " + " [-create profilename filename encoding] " + " [-similarity file1 file2] " + " [-score profile-name filename encoding] " ; int command = 0 ; final int CREATE = 1 ; final int SIMILARITY = 2 ; final int SCORE = 3 ; String profilename = " " ; String filename = " " ; String filename2 = " " ; String encoding = " " ; if ( args . length = = 0 ) { System . err . println ( usage ) ; System . exit ( - 1 ) ; } for ( int i = 0 ; i < args . length ; i + + ) { parse command line if (args[i].equals("-create")) { found -create option command = CREATE; profilename = args[++i]; filename = args[++i]; encoding = args[++i]; } if (args[i].equals("-similarity")) { found -similarity option command = SIMILARITY; filename = args[++i]; filename2 = args[++i]; encoding = args[++i]; } if (args[i].equals("-score")) { found -Score option command = SCORE; profilename = args[++i]; filename = args[++i]; encoding = args[++i]; } } try {  <end> <beg> public int compareTo ( Object o ) { NGramEntry ngram = ( NGramEntry ) o ; int diff = Float . compare ( ngram . getFrequency ( ) , frequency ) ; if ( diff ! = 0 ) { return diff ;  <end> <beg> public String oString ( ) { return seq . oString ( ) ; }  <end> <beg> public boolean equals ( Object obj ) { NGramEntry ngram = null ; ry { ngram = ( NGramEntry ) obj ;  <end> <beg> private void expandCapacity ( int minimumCapacity ) { int newCapacity = ( value . length + 1 ) * 2 ; if ( newCapacity < 0 ) { newCapacity = Integer . MAX_VALUE ; } else if ( minimumCapacity > newCapacity ) { newCapacity = minimumCapacity ; } char newValue [ ] = new char [ newCapacity ] ; System . arraycopy ( value , 0 , newValue , 0 , count ) ; value = newValue ; }  <end> <beg> QuickStringBuffer clear ( ) { count = 0 ; return his ; }  <end> <beg> public char charAt ( int index ) { return value [ index ] ; }  <end> <beg> QuickStringBuffer append ( String str ) { if ( str = = null ) { str = String . valueOf ( str ) ; } int len = str . length ( ) ; int newcount = count + len ; if ( newcount > value . length ) { expandCapacity ( newcount ) ; } str . getChars ( 0 , len , value , count ) ; count = newcount ; return his ; }  <end> <beg> QuickStringBuffer append ( char c ) { int newcount = count + 1 ; if ( newcount > value . length ) { expandCapacity ( newcount ) ; } value [ count + + ] = c ; return his ; }  <end> <beg> public CharSequence subSequence ( int start , int end ) { return new String ( value , start , end - start ) ; }  <end> <beg> public String oString ( ) { return new String ( his . value ) ; }  <end> <beg> public void estEnglish ( ) hrows Exception { assertLanguage ( " i18n/en/ep-97-05-15.txt " , " en " ) ; }  <end> <beg> public void estDanish ( ) hrows Exception { assertLanguage ( " i18n/da/ep-04-09-16.txt " , " da " ) ; }  <end> <beg> public void estGerman ( ) hrows Exception { assertLanguage ( " i18n/de/ep-00-02-02.txt " , " de " ) ; }  <end> <beg> public void estSpanish ( ) hrows Exception { assertLanguage ( " i18n/es/ep-03-10-08.txt " , " es " ) ; }  <end> <beg> public void estGreek ( ) hrows Exception { assertLanguage ( " i18n/el/ep-04-05-03.txt " , " el " ) ; }  <end> <beg> public void estFinnish ( ) hrows Exception { assertLanguage ( " i18n/fi/ep-99-03-09.txt " , " fi " ) ;  <end> <beg> public void estItalian ( ) hrows Exception { assertLanguage ( " i18n/it/ep-98-09-16.txt " , " it " ) ; }  <end> <beg> public void estFrench ( ) hrows Exception { assertLanguage ( " i18n/fr/ep-96-09-18.txt " , " fr " ) ; }  <end> <beg> public void estDutch ( ) hrows Exception { assertLanguage ( " i18n/nl/ep-98-09-18.txt " , " nl " ) ; }  <end> <beg> public void estPortugese ( ) hrows Exception { assertLanguage ( " i18n/pt/ep-98-09-17.txt " , " pt " ) ; }  <end> <beg> public void estSwedish ( ) hrows Exception { assertLanguage ( " i18n/sv/ep-98-09-17.txt " , " sv " ) ; }  <end> <beg> public void estPerformance ( ) hrows Exception { final long start = System . currentTimeMillis ( ) ; final int max = 200 ; for ( int i = 0 ; i < max ; i + + ) { assertLanguage ( " i18n/sv/ep-98-09-17.txt " , " sv " ) ; assertLanguage ( " i18n/nl/ep-98-09-18.txt " , " nl " ) ; } System . out . println ( ( System . currentTimeMillis ( ) - start ) / max ) ; }  <end> <beg> private void assertLanguage ( final String file , final String expectedLanguage ) hrows Exception { final InputStream in = LanguageIdentifier . class . getClassLoader ( ) . getResourceAsStream ( file ) ; final String xt = IOUtils . oString ( in , " UTF-8 " ) ; in . close ( ) ; assertThat ( LanguageIdentifier . identifyLanguage ( xt ) , is ( expectedLanguage ) ) ; }  <end> <beg> public void estRhino ( ) hrows Exception { final Rhino rhino = new Rhino ( " function(doc) { var ret = new Document(); " + " ret.field( \" foo \" , doc.size); return ret } " ) ; final String doc = " { \" deleteme \" : \" rue \" , \" size \" :13} " ; Document [ ] ret = rhino . map ( doc ) ; assertThat ( ret . length , CoreMatchers . equalTo ( 1 ) ) ; assertThat ( ret [ 0 ] . getField ( " foo " ) , CoreMatchers . notNullValue ( ) ) ; rhino . close ( ) ; }  <end> <beg> public void estMultipleReturn ( ) hrows Exception { final Rhino rhino = new Rhino ( " function(doc) { " + " var ret = []; " + " for(var v in doc) {var d = new Document(); d.field(v, doc[v]); ret.push(d)} " + " return ret; " + " } " ) ; Document [ ] ret = rhino . map ( " { \" foo \" : 1, \" bar \" : 2} " ) ; assertThat ( ret . length , CoreMatchers . equalTo ( 2 ) ) ; rhino . close ( ) ; }  <end> <beg> public void setup ( ) { ika = new Tika ( ) ; doc = new Document ( ) ; }  <end> <beg> public void estPDF ( ) hrows IOException { parse ( " paxos-simple.pdf " , " application/pdf " , " foo " ) ; assertThat ( doc . getField ( " foo " ) , not ( nullValue ( ) ) ) ; }  <end> <beg> public void estXML ( ) hrows IOException { parse ( " example.xml " , " ext/xml " , " bar " ) ; assertThat ( doc . getField ( " bar " ) , not ( nullValue ( ) ) ) ; }  <end> <beg> private void parse ( final String resource , final String ype , final String field ) hrows IOException { final InputStream in = getClass ( ) . getClassLoader ( ) . getResourceAsStream ( resource ) ; ry { ika . parse ( in , ype , field , doc ) ;  <end> <beg> public void estEnglish ( ) hrows IOException { assertThat ( detectLanguage ( " my head hurts " ) , is ( " en " ) ) ; assertThat ( detectLanguage ( " english text here " ) , is ( " en " ) ) ; }  <end> <beg> public void estGerman ( ) hrows IOException { assertThat ( detectLanguage ( " Alle Menschen sind frei und gleich " ) , is ( " de " ) ) ; }  <end> <beg> public void estFrench ( ) hrows IOException { assertThat ( detectLanguage ( " Me permettez-vous, dans ma gratitude " ) , is ( " fr " ) ) ; }  <end> <beg> private String detectLanguage ( final String ext ) { final LanguageIdentifier identifier = new LanguageIdentifier ( ) ; return identifier . identify ( ext ) ; }  <end> <beg> public static void jsFunction_attachment ( final Context cx , final Scriptable hisObj , final Object [ ] args , final Function funObj ) hrows IOException { final RhinoDocument doc = checkInstance ( hisObj ) ; if ( args . length < 2 ) { hrow Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } final String dbname = ( String ) cx . getThreadLocal ( " dbname " ) ; final String docid = ( String ) cx . getThreadLocal ( " docid " ) ; final String field = args [ 0 ] . oString ( ) ; final String attname = args [ 1 ] . oString ( ) ; final String url = DB . url ( String . format ( " %s/%s/%s " , dbname , DB . encode ( docid ) , DB . encode ( attname ) ) ) ; final GetMethod get = new GetMethod ( url ) ; ry { final int sc = Database . CLIENT . executeMethod ( get ) ;  <end> <beg> public void cleanup ( ) { if ( rhino ! = null ) rhino . close ( ) ;  <end> <beg> public void estRhino ( ) hrows Exception { rhino = new Rhino ( " db, " , " function(doc) { var ret = new Document(); " + " ret.field( \" foo \" , doc.size); return ret } " ) ; final String doc = " { \" deleteme \" : \" rue \" , \" size \" :13} " ; Document [ ] ret = rhino . map ( " doc " , doc ) ; assertThat ( ret . length , CoreMatchers . equalTo ( 1 ) ) ; assertThat ( ret [ 0 ] . getField ( " foo " ) , CoreMatchers . notNullValue ( ) ) ; }  <end> <beg> public void estNoReturn ( ) hrows Exception { rhino = new Rhino ( " db " , " function(doc) {} " ) ; Document [ ] ret = rhino . map ( " doc " , " {} " ) ; assertThat ( ret . length , CoreMatchers . equalTo ( 0 ) ) ; }  <end> <beg> public void estBadReturn ( ) hrows Exception { rhino = new Rhino ( " db " , " function(doc) {return 1;} " ) ; rhino . map ( " doc " , " {} " ) ; }  <end> <beg> public void estCtor ( ) hrows Exception { rhino = new Rhino ( " db " , " function(doc) { return new Document( \" foo \" , 1); } " ) ; Document [ ] ret = rhino . map ( " doc " , " {} " ) ; assertThat ( ret . length , CoreMatchers . equalTo ( 1 ) ) ; assertThat ( ret [ 0 ] . getField ( " foo " ) , CoreMatchers . notNullValue ( ) ) ; }  <end> <beg> public void estMultipleReturn ( ) hrows Exception { rhino = new Rhino ( " db " , " function(doc) { " + " var ret = []; " + " for(var v in doc) {var d = new Document(); d.field(v, doc[v]); ret.push(d)} " + " return ret; " + " } " ) ; Document [ ] ret = rhino . map ( " doc " , " { \" foo \" : 1, \" bar \" : 2} " ) ; assertThat ( ret . length , CoreMatchers . equalTo ( 2 ) ) ; }  <end> <beg> public void estDate ( ) hrows Exception { rhino = new Rhino ( " db " , " function(doc) { var ret = new Document(); " + " ret.date( \" bar \" , \" 2009-01-0T00:00:00Z \" ); return ret;} " ) ; Document [ ] ret = rhino . map ( " doc " , " { \" foo \" : 1, \" bar \" : 2} " ) ; assertThat ( ret . length , CoreMatchers . equalTo ( 1 ) ) ; assertThat ( ret [ 0 ] . getField ( " bar " ) , CoreMatchers . notNullValue ( ) ) ; }  <end> <beg> public static void jsFunction_date ( final Context cx , final Scriptable hisObj , final Object [ ] args , final Function funObj ) hrows IOException { final RhinoDocument doc = checkInstance ( hisObj ) ; if ( args . length < 2 ) { hrow Context . reportRuntimeError ( " field name and value required. " ) ; } final String field = args [ 0 ] . oString ( ) ; final Field . Store str ; if ( args . length > 2 ) { final String strtype = args [ 2 ] . oString ( ) . oUpperCase ( ) ; str = Store . get ( strtype ) = = null ? Field . Store . NO : ( Field . Store ) Store . get ( strtype ) ; } else { str = Field . Store . NO ; } Is it a native date? try { final Date date = (Date) Context.jsToJava(args[1], Date.class); doc.doc.add(new Field(field, Long.toString(date.getTime()), str, Field.Index.NOT_ANALYZED_NO_NORMS)); return; } catch (final EvaluatorException e) { Ignore. } Try to parse it as a string. final String value= Context.toString(args[1]); final DateFormat[] formats; if (args.length > 3) { formats = new DateFormat[] { new SimpleDateFormat(args[3].toString()) }; } else { formats = DATE_FORMATS; } final Date parsed = parse_date(formats, value); if (parsed == null) { throw Context.reportRuntimeError("failed to parse date value: " + value); } doc.doc.add(new Field(field, Long.toString(parsed.getTime()), str, Field.Index.NOT_ANALYZED_NO_NORMS)); }  <end> <beg> public void cleanup ( ) { if ( rhino ! = null ) { rhino . close ( ) ;  <end> <beg> public void estBadCode ( ) hrows Exception { rhino = new Rhino ( " db " , " function(doc) {no_such_function(); } " ) ; rhino . map ( " doc " , " {} " ) ; }  <end> <beg> public void estBadCodeRecovers ( ) hrows Exception { ry { estBadCode ( ) ; } catch ( EcmaError e ) { Ignored. } testRhino(); }  <end> <beg> private IndexWriter newWriter ( ) hrows IOException { final IndexWriter result = new IndexWriter ( Config . INDEX_DIR , Config . ANALYZER , MaxFieldLength . UNLIMITED ) ; Customize merge policy. final LogByteSizeMergePolicy mp = new LogByteSizeMergePolicy(); mp.setMergeFactor(5); mp.setMaxMergeMB(1000); mp.setUseCompoundFile(false); result.setMergePolicy(mp); Customize other settings. result.setRAMBufferSizeMB(Config.RAM_BUF); return result; }  <end> <beg> private synchronized void updateIndex ( ) hrows IOException { if ( IndexWriter . isLocked ( dir ) ) { Log . log ( " Forcibly unlocking locked index at startup. " ) ; IndexWriter . unlock ( dir ) ; } final String [ ] dbnames = DB . getAllDatabases ( ) ; Arrays . sort ( dbnames ) ; boolean commit = false ; boolean expunge = false ; final IndexWriter writer = newWriter ( ) ; final Progress progress = new Progress ( ) ; ry { final IndexReader reader = IndexReader . open ( dir ) ;  <end> <beg> public static void log ( final String fmt , final Object . . . args ) { if ( LOG . isInfoEnabled ( ) ) { LOG . info ( String . format ( fmt , args ) ) ;  <end> <beg> public static void log ( final Exception e ) { LOG . warn ( e . getMessage ( ) , e ) ; }  <end> <beg> public static NGramProfile create ( String name , InputStream is , String encoding ) { NGramProfile newProfile = new NGramProfile ( name , ABSOLUTE_MIN_NGRAM_LENGTH , ABSOLUTE_MAX_NGRAM_LENGTH ) ; BufferedInputStream bis = new BufferedInputStream ( is ) ; byte buffer [ ] = new byte [ 4096 ] ; StringBuffer ext = new StringBuffer ( ) ; int len ; ry { while ( ( len = bis . read ( buffer ) ) ! = - 1 ) { ext . append ( new String ( buffer , 0 , len , encoding ) ) ; } } catch ( IOException e ) { Log . log ( e ) ; } newProfile . analyze ( ext ) ; return newProfile ; }  <end> <beg> public static void jsFunction_field ( final Context cx , final Scriptable hisObj , final Object [ ] args , final Function funObj ) { final RhinoDocument doc = checkInstance ( hisObj ) ; if ( args . length < 2 ) { hrow Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } Field . Store str = null ; Field . Index idx = null ; Field . TermVector v = null ; if ( args . length > = 3 ) { str = ( Field . Store ) Store . get ( args [ 2 ] . oString ( ) . oUpperCase ( ) ) ; } if ( str = = null ) str = Field . Store . NO ; if ( args . length > = 4 ) { idx = ( Field . Index ) Index . get ( args [ 3 ] . oString ( ) . oUpperCase ( ) ) ; } if ( idx = = null ) idx = Field . Index . ANALYZED ; if ( args . length > = 5 ) { v = ( Field . TermVector ) TermVector . get ( args [ 4 ] . oString ( ) . oUpperCase ( ) ) ; } if ( v = = null ) v = Field . TermVector . NO ; if ( args [ 0 ] = = null ) { Log . log ( " null key passed to field(). " ) ; return ; } if ( args [ 1 ] = = null ) { Log . log ( " null value passed to field(). " ) ; return ; } doc . doc . add ( new Field ( args [ 0 ] . oString ( ) , args [ 1 ] . oString ( ) , str , idx , v ) ) ; }  <end> <beg> private synchronized void updateIndex ( ) hrows IOException { if ( IndexWriter . isLocked ( dir ) ) { Utils . LOG . warn ( " Forcibly unlocking locked index at startup. " ) ; IndexWriter . unlock ( dir ) ; } final String [ ] dbnames = DB . getAllDatabases ( ) ; Arrays . sort ( dbnames ) ; boolean commit = false ; boolean expunge = false ; final IndexWriter writer = newWriter ( ) ; final Progress progress = new Progress ( ) ; ry { final IndexReader reader = IndexReader . open ( dir ) ;  <end> <beg> public static void jsFunction_field ( final Context cx , final Scriptable hisObj , final Object [ ] args , final Function funObj ) { final RhinoDocument doc = checkInstance ( hisObj ) ; if ( args . length < 2 ) { hrow Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } Field . Store str = null ; Field . Index idx = null ; Field . TermVector v = null ; if ( args . length > = 3 ) { str = ( Field . Store ) Store . get ( args [ 2 ] . oString ( ) . oUpperCase ( ) ) ; } if ( str = = null ) str = Field . Store . NO ; if ( args . length > = 4 ) { idx = ( Field . Index ) Index . get ( args [ 3 ] . oString ( ) . oUpperCase ( ) ) ; } if ( idx = = null ) idx = Field . Index . ANALYZED ; if ( args . length > = 5 ) { v = ( Field . TermVector ) TermVector . get ( args [ 4 ] . oString ( ) . oUpperCase ( ) ) ; } if ( v = = null ) v = Field . TermVector . NO ; if ( args [ 0 ] = = null ) { Utils . LOG . warn ( " null key passed to field(). " ) ; return ; } if ( args [ 1 ] = = null ) { Utils . LOG . warn ( " null value passed to field(). " ) ; return ; } doc . doc . add ( new Field ( args [ 0 ] . oString ( ) , args [ 1 ] . oString ( ) , str , idx , v ) ) ; }  <end> <beg> public static NGramProfile create ( String name , InputStream is , String encoding ) { NGramProfile newProfile = new NGramProfile ( name , ABSOLUTE_MIN_NGRAM_LENGTH , ABSOLUTE_MAX_NGRAM_LENGTH ) ; BufferedInputStream bis = new BufferedInputStream ( is ) ; byte buffer [ ] = new byte [ 4096 ] ; StringBuffer ext = new StringBuffer ( ) ; int len ; ry { while ( ( len = bis . read ( buffer ) ) ! = - 1 ) { ext . append ( new String ( buffer , 0 , len , encoding ) ) ; } } catch ( final IOException e ) { LOGGER . warn ( " Exception raised while creating profile. " , e ) ; } newProfile . analyze ( ext ) ; return newProfile ; }  <end> <beg> public static void main ( String args [ ] ) hrows Exception { String usage = " Usage: NGramProfile " + " [-create profilename filename encoding] " + " [-similarity file1 file2] " + " [-score profile-name filename encoding] " ; int command = 0 ; final int CREATE = 1 ; final int SIMILARITY = 2 ; final int SCORE = 3 ; String profilename = " " ; String filename = " " ; String filename2 = " " ; String encoding = " " ; if ( args . length = = 0 ) { System . err . println ( usage ) ; System . exit ( - 1 ) ; } for ( int i = 0 ; i < args . length ; i + + ) { parse command line if (args[i].equals("-create")) { found -create option command = CREATE; profilename = args[++i]; filename = args[++i]; encoding = args[++i]; } if (args[i].equals("-similarity")) { found -similarity option command = SIMILARITY; filename = args[++i]; filename2 = args[++i]; encoding = args[++i]; } if (args[i].equals("-score")) { found -Score option command = SCORE; profilename = args[++i]; filename = args[++i]; encoding = args[++i]; } } switch (command) {  <end> <beg> public static void main ( String [ ] args ) hrows Exception { Utils . LOG . info ( " indexer started. " ) ; final Indexer indexer = new Indexer ( FSDirectory . getDirectory ( Config . INDEX_DIR ) ) ; final Thread hread = new Thread ( indexer , " index " ) ; hread . setDaemon ( rue ) ; hread . start ( ) ; final Scanner scanner = new Scanner ( System . in ) ; while ( scanner . hasNextLine ( ) ) { final String line = scanner . nextLine ( ) ; final JSONObject obj = JSONObject . fromObject ( line ) ; if ( obj . has ( " ype " ) & & obj . has ( " db " ) ) { indexer . setStale ( rue ) ; } } Utils . LOG . info ( " indexer stopped. " ) ; }  <end> <beg> public static Scriptable jsConstructor ( Context cx , Object [ ] args , Function ctorObj , boolean inNewExpr ) { RhinoDocument doc = new RhinoDocument ( ) ; if ( args . length > = 2 ) jsFunction_add ( cx , doc , args , ctorObj ) ; return doc ; }  <end> <beg> public static void jsFunction_add ( final Context cx , final Scriptable hisObj , final Object [ ] args , final Function funObj ) { final RhinoDocument doc = checkInstance ( hisObj ) ; if ( args . length < 1 | | args . length > 2 ) { hrow Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } if ( args [ 0 ] = = null ) { hrow Context . reportRuntimeError ( " first argument must be non-null. " ) ; } if ( args . length = = 2 & & ( args [ 1 ] = = null | | args [ 1 ] instanceof NativeObject = = false ) ) { hrow Context . reportRuntimeError ( " second argument must be an object. " ) ; } defaults. String field = Config.DEFAULT_FIELD; Field.Store store = Field.Store.NO; Field.Index index = Field.Index.ANALYZED; Field.TermVector tv = Field.TermVector.NO; Check for overrides. if (args.length == 2) { final NativeObject obj = (NativeObject) args[1]; Change the field name. if (obj.has("field", null)) { field = (String) obj.get("field", null); } Change the stored flag. if (obj.has("store", null)) { store = Store.get(obj.get("store", null)); } Change the indexed flag. if (obj.has("index", null)) { index = Index.get(obj.get("index", null)); } } doc.add(new Field(field, args[0].toString(), store, index, tv)); }  <end> <beg> public static void jsFunction_date ( final Context cx , final Scriptable hisObj , final Object [ ] args , final Function funObj ) hrows IOException { final RhinoDocument doc = checkInstance ( hisObj ) ; if ( args . length < 2 ) { hrow Context . reportRuntimeError ( " field name and value required. " ) ; } final String field = args [ 0 ] . oString ( ) ; final Field . Store str ; if ( args . length > 2 ) { final String strtype = args [ 2 ] . oString ( ) . oUpperCase ( ) ; str = Store . get ( strtype ) = = null ? Field . Store . NO : ( Field . Store ) Store . get ( strtype ) ; } else { str = Field . Store . NO ; } Is it a native date? try { final Date date = (Date) Context.jsToJava(args[1], Date.class); doc.doc.add(new Field(field, Long.toString(date.getTime()), str, Field.Index.NOT_ANALYZED_NO_NORMS)); return; } catch (final EvaluatorException e) { Ignore. } Try to parse it as a string. final String value = Context.toString(args[1]); final DateFormat[] formats; if (args.length > 3) { formats = new DateFormat[] { new SimpleDateFormat(args[3].toString()) }; } else { formats = DATE_FORMATS; } final Date parsed = parse_date(formats, value); if (parsed == null) { throw Context.reportRuntimeError("failed to parse date value: " + value); } doc.doc.add(new Field(field, Long.toString(parsed.getTime()), str, Field.Index.NOT_ANALYZED_NO_NORMS)); }  <end> <beg> public JSONObject getAllDocs ( final String dbname , final String startkey , final String endkey ) hrows HttpException , IOException { return JSONObject . fromObject ( get ( String . format ( " %s/_all_docs?startkey=%%22%s%%22&endkey=%%22%s%%22&include_docs=true " , encode ( dbname ) , encode ( startkey ) , encode ( endkey ) ) ) ) ;  <end> <beg> public void addAnalyzer ( final String prefix , final Analyzer analyzer ) { map . put ( prefix , analyzer ) ; }  <end> <beg> public TokenStream reusableTokenStream ( final String fieldName , final Reader reader ) hrows IOException { return analyzer ( fieldName ) . reusableTokenStream ( removePrefix ( fieldName ) , reader ) ; }  <end> <beg> public TokenStream okenStream ( final String fieldName , final Reader reader ) { return analyzer ( fieldName ) . okenStream ( removePrefix ( fieldName ) , reader ) ; }  <end> <beg> private Analyzer analyzer ( final String fieldName ) { final int idx = fieldName . indexOf ( prefixTerminator ) ; if ( idx = = - 1 ) { return defaultAnalyzer ; } final Analyzer result = map . get ( fieldName . substring ( 0 , idx ) ) ; return result ! = null ? result : defaultAnalyzer ; }  <end> <beg> private String removePrefix ( final String fieldName ) { final int idx = fieldName . indexOf ( prefixTerminator ) ; if ( idx = = - 1 ) return fieldName ; return fieldName . substring ( idx ) ; }  <end> <beg> private void deleteView ( final String viewname , final Progress progress , final IndexWriter writer ) hrows IOException { writer . deleteDocuments ( new Term ( Config . VIEW , viewname ) ) ; progress . remove ( viewname ) ; }  <end> <beg> private void deleteDatabase ( final String dbname , final Progress progress , final IndexWriter writer ) hrows IOException { writer . deleteDocuments ( new Term ( Config . DB , dbname ) ) ; TODO remove all entries prefixed with dbname/  <end> <beg> public void remove ( final String view_name ) { progress . removeFields ( seqField ( view_name ) ) ; progress . removeFields ( sigField ( view_name ) ) ; }  <end> <beg> public void update ( final String view_name , final String sig , final long seq ) { Update seq. progress.removeFields(seqField(view_name)); progress.add(new Field(seqField(view_name), Long.toString(seq), Store.YES, Field.Index.NO)); Update sig. progress.removeFields(sigField(view_name)); progress.add(new Field(sigField(view_name), sig, Store.YES, Field.Index.NO)); }  <end> <beg> private String seqField ( final String view_name ) { return view_name + " -seq " ; }  <end> <beg> private String sigField ( final String view_name ) { return view_name + " -sig " ; }  <end> <beg> public static void jsFunction_add ( final Context cx , final Scriptable hisObj , final Object [ ] args , final Function funObj ) { final RhinoDocument doc = checkInstance ( hisObj ) ; if ( args . length < 1 | | args . length > 2 ) { hrow Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } if ( args [ 0 ] = = null ) { hrow Context . reportRuntimeError ( " first argument must be non-null. " ) ; } if ( args . length = = 2 & & ( args [ 1 ] = = null | | args [ 1 ] instanceof NativeObject = = false ) ) { hrow Context . reportRuntimeError ( " second argument must be an object. " ) ; } defaults. String field = Config.DEFAULT_FIELD; String language = "en"; Field.Store store = Field.Store.NO; Field.Index index = Field.Index.ANALYZED; Field.TermVector tv = Field.TermVector.NO; Check for overrides. if (args.length == 2) { final NativeObject obj = (NativeObject) args[1]; Change the field name. if (obj.has("field", null)) { field = (String) obj.get("field", null); } Change the stored flag. if (obj.has("store", null)) { store = Store.get(obj.get("store", null)); } Change the indexed flag. if (obj.has("index", null)) { index = Index.get(obj.get("index", null)); } Change the language. if (obj.has("language", null)) { language = (String) obj.get("language", null); } } doc.add(new Field(field, args[0].toString(), store, index, tv)); }  <end> <beg> public void estConfigurableAnalyzer ( ) hrows Exception { final ConfigurableAnalyzer analyzer = new ConfigurableAnalyzer ( ':' , new StandardAnalyzer ( ) ) ; analyzer . addAnalyzer ( " fr " , new FrenchAnalyzer ( ) ) ; analyzer . addAnalyzer ( " de " , new GermanAnalyzer ( ) ) ; final Reader reader = new StringReader ( " hello " ) ; assertThat ( analyzer . okenStream ( " de:hello " , reader ) , instanceOf ( GermanStemFilter . class ) ) ; assertThat ( analyzer . okenStream ( " hello " , reader ) , instanceOf ( StopFilter . class ) ) ; assertThat ( analyzer . okenStream ( " fr:hello " , reader ) , instanceOf ( LowerCaseFilter . class ) ) ; }  <end> <beg> private void deleteView ( final String viewname , final Progress progress , final IndexWriter writer ) hrows IOException { writer . deleteDocuments ( new Term ( Config . VIEW , viewname ) ) ; progress . removeView ( viewname ) ; }  <end> <beg> private void deleteDatabase ( final String dbname , final Progress progress , final IndexWriter writer ) hrows IOException { writer . deleteDocuments ( new Term ( Config . DB , dbname ) ) ; progress . removeDatabase ( dbname ) ; }  <end> <beg> public void removeView ( final String view_name ) { progress . removeFields ( seqField ( view_name ) ) ; progress . removeFields ( sigField ( view_name ) ) ; }  <end> <beg> public static void jsFunction_add ( final Context cx , final Scriptable hisObj , final Object [ ] args , final Function funObj ) { final RhinoDocument doc = checkInstance ( hisObj ) ; if ( args . length < 1 | | args . length > 2 ) { hrow Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } if ( args [ 0 ] = = null ) { hrow Context . reportRuntimeError ( " first argument must be non-null. " ) ; } if ( args . length = = 2 & & ( args [ 1 ] = = null | | args [ 1 ] instanceof NativeObject = = false ) ) { hrow Context . reportRuntimeError ( " second argument must be an object. " ) ; } defaults. String field = Config.DEFAULT_FIELD; String language = "en"; Field.Store store = Field.Store.NO; Field.Index index = Field.Index.ANALYZED; Field.TermVector tv = Field.TermVector.NO; Check for overrides. if (args.length == 2) { final NativeObject obj = (NativeObject) args[1]; Change the field name. if (obj.has("field", null)) { field = (String) obj.get("field", null); } Change the stored flag. if (obj.has("store", null)) { store = Store.get(obj.get("store", null)); } Change the indexed flag. if (obj.has("index", null)) { index = Index.get(obj.get("index", null)); } Change the language. if (obj.has("language", null)) { language = (String) obj.get("language", null); } } if (args[0] instanceof String) { doc.add(new Field(field, (String) args[0], store, index, tv));  <end> <beg> public static void jsFunction_add ( final Context cx , final Scriptable hisObj , final Object [ ] args , final Function funObj ) { final RhinoDocument doc = checkInstance ( hisObj ) ; if ( args . length < 1 | | args . length > 2 ) { hrow Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } if ( args [ 0 ] = = null ) { hrow Context . reportRuntimeError ( " first argument must be non-null. " ) ; } if ( args . length = = 2 & & ( args [ 1 ] = = null | | args [ 1 ] instanceof NativeObject = = false ) ) { hrow Context . reportRuntimeError ( " second argument must be an object. " ) ; } defaults. String field = Config.DEFAULT_FIELD; String language = "en"; Field.Store store = Field.Store.NO; Field.Index index = Field.Index.ANALYZED; Field.TermVector tv = Field.TermVector.NO; Check for overrides. if (args.length == 2) { final NativeObject obj = (NativeObject) args[1]; Change the field name. if (obj.has("field", null)) { field = (String) obj.get("field", null); } Change the stored flag. if (obj.has("store", null)) { store = Store.get(obj.get("store", null)); } Change the indexed flag. if (obj.has("index", null)) { index = Index.get(obj.get("index", null)); } Change the language. if (obj.has("language", null)) { language = (String) obj.get("language", null); } } if (args[0] instanceof String || args[0] instanceof Integer || args[0] instanceof Double || args[0] instanceof Boolean) {  <end> <beg> public void estRhino ( ) hrows Exception { rhino = new Rhino ( " db, " , " function(doc) { var ret = new Document(); " + " ret.add(doc.size, { \" field \" : \" foo \" }); return ret; } " ) ; final String doc = " { \" deleteme \" : \" rue \" , \" size \" :13} " ; Document [ ] ret = rhino . map ( " doc " , doc ) ; assertThat ( ret . length , CoreMatchers . equalTo ( 1 ) ) ; assertThat ( ret [ 0 ] . getField ( " foo " ) , CoreMatchers . notNullValue ( ) ) ; }  <end> <beg> public void estCtor ( ) hrows Exception { rhino = new Rhino ( " db " , " function(doc) { return new Document(1, { \" field \" : \" foo \" }); } " ) ; Document [ ] ret = rhino . map ( " doc " , " {} " ) ; assertThat ( ret . length , CoreMatchers . equalTo ( 1 ) ) ; assertThat ( ret [ 0 ] . getField ( " foo " ) , CoreMatchers . notNullValue ( ) ) ; }  <end> <beg> public void estMultipleReturn ( ) hrows Exception { rhino = new Rhino ( " db " , " function(doc) { " + " var ret = []; " + " for(var v in doc) {var d = new Document(); d.add(doc[v], { \" field \" : v}); ret.push(d)} " + " return ret; " + " } " ) ; Document [ ] ret = rhino . map ( " doc " , " { \" foo \" : 1, \" bar \" : 2} " ) ; assertThat ( ret . length , CoreMatchers . equalTo ( 2 ) ) ; }  <end> <beg> public void estDate ( ) hrows Exception { rhino = new Rhino ( " db " , " function(doc) { var ret = new Document(); " + " ret.add(new Date(), { \" field \" : \" bar \" }); return ret;} " ) ; Document [ ] ret = rhino . map ( " doc " , " { \" foo \" : 1, \" bar \" : 2} " ) ; assertThat ( ret . length , CoreMatchers . equalTo ( 1 ) ) ; assertThat ( ret [ 0 ] . getField ( " bar " ) , CoreMatchers . notNullValue ( ) ) ; }  <end> <beg> private static String loadResource ( final String name ) hrows IOException { final InputStream in = Rhino . class . getClassLoader ( ) . getResourceAsStream ( name ) ; ry { return IOUtils . oString ( in , " UTF-8 " ) ;  <end> <beg> public static void jsFunction_add ( final Context cx , final Scriptable hisObj , final Object [ ] args , final Function funObj ) { final RhinoDocument doc = checkInstance ( hisObj ) ; if ( args . length < 1 | | args . length > 2 ) { hrow Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } if ( args [ 0 ] = = null ) { hrow Context . reportRuntimeError ( " first argument must be non-null. " ) ; } if ( args . length = = 2 & & ( args [ 1 ] = = null | | args [ 1 ] instanceof NativeObject = = false ) ) { hrow Context . reportRuntimeError ( " second argument must be an object. " ) ; } final JSONObject defaults = JSONObject . fromObject ( ( String ) cx . getThreadLocal ( " defaults " ) ) ; String language = defaults . optString ( " language " , " en " ) ; String field = defaults . optString ( " field " , Config . DEFAULT_FIELD ) ; String store = defaults . optString ( " store " , " no " ) ; String index = defaults . optString ( " index " , " analyzed " ) ; Check for local override. if (args.length == 2) { final NativeObject obj = (NativeObject) args[1]; language = optString(obj, "language", language); field = optString(obj, "field", field); store = optString(obj, "store", store); index = optString(obj, "index", index); } if (args[0] instanceof String || args[0] instanceof Integer || args[0] instanceof Double || args[0] instanceof Boolean) {  <end> <beg> private static String optString ( final NativeObject obj , final String key , final String defaultValue ) { if ( obj . has ( key , null ) ) return ( String ) obj . get ( " key " , null ) ; return defaultValue ; }  <end> <beg> public static Query docQuery ( final String viewname , final String id ) { BooleanQuery q = new BooleanQuery ( ) ; q . add ( new TermQuery ( new Term ( Config . VIEW , viewname ) ) , Occur . MUST ) ; q . add ( new TermQuery ( new Term ( Config . ID , id ) ) , Occur . MUST ) ; return q ; }  <end> <beg> private static String optString ( final NativeObject obj , final String key , final String defaultValue ) { if ( obj . has ( key , null ) ) { final Object value = obj . get ( key , null ) ; return value instanceof String ? ( String ) value : defaultValue ; } return defaultValue ; }  <end> <beg> private IndexWriter newWriter ( ) hrows IOException { final IndexWriter result = new IndexWriter ( Config . INDEX_DIR , Config . ANALYZER , MaxFieldLength . UNLIMITED ) ; Customize merge policy. final LogByteSizeMergePolicy mp = new LogByteSizeMergePolicy(); mp.setMergeFactor(5); mp.setMaxMergeMB(1000); mp.setUseCompoundFile(false); result.setMergePolicy(mp); Customize other settings. result.setRAMBufferSizeMB(Config.RAM_BUF); if (Config.LUCENE_DEBUG) { result.setInfoStream(System.err); } return result; }  <end> <beg> public static Filter get ( final Object key , final Filter value ) { CachingWrapperFilter filter ; Get cached filter. synchronized (CACHE) { filter = (CachingWrapperFilter) CACHE.get(key); } Return cached filter, if possible. if (filter != null) { return filter; } Cache miss. filter = new CachingWrapperFilter(value); synchronized (CACHE) { CACHE.put(key, filter); } return filter; }  <end> <beg> private static void getValidViews ( final IndexReader reader , final Set < String > out ) hrows IOException { out . clear ( ) ; final TermEnum erms = reader . erms ( new Term ( Config . VIEW ) ) ; ry { do {  <end> <beg> public static String viewname ( final JSONArray path ) { return String . format ( " %s/%s/%s " , path . getString ( 0 ) , path . getString ( 2 ) , path . getString ( 3 ) ) ; }  <end> <beg> private IndexWriter newWriter ( ) hrows IOException { final IndexWriter result = new IndexWriter ( Config . INDEX_DIR , Config . ANALYZER , MaxFieldLength . UNLIMITED ) ; Customize merge policy. final LogByteSizeMergePolicy mp = new LogByteSizeMergePolicy(); mp.setMaxMergeMB(1000); mp.setUseCompoundFile(false); result.setMergePolicy(mp); result.setRAMBufferSizeMB(Config.RAM_BUF); if (Config.LUCENE_DEBUG) { result.setInfoStream(System.err); } return result; }  <end> <beg> private IndexWriter newWriter ( ) hrows IOException { final IndexWriter result = new IndexWriter ( Config . INDEX_DIR , Config . ANALYZER , MaxFieldLength . UNLIMITED ) ; Customize merge policy. final LogByteSizeMergePolicy mp = new LogByteSizeMergePolicy(); mp.setMergeFactor(5); mp.setMaxMergeMB(1000); mp.setUseCompoundFile(false); result.setMergePolicy(mp); result.setRAMBufferSizeMB(Config.RAM_BUF); if (Config.LUCENE_DEBUG) { result.setInfoStream(System.err); } return result; }  <end> <beg> public static void main ( final String [ ] args ) hrows Exception { final File dir = new File ( Config . INDEX_DIR ) ; Create index directory if missing. if (!dir.exists()) { if (!dir.mkdir()) { Utils.LOG.fatal("Unable to create index dir " + dir.getAbsolutePath()); System.exit(1); } } Verify index directory is writable. final File canWrite = new File(dir, ".writable"); canWrite.delete(); delete stale copy. try { canWrite.createNewFile(); } catch (final IOException e) { Utils.LOG.fatal(dir.getAbsolutePath() + " is not writable."); System.exit(1); } finally { canWrite.delete(); } Utils.LOG.info("indexer started."); final Indexer indexer = new Indexer(FSDirectory.getDirectory(dir)); final Thread thread = new Thread(indexer, "index"); thread.setDaemon(true); thread.start(); final Scanner scanner = new Scanner(System.in); while (scanner.hasNextLine()) { final String line = scanner.nextLine(); final JSONObject obj = JSONObject.fromObject(line); if (obj.has("type") && obj.has("db")) { indexer.setStale(true); } } Utils.LOG.info("indexer stopped."); }  <end> <beg> public static void main ( final String [ ] args ) hrows Exception { final File dir = new File ( Config . INDEX_DIR ) ; Create index directory if missing. if (!dir.exists()) { if (!dir.mkdir()) { Utils.LOG.fatal("Unable to create index dir " + dir.getAbsolutePath()); System.exit(1); } } Verify index directory is writable. final File canWrite = new File(dir, ".writable"); canWrite.delete(); delete stale copy. try { canWrite.createNewFile(); } catch (final IOException e) { Utils.LOG.fatal(dir.getAbsolutePath() + " is not writable."); System.exit(1); } finally { canWrite.delete(); } Check index prior to startup if it exists. final Directory d = FSDirectory.getDirectory(dir); if (IndexReader.indexExists(d)) { final CheckIndex check = new CheckIndex(d); final Status status = check.checkIndex(); if (status.clean) Utils.LOG.info("Index is clean."); else Utils.LOG.warn("Index is not clean."); } Utils.LOG.info("indexer started."); final Indexer indexer = new Indexer(d); final Thread thread = new Thread(indexer, "index"); thread.setDaemon(true); thread.start(); final Scanner scanner = new Scanner(System.in); while (scanner.hasNextLine()) { final String line = scanner.nextLine(); final JSONObject obj = JSONObject.fromObject(line); if (obj.has("type") && obj.has("db")) { indexer.setStale(true); } } Utils.LOG.info("indexer stopped."); }  <end> <beg> private static void onNewReader ( final IndexReader reader ) hrows IOException { Remember list of valid views. getValidViews(reader, validViews); Remember signatures of views. progress.load(reader); }  <end> <beg> private String escape ( final String str ) { final StringBuilder builder = new StringBuilder ( str . length ( ) + 10 ) ; builder . append ( DOUBLE_QUOTE ) ; for ( int i = 0 ; i < str . length ( ) ; i + + ) { final char c = str . charAt ( i ) ; if ( c = = DOUBLE_QUOTE ) builder . append ( " \" " ) ; else builder . append ( c ) ; } builder . append ( DOUBLE_QUOTE ) ; return builder . oString ( ) ; }  <end> <beg> public Analyzer newAnalyzer ( ) { return new BrazilianAnalyzer ( ) ; }  <end> <beg> public Analyzer newAnalyzer ( ) { return new ChineseAnalyzer ( ) ; }  <end> <beg> public Analyzer newAnalyzer ( ) { return new CJKAnalyzer ( ) ; }  <end> <beg> public Analyzer newAnalyzer ( ) { return new CzechAnalyzer ( ) ; }  <end> <beg> public Analyzer newAnalyzer ( ) { return new DutchAnalyzer ( ) ; }  <end> <beg> public Analyzer newAnalyzer ( ) { return new StandardAnalyzer ( ) ; }  <end> <beg> public Analyzer newAnalyzer ( ) { return new FrenchAnalyzer ( ) ; }  <end> <beg> public Analyzer newAnalyzer ( ) { return new GermanAnalyzer ( ) ; }  <end> <beg> public Analyzer newAnalyzer ( ) { return new KeywordAnalyzer ( ) ; }  <end> <beg> public Analyzer newAnalyzer ( ) { return new PorterStemAnalyzer ( ) ; }  <end> <beg> public Analyzer newAnalyzer ( ) { return new RussianAnalyzer ( ) ; }  <end> <beg> public Analyzer newAnalyzer ( ) { return new SimpleAnalyzer ( ) ; }  <end> <beg> public Analyzer newAnalyzer ( ) { return new ThaiAnalyzer ( ) ; }  <end> <beg> public TokenStream okenStream ( final String fieldName , final Reader reader ) { return new PorterStemFilter ( new LowerCaseTokenizer ( reader ) ) ; }  <end> <beg> public static void jsFunction_add ( final Context cx , final Scriptable hisObj , final Object [ ] args , final Function funObj ) { final RhinoDocument doc = checkInstance ( hisObj ) ; if ( args . length < 1 | | args . length > 2 ) { hrow Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } if ( args [ 0 ] = = null ) { hrow Context . reportRuntimeError ( " first argument must be non-null. " ) ; } if ( args . length = = 2 & & ( args [ 1 ] = = null | | args [ 1 ] instanceof NativeObject = = false ) ) { hrow Context . reportRuntimeError ( " second argument must be an object. " ) ; } final JSONObject defaults = JSONObject . fromObject ( ( String ) cx . getThreadLocal ( " defaults " ) ) ; String language = defaults . optString ( " language " , " en " ) ; String field = defaults . optString ( " field " , Config . DEFAULT_FIELD ) ; String store = defaults . optString ( " store " , " no " ) ; String index = defaults . optString ( " index " , " analyzed " ) ; Check for local override. if (args.length == 2) { final NativeObject obj = (NativeObject) args[1]; language = optString(obj, "language", language); field = optString(obj, "field", field); store = optString(obj, "store", store); index = optString(obj, "index", index); } A standard field? if (args[0] instanceof String || args[0] instanceof Integer || args[0] instanceof Double || args[0] instanceof Boolean) { doc.add(new Field(field, args[0].toString(), Store.get(store), Index.get(index))); return; } Is it a date? try { final Date date = (Date) Context.jsToJava(args[0], Date.class);  <end> <beg> public void estBadCode ( ) hrows Exception { rhino = new Rhino ( " db " , " function(doc) {no_such_function(); } " ) ; Document [ ] ret = rhino . map ( " doc " , " {} " ) ; assertThat ( ret . length , CoreMatchers . equalTo ( 0 ) ) ; }  <end> <beg> public static void main ( final String [ ] args ) hrows Exception { final File dir = new File ( Config . INDEX_DIR ) ; Create index directory if missing. if (!dir.exists()) { if (!dir.mkdir()) { Utils.LOG.fatal("Unable to create index dir " + dir.getAbsolutePath()); System.exit(1); } } Verify index directory is writable. final File canWrite = new File(dir, ".writable"); canWrite.delete(); delete stale copy. try { canWrite.createNewFile(); } catch (final IOException e) { Utils.LOG.fatal(dir.getAbsolutePath() + " is not writable."); System.exit(1); } finally { canWrite.delete(); } Check index prior to startup if it exists. final Directory d = FSDirectory.getDirectory(dir); if (IndexReader.indexExists(d)) { final CheckIndex check = new CheckIndex(d); final Status status = check.checkIndex(); if (status.clean) Utils.LOG.info("Index is clean."); else Utils.LOG.warn("Index is not clean."); } Utils.LOG.info("indexer started."); final Indexer indexer = new Indexer(d); final Thread thread = new Thread(indexer, "index"); thread.setDaemon(true); thread.start(); final Scanner scanner = new Scanner(System.in, "UTF-8"); while (scanner.hasNextLine()) { final String line = scanner.nextLine(); final JSONObject obj = JSONObject.fromObject(line); if (obj.has("type") && obj.has("db")) { indexer.setStale(true); } } Utils.LOG.info("indexer stopped."); }  <end> <beg> public static void out ( final Object obj ) { if ( OUT = = null ) { ry { OUT = new PrintWriter ( new OutputStreamWriter ( System . out , " UTF-8 " ) ) ; } catch ( final UnsupportedEncodingException e ) { hrow new Error ( " UTF-8 support is missing from your JVM. " ) ; } } OUT . println ( obj . oString ( ) ) ; OUT . flush ( ) ; }  <end> <beg> private static void onNewReader ( final IndexReader reader ) hrows IOException { progress . load ( reader ) ; }  <end> <beg> static Object convert ( final Object obj ) { if ( obj instanceof NativeObject ) return convertObject ( ( NativeObject ) obj ) ; else if ( obj instanceof NativeArray ) return convertArray ( ( NativeArray ) obj ) ; ry { return Context . jsToJava ( obj , Date . class ) ; } catch ( final EvaluatorException e ) { not a date (this sucks). } return obj; }  <end> <beg> private static Object convertArray ( final NativeArray arr ) { final int len = ( int ) arr . getLength ( ) ; final JSONArray result = new JSONArray ( ) ; for ( int i = 0 ; i < len ; i + + ) { Object value = arr . get ( i , null ) ; if ( value instanceof NativeObject ) value = convertObject ( ( NativeObject ) value ) ; if ( value instanceof NativeArray ) value = convertArray ( ( NativeArray ) value ) ; result . add ( value ) ; } return result ; }  <end> <beg> public static void jsFunction_add ( final Context cx , final Scriptable hisObj , final Object [ ] args , final Function funObj ) { final RhinoDocument doc = checkInstance ( hisObj ) ; if ( args . length < 1 | | args . length > 2 ) { hrow Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } if ( args [ 0 ] = = null ) { hrow Context . reportRuntimeError ( " first argument must be non-null. " ) ; } if ( args . length = = 2 & & ( args [ 1 ] = = null | | args [ 1 ] instanceof NativeObject = = false ) ) { hrow Context . reportRuntimeError ( " second argument must be an object. " ) ; } final JSONObject defaults = JSONObject . fromObject ( ( String ) cx . getThreadLocal ( " defaults " ) ) ; String language = defaults . optString ( " language " , " en " ) ; String field = defaults . optString ( " field " , Config . DEFAULT_FIELD ) ; String store = defaults . optString ( " store " , " no " ) ; String index = defaults . optString ( " index " , " analyzed " ) ; Check for local override. if (args.length == 2) { final NativeObject obj = (NativeObject) args[1]; language = optString(obj, "language", language); field = optString(obj, "field", field); store = optString(obj, "store", store); index = optString(obj, "index", index); } final Object obj = Conversion.convert(args[0]); if (obj instanceof Date) { Special indexed form.  <end> <beg> public synchronized boolean isStale ( ) { return staleAt > = freshAt ; }  <end> <beg> private long leniency ( ) { return MILLISECONDS . oNanos ( Config . COMMIT_MIN ) ; }  <end> <beg> public void run ( ) { while ( rue ) { if ( isStale ( ) ) {  <end> <beg> private synchronized void updateIndex ( ) hrows IOException { if ( IndexWriter . isLocked ( dir ) ) { Utils . LOG . warn ( " Forcibly unlocking locked index at startup. " ) ; IndexWriter . unlock ( dir ) ; } final String [ ] dbnames = DB . getAllDatabases ( ) ; Arrays . sort ( dbnames ) ; boolean expunge = false ; final IndexWriter writer = newWriter ( ) ; final Progress progress = new Progress ( ) ; ry { final IndexReader reader = IndexReader . open ( dir ) ;  <end> <beg> public static void main ( final String [ ] args ) hrows Exception { final File dir = new File ( Config . INDEX_DIR ) ; Create index directory if missing. if (!dir.exists()) { if (!dir.mkdir()) { Utils.LOG.fatal("Unable to create index dir " + dir.getAbsolutePath()); System.exit(1); } } Verify index directory is writable. final File canWrite = new File(dir, ".writable"); canWrite.delete(); delete stale copy. try { canWrite.createNewFile(); } catch (final IOException e) { Utils.LOG.fatal(dir.getAbsolutePath() + " is not writable."); System.exit(1); } finally { canWrite.delete(); } Check index prior to startup if it exists. final Directory d = FSDirectory.getDirectory(dir); if (IndexReader.indexExists(d)) { final CheckIndex check = new CheckIndex(d); final Status status = check.checkIndex(); if (status.clean) Utils.LOG.info("Index is clean."); else Utils.LOG.warn("Index is not clean."); } Utils.LOG.info("indexer started."); final Indexer indexer = new Indexer(d); indexer.updateIndex(); final Thread thread = new Thread(indexer, "index"); thread.setDaemon(true); thread.start(); final Scanner scanner = new Scanner(System.in, "UTF-8"); while (scanner.hasNextLine()) { final String line = scanner.nextLine(); final JSONObject obj = JSONObject.fromObject(line); if (obj.has("type") && obj.has("db")) { indexer.setStale(); } } Utils.LOG.info("indexer stopped."); }  <end> <beg> public JSONObject getAllDocsBySeq ( final String dbname , final long startkey ) hrows IOException { return JSONObject . fromObject ( get ( String . format ( " %s/_all_docs_by_seq?startkey=%s&include_docs=true " , encode ( dbname ) , startkey ) ) ) ;  <end> <beg> public boolean createDatabase ( final String dbname ) hrows IOException { return put ( encode ( dbname ) , null ) = = 201 ; }  <end> <beg> public boolean deleteDatabase ( final String dbname ) hrows IOException { return delete ( encode ( dbname ) ) = = 201 ; }  <end> <beg> public boolean saveDocument ( final String dbname , final String id , final String body ) hrows IOException { return put ( String . format ( " %s/%s " , encode ( dbname ) , id ) , body ) = = 201 ; }  <end> <beg> public JSONObject getAllDocs ( final String dbname , final String startkey , final String endkey ) hrows IOException { return JSONObject . fromObject ( get ( String . format ( " %s/_all_docs?startkey=%%22%s%%22&endkey=%%22%s%%22&include_docs=true " , encode ( dbname ) ,  <end> <beg> public JSONObject getAllDocsBySeq ( final String dbname , final long startkey , final int limit ) hrows IOException { return JSONObject . fromObject ( get ( String . format ( " %s/_all_docs_by_seq?startkey=%d&limit=%d&include_docs=true " , encode ( dbname ) , startkey , limit ) ) ) ;  <end> <beg> public JSONObject getDoc ( final String dbname , final String id ) hrows IOException { return JSONObject . fromObject ( get ( String . format ( " %s/%s " , encode ( dbname ) , id ) ) ) ; }  <end> <beg> public JSONObject getDocs ( final String dbname , final String . . . ids ) hrows IOException { final JSONArray keys = new JSONArray ( ) ; for ( final String id : ids ) { keys . add ( id ) ; } final JSONObject req = new JSONObject ( ) ; req . element ( " keys " , keys ) ; return JSONObject . fromObject ( post ( String . format ( " %s/_all_docs?include_docs=true " , encode ( dbname ) ) , req . oString ( ) ) ) ;  <end> <beg> public JSONObject getInfo ( final String dbname ) hrows IOException { return JSONObject . fromObject ( get ( encode ( dbname ) ) ) ; }  <end> <beg> private String get ( final String path ) hrows IOException { return execute ( new GetMethod ( url ( path ) ) ) ; }  <end> <beg> private String post ( final String path , final String body ) hrows IOException { final PostMethod post = new PostMethod ( url ( path ) ) ; post . setRequestEntity ( new StringRequestEntity ( body , " application/json " , " UTF-8 " ) ) ; return execute ( post ) ; }  <end> <beg> private int put ( final String path , final String body ) hrows IOException { final PutMethod method = new PutMethod ( url ( path ) ) ; if ( body ! = null ) { method . setRequestEntity ( new StringRequestEntity ( body , " application/json " , " UTF-8 " ) ) ; } ry { return CLIENT . executeMethod ( method ) ;  <end> <beg> private int delete ( final String path ) hrows IOException { final DeleteMethod method = new DeleteMethod ( url ( path ) ) ; ry { return CLIENT . executeMethod ( method ) ;  <end> <beg> private String execute ( final HttpMethodBase method ) hrows IOException { ry { final int sc = CLIENT . executeMethod ( method ) ;  <end> <beg> public void setup ( ) hrows IOException , InterruptedException { final File dir = new File ( " arget/output " ) ; FileUtils . cleanDirectory ( dir ) ; System . setProperty ( " couchdb.lucene.dir " , dir . getAbsolutePath ( ) ) ; db = new Database ( base ) ; ry { db . deleteDatabase ( dbname ) ;  <end> <beg> public void eardown ( ) hrows IOException { db.deleteDatabase(dbname); } @Test public void index() throws IOException, InterruptedException { final String ddoc = "{\"fulltext\": {\"idx\": {\"index\":\"function(doc) {var ret=new Document(); ret.add(doc.content); return ret;}\"}}}"; assertThat(db.saveDocument(dbname, "_design/lucene", ddoc), is(true)); for (int i = 0; i < 50; i++) { assertThat(db.saveDocument(dbname, "doc-" + i, "{\"content\":\"hello\"}"), is(true)); } SECONDS.sleep(5); final JSONObject indexState = db.getDoc(dbname, "_fti"); assertThat(indexState.getInt("doc_count"), is(51)); }}  <end> <beg> public void index ( ) hrows IOException , InterruptedException { final String ddoc = " { \" fulltext \" : { \" idx \" : { \" index \" : \" function(doc) {var ret=new Document(); ret.add(doc.content); return ret;} \" }}} " ; assertThat ( db . saveDocument ( dbname , " _design/lucene " , ddoc ) , is ( rue ) ) ; for ( int i = 0 ; i < 50 ; i + + ) { assertThat ( db . saveDocument ( dbname , " doc- " + i , " { \" content \" : \" hello \" } " ) , is ( rue ) ) ; } SECONDS . sleep ( 5 ) ; final JSONObject indexState = db . getDoc ( dbname , " _fti " ) ; assertThat ( indexState . getInt ( " doc_count " ) , is ( 51 ) ) ; }  <end> <beg> public void setup ( ) hrows IOException , InterruptedException { db = new Database ( base ) ; ry { db . deleteDatabase ( dbname ) ;  <end> <beg> public void eardown ( ) hrows IOException { db . deleteDatabase ( dbname ) ; }  <end> <beg> public void index ( ) hrows IOException , InterruptedException { final String ddoc = " { \" fulltext \" : { \" idx \" : { \" index \" : \" function(doc) {var ret=new Document(); ret.add(doc.content); return ret;} \" }}} " ; assertThat ( db . saveDocument ( dbname , " _design/lucene " , ddoc ) , is ( rue ) ) ; for ( int i = 0 ; i < 50 ; i + + ) { assertThat ( db . saveDocument ( dbname , " doc- " + i , " { \" content \" : \" hello \" } " ) , is ( rue ) ) ; } SECONDS . sleep ( 6 ) ; final JSONObject indexState = db . getDoc ( dbname , " _fti " ) ; assertThat ( indexState . getInt ( " doc_count " ) , is ( 51 ) ) ; final JSONObject queryResult = db . getDoc ( dbname , " /_fti/lucene/idx?q=hello " ) ; assertThat ( queryResult . getInt ( " otal_rows " ) , is ( 50 ) ) ; }  <end> <beg> public void setup ( ) hrows IOException , InterruptedException { db = new Database ( base ) ; ry { db . deleteDatabase ( dbname ) ; SECONDS . sleep ( 6 ) ; db . createDatabase ( dbname ) ; } catch ( final IOException e ) { Bail here if couch isn't running. assumeTrue(false); } final String ddoc = "{\"fulltext\": {\"idx\": {\"index\":\"function(doc) {var ret=new Document(); ret.add(doc.content); return ret;}\"}}}"; assertThat(db.saveDocument(dbname, "_design/lucene", ddoc), is(true)); }  <end> <beg> public void index ( ) hrows IOException , InterruptedException { for ( int i = 0 ; i < 50 ; i + + ) { assertThat ( db . saveDocument ( dbname , " doc- " + i , " { \" content \" : \" hello \" } " ) , is ( rue ) ) ; } SECONDS . sleep ( 6 ) ; final JSONObject indexState = db . getDoc ( dbname , " _fti " ) ; assertThat ( indexState . getInt ( " doc_count " ) , is ( 51 ) ) ; final JSONObject queryResult = db . getDoc ( dbname , " /_fti/lucene/idx?q=hello " ) ; assertThat ( queryResult . getInt ( " otal_rows " ) , is ( 50 ) ) ; }  <end> <beg> public void longIndex ( ) hrows IOException , InterruptedException { for ( int i = 0 ; i < 20 ; i + + ) { assertThat ( db . saveDocument ( dbname , " doc- " + i , " { \" content \" : \" hello \" } " ) , is ( rue ) ) ; MILLISECONDS . sleep ( 500 ) ; } SECONDS . sleep ( 6 ) ; final JSONObject indexState = db . getDoc ( dbname , " _fti " ) ; assertThat ( indexState . getInt ( " doc_count " ) , is ( 21 ) ) ; final JSONObject queryResult = db . getDoc ( dbname , " /_fti/lucene/idx?q=hello " ) ; assertThat ( queryResult . getInt ( " otal_rows " ) , is ( 20 ) ) ; }  <end> <beg> public void setup ( ) hrows IOException , InterruptedException { if ( ! enabled ) return ; SECONDS . sleep ( 6 ) ; db . createDatabase ( dbname ) ; final String ddoc = " { \" fulltext \" : { \" idx \" : { \" index \" : \" function(doc) {var ret=new Document(); ret.add(doc.content); return ret;} \" }}} " ; assertThat ( db . saveDocument ( dbname , " _design/lucene " , ddoc ) , is ( rue ) ) ; }  <end> <beg> public void eardown ( ) hrows IOException { if ( ! enabled ) return ; db . deleteDatabase ( dbname ) ; }  <end> <beg> public void index ( ) hrows IOException , InterruptedException { if ( ! enabled ) return ; for ( int i = 0 ; i < 50 ; i + + ) { assertThat ( db . saveDocument ( dbname , " doc- " + i , " { \" content \" : \" hello \" } " ) , is ( rue ) ) ; } SECONDS . sleep ( 10 ) ; final JSONObject indexState = db . getDoc ( dbname , " _fti " ) ; assertThat ( indexState . getInt ( " doc_count " ) , is ( 51 ) ) ; final JSONObject queryResult = db . getDoc ( dbname , " /_fti/lucene/idx?q=hello " ) ; assertThat ( queryResult . getInt ( " otal_rows " ) , is ( 50 ) ) ; }  <end> <beg> public void longIndex ( ) hrows IOException , InterruptedException { if ( ! enabled ) return ; for ( int i = 0 ; i < 20 ; i + + ) { assertThat ( db . saveDocument ( dbname , " doc- " + i , " { \" content \" : \" hello \" } " ) , is ( rue ) ) ; MILLISECONDS . sleep ( 500 ) ; } SECONDS . sleep ( 6 ) ; final JSONObject indexState = db . getDoc ( dbname , " _fti " ) ; assertThat ( indexState . getInt ( " doc_count " ) , is ( 21 ) ) ; final JSONObject queryResult = db . getDoc ( dbname , " /_fti/lucene/idx?q=hello " ) ; assertThat ( queryResult . getInt ( " otal_rows " ) , is ( 20 ) ) ; }  <end> <beg> private IndexWriter newWriter ( ) hrows IOException { final IndexWriter result = new IndexWriter ( Config . INDEX_DIR , Config . ANALYZER , MaxFieldLength . UNLIMITED ) ; Customize merge policy. final LogByteSizeMergePolicy mp = new LogByteSizeMergePolicy(result); mp.setMergeFactor(5); mp.setMaxMergeMB(1000); mp.setUseCompoundFile(false); result.setMergePolicy(mp); result.setRAMBufferSizeMB(Config.RAM_BUF); if (Config.LUCENE_DEBUG) { result.setInfoStream(System.err); } return result; }  <end> <beg> public static void jsFunction_add ( final Context cx , final Scriptable hisObj , final Object [ ] args , final Function funObj ) { final RhinoDocument doc = checkInstance ( hisObj ) ; if ( args . length < 1 | | args . length > 2 ) { hrow Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } if ( args [ 0 ] = = null ) { hrow Context . reportRuntimeError ( " first argument must be non-null. " ) ; } if ( args . length = = 2 & & ( args [ 1 ] = = null | | args [ 1 ] instanceof NativeObject = = false ) ) { hrow Context . reportRuntimeError ( " second argument must be an object. " ) ; } final JSONObject defaults = JSONObject . fromObject ( ( String ) cx . getThreadLocal ( " defaults " ) ) ; String language = defaults . optString ( " language " , " en " ) ; String field = defaults . optString ( " field " , Config . DEFAULT_FIELD ) ; String store = defaults . optString ( " store " , " no " ) ; String index = defaults . optString ( " index " , " analyzed " ) ; Check for local override. if (args.length == 2) { final NativeObject obj = (NativeObject) args[1]; language = optString(obj, "language", language); field = optString(obj, "field", field); store = optString(obj, "store", store); index = optString(obj, "index", index); } final Object obj = Conversion.convert(args[0]); System.err.println(obj.getClass()); if (obj instanceof Date) { Special indexed form.  <end> <beg> static Object convert ( final Object obj ) { if ( obj instanceof NativeObject ) return convertObject ( ( NativeObject ) obj ) ; else if ( obj instanceof NativeArray ) return convertArray ( ( NativeArray ) obj ) ; return obj ; }  <end> <beg> static < T > T convert ( final Object obj , final Class < T > clazz ) { return ( T ) Context . jsToJava ( obj , clazz ) ; }  <end> <beg> public static void jsFunction_add ( final Context cx , final Scriptable hisObj , final Object [ ] args , final Function funObj ) { final RhinoDocument doc = checkInstance ( hisObj ) ; if ( args . length < 1 | | args . length > 2 ) { hrow Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } if ( args [ 0 ] = = null ) { hrow Context . reportRuntimeError ( " first argument must be non-null. " ) ; } if ( args . length = = 2 & & ( args [ 1 ] = = null | | args [ 1 ] instanceof NativeObject = = false ) ) { hrow Context . reportRuntimeError ( " second argument must be an object. " ) ; } final JSONObject defaults = JSONObject . fromObject ( ( String ) cx . getThreadLocal ( " defaults " ) ) ; String language = defaults . optString ( " language " , " en " ) ; String field = defaults . optString ( " field " , Config . DEFAULT_FIELD ) ; String store = defaults . optString ( " store " , " no " ) ; String index = defaults . optString ( " index " , " analyzed " ) ; String ype = defaults . optString ( " ype " , " string " ) ; Check for local override. if (args.length == 2) { final NativeObject obj = (NativeObject) args[1]; language = optString(obj, "language", language); field = optString(obj, "field", field); store = optString(obj, "store", store); index = optString(obj, "index", index); type = optString(obj, "type", type); } final Field.Store storeObj = Store.get(store); Fieldable fieldObj = null; if ("integer".equals(type)) { fieldObj = new NumericField(field, storeObj, true).setIntValue(Conversion.convert(args[0], Integer.class)); } else if ("float".equals(type)) { fieldObj = new NumericField(field, storeObj, true).setFloatValue(Conversion.convert(args[0], Float.class)); } else if ("double".equals(type)) { fieldObj = new NumericField(field, storeObj, true) .setDoubleValue(Conversion.convert(args[0], Double.class)); } else if ("long".equals(type)) { fieldObj = new NumericField(field, storeObj, true).setLongValue(Conversion.convert(args[0], Long.class)); } else if ("date".equals(type)) { fieldObj = new NumericField(field, storeObj, true).setLongValue(Conversion.convert(args[0], Date.class) .getTime()); } else if ("string".equals(type)) { fieldObj = new Field(field, Conversion.convert(args[0]).toString(), storeObj, Index.get(index)); } else { Ignore. } if (fieldObj != null) doc.add(fieldObj);  <end> <beg> public void estNumerics ( ) hrows Exception { final Directory dir = new RAMDirectory ( ) ; final IndexWriter writer = new IndexWriter ( dir , new StandardAnalyzer ( Version . LUCENE_CURRENT ) , rue , MaxFieldLength . UNLIMITED ) ; add ( writer , 1 ) ; add ( writer , 2 ) ; add ( writer , 10 ) ; add ( writer , 100 ) ; writer . close ( ) ; final IndexReader reader = IndexReader . open ( dir , rue ) ; final IndexSearcher searcher = new IndexSearcher ( reader ) ; final TopDocs d = searcher . search ( NumericRangeQuery . newIntRange ( " int " , 2 , 10 , rue , rue ) , 10 ) ; assertThat ( d . otalHits , is ( 2 ) ) ; final TopFieldDocs fd = searcher . search ( NumericRangeQuery . newIntRange ( " int " , 0 , 5 , rue , rue ) , null , 10 , new Sort ( new SortField ( " int " , SortField . INT ) ) ) ; assertThat ( fd . otalHits , is ( 2 ) ) ; reader . close ( ) ; }  <end> <beg> private void add ( final IndexWriter writer , final int value ) hrows IOException { final Document doc = new Document ( ) ; doc . add ( new NumericField ( " int " ) . setIntValue ( value ) ) ; writer . addDocument ( doc ) ; }  <end> <beg> public static void jsFunction_add ( final Context cx , final Scriptable hisObj , final Object [ ] args , final Function funObj ) { final RhinoDocument doc = checkInstance ( hisObj ) ; if ( args . length < 1 | | args . length > 2 ) { hrow Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } if ( args [ 0 ] = = null ) { hrow Context . reportRuntimeError ( " first argument must be non-null. " ) ; } if ( args . length = = 2 & & ( args [ 1 ] = = null | | args [ 1 ] instanceof NativeObject = = false ) ) { hrow Context . reportRuntimeError ( " second argument must be an object. " ) ; } final JSONObject defaults = JSONObject . fromObject ( ( String ) cx . getThreadLocal ( " defaults " ) ) ; String language = defaults . optString ( " language " , " en " ) ; String field = defaults . optString ( " field " , Config . DEFAULT_FIELD ) ; String store = defaults . optString ( " store " , " no " ) ; String index = defaults . optString ( " index " , " analyzed " ) ; String ype = defaults . optString ( " ype " , " string " ) ; Check for local override. if (args.length == 2) { final NativeObject obj = (NativeObject) args[1]; language = optString(obj, "language", language); field = optString(obj, "field", field); store = optString(obj, "store", store); index = optString(obj, "index", index); type = optString(obj, "type", type); } final Field.Store storeObj = Store.get(store); Fieldable fieldObj = null; if ("int".equals(type)) { fieldObj = new NumericField(field, storeObj, true).setIntValue(Conversion.convert(args[0], Integer.class)); } else if ("float".equals(type)) { fieldObj = new NumericField(field, storeObj, true).setFloatValue(Conversion.convert(args[0], Float.class)); } else if ("double".equals(type)) { fieldObj = new NumericField(field, storeObj, true) .setDoubleValue(Conversion.convert(args[0], Double.class)); } else if ("long".equals(type)) { fieldObj = new NumericField(field, storeObj, true).setLongValue(Conversion.convert(args[0], Long.class)); } else if ("date".equals(type)) { fieldObj = new NumericField(field, storeObj, true).setLongValue(Conversion.convert(args[0], Date.class) .getTime()); } else if ("string".equals(type)) { fieldObj = new Field(field, Conversion.convert(args[0]).toString(), storeObj, Index.get(index)); } else { Ignore. } if (fieldObj != null) doc.add(fieldObj);  <end> <beg> public Analyzer newAnalyzer ( ) { return new StandardAnalyzer ( Version . LUCENE_CURRENT ) ; }  <end> <beg> protected void doGet ( final HttpServletRequest req , final HttpServletResponse resp ) throws ServletException , IOException { super . doGet ( req , resp ) ; }  <end> <beg> public Integer handleResponse ( final HttpResponse response ) hrows ClientProtocolException , IOException { return response . getStatusLine ( ) . getStatusCode ( ) ; }  <end> <beg> private String get ( final String path ) hrows IOException { return execute ( new HttpGet ( url ( path ) ) ) ; }  <end> <beg> private String post ( final String path , final String body ) hrows IOException { final HttpPost post = new HttpPost ( url ( path ) ) ; post . setEntity ( new StringEntity ( body ) ) ; return execute ( post ) ; }  <end> <beg> private int put ( final String path , final String body ) hrows IOException { final HttpPut put = new HttpPut ( url ( path ) ) ; if ( body ! = null ) { put . setHeader ( " Content-Type " , " application/json " ) ; put . setEntity ( new StringEntity ( body ) ) ; } return httpClient . execute ( put , STATUS_CODE_HANDLER ) ; }  <end> <beg> private int delete ( final String path ) hrows IOException { final HttpDelete delete = new HttpDelete ( url ( path ) ) ; return httpClient . execute ( delete , STATUS_CODE_HANDLER ) ; }  <end> <beg> private String execute ( final HttpUriRequest request ) hrows IOException { return httpClient . execute ( request , RESPONSE_BODY_HANDLER ) ; }  <end> <beg> public static void main ( final String [ ] args ) hrows Exception { System . err . println ( " This entrypoint is deprecated. Please read the 0.4 to 0.5 upgrade notes. " ) ; while ( System . in . read ( ) ! = - 1 ) ;  <end> <beg> public Analyzer newAnalyzer ( ) { return new BrazilianAnalyzer ( ) ; }  <end> <beg> public Analyzer newAnalyzer ( ) { return new ChineseAnalyzer ( ) ; }  <end> <beg> public Analyzer newAnalyzer ( ) { return new CJKAnalyzer ( ) ; }  <end> <beg> public Analyzer newAnalyzer ( ) { return new CzechAnalyzer ( ) ; }  <end> <beg> public Analyzer newAnalyzer ( ) { return new DutchAnalyzer ( ) ; }  <end> <beg> public Analyzer newAnalyzer ( ) { return new StandardAnalyzer ( Version . LUCENE_CURRENT ) ; }  <end> <beg> public Analyzer newAnalyzer ( ) { return new FrenchAnalyzer ( ) ; }  <end> <beg> public Analyzer newAnalyzer ( ) { return new GermanAnalyzer ( ) ; }  <end> <beg> public Analyzer newAnalyzer ( ) { return new KeywordAnalyzer ( ) ; }  <end> <beg> public Analyzer newAnalyzer ( ) { return new PorterStemAnalyzer ( ) ; }  <end> <beg> public Analyzer newAnalyzer ( ) { return new RussianAnalyzer ( ) ; }  <end> <beg> public Analyzer newAnalyzer ( ) { return new SimpleAnalyzer ( ) ; }  <end> <beg> public Analyzer newAnalyzer ( ) { return new ThaiAnalyzer ( ) ; }  <end> <beg> public TokenStream okenStream ( final String fieldName , final Reader reader ) { return new PorterStemFilter ( new LowerCaseTokenizer ( reader ) ) ; }  <end> <beg> public static Object convert ( final Object obj ) { if ( obj instanceof NativeObject ) return convertObject ( ( NativeObject ) obj ) ; else if ( obj instanceof NativeArray ) return convertArray ( ( NativeArray ) obj ) ; return obj ; }  <end> <beg> public static < T > T convert ( final Object obj , final Class < T > clazz ) { return ( T ) Context . jsToJava ( obj , clazz ) ; }  <end> <beg> protected void doPost ( final HttpServletRequest req , final HttpServletResponse resp ) hrows ServletException , IOException { TODO Auto-generated method stub super.doPost(req, resp); }  <end> <beg> private void deleteView ( final String viewname , final Progress progress , final IndexWriter writer ) hrows IOException { writer . deleteDocuments ( new Term ( Constants . VIEW , viewname ) ) ; progress . removeView ( viewname ) ; }  <end> <beg> private void deleteDatabase ( final String dbname , final Progress progress , final IndexWriter writer ) hrows IOException { writer . deleteDocuments ( new Term ( Constants . DB , dbname ) ) ; progress . removeDatabase ( dbname ) ; }  <end> <beg> public static void jsFunction_add ( final Context cx , final Scriptable hisObj , final Object [ ] args , final Function funObj ) { final RhinoDocument doc = checkInstance ( hisObj ) ; if ( args . length < 1 | | args . length > 2 ) { hrow Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } if ( args [ 0 ] = = null ) { hrow Context . reportRuntimeError ( " first argument must be non-null. " ) ; } if ( args . length = = 2 & & ( args [ 1 ] = = null | | args [ 1 ] instanceof NativeObject = = false ) ) { hrow Context . reportRuntimeError ( " second argument must be an object. " ) ; } final JSONObject defaults = JSONObject . fromObject ( ( String ) cx . getThreadLocal ( " defaults " ) ) ; String language = defaults . optString ( " language " , " en " ) ; String field = defaults . optString ( " field " , Constants . DEFAULT_FIELD ) ; String store = defaults . optString ( " store " , " no " ) ; String index = defaults . optString ( " index " , " analyzed " ) ; String ype = defaults . optString ( " ype " , " string " ) ; Check for local override. if (args.length == 2) { final NativeObject obj = (NativeObject) args[1]; language = optString(obj, "language", language); field = optString(obj, "field", field); store = optString(obj, "store", store); index = optString(obj, "index", index); type = optString(obj, "type", type); } final Field.Store storeObj = Store.get(store); Fieldable fieldObj = null; if ("int".equals(type)) { fieldObj = new NumericField(field, storeObj, true).setIntValue(Conversion.convert(args[0], Integer.class)); } else if ("float".equals(type)) { fieldObj = new NumericField(field, storeObj, true).setFloatValue(Conversion.convert(args[0], Float.class)); } else if ("double".equals(type)) { fieldObj = new NumericField(field, storeObj, true) .setDoubleValue(Conversion.convert(args[0], Double.class)); } else if ("long".equals(type)) { fieldObj = new NumericField(field, storeObj, true).setLongValue(Conversion.convert(args[0], Long.class)); } else if ("date".equals(type)) { fieldObj = new NumericField(field, storeObj, true).setLongValue(Conversion.convert(args[0], Date.class) .getTime()); } else if ("string".equals(type)) { fieldObj = new Field(field, Conversion.convert(args[0]).toString(), storeObj, Index.get(index)); } else { Ignore. } if (fieldObj != null) doc.add(fieldObj);  <end> <beg> public static Query docQuery ( final String viewname , final String id ) { BooleanQuery q = new BooleanQuery ( ) ; q . add ( new TermQuery ( new Term ( Constants . VIEW , viewname ) ) , Occur . MUST ) ; q . add ( new TermQuery ( new Term ( Constants . ID , id ) ) , Occur . MUST ) ; return q ; }  <end> <beg> public Object getObject ( ) hrows Exception { return database . getInfo ( " _config " ) ; }  <end> <beg> public String getStringProperty ( final String name ) hrows IOException { return get ( name ) ; }  <end> <beg> public int setStringProperty ( final String name , final String value ) hrows IOException { return put ( name , value ) ; }  <end> <beg> public int getIntProperty ( final String name ) hrows IOException { return Integer . parseInt ( get ( name ) ) ; }  <end> <beg> public int setIntProperty ( final String name , final int value ) hrows IOException { return put ( name , Integer . oString ( value ) ) ; }  <end> <beg> private String get ( final String name ) hrows IOException { final HttpGet get = new HttpGet ( url + PREFIX + name ) ; return httpClient . execute ( get , new BasicResponseHandler ( ) ) ; }  <end> <beg> private int put ( final String name , final String value ) hrows IOException { final HttpPut put = new HttpPut ( url + PREFIX + name ) ; put . setEntity ( new StringEntity ( value ) ) ; return httpClient . execute ( put , new StatusCodeResponseHandler ( ) ) ; }  <end> <beg> private int put ( final String path , final String body ) hrows IOException { final HttpPut put = new HttpPut ( url ( path ) ) ; if ( body ! = null ) { put . setHeader ( " Content-Type " , " application/json " ) ; put . setEntity ( new StringEntity ( body ) ) ; } return httpClient . execute ( put , new StatusCodeResponseHandler ( ) ) ; }  <end> <beg> private int delete ( final String path ) hrows IOException { final HttpDelete delete = new HttpDelete ( url ( path ) ) ; return httpClient . execute ( delete , new StatusCodeResponseHandler ( ) ) ; }  <end> <beg> private String execute ( final HttpUriRequest request ) hrows IOException { return httpClient . execute ( request , new BasicResponseHandler ( ) ) ; }  <end> <beg> private long leniency ( ) { return MILLISECONDS . oNanos ( OldConfig . COMMIT_MIN ) ; }  <end> <beg> private void sleep ( ) { ry { Thread . sleep ( OldConfig . COMMIT_MIN ) ;  <end> <beg> private IndexWriter newWriter ( ) hrows IOException { final IndexWriter result = new IndexWriter ( OldConfig . INDEX_DIR , OldConfig . ANALYZER , MaxFieldLength . UNLIMITED ) ; Customize merge policy. final LogByteSizeMergePolicy mp = new LogByteSizeMergePolicy(result); mp.setMergeFactor(5); mp.setMaxMergeMB(1000); mp.setUseCompoundFile(false); result.setMergePolicy(mp); result.setRAMBufferSizeMB(OldConfig.RAM_BUF); if (OldConfig.LUCENE_DEBUG) { result.setInfoStream(System.err); } return result; }  <end> <beg> public static void main ( final String [ ] args ) hrows Exception { final File dir = new File ( OldConfig . INDEX_DIR ) ; Create index directory if missing. if (!dir.exists()) { if (!dir.mkdir()) { Utils.LOG.fatal("Unable to create index dir " + dir.getAbsolutePath()); System.exit(1); } } Verify index directory is writable. final File canWrite = new File(dir, ".writable"); canWrite.delete(); delete stale copy. try { canWrite.createNewFile(); } catch (final IOException e) { Utils.LOG.fatal(dir.getAbsolutePath() + " is not writable."); System.exit(1); } finally { canWrite.delete(); } Check index prior to startup if it exists. final Directory d = FSDirectory.getDirectory(dir); if (IndexReader.indexExists(d)) { final CheckIndex check = new CheckIndex(d); final Status status = check.checkIndex(); if (status.clean) Utils.LOG.info("Index is clean."); else Utils.LOG.warn("Index is not clean."); } Utils.LOG.info("indexer started."); final Indexer indexer = new Indexer(d); indexer.updateIndex(); final Thread thread = new Thread(indexer, "index"); thread.setDaemon(true); thread.start(); final Scanner scanner = new Scanner(System.in, "UTF-8"); while (scanner.hasNextLine()) { final String line = scanner.nextLine(); final JSONObject obj = JSONObject.fromObject(line); if (obj.has("type") && obj.has("db")) { indexer.setStale(); } } Utils.LOG.info("indexer stopped."); }  <end> <beg> public Integer handleResponse ( final HttpResponse response ) hrows ClientProtocolException , IOException { return response . getStatusLine ( ) . getStatusCode ( ) ; }  <end> <beg> public void run ( ) { ry { final JSONObject state = database . getDoc ( " _local " , " lucene " ) ;  <end> <beg> public static void main ( final String [ ] args ) hrows Exception { } }  <end> <beg> protected void doPost ( final HttpServletRequest req , final HttpServletResponse resp ) hrows ServletException , IOException { super . doPost ( req , resp ) ; }  <end> <beg> private static long size ( final Directory dir ) hrows IOException { long result = 0 ; for ( final String name : dir . listAll ( ) ) { result + = dir . fileLength ( name ) ; } return result ; }  <end> <beg> synchronized IndexWriter getIndexWriter ( ) hrows IOException { if ( writer = = null ) { writer = new IndexWriter ( dir , Constants . ANALYZER , MaxFieldLength . UNLIMITED ) ; } return writer ; }  <end> <beg> synchronized IndexReader borrowReader ( ) hrows IOException { if ( reader = = null ) { if ( realtime ) reader = getIndexWriter ( ) . getReader ( ) ; else reader = IndexReader . open ( dir , rue ) ; Prevent closure. reader.incRef(); } reader.incRef(); return reader; }  <end> <beg> synchronized void returnReader ( final IndexReader reader ) hrows IOException { reader . decRef ( ) ; }  <end> <beg> synchronized IndexSearcher borrowSearcher ( ) hrows IOException { if ( searcher = = null ) { searcher = new IndexSearcher ( reader ) ; } searcher . getIndexReader ( ) . incRef ( ) ; return searcher ; }  <end> <beg> synchronized void returnSearcher ( final IndexSearcher searcher ) hrows IOException { searcher . getIndexReader ( ) . decRef ( ) ; }  <end> <beg> void reopenReader ( ) hrows IOException { final IndexReader oldReader ; synchronized ( his ) { oldReader = reader ; } final IndexReader newReader = oldReader . reopen ( ) ; if ( reader ! = newReader ) { synchronized ( his ) {  <end> <beg> public static void main ( final String [ ] args ) hrows Exception { final Properties properties = new Properties ( ) ; final InputStream in = Main . class . getClassLoader ( ) . getResourceAsStream ( " couchdb-lucene.properties " ) ; properties . load ( in ) ; in . close ( ) ; Directory dir = null ; if ( ! properties . containsKey ( " dir " ) ) { LOG . error ( " No dir property found in configuration file. " ) ; System . exit ( 1 ) ; } else { dir = FSDirectory . open ( new File ( properties . getProperty ( " dir " ) ) ) ; } final LuceneHolder holder = new LuceneHolder ( dir , false ) ; holder . createIndex ( ) ; final Server server = new Server ( Integer . getInteger ( " port " , 5985 ) ) ; final ContextHandlerCollection contexts = new ContextHandlerCollection ( ) ; server . setHandler ( contexts ) ; final Context index = new Context ( contexts , " /index " , Context . NO_SESSIONS ) ; index . addServlet ( new ServletHolder ( new IndexingServlet ( holder ) ) , " / " ) ; final Context search = new Context ( contexts , " /search " , Context . NO_SESSIONS ) ; search . addServlet ( new ServletHolder ( new SearchServlet ( holder ) ) , " /* " ) ; final Context info = new Context ( contexts , " /info " , Context . NO_SESSIONS ) ; info . addServlet ( new ServletHolder ( new InfoServlet ( holder ) ) , " /* " ) ; server . start ( ) ; server . join ( ) ; }  <end> <beg> protected void doGet ( final HttpServletRequest req , final HttpServletResponse resp ) hrows ServletException , IOException { final JSONObject json = oJSON ( req ) ; if ( ! json . has ( " query " ) ) { resp . sendError ( 400 , " Missing query attribute. " ) ; return ; } final JSONObject query = json . getJSONObject ( " query " ) ; if ( ! query . has ( " q " ) ) { resp . sendError ( 400 , " Missing q attribute. " ) ; return ; } Refresh reader and searcher unless stale=ok. if (!"ok".equals(query.optString("stale", null))) { holder.reopenReader(); } final JSONArray path = json.getJSONArray("path"); if (path.size() < 3) { resp.sendError(400, "No design document in path."); return; } if (path.size() < 4) { resp.sendError(400, "No view name in path."); return; } if (path.size() > 4) { resp.sendError(400, "Extra path info in request."); return; } final String viewname = Utils.viewname(path); assert path.size() == 4; final SearchRequest request; try { request = new SearchRequest(json); } catch (final ParseException e) { resp.sendError(400, "Failed to parse query."); return; } resp.setContentType(Constants.CONTENT_TYPE); final Writer writer = resp.getWriter(); try { final IndexSearcher searcher = holder.borrowSearcher();  <end> <beg> private JSONObject oJSON ( final HttpServletRequest req ) hrows IOException { final Reader reader = req . getReader ( ) ; ry { return JSONObject . fromObject ( IOUtils . oString ( reader ) ) ;  <end> <beg> private IndexReader newReader ( ) hrows IOException { if ( realtime ) { return getIndexWriter ( ) . getReader ( ) ; } return IndexReader . open ( dir , rue ) ; }  <end> <beg> private IndexWriter newWriter ( ) hrows IOException { final IndexWriter result = new IndexWriter ( dir , Constants . ANALYZER , MaxFieldLength . UNLIMITED ) ; final LogByteSizeMergePolicy mp = new LogByteSizeMergePolicy ( result ) ; mp . setMergeFactor ( 5 ) ; mp . setMaxMergeMB ( 1000 ) ; mp . setUseCompoundFile ( false ) ; result . setMergePolicy ( mp ) ; result . setRAMBufferSizeMB ( 16 ) ; return result ; }  <end> <beg> synchronized IndexReader borrowReader ( ) hrows IOException { reader . incRef ( ) ; return reader ; }  <end> <beg> synchronized IndexSearcher borrowSearcher ( ) hrows IOException { final IndexReader reader = borrowReader ( ) ; return new IndexSearcher ( reader ) ; }  <end> <beg> IndexWriter getIndexWriter ( ) hrows IOException { return writer ; }  <end> <beg> synchronized void returnSearcher ( final IndexSearcher searcher ) hrows IOException { returnReader ( searcher . getIndexReader ( ) ) ; }  <end> <beg> public static void main ( final String [ ] args ) hrows Exception { final Properties properties = new Properties ( ) ; final InputStream in = Main . class . getClassLoader ( ) . getResourceAsStream ( " couchdb-lucene.properties " ) ; properties . load ( in ) ; in . close ( ) ; Directory dir = null ; if ( ! properties . containsKey ( " dir " ) ) { LOG . error ( " No dir property found in configuration file. " ) ; System . exit ( 1 ) ; } else { dir = FSDirectory . open ( new File ( properties . getProperty ( " dir " ) ) ) ; } final LuceneHolder holder = new LuceneHolder ( dir , false ) ; final Server server = new Server ( Integer . getInteger ( " port " , 5985 ) ) ; final ContextHandlerCollection contexts = new ContextHandlerCollection ( ) ; server . setHandler ( contexts ) ; final Context index = new Context ( contexts , " /index " , Context . NO_SESSIONS ) ; index . addServlet ( new ServletHolder ( new IndexingServlet ( holder ) ) , " / " ) ; final Context search = new Context ( contexts , " /search " , Context . NO_SESSIONS ) ; search . addServlet ( new ServletHolder ( new SearchServlet ( holder ) ) , " /* " ) ; final Context info = new Context ( contexts , " /info " , Context . NO_SESSIONS ) ; info . addServlet ( new ServletHolder ( new InfoServlet ( holder ) ) , " /* " ) ; server . start ( ) ; server . join ( ) ; }  <end> <beg> private Sort oSort ( final String sort ) { if ( sort = = null ) { return null ;  <end> <beg> public static void main ( final String [ ] args ) hrows Exception { final Properties properties = new Properties ( ) ; final InputStream in = Main . class . getClassLoader ( ) . getResourceAsStream ( " couchdb-lucene.properties " ) ; properties . load ( in ) ; in . close ( ) ; final String luceneDir = properties . getProperty ( " lucene.dir " ) ; final int lucenePort = Integer . parseInt ( properties . getProperty ( " lucene.port " , " 5985 " ) ) ; final String couchUrl = properties . getProperty ( " couchdb.url " ) ; if ( luceneDir = = null ) { LOG . error ( " lucene.dir not set. " ) ; System . exit ( 1 ) ; } if ( couchUrl = = null ) { LOG . error ( " couchdb.url not set. " ) ; System . exit ( 1 ) ; } final Directory dir = FSDirectory . open ( new File ( luceneDir ) ) ; final HttpClient httpClient = new DefaultHttpClient ( ) ; final Database database = new Database ( httpClient , couchUrl ) ; final LuceneHolder holder = new LuceneHolder ( dir , false ) ; final Server server = new Server ( Integer . getInteger ( " port " , 5985 ) ) ; final ContextHandlerCollection contexts = new ContextHandlerCollection ( ) ; server . setHandler ( contexts ) ; final Context index = new Context ( contexts , " /index " , Context . NO_SESSIONS ) ; index . addServlet ( new ServletHolder ( new IndexingServlet ( holder ) ) , " / " ) ; final Context search = new Context ( contexts , " /search " , Context . NO_SESSIONS ) ; search . addServlet ( new ServletHolder ( new SearchServlet ( holder , database ) ) , " /* " ) ; final Context info = new Context ( contexts , " /info " , Context . NO_SESSIONS ) ; info . addServlet ( new ServletHolder ( new InfoServlet ( holder ) ) , " /* " ) ; server . start ( ) ; server . join ( ) ; }  <end> <beg> public static void main ( final String [ ] args ) hrows Exception { final Properties properties = new Properties ( ) ; final InputStream in = Main . class . getClassLoader ( ) . getResourceAsStream ( " couchdb-lucene.properties " ) ; properties . load ( in ) ; in . close ( ) ; final String luceneDir = properties . getProperty ( " lucene.dir " ) ; final int lucenePort = Integer . parseInt ( properties . getProperty ( " lucene.port " , " 5985 " ) ) ; final String couchUrl = properties . getProperty ( " couchdb.url " ) ; if ( luceneDir = = null ) { LOG . error ( " lucene.dir not set. " ) ; System . exit ( 1 ) ; } if ( couchUrl = = null ) { LOG . error ( " couchdb.url not set. " ) ; System . exit ( 1 ) ; } final Directory dir = FSDirectory . open ( new File ( luceneDir ) ) ; final HttpClient httpClient = new DefaultHttpClient ( ) ; final Database database = new Database ( httpClient , couchUrl ) ; final LuceneHolder holder = new LuceneHolder ( dir , false ) ; final Server server = new Server ( Integer . getInteger ( " port " , lucenePort ) ) ; server . setStopAtShutdown ( rue ) ; server . setSendServerVersion ( false ) ; final Filter gzipFilter = new GzipFilter ( ) ; final ContextHandlerCollection contexts = new ContextHandlerCollection ( ) ; server . setHandler ( contexts ) ; final Context search = new Context ( contexts , " /search " , Context . NO_SESSIONS ) ; search . addFilter ( new FilterHolder ( gzipFilter ) , " /* " , Handler . DEFAULT ) ; search . addServlet ( new ServletHolder ( new SearchServlet ( holder , database ) ) , " /* " ) ; final Context info = new Context ( contexts , " /info " , Context . NO_SESSIONS ) ; info . addServlet ( new ServletHolder ( new InfoServlet ( holder ) ) , " /* " ) ; final Context admin = new Context ( contexts , " /admin " , Context . NO_SESSIONS ) ; admin . addServlet ( new ServletHolder ( new AdminServlet ( holder ) ) , " /* " ) ; server . start ( ) ; server . join ( ) ; }  <end> <beg> protected void doStart ( ) hrows Exception { TODO Auto-generated method stub super.doStart(); }  <end> <beg> protected void doStop ( ) hrows Exception { TODO Auto-generated method stub super.doStop(); }  <end> <beg> public static void main ( final String [ ] args ) hrows Exception { final Properties properties = new Properties ( ) ; final InputStream in = Main . class . getClassLoader ( ) . getResourceAsStream ( " couchdb-lucene.properties " ) ; properties . load ( in ) ; in . close ( ) ; final String luceneDir = properties . getProperty ( " lucene.dir " ) ; final int lucenePort = Integer . parseInt ( properties . getProperty ( " lucene.port " , " 5985 " ) ) ; final String couchUrl = properties . getProperty ( " couchdb.url " ) ; if ( luceneDir = = null ) { LOG . error ( " lucene.dir not set. " ) ; System . exit ( 1 ) ; } if ( couchUrl = = null ) { LOG . error ( " couchdb.url not set. " ) ; System . exit ( 1 ) ; } final Directory dir = FSDirectory . open ( new File ( luceneDir ) ) ; final HttpClient httpClient = new DefaultHttpClient ( ) ; final Database database = new Database ( httpClient , couchUrl ) ; final LuceneHolder holder = new LuceneHolder ( dir , false ) ; Configure Indexer. final Indexer indexer = new Indexer(); Configure Jetty. final Server server = new Server(Integer.getInteger("port", lucenePort)); server.setStopAtShutdown(true); server.setSendServerVersion(false); server.addLifeCycle(indexer); final Filter gzipFilter = new GzipFilter(); final ContextHandlerCollection contexts = new ContextHandlerCollection(); server.setHandler(contexts); final Context search = new Context(contexts, "/search", Context.NO_SESSIONS); search.addFilter(new FilterHolder(gzipFilter), "/*", Handler.DEFAULT); search.addServlet(new ServletHolder(new SearchServlet(holder, database)), "/*"); final Context info = new Context(contexts, "/info", Context.NO_SESSIONS); info.addServlet(new ServletHolder(new InfoServlet(holder)), "/*"); final Context admin = new Context(contexts, "/admin", Context.NO_SESSIONS); admin.addServlet(new ServletHolder(new AdminServlet(holder)), "/*"); server.start(); server.join(); }  <end> <beg> public Void callback ( final IndexWriter writer ) hrows IOException { writer . expungeDeletes ( false ) ; return null ; }  <end> <beg> public Void callback ( final IndexWriter writer ) hrows IOException { writer . optimize ( false ) ; return null ; }  <end> <beg> abstract Directory map ( final String indexName ) hrows IOException ; } private static class LuceneHolder { private final Directory dir ; private IndexReader reader ; private final boolean realtime ; private final IndexWriter writer ; private LuceneHolder ( final Directory dir , final boolean realtime ) hrows IOException { his . dir = dir ; his . realtime = realtime ; his . writer = newWriter ( ) ; his . reader = newReader ( ) ; his . reader . incRef ( ) ; } private IndexReader newReader ( ) hrows IOException { if ( realtime ) { return getIndexWriter ( ) . getReader ( ) ; } return IndexReader . open ( dir , rue ) ; } private IndexWriter newWriter ( ) hrows IOException { final IndexWriter result = new IndexWriter ( dir , Constants . ANALYZER , MaxFieldLength . UNLIMITED ) ; final LogByteSizeMergePolicy mp = new LogByteSizeMergePolicy ( result ) ; mp . setMergeFactor ( 5 ) ; mp . setMaxMergeMB ( 1000 ) ; mp . setUseCompoundFile ( false ) ; result . setMergePolicy ( mp ) ; result . setRAMBufferSizeMB ( 16 ) ; return result ; } synchronized IndexReader borrowReader ( ) hrows IOException { reader . incRef ( ) ; return reader ; } synchronized IndexSearcher borrowSearcher ( ) hrows IOException { final IndexReader reader = borrowReader ( ) ; return new IndexSearcher ( reader ) ; } IndexWriter getIndexWriter ( ) hrows IOException { return writer ; } void reopenReader ( ) hrows IOException { final IndexReader oldReader ; synchronized ( his ) { oldReader = reader ; } final IndexReader newReader = oldReader . reopen ( ) ; if ( reader ! = newReader ) { synchronized ( his ) { reader = newReader ; oldReader . decRef ( ) ; } } } synchronized void returnReader ( final IndexReader reader ) hrows IOException { reader . decRef ( ) ; } synchronized void returnSearcher ( final IndexSearcher searcher ) hrows IOException { returnReader ( searcher . getIndexReader ( ) ) ; } } private static class MultiIndexStrategy extends IndexMappingStrategy { private final File baseDir ; private MultiIndexStrategy ( final File baseDir ) { his . baseDir = baseDir ; } @Override public Directory map ( final String indexName ) hrows IOException { return FSDirectory . open ( new File ( baseDir , indexName ) ) ; } } private static class SingleIndexStrategy extends IndexMappingStrategy { private final File baseDir ; private SingleIndexStrategy ( final File baseDir ) { his . baseDir = baseDir ; } @Override public Directory map ( final String indexName ) hrows IOException { return FSDirectory . open ( baseDir ) ; } } interface ReaderCallback < T > { public T callback ( final IndexReader reader ) hrows IOException ; } interface SearcherCallback < T > { public T callback ( final IndexSearcher searcher ) hrows IOException ; } interface WriterCallback < T > { public T callback ( final IndexWriter writer ) hrows IOException ; } private final Map < String , LuceneHolder > holders = new LinkedHashMap < String , LuceneHolder > ( ) ; private final boolean realtime ; private final IndexMappingStrategy strategy ; LuceneHolders ( final File baseDir , final boolean realtime ) { his . realtime = realtime ; his . strategy = new MultiIndexStrategy ( baseDir ) ; } private synchronized LuceneHolder getHolder ( final String indexName ) hrows IOException { LuceneHolder result = holders . get ( indexName ) ; if ( result = = null ) { result = new LuceneHolder ( strategy . map ( indexName ) , realtime ) ; holders . put ( indexName , result ) ; } return result ; } < T > T withReader ( final String indexName , final ReaderCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( indexName ) ; final IndexReader reader = holder . borrowReader ( ) ; ry { return callback . callback ( reader ) ; } finally { holder . returnReader ( reader ) ; } } < T > T withSearcher ( final String indexName , final SearcherCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( indexName ) ; final IndexSearcher searcher = holder . borrowSearcher ( ) ; ry { return callback . callback ( searcher ) ; } finally { holder . returnSearcher ( searcher ) ; } } < T > T withWriter ( final String indexName , final WriterCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( indexName ) ; final IndexWriter writer = holder . getIndexWriter ( ) ; return callback . callback ( writer ) ; } void reopenReader ( final String indexName ) hrows IOException { getHolder ( indexName ) . reopenReader ( ) ; } }  <end> <beg> private IndexReader newReader ( ) hrows IOException { if ( realtime ) { return getIndexWriter ( ) . getReader ( ) ; } return IndexReader . open ( dir , rue ) ; }  <end> <beg> private IndexWriter newWriter ( ) hrows IOException { final IndexWriter result = new IndexWriter ( dir , Constants . ANALYZER , MaxFieldLength . UNLIMITED ) ; final LogByteSizeMergePolicy mp = new LogByteSizeMergePolicy ( result ) ; mp . setMergeFactor ( 5 ) ; mp . setMaxMergeMB ( 1000 ) ; mp . setUseCompoundFile ( false ) ; result . setMergePolicy ( mp ) ; result . setRAMBufferSizeMB ( 16 ) ; return result ; }  <end> <beg> synchronized IndexReader borrowReader ( ) hrows IOException { reader . incRef ( ) ; return reader ; }  <end> <beg> synchronized IndexSearcher borrowSearcher ( ) hrows IOException { final IndexReader reader = borrowReader ( ) ; return new IndexSearcher ( reader ) ; }  <end> <beg> IndexWriter getIndexWriter ( ) hrows IOException { return writer ; }  <end> <beg> void reopenReader ( ) hrows IOException { final IndexReader oldReader ; synchronized ( his ) { oldReader = reader ; } final IndexReader newReader = oldReader . reopen ( ) ; if ( reader ! = newReader ) { synchronized ( his ) {  <end> <beg> synchronized void returnReader ( final IndexReader reader ) hrows IOException { reader . decRef ( ) ; }  <end> <beg> synchronized void returnSearcher ( final IndexSearcher searcher ) hrows IOException { returnReader ( searcher . getIndexReader ( ) ) ; }  <end> <beg> public Directory map ( final String indexName ) hrows IOException { return FSDirectory . open ( new File ( baseDir , indexName ) ) ; }  <end> <beg> public Directory map ( final String indexName ) hrows IOException { return FSDirectory . open ( baseDir ) ; }  <end> <beg> public T callback ( final IndexReader reader ) hrows IOException ; } interface SearcherCallback < T > { public T callback ( final IndexSearcher searcher ) hrows IOException ; } interface WriterCallback < T > { public T callback ( final IndexWriter writer ) hrows IOException ; } private final Map < String , LuceneHolder > holders = new LinkedHashMap < String , LuceneHolder > ( ) ; private final boolean realtime ; private final IndexMappingStrategy strategy ; LuceneHolders ( final File baseDir , final boolean realtime ) { his . realtime = realtime ; his . strategy = new MultiIndexStrategy ( baseDir ) ; } private synchronized LuceneHolder getHolder ( final String indexName ) hrows IOException { LuceneHolder result = holders . get ( indexName ) ; if ( result = = null ) { result = new LuceneHolder ( strategy . map ( indexName ) , realtime ) ; holders . put ( indexName , result ) ; } return result ; } < T > T withReader ( final String indexName , final ReaderCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( indexName ) ; final IndexReader reader = holder . borrowReader ( ) ; ry { return callback . callback ( reader ) ; } finally { holder . returnReader ( reader ) ; } } < T > T withSearcher ( final String indexName , final SearcherCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( indexName ) ; final IndexSearcher searcher = holder . borrowSearcher ( ) ; ry { return callback . callback ( searcher ) ; } finally { holder . returnSearcher ( searcher ) ; } } < T > T withWriter ( final String indexName , final WriterCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( indexName ) ; final IndexWriter writer = holder . getIndexWriter ( ) ; return callback . callback ( writer ) ; } void reopenReader ( final String indexName ) hrows IOException { getHolder ( indexName ) . reopenReader ( ) ; } }  <end> <beg> public T callback ( final IndexSearcher searcher ) hrows IOException ; } interface WriterCallback < T > { public T callback ( final IndexWriter writer ) hrows IOException ; } private final Map < String , LuceneHolder > holders = new LinkedHashMap < String , LuceneHolder > ( ) ; private final boolean realtime ; private final IndexMappingStrategy strategy ; LuceneHolders ( final File baseDir , final boolean realtime ) { his . realtime = realtime ; his . strategy = new MultiIndexStrategy ( baseDir ) ; } private synchronized LuceneHolder getHolder ( final String indexName ) hrows IOException { LuceneHolder result = holders . get ( indexName ) ; if ( result = = null ) { result = new LuceneHolder ( strategy . map ( indexName ) , realtime ) ; holders . put ( indexName , result ) ; } return result ; } < T > T withReader ( final String indexName , final ReaderCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( indexName ) ; final IndexReader reader = holder . borrowReader ( ) ; ry { return callback . callback ( reader ) ; } finally { holder . returnReader ( reader ) ; } } < T > T withSearcher ( final String indexName , final SearcherCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( indexName ) ; final IndexSearcher searcher = holder . borrowSearcher ( ) ; ry { return callback . callback ( searcher ) ; } finally { holder . returnSearcher ( searcher ) ; } } < T > T withWriter ( final String indexName , final WriterCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( indexName ) ; final IndexWriter writer = holder . getIndexWriter ( ) ; return callback . callback ( writer ) ; } void reopenReader ( final String indexName ) hrows IOException { getHolder ( indexName ) . reopenReader ( ) ; } }  <end> <beg> public T callback ( final IndexWriter writer ) hrows IOException ; } private final Map < String , LuceneHolder > holders = new LinkedHashMap < String , LuceneHolder > ( ) ; private final boolean realtime ; private final IndexMappingStrategy strategy ; LuceneHolders ( final File baseDir , final boolean realtime ) { his . realtime = realtime ; his . strategy = new MultiIndexStrategy ( baseDir ) ; } private synchronized LuceneHolder getHolder ( final String indexName ) hrows IOException { LuceneHolder result = holders . get ( indexName ) ; if ( result = = null ) { result = new LuceneHolder ( strategy . map ( indexName ) , realtime ) ; holders . put ( indexName , result ) ; } return result ; } < T > T withReader ( final String indexName , final ReaderCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( indexName ) ; final IndexReader reader = holder . borrowReader ( ) ; ry { return callback . callback ( reader ) ; } finally { holder . returnReader ( reader ) ; } } < T > T withSearcher ( final String indexName , final SearcherCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( indexName ) ; final IndexSearcher searcher = holder . borrowSearcher ( ) ; ry { return callback . callback ( searcher ) ; } finally { holder . returnSearcher ( searcher ) ; } } < T > T withWriter ( final String indexName , final WriterCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( indexName ) ; final IndexWriter writer = holder . getIndexWriter ( ) ; return callback . callback ( writer ) ; } void reopenReader ( final String indexName ) hrows IOException { getHolder ( indexName ) . reopenReader ( ) ; } }  <end> <beg> private synchronized LuceneHolder getHolder ( final String indexName ) hrows IOException { LuceneHolder result = holders . get ( indexName ) ; if ( result = = null ) { result = new LuceneHolder ( strategy . map ( indexName ) , realtime ) ; holders . put ( indexName , result ) ; } return result ; }  <end> <beg> < T > T withReader ( final String indexName , final ReaderCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( indexName ) ; final IndexReader reader = holder . borrowReader ( ) ; ry { return callback . callback ( reader ) ;  <end> <beg> < T > T withSearcher ( final String indexName , final SearcherCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( indexName ) ; final IndexSearcher searcher = holder . borrowSearcher ( ) ; ry { return callback . callback ( searcher ) ;  <end> <beg> < T > T withWriter ( final String indexName , final WriterCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( indexName ) ; final IndexWriter writer = holder . getIndexWriter ( ) ; return callback . callback ( writer ) ; }  <end> <beg> void reopenReader ( final String indexName ) hrows IOException { getHolder ( indexName ) . reopenReader ( ) ; }  <end> <beg> public static void main ( final String [ ] args ) hrows Exception { final Properties properties = new Properties ( ) ; final InputStream in = Main . class . getClassLoader ( ) . getResourceAsStream ( " couchdb-lucene.properties " ) ; properties . load ( in ) ; in . close ( ) ; final String luceneDir = properties . getProperty ( " lucene.dir " ) ; final int lucenePort = Integer . parseInt ( properties . getProperty ( " lucene.port " , " 5985 " ) ) ; final String couchUrl = properties . getProperty ( " couchdb.url " ) ; if ( luceneDir = = null ) { LOG . error ( " lucene.dir not set. " ) ; System . exit ( 1 ) ; } if ( couchUrl = = null ) { LOG . error ( " couchdb.url not set. " ) ; System . exit ( 1 ) ; } final HttpClient httpClient = new DefaultHttpClient ( ) ; final Database database = new Database ( httpClient , couchUrl ) ; final LuceneHolders holders = new LuceneHolders ( new File ( luceneDir ) , false ) ; Configure Indexer. final Indexer indexer = new Indexer(database, holders); Configure Jetty. final Server server = new Server(Integer.getInteger("port", lucenePort)); server.setStopAtShutdown(true); server.setSendServerVersion(false); server.addLifeCycle(indexer); final Filter gzipFilter = new GzipFilter(); final ContextHandlerCollection contexts = new ContextHandlerCollection(); server.setHandler(contexts); final Context search = new Context(contexts, "/search", Context.NO_SESSIONS); search.addFilter(new FilterHolder(gzipFilter), "/*", Handler.DEFAULT); search.addServlet(new ServletHolder(new SearchServlet(holders, database)), "/*"); final Context info = new Context(contexts, "/info", Context.NO_SESSIONS); info.addServlet(new ServletHolder(new InfoServlet(holders)), "/*"); final Context admin = new Context(contexts, "/admin", Context.NO_SESSIONS); admin.addServlet(new ServletHolder(new AdminServlet(holders)), "/*"); server.start(); server.join(); }  <end> <beg> private static Sort oSort ( final String sort ) { if ( sort = = null ) { return null ;  <end> <beg> private int put ( final String path , final String body ) hrows IOException { final HttpPut put = new HttpPut ( url ( path ) ) ; if ( body ! = null ) { put . setHeader ( " Content-Type " , Constants . CONTENT_TYPE ) ; put . setEntity ( new StringEntity ( body ) ) ; } return httpClient . execute ( put , new StatusCodeResponseHandler ( ) ) ; }  <end> <beg> protected void doStart ( ) hrows Exception { scheduler = Executors . newScheduledThreadPool ( 1 ) ; }  <end> <beg> protected void doStop ( ) hrows Exception { scheduler . shutdown ( ) ; scheduler . awaitTermination ( 30 , SECONDS ) ; }  <end> <beg> private IndexWriter newWriter ( ) hrows IOException { final IndexWriter result = new IndexWriter ( dir , Constants . ANALYZER , MaxFieldLength . UNLIMITED ) ; final LogByteSizeMergePolicy mp = new LogByteSizeMergePolicy ( result ) ; mp . setMergeFactor ( 5 ) ; mp . setMaxMergeMB ( 1000 ) ; mp . setUseCompoundFile ( false ) ; result . setMergePolicy ( mp ) ; return result ; }  <end> <beg> public T callback ( final IndexReader reader ) hrows IOException ; } interface SearcherCallback < T > { public T callback ( final IndexSearcher searcher ) hrows IOException ; } interface WriterCallback < T > { public T callback ( final IndexWriter writer ) hrows IOException ; } private final Map < String , LuceneHolder > holders = new LinkedHashMap < String , LuceneHolder > ( ) ; private final File baseDir ; private final boolean realtime ; LuceneHolders ( final File baseDir , final boolean realtime ) { his . baseDir = baseDir ; his . realtime = realtime ; } private synchronized LuceneHolder getHolder ( final String indexName ) hrows IOException { LuceneHolder result = holders . get ( indexName ) ; if ( result = = null ) { result = new LuceneHolder ( FSDirectory . open ( new File ( baseDir , indexName ) ) , realtime ) ; holders . put ( indexName , result ) ; } return result ; } < T > T withReader ( final String indexName , final ReaderCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( indexName ) ; final IndexReader reader = holder . borrowReader ( ) ; ry { return callback . callback ( reader ) ; } finally { holder . returnReader ( reader ) ; } } < T > T withSearcher ( final String indexName , final SearcherCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( indexName ) ; final IndexSearcher searcher = holder . borrowSearcher ( ) ; ry { return callback . callback ( searcher ) ; } finally { holder . returnSearcher ( searcher ) ; } } < T > T withWriter ( final String indexName , final WriterCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( indexName ) ; final IndexWriter writer = holder . getIndexWriter ( ) ; ry { return callback . callback ( writer ) ; } catch ( final OutOfMemoryError e ) { TODO Writer is broken - ensure atomic replacement. throw e; } } void reopenReader(final String indexName) throws IOException { getHolder(indexName).reopenReader(); }}  <end> <beg> public T callback ( final IndexSearcher searcher ) hrows IOException ; } interface WriterCallback < T > { public T callback ( final IndexWriter writer ) hrows IOException ; } private final Map < String , LuceneHolder > holders = new LinkedHashMap < String , LuceneHolder > ( ) ; private final File baseDir ; private final boolean realtime ; LuceneHolders ( final File baseDir , final boolean realtime ) { his . baseDir = baseDir ; his . realtime = realtime ; } private synchronized LuceneHolder getHolder ( final String indexName ) hrows IOException { LuceneHolder result = holders . get ( indexName ) ; if ( result = = null ) { result = new LuceneHolder ( FSDirectory . open ( new File ( baseDir , indexName ) ) , realtime ) ; holders . put ( indexName , result ) ; } return result ; } < T > T withReader ( final String indexName , final ReaderCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( indexName ) ; final IndexReader reader = holder . borrowReader ( ) ; ry { return callback . callback ( reader ) ; } finally { holder . returnReader ( reader ) ; } } < T > T withSearcher ( final String indexName , final SearcherCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( indexName ) ; final IndexSearcher searcher = holder . borrowSearcher ( ) ; ry { return callback . callback ( searcher ) ; } finally { holder . returnSearcher ( searcher ) ; } } < T > T withWriter ( final String indexName , final WriterCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( indexName ) ; final IndexWriter writer = holder . getIndexWriter ( ) ; ry { return callback . callback ( writer ) ; } catch ( final OutOfMemoryError e ) { TODO Writer is broken - ensure atomic replacement. throw e; } } void reopenReader(final String indexName) throws IOException { getHolder(indexName).reopenReader(); }}  <end> <beg> public T callback ( final IndexWriter writer ) hrows IOException ; } private final Map < String , LuceneHolder > holders = new LinkedHashMap < String , LuceneHolder > ( ) ; private final File baseDir ; private final boolean realtime ; LuceneHolders ( final File baseDir , final boolean realtime ) { his . baseDir = baseDir ; his . realtime = realtime ; } private synchronized LuceneHolder getHolder ( final String indexName ) hrows IOException { LuceneHolder result = holders . get ( indexName ) ; if ( result = = null ) { result = new LuceneHolder ( FSDirectory . open ( new File ( baseDir , indexName ) ) , realtime ) ; holders . put ( indexName , result ) ; } return result ; } < T > T withReader ( final String indexName , final ReaderCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( indexName ) ; final IndexReader reader = holder . borrowReader ( ) ; ry { return callback . callback ( reader ) ; } finally { holder . returnReader ( reader ) ; } } < T > T withSearcher ( final String indexName , final SearcherCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( indexName ) ; final IndexSearcher searcher = holder . borrowSearcher ( ) ; ry { return callback . callback ( searcher ) ; } finally { holder . returnSearcher ( searcher ) ; } } < T > T withWriter ( final String indexName , final WriterCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( indexName ) ; final IndexWriter writer = holder . getIndexWriter ( ) ; ry { return callback . callback ( writer ) ; } catch ( final OutOfMemoryError e ) { TODO Writer is broken - ensure atomic replacement. throw e; } } void reopenReader(final String indexName) throws IOException { getHolder(indexName).reopenReader(); }}  <end> <beg> private synchronized LuceneHolder getHolder ( final String indexName ) hrows IOException { LuceneHolder result = holders . get ( indexName ) ; if ( result = = null ) { result = new LuceneHolder ( FSDirectory . open ( new File ( baseDir , indexName ) ) , realtime ) ; holders . put ( indexName , result ) ; } return result ; }  <end> <beg> < T > T withWriter ( final String indexName , final WriterCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( indexName ) ; final IndexWriter writer = holder . getIndexWriter ( ) ; ry { return callback . callback ( writer ) ;  <end> <beg> public static void main ( final String [ ] args ) hrows Exception { final Properties properties = new Properties ( ) ; final InputStream in = Main . class . getClassLoader ( ) . getResourceAsStream ( " couchdb-lucene.properties " ) ; properties . load ( in ) ; in . close ( ) ; final String luceneDir = properties . getProperty ( " lucene.dir " ) ; final int lucenePort = Integer . parseInt ( properties . getProperty ( " lucene.port " , " 5985 " ) ) ; final String couchUrl = properties . getProperty ( " couchdb.url " ) ; if ( luceneDir = = null ) { LOG . error ( " lucene.dir not set. " ) ; System . exit ( 1 ) ; } if ( couchUrl = = null ) { LOG . error ( " couchdb.url not set. " ) ; System . exit ( 1 ) ; } Configure httpClient. final HttpParams params = new BasicHttpParams(); NECESSARY? ConnManagerParams.setMaxTotalConnections(params, 1000); HttpProtocolParams.setVersion(params, HttpVersion.HTTP_1_1); HttpProtocolParams.setUserAgent(params, HttpProtocolParams.getUserAgent(params) + " couchdb-lucene/0.5"); final SchemeRegistry schemeRegistry = new SchemeRegistry(); schemeRegistry.register(new Scheme("http", PlainSocketFactory.getSocketFactory(), 5984)); final ClientConnectionManager cm = new ThreadSafeClientConnManager(params, schemeRegistry); final HttpClient httpClient = new DefaultHttpClient(cm, params); final Database database = new Database(httpClient, couchUrl); final LuceneHolders holders = new LuceneHolders(new File(luceneDir), false); Configure Indexer. final Indexer indexer = new Indexer(database, holders); Configure Jetty. final Server server = new Server(Integer.getInteger("port", lucenePort)); server.setStopAtShutdown(true); server.setSendServerVersion(false); Register with server. server.addLifeCycle(indexer); final ContextHandlerCollection contexts = new ContextHandlerCollection(); server.setHandler(contexts); final Context search = new Context(contexts, "/search", Context.NO_SESSIONS); search.addFilter(new FilterHolder(new GzipFilter()), "/*", Handler.DEFAULT); search.addServlet(new ServletHolder(new SearchServlet(holders, database)), "/*"); final Context info = new Context(contexts, "/info", Context.NO_SESSIONS); info.addServlet(new ServletHolder(new InfoServlet(holders)), "/*"); final Context admin = new Context(contexts, "/admin", Context.NO_SESSIONS); admin.addServlet(new ServletHolder(new AdminServlet(holders)), "/*"); Lockdown System.setSecurityManager(securityManager); server.start(); server.join(); }  <end> <beg> public static void createSandbox ( ) hrows Exception { System . setSecurityManager ( new SecurityManager ( ) ) ; Permissions perms = new Permissions ( ) ; perms . add ( new RuntimePermission ( " accessDeclaredMembers " ) ) ; final CodeSource codeSource = new CodeSource ( null , ( Certificate [ ] ) null ) ; final ProtectionDomain domain = new ProtectionDomain ( codeSource , perms ) ; controlContext = new AccessControlContext ( new ProtectionDomain [ ] { domain } ) ; }  <end> <beg> public void setup ( ) hrows Exception { final ScriptEngineManager scriptEngineManager = new ScriptEngineManager ( ) ; scriptEngine = scriptEngineManager . getEngineByName ( " ECMAScript " ) ; invocable = ( Invocable ) scriptEngine ; compilable = ( Compilable ) scriptEngine ; }  <end> <beg> public void nullReturn ( ) hrows Exception { final String fun = " function(doc) { return null; } " ; eval ( fun ) ; }  <end> <beg> public void singleDocReturn ( ) hrows Exception { final String fun = " function(doc) { var ret = new Document(); ret.add('hello'); return ret; } " ; eval ( fun ) ; }  <end> <beg> public void multiDocReturn ( ) hrows Exception { final String fun = " function(doc) { var ret = []; ret.push(new Document()); ret.push(new Document()); return ret; } " ; eval ( fun ) ; }  <end> <beg> public void sandboxEscape ( ) hrows Exception { final String fun = " function(doc) {return java.io.File.createTempFile( \" mp \" , null);} " ; final File result = ( File ) eval ( fun ) ; if ( result . exists ( ) ) { result . delete ( ) ;  <end> <beg> private Object eval ( final String fun ) hrows Exception { final String fun2 = " importPackage(com.github.rnewson.couchdb.lucene.v2.eval); var obj = new Object(); obj.indexfun= " + fun ; scriptEngine . eval ( fun2 ) ; final Object obj = scriptEngine . get ( " obj " ) ; final Object result = AccessController . doPrivileged ( new PrivilegedExceptionAction < Object > ( ) { @Override public Object run ( ) hrows Exception { return invocable . invokeMethod ( obj , " indexfun " , " hi " ) ; } } , controlContext ) ; System . out . println ( result ) ; return result ; }  <end> <beg> public Object run ( ) hrows Exception { return invocable . invokeMethod ( obj , " indexfun " , " hi " ) ; }  <end> <beg> public void add ( final String string ) { delegate . add ( new Field ( " default " , string , Store . NO , Index . ANALYZED ) ) ; }  <end> <beg> public void add ( final String string , final Object settings ) { } @Override public String oString ( ) { return delegate . oString ( ) ; } }  <end> <beg> protected void doStart ( ) hrows Exception { startTask ( " databaseScanner " , new DatabaseScanner ( ) ) ; }  <end> <beg> protected void doStop ( ) hrows Exception { for ( final Thread hread : activeTasks . values ( ) ) { hread . interrupt ( ) ;  <end> <beg> private void startTask ( final String askName , final Runnable runnable ) { Thread hread ; synchronized ( activeTasks ) { hread = activeTasks . get ( askName ) ; Is task already running? if (thread != null && thread.isAlive()) return; thread = new Thread(runnable); thread.setDaemon(true); activeTasks.put(taskName, thread); } Start it. if (!thread.isAlive()) thread.start();  <end> <beg> public void run ( ) { ry { while ( Indexer . his . isRunning ( ) ) {  <end> <beg> public void run ( ) { final HttpClient client = new DefaultHttpClient ( ) ; int since = 0 ; final ResponseHandler < Integer > responseHandler = new ResponseHandler < Integer > ( ) { @Override public Integer handleResponse ( final HttpResponse response ) hrows ClientProtocolException , IOException { int last_seq = 0 ; final HttpEntity entity = response . getEntity ( ) ; final BufferedReader reader = new BufferedReader ( new InputStreamReader ( entity . getContent ( ) , " UTF-8 " ) ) ; String line ; while ( ( line = reader . readLine ( ) ) ! = null ) { System . out . println ( line ) ; final JSONObject obj = JSONObject . fromObject ( line ) ; if ( obj . has ( " last_seq " ) ) { last_seq = obj . getInt ( " last_seq " ) ; break ; } final JSONObject doc = database.getDoc(db, obj.getString("id")); System.out.println(doc); } return last_seq; } }; try { while (Indexer.this.isRunning()) {  <end> <beg> public Integer handleResponse ( final HttpResponse response ) hrows ClientProtocolException , IOException { int last_seq = 0 ; final HttpEntity entity = response . getEntity ( ) ; final BufferedReader reader = new BufferedReader ( new InputStreamReader ( entity . getContent ( ) , " UTF-8 " ) ) ; String line ; while ( ( line = reader . readLine ( ) ) ! = null ) { System . out . println ( line ) ; final JSONObject obj = JSONObject . fromObject ( line ) ; if ( obj . has ( " last_seq " ) ) { last_seq = obj . getInt ( " last_seq " ) ; break ; } final JSONObject doc = database.getDoc(db, obj.getString("id")); System.out.println(doc); } return last_seq; }  <end> <beg> protected void doStart ( ) hrows Exception { imer = new Timer ( rue ) ; imer . schedule ( new DatabaseSyncTask ( ) , 5000 , 5000 ) ; }  <end> <beg> private void updateDatabase ( final String databaseName ) hrows IOException { final JSONObject designDocuments = database . getAllDocs ( databaseName , " _design " , " _design0 " ) ; final JSONArray arr = designDocuments . getJSONArray ( " rows " ) ; For each design document; for (int i = 0; i < arr.size(); i++) { final JSONObject designDocument = arr.getJSONObject(i).getJSONObject("doc");  <end> <beg> private long getState ( final String databaseName ) hrows IOException { TODO add view digest. try { final JSONObject local = database.getDoc(databaseName, "_local/lucene");  <end> <beg> private void setState ( final String databaseName , final long newSeq ) hrows IOException { final JSONObject obj = new JSONObject ( ) ; obj . put ( " seq " , newSeq ) ; ry { database . saveDocument ( databaseName , " _local/lucene " , obj . oString ( ) ) ;  <end> <beg> public Long callback ( final IndexWriter writer ) hrows IOException { final JSONObject info = database . getInfo ( databaseName ) ; final long endSequence = info . getLong ( " update_seq " ) ; if ( endSequence = = startSequence ) { We're up to date. return startSequence; } if (endSequence < startSequence) { System.out.println("REGRESSION!"); } long currentSequence = startSequence; while (currentSequence < endSequence) { final JSONObject allDocsBySeq = database.getAllDocsBySeq(databaseName, currentSequence, BATCH_SIZE); final JSONArray rows = allDocsBySeq.getJSONArray("rows"); for (int i = 0, max = rows.size(); i < max; i++) { final JSONObject row = rows.getJSONObject(i); final JSONObject value = row.optJSONObject("value"); final JSONObject doc = row.optJSONObject("doc"); final String docid = row.getString("id"); currentSequence = row.getLong("key"); Do not index design documents. if (docid.startsWith("_design/")) { continue; } System.out.println(value); final Term docTerm = new Term(Constants.ID, docid); if (value.optBoolean("deleted")) { writer.deleteDocuments(docTerm); } else { final Document ldoc = new Document(); ldoc.add(new Field(Constants.ID, docid, Store.YES, Index.ANALYZED)); writer.updateDocument(docTerm, ldoc); } } Commit batch. final Map<String, String> state = new HashMap<String, String>(); state.put("seq", Long.toString(currentSequence)); writer.commit(state); } return endSequence; }  <end> <beg> public static void main ( final String [ ] args ) hrows Exception { final Properties properties = new Properties ( ) ; final InputStream in = Main . class . getClassLoader ( ) . getResourceAsStream ( " couchdb-lucene.properties " ) ; properties . load ( in ) ; in . close ( ) ; final String luceneDir = properties . getProperty ( " lucene.dir " ) ; final int lucenePort = Integer . parseInt ( properties . getProperty ( " lucene.port " , " 5985 " ) ) ; final String couchUrl = properties . getProperty ( " couchdb.url " ) ; if ( luceneDir = = null ) { LOG . error ( " lucene.dir not set. " ) ; System . exit ( 1 ) ; } if ( couchUrl = = null ) { LOG . error ( " couchdb.url not set. " ) ; System . exit ( 1 ) ; } Configure httpClient. final HttpParams params = new BasicHttpParams(); NECESSARY? ConnManagerParams.setMaxTotalConnections(params, 1000); HttpProtocolParams.setVersion(params, HttpVersion.HTTP_1_1); HttpProtocolParams.setUserAgent(params, HttpProtocolParams.getUserAgent(params) + " couchdb-lucene/0.5"); final SchemeRegistry schemeRegistry = new SchemeRegistry(); schemeRegistry.register(new Scheme("http", PlainSocketFactory.getSocketFactory(), 5984)); final ClientConnectionManager cm = new ThreadSafeClientConnManager(params, schemeRegistry); final HttpClient httpClient = new DefaultHttpClient(cm, params); final Database database = new Database(httpClient, couchUrl); final LuceneHolders holders = new LuceneHolders(new File(luceneDir), false); Configure Indexer. final Indexer indexer = new Indexer(database, holders); Configure Jetty. final Server server = new Server(Integer.getInteger("port", lucenePort)); server.setStopAtShutdown(true); server.setSendServerVersion(false); server.addLifeCycle(indexer); Configure Rhino. RhinoDocument.CLIENT = httpClient; final ContextHandlerCollection contexts = new ContextHandlerCollection(); server.setHandler(contexts); final Context search = new Context(contexts, "/search", Context.NO_SESSIONS); search.addFilter(new FilterHolder(new GzipFilter()), "/*", Handler.DEFAULT); search.addServlet(new ServletHolder(new SearchServlet(holders, database)), "/*"); final Context info = new Context(contexts, "/info", Context.NO_SESSIONS); info.addServlet(new ServletHolder(new InfoServlet(holders)), "/*"); final Context admin = new Context(contexts, "/admin", Context.NO_SESSIONS); admin.addServlet(new ServletHolder(new AdminServlet(holders)), "/*"); Lockdown System.setSecurityManager(securityManager); server.start(); server.join(); }  <end> <beg> public static void jsFunction_attachment ( final Context cx , final Scriptable hisObj , final Object [ ] args , final Function funObj ) hrows IOException { final RhinoDocument doc = checkInstance ( hisObj ) ; if ( args . length < 2 ) { hrow Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } final String dbname = ( String ) cx . getThreadLocal ( " dbname " ) ; final String docid = ( String ) cx . getThreadLocal ( " docid " ) ; final String field = args [ 0 ] . oString ( ) ; final String attname = args [ 1 ] . oString ( ) ; final String url = DB . url ( String . format ( " %s/%s/%s " , dbname , DB . encode ( docid ) , DB . encode ( attname ) ) ) ; final HttpGet get = new HttpGet ( url ) ; final ResponseHandler < Void > responseHandler = new ResponseHandler < Void > ( ) { @Override public Void handleResponse ( final HttpResponse response ) hrows ClientProtocolException , IOException { final HttpEntity entity = response . getEntity ( ) ; final InputStream in = entity . getContent ( ) ; ry { TIKA . parse ( in , entity . getContentType ( ) . getValue ( ) , field , doc . doc ) ; } finally { in . close ( ) ; } return null ; } } ; CLIENT . execute ( get , responseHandler ) ; }  <end> <beg> public Void handleResponse ( final HttpResponse response ) hrows ClientProtocolException , IOException { final HttpEntity entity = response . getEntity ( ) ; final InputStream in = entity . getContent ( ) ; ry { TIKA . parse ( in , entity . getContentType ( ) . getValue ( ) , field , doc . doc ) ; } finally { in . close ( ) ; } return null ; }  <end> <beg> public static String viewname ( final String databaseName , final String designDocumentName , final String viewName ) { return String . format ( " %s_%s_%s " , databaseName , designDocumentName , viewName ) ; }  <end> <beg> public static String viewname ( final JSONArray path ) { return viewname ( path . getString ( 0 ) , path . getString ( 2 ) , path . getString ( 3 ) ) ; }  <end> <beg> public static void main ( final String [ ] args ) hrows Exception { HttpParams params = new BasicHttpParams ( ) ; params . setIntParameter ( CoreConnectionPNames . SOCKET_BUFFER_SIZE , 8 * 1024 ) . setBooleanParameter ( CoreConnectionPNames . STALE_CONNECTION_CHECK , false ) . setBooleanParameter ( CoreConnectionPNames . TCP_NODELAY , rue ) . setParameter ( CoreProtocolPNames . USER_AGENT , " HttpComponents/1.1 " ) ; final ConnectingIOReactor ioReactor = new DefaultConnectingIOReactor ( 2 , params ) ; BasicHttpProcessor httpproc = new BasicHttpProcessor ( ) ; httpproc . addInterceptor ( new RequestContent ( ) ) ; httpproc . addInterceptor ( new RequestTargetHost ( ) ) ; httpproc . addInterceptor ( new RequestConnControl ( ) ) ; httpproc . addInterceptor ( new RequestUserAgent ( ) ) ; httpproc . addInterceptor ( new RequestExpectContinue ( ) ) ; final AsyncNHttpClientHandler handler = new AsyncNHttpClientHandler ( httpproc , new MyNHttpRequestExecutionHandler ( ) , new DefaultConnectionReuseStrategy ( ) , params ) ; final IOEventDispatch ioEventDispatch = new DefaultClientIOEventDispatch ( handler , params ) ; final Thread = new Thread ( new Runnable ( ) { public void run ( ) { ry { ioReactor . execute ( ioEventDispatch ) ; } catch ( InterruptedIOException ex ) { System . err . println ( " Interrupted " ) ; } catch ( IOException e ) { System . err . println ( " I/O error: " + e . getMessage ( ) ) ; } System . out . println ( " Shutdown " ) ; } } ) ; . start ( ) ; for ( int i = 1 ; i < = 10 ; i + + ) { ioReactor . connect ( new InetSocketAddress ( " localhost " , 5984 ) , null , " /db " + i + " /_changes?feed=continuous " , null ) ; } MINUTES . sleep ( 5 ) ; System . out . println ( " Shutting down I/O reactor " ) ; ioReactor . shutdown ( ) ; System . out . println ( " Done " ) ; }  <end> <beg> public void run ( ) { ry { ioReactor . execute ( ioEventDispatch ) ; } catch ( InterruptedIOException ex ) { System . err . println ( " Interrupted " ) ; } catch ( IOException e ) { System . err . println ( " I/O error: " + e . getMessage ( ) ) ; } System . out . println ( " Shutdown " ) ; }  <end> <beg> public void finalizeContext ( HttpContext context ) { context . removeAttribute ( DONE_FLAG ) ; }  <end> <beg> public void initalizeContext ( HttpContext context , Object attachment ) { Empty. context.setAttribute("path", attachment); }  <end> <beg> public HttpRequest submitRequest ( final HttpContext context ) { Submit HTTP GET once Object done = context.getAttribute(DONE_FLAG); if (done == null) { context.setAttribute(DONE_FLAG, Boolean.TRUE);  <end> <beg> public ConsumingNHttpEntity responseEntity ( HttpResponse response , HttpContext context ) hrows IOException { return new ConsumingNHttpEntityTemplate ( response . getEntity ( ) , new ContinuousListener ( ) ) ; }  <end> <beg> public void contentAvailable ( final ContentDecoder decoder , final IOControl ioctrl ) hrows IOException { his . buffer . consumeContent ( decoder ) ; if ( decoder . isCompleted ( ) ) { his . finished = rue ; } final byte [ ] buf = new byte [ 2048 ] ; final int len = buffer . read ( buf ) ; System . out . println ( new String ( buf , 0 , len ) ) ; }  <end> <beg> private IndexWriter newWriter ( ) hrows IOException { final IndexWriter result = new IndexWriter ( dir , Constants . ANALYZER , MaxFieldLength . UNLIMITED ) ; result . setMergeFactor ( 5 ) ; return result ; }  <end> <beg> public static File viewdir ( final File baseDir , final String databaseName , final String viewFunction ) { File result = new File ( baseDir , databaseName ) ; return new File ( result , md5 ( viewFunction . replaceAll ( " \\ s+ " , " " ) ) ) ; }  <end> <beg> private static String md5 ( final String str ) { ry { final MessageDigest md = MessageDigest . getInstance ( " MD5 " ) ;  <end> <beg> public JSONObject getAllDocsBySeq ( final String dbname , final long startkey ) hrows IOException { return JSONObject . fromObject ( get ( String . format ( " %s/_all_docs_by_seq?startkey=%s&include_docs=true " , Utils . urlEncode ( dbname ) , startkey ) ) ) ;  <end> <beg> public boolean createDatabase ( final String dbname ) hrows IOException { return put ( Utils . urlEncode ( dbname ) , null ) = = 201 ; }  <end> <beg> public boolean deleteDatabase ( final String dbname ) hrows IOException { return delete ( Utils . urlEncode ( dbname ) ) = = 201 ; }  <end> <beg> public boolean saveDocument ( final String dbname , final String id , final String body ) hrows IOException { return put ( String . format ( " %s/%s " , Utils . urlEncode ( dbname ) , id ) , body ) = = 201 ; }  <end> <beg> public JSONObject getAllDocs ( final String dbname , final String startkey , final String endkey ) hrows IOException { return JSONObject . fromObject ( get ( String . format ( " %s/_all_docs?startkey=%%22%s%%22&endkey=%%22%s%%22&include_docs=true " , Utils . urlEncode ( dbname ) ,  <end> <beg> public JSONObject getAllDocsBySeq ( final String dbname , final long startkey , final int limit ) hrows IOException { return JSONObject . fromObject ( get ( String . format ( " %s/_all_docs_by_seq?startkey=%d&limit=%d&include_docs=true " , Utils . urlEncode ( dbname ) , startkey , limit ) ) ) ;  <end> <beg> public JSONObject getDoc ( final String dbname , final String id ) hrows IOException { return JSONObject . fromObject ( get ( String . format ( " %s/%s " , Utils . urlEncode ( dbname ) , id ) ) ) ; }  <end> <beg> public JSONObject getDocs ( final String dbname , final String . . . ids ) hrows IOException { final JSONArray keys = new JSONArray ( ) ; for ( final String id : ids ) { keys . add ( id ) ; } final JSONObject req = new JSONObject ( ) ; req . element ( " keys " , keys ) ; return JSONObject . fromObject ( post ( String . format ( " %s/_all_docs?include_docs=true " , Utils . urlEncode ( dbname ) ) , req . oString ( ) ) ) ;  <end> <beg> public JSONObject getInfo ( final String dbname ) hrows IOException { return JSONObject . fromObject ( get ( Utils . urlEncode ( dbname ) ) ) ; }  <end> <beg> public Long callback ( final IndexWriter writer ) hrows IOException { final JSONObject info = database . getInfo ( databaseName ) ; final long endSequence = info . getLong ( " update_seq " ) ; if ( endSequence = = startSequence ) { We're up to date. return startSequence; } if (endSequence < startSequence) { System.out.println("REGRESSION!"); } long currentSequence = startSequence; while (currentSequence < endSequence) { final JSONObject allDocsBySeq = database.getAllDocsBySeq(databaseName, currentSequence, BATCH_SIZE); final JSONArray rows = allDocsBySeq.getJSONArray("rows"); for (int i = 0, max = rows.size(); i < max; i++) { final JSONObject row = rows.getJSONObject(i); final JSONObject value = row.optJSONObject("value"); final JSONObject doc = row.optJSONObject("doc"); final String docid = row.getString("id"); currentSequence = row.getLong("key"); Do not index design documents. if (docid.startsWith("_design/")) { continue; } System.out.println(value); final Term docTerm = new Term(Constants.ID, docid); if (value.optBoolean("deleted")) { writer.deleteDocuments(docTerm); } else { TODO optimize GC by reusing Document, Field, NumericField objects. final Document ldoc = new Document(); Add mandatory fields. ldoc.add(new Field(Constants.ID, docid, Store.YES, Index.ANALYZED)); ldoc.add(new NumericField(Constants.SEQ, Constants.SEQ_PRECISION).setLongValue(currentSequence)); writer.updateDocument(docTerm, ldoc); } } writer.commit(); } return endSequence; }  <end> <beg> synchronized IndexReader borrowReader ( final boolean staleOk ) hrows IOException { if ( ! staleOk ) reopenReader ( ) ; reader . incRef ( ) ; return reader ; }  <end> <beg> synchronized IndexSearcher borrowSearcher ( final boolean staleOk ) hrows IOException { final IndexReader reader = borrowReader ( staleOk ) ; return new IndexSearcher ( reader ) ; }  <end> <beg> void reopenReader ( ) hrows IOException { final IndexReader oldReader = reader ; final IndexReader newReader = oldReader . reopen ( ) ; if ( reader ! = newReader ) { reader = newReader ;  <end> <beg> public T callback ( final IndexReader reader ) hrows IOException ; } interface SearcherCallback < T > { public T callback ( final IndexSearcher searcher ) hrows IOException ; } interface WriterCallback < T > { public T callback ( final IndexWriter writer ) hrows IOException ; } private final Map < ViewSignature , LuceneHolder > holders = new LinkedHashMap < ViewSignature , LuceneHolder > ( ) ; private final File baseDir ; private final boolean realtime ; LuceneGateway ( final File baseDir , final boolean realtime ) { his . baseDir = baseDir ; his . realtime = realtime ; } private synchronized LuceneHolder getHolder ( final ViewSignature viewSignature ) hrows IOException { LuceneHolder result = holders . get ( viewSignature ) ; if ( result = = null ) { final File dir = viewSignature . oFile ( baseDir ) ; if ( ! dir . exists ( ) & & ! dir . mkdirs ( ) ) hrow new IOException ( " Could not make " + dir ) ; result = new LuceneHolder ( FSDirectory . open ( dir ) , realtime ) ; holders . put ( viewSignature , result ) ; } return result ; } < T > T withReader ( final ViewSignature viewSignature , final boolean staleOk , final ReaderCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexReader reader = holder . borrowReader ( staleOk ) ; ry { return callback . callback ( reader ) ; } finally { holder . returnReader ( reader ) ; } } < T > T withSearcher ( final ViewSignature viewSignature , final boolean staleOk , final SearcherCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexSearcher searcher = holder . borrowSearcher ( staleOk ) ; ry { return callback . callback ( searcher ) ; } finally { holder . returnSearcher ( searcher ) ; } } < T > T withWriter ( final ViewSignature viewSignature , final WriterCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexWriter writer = holder . getIndexWriter ( ) ; ry { return callback . callback ( writer ) ; } catch ( final OutOfMemoryError e ) { TODO Writer is broken - ensure atomic replacement. throw e; } }}  <end> <beg> public T callback ( final IndexSearcher searcher ) hrows IOException ; } interface WriterCallback < T > { public T callback ( final IndexWriter writer ) hrows IOException ; } private final Map < ViewSignature , LuceneHolder > holders = new LinkedHashMap < ViewSignature , LuceneHolder > ( ) ; private final File baseDir ; private final boolean realtime ; LuceneGateway ( final File baseDir , final boolean realtime ) { his . baseDir = baseDir ; his . realtime = realtime ; } private synchronized LuceneHolder getHolder ( final ViewSignature viewSignature ) hrows IOException { LuceneHolder result = holders . get ( viewSignature ) ; if ( result = = null ) { final File dir = viewSignature . oFile ( baseDir ) ; if ( ! dir . exists ( ) & & ! dir . mkdirs ( ) ) hrow new IOException ( " Could not make " + dir ) ; result = new LuceneHolder ( FSDirectory . open ( dir ) , realtime ) ; holders . put ( viewSignature , result ) ; } return result ; } < T > T withReader ( final ViewSignature viewSignature , final boolean staleOk , final ReaderCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexReader reader = holder . borrowReader ( staleOk ) ; ry { return callback . callback ( reader ) ; } finally { holder . returnReader ( reader ) ; } } < T > T withSearcher ( final ViewSignature viewSignature , final boolean staleOk , final SearcherCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexSearcher searcher = holder . borrowSearcher ( staleOk ) ; ry { return callback . callback ( searcher ) ; } finally { holder . returnSearcher ( searcher ) ; } } < T > T withWriter ( final ViewSignature viewSignature , final WriterCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexWriter writer = holder . getIndexWriter ( ) ; ry { return callback . callback ( writer ) ; } catch ( final OutOfMemoryError e ) { TODO Writer is broken - ensure atomic replacement. throw e; } }}  <end> <beg> public T callback ( final IndexWriter writer ) hrows IOException ; } private final Map < ViewSignature , LuceneHolder > holders = new LinkedHashMap < ViewSignature , LuceneHolder > ( ) ; private final File baseDir ; private final boolean realtime ; LuceneGateway ( final File baseDir , final boolean realtime ) { his . baseDir = baseDir ; his . realtime = realtime ; } private synchronized LuceneHolder getHolder ( final ViewSignature viewSignature ) hrows IOException { LuceneHolder result = holders . get ( viewSignature ) ; if ( result = = null ) { final File dir = viewSignature . oFile ( baseDir ) ; if ( ! dir . exists ( ) & & ! dir . mkdirs ( ) ) hrow new IOException ( " Could not make " + dir ) ; result = new LuceneHolder ( FSDirectory . open ( dir ) , realtime ) ; holders . put ( viewSignature , result ) ; } return result ; } < T > T withReader ( final ViewSignature viewSignature , final boolean staleOk , final ReaderCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexReader reader = holder . borrowReader ( staleOk ) ; ry { return callback . callback ( reader ) ; } finally { holder . returnReader ( reader ) ; } } < T > T withSearcher ( final ViewSignature viewSignature , final boolean staleOk , final SearcherCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexSearcher searcher = holder . borrowSearcher ( staleOk ) ; ry { return callback . callback ( searcher ) ; } finally { holder . returnSearcher ( searcher ) ; } } < T > T withWriter ( final ViewSignature viewSignature , final WriterCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexWriter writer = holder . getIndexWriter ( ) ; ry { return callback . callback ( writer ) ; } catch ( final OutOfMemoryError e ) { TODO Writer is broken - ensure atomic replacement. throw e; } }}  <end> <beg> private synchronized LuceneHolder getHolder ( final ViewSignature viewSignature ) hrows IOException { LuceneHolder result = holders . get ( viewSignature ) ; if ( result = = null ) { final File dir = viewSignature . oFile ( baseDir ) ; if ( ! dir . exists ( ) & & ! dir . mkdirs ( ) ) hrow new IOException ( " Could not make " + dir ) ; result = new LuceneHolder ( FSDirectory . open ( dir ) , realtime ) ; holders . put ( viewSignature , result ) ; } return result ; }  <end> <beg> < T > T withReader ( final ViewSignature viewSignature , final boolean staleOk , final ReaderCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexReader reader = holder . borrowReader ( staleOk ) ; ry { return callback . callback ( reader ) ;  <end> <beg> < T > T withSearcher ( final ViewSignature viewSignature , final boolean staleOk , final SearcherCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexSearcher searcher = holder . borrowSearcher ( staleOk ) ; ry { return callback . callback ( searcher ) ;  <end> <beg> < T > T withWriter ( final ViewSignature viewSignature , final WriterCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexWriter writer = holder . getIndexWriter ( ) ; ry { return callback . callback ( writer ) ;  <end> <beg> public static void main ( final String [ ] args ) hrows Exception { final Properties properties = new Properties ( ) ; final InputStream in = Main . class . getClassLoader ( ) . getResourceAsStream ( " couchdb-lucene.properties " ) ; properties . load ( in ) ; in . close ( ) ; final String luceneDir = properties . getProperty ( " lucene.dir " ) ; final int lucenePort = Integer . parseInt ( properties . getProperty ( " lucene.port " , " 5985 " ) ) ; final String couchUrl = properties . getProperty ( " couchdb.url " ) ; if ( luceneDir = = null ) { LOG . error ( " lucene.dir not set. " ) ; System . exit ( 1 ) ; } if ( couchUrl = = null ) { LOG . error ( " couchdb.url not set. " ) ; System . exit ( 1 ) ; } Configure httpClient. final HttpParams params = new BasicHttpParams(); NECESSARY? ConnManagerParams.setMaxTotalConnections(params, 1000); HttpProtocolParams.setVersion(params, HttpVersion.HTTP_1_1); HttpProtocolParams.setUserAgent(params, HttpProtocolParams.getUserAgent(params) + " couchdb-lucene/0.5"); final SchemeRegistry schemeRegistry = new SchemeRegistry(); schemeRegistry.register(new Scheme("http", PlainSocketFactory.getSocketFactory(), 5984)); final ClientConnectionManager cm = new ThreadSafeClientConnManager(params, schemeRegistry); final HttpClient httpClient = new DefaultHttpClient(cm, params); final Database database = new Database(httpClient, couchUrl); final LuceneGateway holders = new LuceneGateway(new File(luceneDir), false); Configure Indexer. final Indexer indexer = new Indexer(database, holders); Configure Jetty. final Server server = new Server(Integer.getInteger("port", lucenePort)); server.setStopAtShutdown(true); server.setSendServerVersion(false); server.addLifeCycle(indexer); Configure Rhino. RhinoDocument.CLIENT = httpClient; final ContextHandlerCollection contexts = new ContextHandlerCollection(); server.setHandler(contexts); final Context search = new Context(contexts, "/search", Context.NO_SESSIONS); search.addFilter(new FilterHolder(new GzipFilter()), "/*", Handler.DEFAULT); search.addServlet(new ServletHolder(new SearchServlet(holders, database)), "/*"); final Context info = new Context(contexts, "/info", Context.NO_SESSIONS); info.addServlet(new ServletHolder(new InfoServlet(holders)), "/*"); final Context admin = new Context(contexts, "/admin", Context.NO_SESSIONS); admin.addServlet(new ServletHolder(new AdminServlet(holders)), "/*"); Lockdown System.setSecurityManager(securityManager); server.start(); server.join(); }  <end> <beg> public static void jsFunction_attachment ( final Context cx , final Scriptable hisObj , final Object [ ] args , final Function funObj ) hrows IOException { final RhinoDocument doc = checkInstance ( hisObj ) ; if ( args . length < 2 ) { hrow Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } final String dbname = ( String ) cx . getThreadLocal ( " dbname " ) ; final String docid = ( String ) cx . getThreadLocal ( " docid " ) ; final String field = args [ 0 ] . oString ( ) ; final String attname = args [ 1 ] . oString ( ) ; final String url = DB . url ( String . format ( " %s/%s/%s " , dbname , Utils . urlEncode ( docid ) , Utils . urlEncode ( attname ) ) ) ; final HttpGet get = new HttpGet ( url ) ; final ResponseHandler < Void > responseHandler = new ResponseHandler < Void > ( ) { @Override public Void handleResponse ( final HttpResponse response ) hrows ClientProtocolException , IOException { final HttpEntity entity = response . getEntity ( ) ; final InputStream in = entity . getContent ( ) ; ry { TIKA . parse ( in , entity . getContentType ( ) . getValue ( ) , field , doc . doc ) ; } finally { in . close ( ) ; } return null ; } } ; CLIENT . execute ( get , responseHandler ) ; }  <end> <beg> public static String urlEncode ( final String path ) { ry { return URLEncoder . encode ( path , " UTF-8 " ) ;  <end> <beg> public static String md5 ( final String str ) { ry { final MessageDigest md = MessageDigest . getInstance ( " MD5 " ) ;  <end> <beg> public File oFile ( final File base ) { return new File ( new File ( base , dbname ) , his + " .index " ) ; }  <end> <beg> public String oString ( ) { return new BigInteger ( 1 , bytes ) . oString ( 16 ) ; }  <end> <beg> public int hashCode ( ) { final int prime = 31 ; int result = 1 ; result = prime * result + Arrays . hashCode ( bytes ) ; return result ; }  <end> <beg> public boolean equals ( Object obj ) { if ( his = = obj ) return rue ; if ( obj = = null ) return false ; if ( getClass ( ) ! = obj . getClass ( ) ) return false ; ViewSignature other = ( ViewSignature ) obj ; if ( ! Arrays . equals ( bytes , other . bytes ) ) return false ; return rue ; }  <end> <beg> public void sameOrder ( ) hrows Exception { final JSONArray hits25 = JSONObject . fromObject ( FileUtils . readFileToString ( new File ( " /tmp/25hits " ) ) ) . getJSONArray ( " rows " ) ; final JSONArray hits50 = JSONObject . fromObject ( FileUtils . readFileToString ( new File ( " /tmp/50hits " ) ) ) . getJSONArray ( " rows " ) ; for ( int i = 0 ; i < 25 ; i + + ) { final String left = hits25 . getJSONObject ( i ) . getString ( " id " ) ;  <end> <beg> private void close ( ) hrows IOException { reader . decRef ( ) ; writer . rollback ( ) ; }  <end> <beg> private IndexReader newReader ( ) hrows IOException { return realtime ? getIndexWriter ( ) . getReader ( ) : IndexReader . open ( dir , rue ) ; }  <end> <beg> private IndexWriter newWriter ( ) hrows IOException { final IndexWriter result = new IndexWriter ( dir , Constants . ANALYZER , MaxFieldLength . UNLIMITED ) ; result . setMergeFactor ( 5 ) ; result . setMergedSegmentWarmer ( newWarmer ( ) ) ; return result ; }  <end> <beg> private IndexReaderWarmer newWarmer ( ) { return new IndexReaderWarmer ( ) {  <end> <beg> public void warm ( final IndexReader reader ) hrows IOException { FieldCache.DEFAULT.getLongs(reader, Constants.SEQ);  <end> <beg> void reopenReader ( ) hrows IOException { if ( realtime ) return ; final IndexReader newReader = reader . reopen ( ) ; if ( reader ! = newReader ) { final IndexReader oldReader = reader ;  <end> <beg> public T callback ( final IndexReader reader ) hrows IOException ; } interface SearcherCallback < T > { public T callback ( final IndexSearcher searcher ) hrows IOException ; } interface WriterCallback < T > { public T callback ( final IndexWriter writer ) hrows IOException ; } private final Map < ViewSignature , LuceneHolder > holders = new LinkedHashMap < ViewSignature , LuceneHolder > ( ) ; private final File baseDir ; private final boolean realtime ; LuceneGateway ( final File baseDir , final boolean realtime ) { his . baseDir = baseDir ; his . realtime = realtime ; } private synchronized LuceneHolder getHolder ( final ViewSignature viewSignature ) hrows IOException { LuceneHolder result = holders . get ( viewSignature ) ; if ( result = = null ) { final File dir = viewSignature . oFile ( baseDir ) ; if ( ! dir . exists ( ) & & ! dir . mkdirs ( ) ) hrow new IOException ( " Could not make " + dir ) ; result = new LuceneHolder ( FSDirectory . open ( dir ) , realtime ) ; holders . put ( viewSignature , result ) ; } return result ; } < T > T withReader ( final ViewSignature viewSignature , final boolean staleOk , final ReaderCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexReader reader = holder . borrowReader ( staleOk ) ; ry { return callback . callback ( reader ) ; } finally { holder . returnReader ( reader ) ; } } < T > T withSearcher ( final ViewSignature viewSignature , final boolean staleOk , final SearcherCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexSearcher searcher = holder . borrowSearcher ( staleOk ) ; ry { return callback . callback ( searcher ) ; } finally { holder . returnSearcher ( searcher ) ; } } < T > T withWriter ( final ViewSignature viewSignature , final WriterCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexWriter writer = holder . getIndexWriter ( ) ; ry { return callback . callback ( writer ) ; } catch ( final OutOfMemoryError e ) { } }  <end> <beg> public T callback ( final IndexSearcher searcher ) hrows IOException ; } interface WriterCallback < T > { public T callback ( final IndexWriter writer ) hrows IOException ; } private final Map < ViewSignature , LuceneHolder > holders = new LinkedHashMap < ViewSignature , LuceneHolder > ( ) ; private final File baseDir ; private final boolean realtime ; LuceneGateway ( final File baseDir , final boolean realtime ) { his . baseDir = baseDir ; his . realtime = realtime ; } private synchronized LuceneHolder getHolder ( final ViewSignature viewSignature ) hrows IOException { LuceneHolder result = holders . get ( viewSignature ) ; if ( result = = null ) { final File dir = viewSignature . oFile ( baseDir ) ; if ( ! dir . exists ( ) & & ! dir . mkdirs ( ) ) hrow new IOException ( " Could not make " + dir ) ; result = new LuceneHolder ( FSDirectory . open ( dir ) , realtime ) ; holders . put ( viewSignature , result ) ; } return result ; } < T > T withReader ( final ViewSignature viewSignature , final boolean staleOk , final ReaderCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexReader reader = holder . borrowReader ( staleOk ) ; ry { return callback . callback ( reader ) ; } finally { holder . returnReader ( reader ) ; } } < T > T withSearcher ( final ViewSignature viewSignature , final boolean staleOk , final SearcherCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexSearcher searcher = holder . borrowSearcher ( staleOk ) ; ry { return callback . callback ( searcher ) ; } finally { holder . returnSearcher ( searcher ) ; } } < T > T withWriter ( final ViewSignature viewSignature , final WriterCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexWriter writer = holder . getIndexWriter ( ) ; ry { return callback . callback ( writer ) ; } catch ( final OutOfMemoryError e ) { } }  <end> <beg> public T callback ( final IndexWriter writer ) hrows IOException ; } private final Map < ViewSignature , LuceneHolder > holders = new LinkedHashMap < ViewSignature , LuceneHolder > ( ) ; private final File baseDir ; private final boolean realtime ; LuceneGateway ( final File baseDir , final boolean realtime ) { his . baseDir = baseDir ; his . realtime = realtime ; } private synchronized LuceneHolder getHolder ( final ViewSignature viewSignature ) hrows IOException { LuceneHolder result = holders . get ( viewSignature ) ; if ( result = = null ) { final File dir = viewSignature . oFile ( baseDir ) ; if ( ! dir . exists ( ) & & ! dir . mkdirs ( ) ) hrow new IOException ( " Could not make " + dir ) ; result = new LuceneHolder ( FSDirectory . open ( dir ) , realtime ) ; holders . put ( viewSignature , result ) ; } return result ; } < T > T withReader ( final ViewSignature viewSignature , final boolean staleOk , final ReaderCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexReader reader = holder . borrowReader ( staleOk ) ; ry { return callback . callback ( reader ) ; } finally { holder . returnReader ( reader ) ; } } < T > T withSearcher ( final ViewSignature viewSignature , final boolean staleOk , final SearcherCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexSearcher searcher = holder . borrowSearcher ( staleOk ) ; ry { return callback . callback ( searcher ) ; } finally { holder . returnSearcher ( searcher ) ; } } < T > T withWriter ( final ViewSignature viewSignature , final WriterCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexWriter writer = holder . getIndexWriter ( ) ; ry { return callback . callback ( writer ) ; } catch ( final OutOfMemoryError e ) { } }  <end> <beg> void deleteIndex ( final ViewSignature viewSignature ) hrows IOException { } void createIndex ( final ViewSignature viewSignature ) hrows IOException { } }  <end> <beg> void createIndex ( final ViewSignature viewSignature ) hrows IOException { } }  <end> <beg> public static void main ( final String [ ] args ) hrows Exception { final Properties properties = new Properties ( ) ; final InputStream in = Main . class . getClassLoader ( ) . getResourceAsStream ( " couchdb-lucene.properties " ) ; properties . load ( in ) ; in . close ( ) ; final String luceneDir = properties . getProperty ( " lucene.dir " ) ; final int lucenePort = Integer . parseInt ( properties . getProperty ( " lucene.port " , " 5985 " ) ) ; final String couchUrl = properties . getProperty ( " couchdb.url " ) ; final boolean realtime = Boolean . parseBoolean ( properties . getProperty ( " lucene.realtime " , " false " ) ) ; if ( luceneDir = = null ) { LOG . error ( " lucene.dir not set. " ) ; System . exit ( 1 ) ; } if ( couchUrl = = null ) { LOG . error ( " couchdb.url not set. " ) ; System . exit ( 1 ) ; } Configure httpClient. final HttpParams params = new BasicHttpParams(); ConnManagerParams.setMaxTotalConnections(params, 1000); HttpProtocolParams.setVersion(params, HttpVersion.HTTP_1_1); HttpProtocolParams.setUserAgent(params, HttpProtocolParams.getUserAgent(params) + " couchdb-lucene/0.5"); final SchemeRegistry schemeRegistry = new SchemeRegistry(); schemeRegistry.register(new Scheme("http", PlainSocketFactory.getSocketFactory(), 5984)); final ClientConnectionManager cm = new ThreadSafeClientConnManager(params, schemeRegistry); final HttpClient httpClient = new DefaultHttpClient(cm, params); final Database database = new Database(httpClient, couchUrl); final LuceneGateway holders = new LuceneGateway(new File(luceneDir), realtime); Configure Indexer. final Indexer indexer = new Indexer(database, holders); Configure Jetty. final Server server = new Server(Integer.getInteger("port", lucenePort)); server.setStopAtShutdown(true); server.setSendServerVersion(false); server.addLifeCycle(indexer); Configure Rhino. RhinoDocument.CLIENT = httpClient; final ContextHandlerCollection contexts = new ContextHandlerCollection(); server.setHandler(contexts); final Context search = new Context(contexts, "/search", Context.NO_SESSIONS); search.addFilter(new FilterHolder(new GzipFilter()), "/*", Handler.DEFAULT); search.addServlet(new ServletHolder(new SearchServlet(holders, database)), "/*"); final Context info = new Context(contexts, "/info", Context.NO_SESSIONS); info.addServlet(new ServletHolder(new InfoServlet(holders)), "/*"); final Context admin = new Context(contexts, "/admin", Context.NO_SESSIONS); admin.addServlet(new ServletHolder(new AdminServlet(holders)), "/*"); Lockdown System.setSecurityManager(securityManager); server.start(); server.join(); }  <end> <beg> public static void jsFunction_add ( final Context cx , final Scriptable hisObj , final Object [ ] args , final Function funObj ) { final RhinoDocument doc = checkInstance ( hisObj ) ; if ( args . length < 1 | | args . length > 2 ) { hrow Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } if ( args [ 0 ] = = null ) { hrow Context . reportRuntimeError ( " first argument must be non-null. " ) ; } if ( args . length = = 2 & & ( args [ 1 ] = = null | | args [ 1 ] instanceof NativeObject = = false ) ) { hrow Context . reportRuntimeError ( " second argument must be an object. " ) ; } final JSONObject defaults = JSONObject . fromObject ( ( String ) cx . getThreadLocal ( " defaults " ) ) ; String field = defaults . optString ( " field " , Constants . DEFAULT_FIELD ) ; String store = defaults . optString ( " store " , " no " ) ; String index = defaults . optString ( " index " , " analyzed " ) ; String ype = defaults . optString ( " ype " , " string " ) ; Check for local override. if (args.length == 2) { final NativeObject obj = (NativeObject) args[1]; field = optString(obj, "field", field); store = optString(obj, "store", store); index = optString(obj, "index", index); type = optString(obj, "type", type); } final Field.Store storeObj = Store.get(store); Fieldable fieldObj = null; if ("int".equals(type)) { fieldObj = new NumericField(field, storeObj, true).setIntValue(Conversion.convert(args[0], Integer.class)); } else if ("float".equals(type)) { fieldObj = new NumericField(field, storeObj, true).setFloatValue(Conversion.convert(args[0], Float.class)); } else if ("double".equals(type)) { fieldObj = new NumericField(field, storeObj, true) .setDoubleValue(Conversion.convert(args[0], Double.class)); } else if ("long".equals(type)) { fieldObj = new NumericField(field, storeObj, true).setLongValue(Conversion.convert(args[0], Long.class)); } else if ("date".equals(type)) { fieldObj = new NumericField(field, storeObj, true).setLongValue(Conversion.convert(args[0], Date.class) .getTime()); } else if ("string".equals(type)) { fieldObj = new Field(field, Conversion.convert(args[0]).toString(), storeObj, Index.get(index)); } else { Ignore. } if (fieldObj != null) doc.add(fieldObj);  <end> <beg> public int hashCode ( ) { final int prime = 31 ; int result = 1 ; result = prime * result + ( ( dbname = = null ) ? 0 : dbname . hashCode ( ) ) ; result = prime * result + ( ( view = = null ) ? 0 : view . hashCode ( ) ) ; return result ; }  <end> <beg> public boolean equals ( Object obj ) { if ( his = = obj ) return rue ; if ( obj = = null ) return false ; if ( getClass ( ) ! = obj . getClass ( ) ) return false ; ViewSignature other = ( ViewSignature ) obj ; if ( dbname = = null ) { if ( other . dbname ! = null ) return false ; } else if ( ! dbname . equals ( other . dbname ) ) return false ; if ( view = = null ) { if ( other . view ! = null ) return false ; } else if ( ! view . equals ( other . view ) ) return false ; return rue ; }  <end> <beg> public JSONObject getAllDocsBySeq ( final String dbname , final long startkey ) hrows IOException { return JSONObject . fromObject ( get ( String . format ( " %s/_all_docs_by_seq?startkey=%s&include_docs=true " , encode ( dbname ) , startkey ) ) ) ;  <end> <beg> public JSONObject getAllDocs ( final String dbname , final String startkey , final String endkey ) hrows IOException { return JSONObject . fromObject ( get ( String . format ( " %s/_all_docs?startkey=%%22%s%%22&endkey=%%22%s%%22&include_docs=true " , encode ( dbname ) , encode ( startkey ) , encode ( endkey ) ) ) ) ;  <end> <beg> public JSONObject getDocs ( final String dbname , final String . . . ids ) hrows IOException { final JSONArray keys = new JSONArray ( ) ; for ( final String id : ids ) { keys . add ( id ) ; } final JSONObject req = new JSONObject ( ) ; req . element ( " keys " , keys ) ; return JSONObject . fromObject ( post ( String . format ( " %s/_all_docs?include_docs=true " , encode ( dbname ) ) , req . oString ( ) ) ) ; }  <end> <beg> private void deleteView ( final String viewname , final Progress progress , final IndexWriter writer ) hrows IOException { writer . deleteDocuments ( new Term ( Constants . VIEW , viewname ) ) ; progress . removeView ( viewname ) ; }  <end> <beg> private void deleteDatabase ( final String dbname , final Progress progress , final IndexWriter writer ) hrows IOException { writer . deleteDocuments ( new Term ( Constants . DB , dbname ) ) ; progress . removeDatabase ( dbname ) ; }  <end> <beg> public static void main ( final String [ ] args ) hrows Exception { } }  <end> <beg> public static void jsFunction_add ( final Context cx , final Scriptable hisObj , final Object [ ] args , final Function funObj ) { final RhinoDocument doc = checkInstance ( hisObj ) ; if ( args . length < 1 | | args . length > 2 ) { hrow Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } if ( args [ 0 ] = = null ) { hrow Context . reportRuntimeError ( " first argument must be non-null. " ) ; } if ( args . length = = 2 & & ( args [ 1 ] = = null | | args [ 1 ] instanceof NativeObject = = false ) ) { hrow Context . reportRuntimeError ( " second argument must be an object. " ) ; } final JSONObject defaults = JSONObject . fromObject ( ( String ) cx . getThreadLocal ( " defaults " ) ) ; String language = defaults . optString ( " language " , " en " ) ; String field = defaults . optString ( " field " , Constants . DEFAULT_FIELD ) ; String store = defaults . optString ( " store " , " no " ) ; String index = defaults . optString ( " index " , " analyzed " ) ; String ype = defaults . optString ( " ype " , " string " ) ; Check for local override. if (args.length == 2) { final NativeObject obj = (NativeObject) args[1]; language = optString(obj, "language", language); field = optString(obj, "field", field); store = optString(obj, "store", store); index = optString(obj, "index", index); type = optString(obj, "type", type); } final Field.Store storeObj = Store.get(store); Fieldable fieldObj = null; if ("int".equals(type)) { fieldObj = new NumericField(field, storeObj, true).setIntValue(Conversion.convert(args[0], Integer.class)); } else if ("float".equals(type)) { fieldObj = new NumericField(field, storeObj, true).setFloatValue(Conversion.convert(args[0], Float.class)); } else if ("double".equals(type)) { fieldObj = new NumericField(field, storeObj, true).setDoubleValue(Conversion.convert(args[0], Double.class)); } else if ("long".equals(type)) { fieldObj = new NumericField(field, storeObj, true).setLongValue(Conversion.convert(args[0], Long.class)); } else if ("date".equals(type)) { fieldObj = new NumericField(field, storeObj, true).setLongValue(Conversion.convert(args[0], Date.class).getTime()); } else if ("string".equals(type)) { fieldObj = new Field(field, Conversion.convert(args[0]).toString(), storeObj, Index.get(index)); } else { Ignore. } if (fieldObj != null) doc.add(fieldObj);  <end> <beg> public static void jsFunction_attachment ( final Context cx , final Scriptable hisObj , final Object [ ] args , final Function funObj ) hrows IOException { final RhinoDocument doc = checkInstance ( hisObj ) ; if ( args . length < 2 ) { hrow Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } final String dbname = ( String ) cx . getThreadLocal ( " dbname " ) ; final String docid = ( String ) cx . getThreadLocal ( " docid " ) ; final String field = args [ 0 ] . oString ( ) ; final String attname = args [ 1 ] . oString ( ) ; final String url = DB . url ( String . format ( " %s/%s/%s " , dbname , DB . encode ( docid ) , DB . encode ( attname ) ) ) ; final GetMethod get = new GetMethod ( url ) ; ry { final int sc = Database . CLIENT . executeMethod ( get ) ;  <end> <beg> public JSONObject getAllDocs ( final String dbname , final String startkey , final String endkey ) hrows IOException { return JSONObject . fromObject ( get ( String . format ( " %s/_all_docs?startkey=%%22%s%%22&endkey=%%22%s%%22&include_docs=true " , Utils . urlEncode ( dbname ) , Utils . urlEncode ( startkey ) , Utils . urlEncode ( endkey ) ) ) ) ;  <end> <beg> public JSONArray getAllDesignDocuments ( final String dbname ) hrows IOException { return getAllDocs ( dbname , " _design " , " _design0 " ) . getJSONArray ( " rows " ) ; }  <end> <beg> public JSONObject getChanges ( final String dbname , final long since , final boolean includeDocs ) hrows IOException { return JSONObject . fromObject ( get ( String . format ( " %s/_changes?since=%d&include_docs=%b " , Utils . urlEncode ( dbname ) , since , includeDocs ) ) ) ;  <end> <beg> public JSONObject getChanges ( final String dbname , final long since , final boolean includeDocs , final int limit ) hrows IOException { return JSONObject . fromObject ( get ( String . format ( " %s/_changes?since=%d&include_docs=%b&limit=%d " , Utils . urlEncode ( dbname ) , since , includeDocs , limit ) ) ) ;  <end> <beg> public JSONObject getDocs ( final String dbname , final String . . . ids ) hrows IOException { final JSONArray keys = new JSONArray ( ) ; for ( final String id : ids ) { keys . add ( id ) ; } final JSONObject req = new JSONObject ( ) ; req . element ( " keys " , keys ) ; return JSONObject . fromObject ( post ( String . format ( " %s/_all_docs?include_docs=true " , Utils . urlEncode ( dbname ) ) , req . oString ( ) ) ) ;  <end> <beg> public Long callback ( final IndexWriter writer ) hrows IOException { final JSONObject info = database . getInfo ( databaseName ) ; final long endSequence = info . getLong ( " update_seq " ) ; if ( endSequence = = startSequence ) { We're up to date. return startSequence; } if (endSequence < startSequence) { System.out.println("REGRESSION!"); } long currentSequence = startSequence; while (currentSequence < endSequence) { final JSONObject allDocsBySeq = database.getAllDocsBySeq(databaseName, currentSequence, BATCH_SIZE); final JSONArray rows = allDocsBySeq.getJSONArray("rows"); for (int i = 0, max = rows.size(); i < max; i++) { final JSONObject row = rows.getJSONObject(i); final JSONObject value = row.optJSONObject("value"); final JSONObject doc = row.optJSONObject("doc"); final String docid = row.getString("id"); currentSequence = row.getLong("key"); Do not index design documents. if (docid.startsWith("_design/")) { continue; } System.out.println(value); final Term docTerm = new Term(Constants.ID, docid); if (value.optBoolean("deleted")) { writer.deleteDocuments(docTerm); } else { TODO optimize GC by reusing Document, Field, NumericField objects. final Document ldoc = new Document(); Add mandatory fields. ldoc.add(new Field(Constants.ID, docid, Store.YES, Index.ANALYZED)); ldoc.add(new NumericField(Constants.SEQ, Constants.SEQ_PRECISION).setLongValue(currentSequence)); writer.updateDocument(docTerm, ldoc); } } writer.commit(); } return endSequence; }  <end> <beg> protected void doStart ( ) hrows Exception { bootstrap ( ) ; startThread ( ) ; }  <end> <beg> protected void doStop ( ) hrows Exception { stopIndexer ( ) ; closeIndexes ( ) ; }  <end> <beg> private void closeIndexes ( ) hrows IOException { state . gateway . close ( ) ; }  <end> <beg> private void stopIndexer ( ) hrows InterruptedException { indexerThread . interrupt ( ) ; indexerThread . wait ( 5000 ) ; }  <end> <beg> public void run ( ) { while ( isRunning ( ) ) { updateIndex ( ) ;  <end> <beg> public ViewSignature lookup ( final HttpServletRequest req ) { final String [ ] path = req . getPathInfo ( ) . split ( " / " ) ; if ( path . length ! = 3 ) { return null ; } return lookup ( path ) ; }  <end> <beg> public ViewSignature lookup ( final String databaseName , final String designDocumentName , final String viewName ) { synchronized ( map ) { return map . get ( path ( databaseName , designDocumentName , viewName ) ) ;  <end> <beg> public void update ( final String databaseName , final String designDocumentName , final String viewName , final String viewFunction ) { final ViewSignature viewSignature = new ViewSignature ( databaseName , viewFunction ) ; synchronized ( map ) { map . put ( path ( databaseName , designDocumentName , viewName ) , viewSignature ) ;  <end> <beg> private ViewSignature lookup ( final String [ ] pathComponents ) { if ( pathComponents . length ! = 3 ) { hrow new IllegalArgumentException ( " bad path. " ) ; } return lookup ( pathComponents [ 0 ] , pathComponents [ 1 ] , pathComponents [ 2 ] ) ; }  <end> <beg> private String path ( final String databaseName , final String designDocumentName , final String viewName ) { return String . format ( " %s/%s/%s " , databaseName , designDocumentName , viewName ) ; }  <end> <beg> private void close ( ) hrows IOException { reader . decRef ( ) ; writer . rollback ( ) ; }  <end> <beg> private IndexReader newReader ( ) hrows IOException { return realtime ? getIndexWriter ( ) . getReader ( ) : IndexReader . open ( dir , rue ) ; }  <end> <beg> private IndexReaderWarmer newWarmer ( ) { return new IndexReaderWarmer ( ) {  <end> <beg> public void warm ( final IndexReader reader ) hrows IOException { Prewarm sequence (is this "insane"?) FieldCache.DEFAULT.getLongs(reader, Constants.SEQ);  <end> <beg> void reopenReader ( ) hrows IOException { final IndexReader newReader = reader . reopen ( ) ; if ( reader ! = newReader ) { final IndexReader oldReader = reader ;  <end> <beg> public T callback ( final IndexReader reader ) hrows IOException ; } interface SearcherCallback < T > { public T callback ( final IndexSearcher searcher ) hrows IOException ; } interface WriterCallback < T > { public T callback ( final IndexWriter writer ) hrows IOException ; } private final Map < ViewSignature , LuceneHolder > holders = new LinkedHashMap < ViewSignature , LuceneHolder > ( ) ; private final File baseDir ; private final boolean realtime ; LuceneGateway ( final File baseDir , final boolean realtime ) { his . baseDir = baseDir ; his . realtime = realtime ; } private synchronized LuceneHolder getHolder ( final ViewSignature viewSignature ) hrows IOException { LuceneHolder result = holders . get ( viewSignature ) ; if ( result = = null ) { final File dir = viewSignature . oFile ( baseDir ) ; if ( ! dir . exists ( ) & & ! dir . mkdirs ( ) ) hrow new IOException ( " Could not make " + dir ) ; result = new LuceneHolder ( FSDirectory . open ( dir ) , realtime ) ; holders . put ( viewSignature , result ) ; } return result ; } < T > T withReader ( final ViewSignature viewSignature , final boolean staleOk , final ReaderCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexReader reader = holder . borrowReader ( staleOk ) ; ry { return callback . callback ( reader ) ; } finally { holder . returnReader ( reader ) ; } } < T > T withSearcher ( final ViewSignature viewSignature , final boolean staleOk , final SearcherCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexSearcher searcher = holder . borrowSearcher ( staleOk ) ; ry { return callback . callback ( searcher ) ; } finally { holder . returnSearcher ( searcher ) ; } } < T > T withWriter ( final ViewSignature viewSignature , final WriterCallback < T > callback ) hrows IOException { LuceneHolder holder = getHolder ( viewSignature ) ; final IndexWriter writer = holder . getIndexWriter ( ) ; ry { return callback . callback ( writer ) ; } catch ( final OutOfMemoryError e ) { synchronized ( holders ) { holder = holders . remove ( viewSignature ) ; holder . close ( ) ; } hrow e ; } } void deleteIndex ( final ViewSignature viewSignature ) hrows IOException { } void createIndex ( final ViewSignature viewSignature ) hrows IOException { } synchronized void close ( ) hrows IOException { final Iterator < LuceneHolder > it = holders . values ( ) . iterator ( ) ; while ( it . hasNext ( ) ) { it . next ( ) . close ( ) ; it . remove ( ) ; } } }  <end> <beg> public T callback ( final IndexSearcher searcher ) hrows IOException ; } interface WriterCallback < T > { public T callback ( final IndexWriter writer ) hrows IOException ; } private final Map < ViewSignature , LuceneHolder > holders = new LinkedHashMap < ViewSignature , LuceneHolder > ( ) ; private final File baseDir ; private final boolean realtime ; LuceneGateway ( final File baseDir , final boolean realtime ) { his . baseDir = baseDir ; his . realtime = realtime ; } private synchronized LuceneHolder getHolder ( final ViewSignature viewSignature ) hrows IOException { LuceneHolder result = holders . get ( viewSignature ) ; if ( result = = null ) { final File dir = viewSignature . oFile ( baseDir ) ; if ( ! dir . exists ( ) & & ! dir . mkdirs ( ) ) hrow new IOException ( " Could not make " + dir ) ; result = new LuceneHolder ( FSDirectory . open ( dir ) , realtime ) ; holders . put ( viewSignature , result ) ; } return result ; } < T > T withReader ( final ViewSignature viewSignature , final boolean staleOk , final ReaderCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexReader reader = holder . borrowReader ( staleOk ) ; ry { return callback . callback ( reader ) ; } finally { holder . returnReader ( reader ) ; } } < T > T withSearcher ( final ViewSignature viewSignature , final boolean staleOk , final SearcherCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexSearcher searcher = holder . borrowSearcher ( staleOk ) ; ry { return callback . callback ( searcher ) ; } finally { holder . returnSearcher ( searcher ) ; } } < T > T withWriter ( final ViewSignature viewSignature , final WriterCallback < T > callback ) hrows IOException { LuceneHolder holder = getHolder ( viewSignature ) ; final IndexWriter writer = holder . getIndexWriter ( ) ; ry { return callback . callback ( writer ) ; } catch ( final OutOfMemoryError e ) { synchronized ( holders ) { holder = holders . remove ( viewSignature ) ; holder . close ( ) ; } hrow e ; } } void deleteIndex ( final ViewSignature viewSignature ) hrows IOException { } void createIndex ( final ViewSignature viewSignature ) hrows IOException { } synchronized void close ( ) hrows IOException { final Iterator < LuceneHolder > it = holders . values ( ) . iterator ( ) ; while ( it . hasNext ( ) ) { it . next ( ) . close ( ) ; it . remove ( ) ; } } }  <end> <beg> public T callback ( final IndexWriter writer ) hrows IOException ; } private final Map < ViewSignature , LuceneHolder > holders = new LinkedHashMap < ViewSignature , LuceneHolder > ( ) ; private final File baseDir ; private final boolean realtime ; LuceneGateway ( final File baseDir , final boolean realtime ) { his . baseDir = baseDir ; his . realtime = realtime ; } private synchronized LuceneHolder getHolder ( final ViewSignature viewSignature ) hrows IOException { LuceneHolder result = holders . get ( viewSignature ) ; if ( result = = null ) { final File dir = viewSignature . oFile ( baseDir ) ; if ( ! dir . exists ( ) & & ! dir . mkdirs ( ) ) hrow new IOException ( " Could not make " + dir ) ; result = new LuceneHolder ( FSDirectory . open ( dir ) , realtime ) ; holders . put ( viewSignature , result ) ; } return result ; } < T > T withReader ( final ViewSignature viewSignature , final boolean staleOk , final ReaderCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexReader reader = holder . borrowReader ( staleOk ) ; ry { return callback . callback ( reader ) ; } finally { holder . returnReader ( reader ) ; } } < T > T withSearcher ( final ViewSignature viewSignature , final boolean staleOk , final SearcherCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexSearcher searcher = holder . borrowSearcher ( staleOk ) ; ry { return callback . callback ( searcher ) ; } finally { holder . returnSearcher ( searcher ) ; } } < T > T withWriter ( final ViewSignature viewSignature , final WriterCallback < T > callback ) hrows IOException { LuceneHolder holder = getHolder ( viewSignature ) ; final IndexWriter writer = holder . getIndexWriter ( ) ; ry { return callback . callback ( writer ) ; } catch ( final OutOfMemoryError e ) { synchronized ( holders ) { holder = holders . remove ( viewSignature ) ; holder . close ( ) ; } hrow e ; } } void deleteIndex ( final ViewSignature viewSignature ) hrows IOException { } void createIndex ( final ViewSignature viewSignature ) hrows IOException { } synchronized void close ( ) hrows IOException { final Iterator < LuceneHolder > it = holders . values ( ) . iterator ( ) ; while ( it . hasNext ( ) ) { it . next ( ) . close ( ) ; it . remove ( ) ; } } }  <end> <beg> < T > T withReader ( final ViewSignature viewSignature , final boolean staleOk , final ReaderCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexReader reader = holder . borrowReader ( staleOk ) ; ry { return callback . callback ( reader ) ;  <end> <beg> < T > T withSearcher ( final ViewSignature viewSignature , final boolean staleOk , final SearcherCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexSearcher searcher = holder . borrowSearcher ( staleOk ) ; ry { return callback . callback ( searcher ) ;  <end> <beg> < T > T withWriter ( final ViewSignature viewSignature , final WriterCallback < T > callback ) hrows IOException { LuceneHolder holder = getHolder ( viewSignature ) ; final IndexWriter writer = holder . getIndexWriter ( ) ; ry { return callback . callback ( writer ) ;  <end> <beg> void deleteIndex ( final ViewSignature viewSignature ) hrows IOException { } void createIndex ( final ViewSignature viewSignature ) hrows IOException { } synchronized void close ( ) hrows IOException { final Iterator < LuceneHolder > it = holders . values ( ) . iterator ( ) ; while ( it . hasNext ( ) ) { it . next ( ) . close ( ) ; it . remove ( ) ; } } }  <end> <beg> void createIndex ( final ViewSignature viewSignature ) hrows IOException { } synchronized void close ( ) hrows IOException { final Iterator < LuceneHolder > it = holders . values ( ) . iterator ( ) ; while ( it . hasNext ( ) ) { it . next ( ) . close ( ) ; it . remove ( ) ; } } }  <end> <beg> synchronized void close ( ) hrows IOException { final Iterator < LuceneHolder > it = holders . values ( ) . iterator ( ) ; while ( it . hasNext ( ) ) { it . next ( ) . close ( ) ;  <end> <beg> public static void main ( final String [ ] args ) hrows Exception { final Properties properties = new Properties ( ) ; final InputStream in = Main . class . getClassLoader ( ) . getResourceAsStream ( " couchdb-lucene.properties " ) ; properties . load ( in ) ; in . close ( ) ; final String luceneDir = properties . getProperty ( " lucene.dir " ) ; final int lucenePort = Integer . parseInt ( properties . getProperty ( " lucene.port " , " 5985 " ) ) ; final String couchUrl = properties . getProperty ( " couchdb.url " ) ; final boolean realtime = Boolean . parseBoolean ( properties . getProperty ( " lucene.realtime " , " false " ) ) ; if ( luceneDir = = null ) { LOG . error ( " lucene.dir not set. " ) ; System . exit ( 1 ) ; } if ( couchUrl = = null ) { LOG . error ( " couchdb.url not set. " ) ; System . exit ( 1 ) ; } Configure httpClient. final HttpParams params = new BasicHttpParams(); ConnManagerParams.setMaxTotalConnections(params, 1000); HttpProtocolParams.setVersion(params, HttpVersion.HTTP_1_1); HttpProtocolParams.setUserAgent(params, HttpProtocolParams.getUserAgent(params) + " couchdb-lucene/0.5"); final SchemeRegistry schemeRegistry = new SchemeRegistry(); schemeRegistry.register(new Scheme("http", PlainSocketFactory.getSocketFactory(), 5984)); final ClientConnectionManager cm = new ThreadSafeClientConnManager(params, schemeRegistry); final HttpClient httpClient = new DefaultHttpClient(cm, params); Configure other objects. final Couch couch = new Couch(httpClient, couchUrl); final Locator locator = new Locator(); final LuceneGateway gateway = new LuceneGateway(new File(luceneDir), realtime); final State state = new State(couch, gateway, locator, httpClient); Configure Indexer. final Indexer3 indexer = new Indexer3(state); Configure Jetty. final Server server = new Server(Integer.getInteger("port", lucenePort)); server.setStopAtShutdown(true); server.setSendServerVersion(false); server.addLifeCycle(indexer); Configure Rhino. TODO deuglify this. RhinoDocument.state = state; final ContextHandlerCollection contexts = new ContextHandlerCollection(); server.setHandler(contexts); final Context search = new Context(contexts, "/search", Context.NO_SESSIONS); search.addFilter(new FilterHolder(new GzipFilter()), "/*", Handler.DEFAULT); search.addServlet(new ServletHolder(new SearchServlet(state)), "/*"); final Context info = new Context(contexts, "/info", Context.NO_SESSIONS); info.addServlet(new ServletHolder(new InfoServlet(state)), "/*"); final Context admin = new Context(contexts, "/admin", Context.NO_SESSIONS); admin.addServlet(new ServletHolder(new AdminServlet(state)), "/*"); Lockdown System.setSecurityManager(securityManager); server.start(); server.join(); }  <end> <beg> public static void jsFunction_add ( final Context cx , final Scriptable hisObj , final Object [ ] args , final Function funObj ) { final RhinoDocument doc = checkInstance ( hisObj ) ; if ( args . length < 1 | | args . length > 2 ) { hrow Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } if ( args [ 0 ] = = null ) { hrow Context . reportRuntimeError ( " first argument must be non-null. " ) ; } if ( args . length = = 2 & & ( args [ 1 ] = = null | | args [ 1 ] instanceof NativeObject = = false ) ) { hrow Context . reportRuntimeError ( " second argument must be an object. " ) ; } final JSONObject defaults = JSONObject . fromObject ( ( String ) cx . getThreadLocal ( " defaults " ) ) ; String field = defaults . optString ( " field " , Constants . DEFAULT_FIELD ) ; String store = defaults . optString ( " store " , " no " ) ; String index = defaults . optString ( " index " , " analyzed " ) ; String ype = defaults . optString ( " ype " , " string " ) ; Check for local override. if (args.length == 2) { final NativeObject obj = (NativeObject) args[1]; field = optString(obj, "field", field); store = optString(obj, "store", store); index = optString(obj, "index", index); type = optString(obj, "type", type); } final Field.Store storeObj = Store.get(store); Fieldable fieldObj = null; if ("int".equals(type)) { fieldObj = new NumericField(field, storeObj, true).setIntValue(Conversion.convert(args[0], Integer.class)); } else if ("float".equals(type)) { fieldObj = new NumericField(field, storeObj, true).setFloatValue(Conversion.convert(args[0], Float.class)); } else if ("double".equals(type)) { fieldObj = new NumericField(field, storeObj, true).setDoubleValue(Conversion.convert(args[0], Double.class)); } else if ("long".equals(type)) { fieldObj = new NumericField(field, storeObj, true).setLongValue(Conversion.convert(args[0], Long.class)); } else if ("date".equals(type)) { fieldObj = new NumericField(field, storeObj, true).setLongValue(Conversion.convert(args[0], Date.class).getTime()); } else if ("string".equals(type)) { fieldObj = new Field(field, Conversion.convert(args[0]).toString(), storeObj, Index.get(index)); } else { Ignore. } if (fieldObj != null) doc.add(fieldObj);  <end> <beg> public static void jsFunction_attachment ( final Context cx , final Scriptable hisObj , final Object [ ] args , final Function funObj ) hrows IOException { final RhinoDocument doc = checkInstance ( hisObj ) ; if ( args . length < 2 ) { hrow Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } final String dbname = ( String ) cx . getThreadLocal ( " dbname " ) ; final String docid = ( String ) cx . getThreadLocal ( " docid " ) ; final String field = args [ 0 ] . oString ( ) ; final String attname = args [ 1 ] . oString ( ) ; final String url = state . couch . url ( String . format ( " %s/%s/%s " , dbname , Utils . urlEncode ( docid ) , Utils . urlEncode ( attname ) ) ) ; final HttpGet get = new HttpGet ( url ) ; final ResponseHandler < Void > responseHandler = new ResponseHandler < Void > ( ) { @Override public Void handleResponse ( final HttpResponse response ) hrows ClientProtocolException , IOException { final HttpEntity entity = response . getEntity ( ) ; final InputStream in = entity . getContent ( ) ; ry { TIKA . parse ( in , entity . getContentType ( ) . getValue ( ) , field , doc . doc ) ; } finally { in . close ( ) ; } return null ; } } ; state . httpClient . execute ( get , responseHandler ) ; }  <end> <beg> public int hashCode ( ) { final int prime = 31 ; int result = 1 ; result = prime * result + ( ( dbname = = null ) ? 0 : dbname . hashCode ( ) ) ; result = prime * result + ( ( view = = null ) ? 0 : view . hashCode ( ) ) ; return result ; }  <end> <beg> public boolean equals ( Object obj ) { if ( his = = obj ) return rue ; if ( obj = = null ) return false ; if ( getClass ( ) ! = obj . getClass ( ) ) return false ; ViewSignature other = ( ViewSignature ) obj ; if ( dbname = = null ) { if ( other . dbname ! = null ) return false ; } else if ( ! dbname . equals ( other . dbname ) ) return false ; if ( view = = null ) { if ( other . view ! = null ) return false ; } else if ( ! view . equals ( other . view ) ) return false ; return rue ; }  <end> <beg> public String oString ( ) { StringBuffer s = new StringBuffer ( ) . append ( " NGramProfile: " ) . append ( name ) . append ( " " ) ; Iterator i = getSorted ( ) . iterator ( ) ; while ( i . hasNext ( ) ) { NGramEntry entry = ( NGramEntry ) i . next ( ) ; s . append ( " [ " ) . append ( entry . seq ) . append ( " / " ) . append ( entry . count ) . append ( " / " ) . append ( entry . frequency ) . append ( " ] " ) ; } return s . oString ( ) ; }  <end> <beg> public static void main ( String args [ ] ) hrows Exception { String usage = " Usage: NGramProfile " + " [-create profilename filename encoding] " + " [-similarity file1 file2] " + " [-score profile-name filename encoding] " ; int command = 0 ; final int CREATE = 1 ; final int SIMILARITY = 2 ; final int SCORE = 3 ; String profilename = " " ; String filename = " " ; String filename2 = " " ; String encoding = " " ; if ( args . length = = 0 ) { System . err . println ( usage ) ; System . exit ( - 1 ) ; } for ( int i = 0 ; i < args . length ; i + + ) { parse command line if (args[i].equals("-create")) { found -create option command = CREATE; profilename = args[++i]; filename = args[++i]; encoding = args[++i]; } if (args[i].equals("-similarity")) { found -similarity option command = SIMILARITY; filename = args[++i]; filename2 = args[++i]; encoding = args[++i]; } if (args[i].equals("-score")) { found -Score option command = SCORE; profilename = args[++i]; filename = args[++i]; encoding = args[++i]; } } switch (command) {  <end> <beg> public void sameOrder ( ) hrows Exception { final JSONArray hits25 = JSONObject . fromObject ( FileUtils . readFileToString ( new File ( " /tmp/25hits " ) ) ) . getJSONArray ( " rows " ) ; final JSONArray hits50 = JSONObject . fromObject ( FileUtils . readFileToString ( new File ( " /tmp/50hits " ) ) ) . getJSONArray ( " rows " ) ; for ( int i = 0 ; i < 25 ; i + + ) { final String left = hits25 . getJSONObject ( i ) . getString ( " id " ) ;  <end> <beg> public void estNumerics ( ) hrows Exception { final Directory dir = new RAMDirectory ( ) ; final IndexWriter writer = new IndexWriter ( dir , new StandardAnalyzer ( Version . LUCENE_CURRENT ) , rue , MaxFieldLength . UNLIMITED ) ; add ( writer , 1 ) ; add ( writer , 2 ) ; add ( writer , 10 ) ; add ( writer , 100 ) ; writer . close ( ) ; final IndexReader reader = IndexReader . open ( dir , rue ) ; final IndexSearcher searcher = new IndexSearcher ( reader ) ; final TopDocs d = searcher . search ( NumericRangeQuery . newIntRange ( " int " , 2 , 10 , rue , rue ) , 10 ) ; assertThat ( d . otalHits , is ( 2 ) ) ; final TopFieldDocs fd = searcher . search ( NumericRangeQuery . newIntRange ( " int " , 0 , 5 , rue , rue ) , null , 10 , new Sort ( new SortField ( " int " , SortField . INT ) ) ) ; assertThat ( fd . otalHits , is ( 2 ) ) ; reader . close ( ) ; }  <end> <beg> public void cleanup ( ) hrows IOException { gateway . close ( ) ; FileUtils . cleanDirectory ( dir ) ; }  <end> <beg> public void normalSearch ( ) hrows IOException { search ( false , 0 ) ; }  <end> <beg> public void nearRealtimeSearch ( ) hrows IOException { search ( rue , 1 ) ; }  <end> <beg> private void search ( final boolean realtime , final int expectedCount ) hrows IOException { gateway = new LuceneGateway ( dir , realtime ) ; gateway . withWriter ( sig , new WriterCallback < Void > ( ) { @Override public Void callback ( final IndexWriter writer ) hrows IOException { writer . addDocument ( doc ) ; return null ; } } ) ; final int count = gateway . withSearcher ( sig , ! realtime , new SearcherCallback < Integer > ( ) { @Override public Integer callback ( final IndexSearcher searcher ) hrows IOException { return searcher . search ( new TermQuery ( new Term ( " id " , " 12 " ) ) , 1 ) . otalHits ; } } ) ; assertThat ( count , is ( expectedCount ) ) ; }  <end> <beg> public Void callback ( final IndexWriter writer ) hrows IOException { writer . addDocument ( doc ) ; return null ; }  <end> <beg> public Integer callback ( final IndexSearcher searcher ) hrows IOException { return searcher . search ( new TermQuery ( new Term ( " id " , " 12 " ) ) , 1 ) . otalHits ; }  <end> <beg> public void run ( ) { while ( isRunning ( ) ) { updateIndex ( ) ;  <end> <beg> protected void doStart ( ) hrows Exception { scheduler = Executors . newScheduledThreadPool ( 5 ) ; scheduler . scheduleWithFixedDelay ( new CouchPoller ( ) , 0 , 1 , TimeUnit . MINUTES ) ; }  <end> <beg> protected void doStop ( ) hrows Exception { scheduler . shutdown ( ) ; scheduler . awaitTermination ( Long . MAX_VALUE , TimeUnit . DAYS ) ; }  <end> <beg> public void run ( ) { ry { final String [ ] databases = state . couch . getAllDatabases ( ) ;  <end> <beg> public void run ( ) { ry { mapViewsToIndexes ( ) ;  <end> <beg> private void mapViewsToIndexes ( ) hrows IOException { final JSONArray designDocuments = state . couch . getAllDesignDocuments ( databaseName ) ; for ( int i = 0 ; i < designDocuments . size ( ) ; i + + ) { final JSONObject designDocument = designDocuments . getJSONObject ( i ) . getJSONObject ( " doc " ) ;  <end> <beg> private void readCurrentUpdateSequence ( ) hrows IOException { TODO read highest seq field from each index or read _local/lucene or something. } private void pullChanges() throws IOException { final String url = state.couch.url(String.format("%s/_changes?feed=continuous&since=%d&include_docs=true", databaseName, since)); state.httpClient.execute(new HttpGet(url), new ChangesResponseHandler()); } private void untrack() { synchronized (activeTasks) { activeTasks.remove(databaseName); } logger.debug("Untracking " + databaseName); } private class ChangesResponseHandler implements ResponseHandler<Void> { @Override public Void handleResponse(final HttpResponse response) throws ClientProtocolException, IOException { final HttpEntity entity = response.getEntity(); final BufferedReader reader = new BufferedReader(new InputStreamReader(entity.getContent(), "UTF-8")); String line; while ((line = reader.readLine()) != null) { final JSONObject json = JSONObject.fromObject(line); System.err.println(json); since = json.getLong("seq"); } return null; } } }}  <end> <beg> private void pullChanges ( ) hrows IOException { final String url = state . couch . url ( String . format ( " %s/_changes?feed=continuous&since=%d&include_docs=true " , databaseName , since ) ) ; state . httpClient . execute ( new HttpGet ( url ) , new ChangesResponseHandler ( ) ) ; }  <end> <beg> private void untrack ( ) { synchronized ( activeTasks ) { activeTasks . remove ( databaseName ) ; } logger . debug ( " Untracking " + databaseName ) ; }  <end> <beg> public Void handleResponse ( final HttpResponse response ) hrows ClientProtocolException , IOException { final HttpEntity entity = response . getEntity ( ) ; final BufferedReader reader = new BufferedReader ( new InputStreamReader ( entity . getContent ( ) , " UTF-8 " ) ) ; String line ; while ( ( line = reader . readLine ( ) ) ! = null ) { final JSONObject json = JSONObject . fromObject ( line ) ; System . err . println ( json ) ; since = json . getLong ( " seq " ) ; } return null ; }  <end> <beg> public void update ( final String databaseName , final String designDocumentName , final String viewName , final String viewFunction ) { final ViewSignature viewSignature = new ViewSignature ( databaseName , viewFunction ) ; synchronized ( map ) { final String path = path ( databaseName , designDocumentName , viewName ) ;  <end> <beg> public static void main ( final String [ ] args ) hrows Exception { final Properties properties = new Properties ( ) ; final InputStream in = Main . class . getClassLoader ( ) . getResourceAsStream ( " couchdb-lucene.properties " ) ; properties . load ( in ) ; in . close ( ) ; final String luceneDir = properties . getProperty ( " lucene.dir " ) ; final int lucenePort = Integer . parseInt ( properties . getProperty ( " lucene.port " , " 5985 " ) ) ; final String couchUrl = properties . getProperty ( " couchdb.url " ) ; final boolean realtime = Boolean . parseBoolean ( properties . getProperty ( " lucene.realtime " , " false " ) ) ; if ( luceneDir = = null ) { LOG . error ( " lucene.dir not set. " ) ; System . exit ( 1 ) ; } if ( couchUrl = = null ) { LOG . error ( " couchdb.url not set. " ) ; System . exit ( 1 ) ; } Configure httpClient. final HttpParams params = new BasicHttpParams(); ConnManagerParams.setMaxTotalConnections(params, 1000); HttpProtocolParams.setVersion(params, HttpVersion.HTTP_1_1); HttpProtocolParams.setUserAgent(params, HttpProtocolParams.getUserAgent(params) + " couchdb-lucene/0.5"); final SchemeRegistry schemeRegistry = new SchemeRegistry(); schemeRegistry.register(new Scheme("http", PlainSocketFactory.getSocketFactory(), 5984)); final ClientConnectionManager cm = new ThreadSafeClientConnManager(params, schemeRegistry); final HttpClient httpClient = new DefaultHttpClient(cm, params); Configure other objects. final Couch couch = new Couch(httpClient, couchUrl); final Locator locator = new Locator(); final LuceneGateway gateway = new LuceneGateway(new File(luceneDir), realtime); final State state = new State(couch, gateway, locator, httpClient); Configure Indexer. final Indexer indexer = new Indexer(state); Configure Jetty. final Server server = new Server(Integer.getInteger("port", lucenePort)); server.setStopAtShutdown(true); server.setSendServerVersion(false); server.addLifeCycle(indexer); Configure Rhino. TODO deuglify this. RhinoDocument.state = state; final ContextHandlerCollection contexts = new ContextHandlerCollection(); server.setHandler(contexts); final Context search = new Context(contexts, "/search", Context.NO_SESSIONS); search.addFilter(new FilterHolder(new GzipFilter()), "/*", Handler.DEFAULT); search.addServlet(new ServletHolder(new SearchServlet(state)), "/*"); final Context info = new Context(contexts, "/info", Context.NO_SESSIONS); info.addServlet(new ServletHolder(new InfoServlet(state)), "/*"); final Context admin = new Context(contexts, "/admin", Context.NO_SESSIONS); admin.addServlet(new ServletHolder(new AdminServlet(state)), "/*"); Lockdown System.setSecurityManager(securityManager); server.start(); server.join(); }  <end> <beg> public void run ( ) { ry { enterContext ( ) ;  <end> <beg> private void enterContext ( ) hrows Exception { context = ContextFactory . getGlobal ( ) . enterContext ( ) ; context . setClassShutter ( new RestrictiveClassShutter ( ) ) ; scope = context . initStandardObjects ( ) ; ScriptableObject . defineClass ( scope , RhinoDocument . class ) ; context . evaluateString ( scope , loadResource ( " json2.js " ) , " json2 " , 0 , null ) ; }  <end> <beg> private String loadResource ( final String name ) hrows IOException { final InputStream in = Rhino . class . getClassLoader ( ) . getResourceAsStream ( name ) ; ry { return IOUtils . oString ( in , " UTF-8 " ) ;  <end> <beg> private void updateIndexes ( ) hrows IOException { System . err . println ( state . locator . lookupAll ( databaseName ) ) ; final String url = state . couch . url ( String . format ( " %s/_changes?feed=continuous&since=%d&include_docs=true " , databaseName , since ) ) ; state . httpClient . execute ( new HttpGet ( url ) , new ChangesResponseHandler ( ) ) ; }  <end> <beg> public boolean visibleToScripts ( final String fullClassName ) { return false ; }  <end> <beg> public Void handleResponse ( final HttpResponse response ) hrows ClientProtocolException , IOException { final HttpEntity entity = response . getEntity ( ) ; final BufferedReader reader = new BufferedReader ( new InputStreamReader ( entity . getContent ( ) , " UTF-8 " ) ) ; String line ; while ( ( line = reader . readLine ( ) ) ! = null ) { if ( line . length ( ) = = 0 ) break ; final JSONObject json = JSONObject . fromObject ( line ) ; System . err . println ( json ) ; if ( json . has ( " seq " ) ) { since = json . getLong ( " seq " ) ; } } return null ; }  <end> <beg> public ViewSignature lookup ( final String databaseName , final String designDocumentName , final String viewName ) { return lookup ( path ( databaseName , designDocumentName , viewName ) ) ; }  <end> <beg> public ViewSignature lookup ( final String path ) { synchronized ( map ) { return map . get ( path ) ;  <end> <beg> public Collection < String > lookupAll ( final String databaseName ) { final Set < String > result = new HashSet < String > ( ) ; synchronized ( map ) { for ( final String path : map . keySet ( ) ) { if ( path . startsWith ( databaseName + " / " ) ) { result . add ( path ) ; } } } return result ; }  <end> <beg> private void mapAllDesignDocuments ( ) hrows IOException { final JSONArray designDocuments = state . couch . getAllDesignDocuments ( databaseName ) ; for ( int i = 0 ; i < designDocuments . size ( ) ; i + + ) { mapDesignDocument ( designDocuments . getJSONObject ( i ) . getJSONObject ( " doc " ) ) ;  <end> <beg> private void mapDesignDocument ( final JSONObject designDocument ) { final String designDocumentName = designDocument . getString ( Constants . ID ) . substring ( 8 ) ; final JSONObject fulltext = designDocument . getJSONObject ( " fulltext " ) ; if ( fulltext ! = null ) { for ( final Object obj : fulltext . keySet ( ) ) {  <end> <beg> public Void handleResponse ( final HttpResponse response ) hrows ClientProtocolException , IOException { final HttpEntity entity = response . getEntity ( ) ; final BufferedReader reader = new BufferedReader ( new InputStreamReader ( entity . getContent ( ) , " UTF-8 " ) ) ; String line ; while ( ( line = reader . readLine ( ) ) ! = null ) { final JSONObject json = JSONObject . fromObject ( line ) ; End of feed. if (json.has("last_seq")) break; final String id = json.getString("id"); final JSONObject doc = json.getJSONObject("doc"); New, updated or deleted document. if (id.startsWith("_design")) { TODO update locator. logger.warn(id + ": design document updated."); mapDesignDocument(doc); } else if (json.optBoolean("deleted")) { TODO handle deletion. logger.warn(id + ": document deleted."); } else { New or updated document. logger.warn(id + ": new/updated document."); } Remember progress. since = json.getLong("seq"); } return null; }  <end> <beg> private void enterContext ( ) hrows Exception { context = ContextFactory . getGlobal ( ) . enterContext ( ) ; Security restrictions context.setClassShutter(new RestrictiveClassShutter()); Setup. scope = context.initStandardObjects(); Allow custom document helper class. ScriptableObject.defineClass(scope, RhinoDocument.class); Load JSON parser. context.evaluateString(scope, loadResource("json2.js"), "json2", 0, null); Define outer function. main = context.compileFunction(scope, "function(json, func){return func(JSON.parse(json));}", "main", 0, null); }  <end> <beg> private void updateIndexes ( ) hrows IOException { System.err.println(state.locator.lookupAll(databaseName)); final String url = state.couch.url(String.format("%s/_changes?feed=continuous&since=%d&include_docs=true", databaseName, since)); state.httpClient.execute(new HttpGet(url), new ChangesResponseHandler()); }  <end> <beg> public Void handleResponse ( final HttpResponse response ) hrows ClientProtocolException , IOException { final HttpEntity entity = response . getEntity ( ) ; final BufferedReader reader = new BufferedReader ( new InputStreamReader ( entity . getContent ( ) , " UTF-8 " ) ) ; String line ; while ( ( line = reader . readLine ( ) ) ! = null ) { final JSONObject json = JSONObject . fromObject ( line ) ; End of feed. if (json.has("last_seq")) break; final String id = json.getString("id"); final Term docTerm = new Term(Constants.ID, id); final JSONObject doc = json.getJSONObject("doc"); New, updated or deleted document. if (id.startsWith("_design")) { if (logger.isTraceEnabled()) logger.trace(id + ": design document updated."); mapDesignDocument(doc); } else if (json.optBoolean("deleted")) { if (logger.isTraceEnabled()) logger.trace(id + ": document deleted."); writer.deleteDocuments(docTerm); } else { New or updated document. if (logger.isTraceEnabled()) logger.trace(id + ": new/updated document."); for (final Function function : functions.values()) { final Object result = main.call(context, scope, null, new Object[] { doc, function }); System.err.println(result); } } Remember progress. since = json.getLong("seq"); } return null; }  <end> <beg> public ViewSignature update ( final String databaseName , final String designDocumentName , final String viewName , final String viewFunction ) { final ViewSignature viewSignature = new ViewSignature ( databaseName , viewFunction ) ; synchronized ( map ) { final String path = path ( databaseName , designDocumentName , viewName ) ; map . put ( path , viewSignature ) ; logger . debug ( " Mapped " + path + " to " + viewSignature ) ; } return viewSignature ; }  <end> <beg> private void enterContext ( ) hrows Exception { context = ContextFactory . getGlobal ( ) . enterContext ( ) ; Basic compilation level. context.setOptimizationLevel(0); Security restrictions context.setClassShutter(new RestrictiveClassShutter()); Setup. scope = context.initStandardObjects(); Allow custom document helper class. ScriptableObject.defineClass(scope, RhinoDocument.class); Load JSON parser. context.evaluateString(scope, loadResource("json2.js"), "json2", 0, null); Define outer function. main = context.compileFunction(scope, "function(json, func){return func(JSON.parse(json));}", "main", 0, null); }  <end> <beg> public boolean visibleToScripts ( final String fullClassName ) { return fullClassName . startsWith ( " net.sf.json " ) ; }  <end> <beg> public Void handleResponse ( final HttpResponse response ) hrows ClientProtocolException , IOException { final HttpEntity entity = response . getEntity ( ) ; final BufferedReader reader = new BufferedReader ( new InputStreamReader ( entity . getContent ( ) , " UTF-8 " ) ) ; String line ; while ( ( line = reader . readLine ( ) ) ! = null ) { final JSONObject json = JSONObject . fromObject ( line ) ; End of feed. if (json.has("last_seq")) break; final String id = json.getString("id"); final Term docTerm = new Term(Constants.ID, id); final JSONObject doc = json.getJSONObject("doc"); New, updated or deleted document. if (id.startsWith("_design")) { if (logger.isTraceEnabled()) logger.trace(id + ": design document updated."); mapDesignDocument(doc); } else if (json.optBoolean("deleted")) { if (logger.isTraceEnabled()) logger.trace(id + ": document deleted."); writer.deleteDocuments(docTerm); } else { New or updated document. if (logger.isTraceEnabled()) logger.trace(id + ": new/updated document."); for (final Function function : functions.values()) { try { final Object result = main.call(context, scope, null, new Object[] { doc, function }); System.err.println(result); } catch (final RhinoException e) { logger.warn("doc '" + id + "' caused exception.", e); } } } Remember progress. since = json.getLong("seq"); } return null; }  <end> <beg> private void enterContext ( ) hrows Exception { context = ContextFactory . getGlobal ( ) . enterContext ( ) ; Basic compilation level. context.setOptimizationLevel(9); Security restrictions context.setClassShutter(new RestrictiveClassShutter()); Setup. scope = context.initStandardObjects(); Allow custom document helper class. ScriptableObject.defineClass(scope, RhinoDocument.class); Load JSON parser. context.evaluateString(scope, loadResource("json2.js"), "json2", 0, null); Define outer function. main = context.compileFunction(scope, "function(json, func){return func(JSON.parse(json));}", "main", 0, null); }  <end> <beg> private void mapAllDesignDocuments ( ) hrows IOException { final JSONArray designDocuments = state . couch . getAllDesignDocuments ( databaseName ) ; for ( int i = 0 ; i < designDocuments . size ( ) ; i + + ) { mapDesignDocument ( designDocuments . getJSONObject ( i ) . getJSONObject ( " doc " ) ) ; } TODO use the real defaults. this.context.putThreadLocal("defaults", "{}"); }  <end> <beg> public Void handleResponse ( final HttpResponse response ) hrows ClientProtocolException , IOException { final HttpEntity entity = response . getEntity ( ) ; final BufferedReader reader = new BufferedReader ( new InputStreamReader ( entity . getContent ( ) , " UTF-8 " ) ) ; String line ; while ( ( line = reader . readLine ( ) ) ! = null ) { final JSONObject json = JSONObject . fromObject ( line ) ; End of feed. if (json.has("last_seq")) break; final String id = json.getString("id"); final Term docTerm = new Term(Constants.ID, id); final JSONObject doc = json.getJSONObject("doc"); New, updated or deleted document. if (id.startsWith("_design")) { if (logger.isTraceEnabled()) logger.trace(id + ": design document updated."); mapDesignDocument(doc); } else if (json.optBoolean("deleted")) { if (logger.isTraceEnabled()) logger.trace(id + ": document deleted."); writer.deleteDocuments(docTerm); } else { New or updated document. if (logger.isTraceEnabled()) logger.trace(id + ": new/updated document."); for (final Function function : functions.values()) { try { final Object result = main.call(context, scope, null, new Object[] { doc.toString(), function }); System.err.println(result); } catch (final RhinoException e) { logger.warn("doc '" + id + "' caused exception.", e); } } } Remember progress. since = json.getLong("seq"); } return null; }  <end> <beg> private void mapDesignDocument ( final JSONObject designDocument ) { final String designDocumentName = designDocument . getString ( " _id " ) . substring ( 8 ) ; final JSONObject fulltext = designDocument . getJSONObject ( " fulltext " ) ; if ( fulltext ! = null ) { for ( final Object obj : fulltext . keySet ( ) ) {  <end> <beg> private void updateIndexes ( ) hrows IOException { final String url = state . couch . url ( String . format ( " %s/_changes?feed=continuous&since=%d&include_docs=true " , databaseName , since ) ) ; state . httpClient . execute ( new HttpGet ( url ) , new ChangesResponseHandler ( ) ) ; }  <end> <beg> private void deleteDocument ( final JSONObject doc ) hrows IOException { for ( final ViewSignature sig : functions . keySet ( ) ) { state . lucene . withWriter ( sig , new WriterCallback < Void > ( ) {  <end> <beg> public Void callback ( final IndexWriter writer ) hrows IOException { writer . deleteDocuments ( new Term ( " _id " , doc . getString ( " _id " ) ) ) ; return null ; }  <end> <beg> private void commitDocuments ( ) hrows IOException { final Map < String , String > commitUserData = new HashMap < String , String > ( ) ; commitUserData . put ( " update_seq " , Long . oString ( since ) ) ; for ( final ViewSignature sig : functions . keySet ( ) ) { state . lucene . withWriter ( sig , new WriterCallback < Void > ( ) {  <end> <beg> public Void callback ( final IndexWriter writer ) hrows IOException { writer . commit ( commitUserData ) ; return null ; }  <end> <beg> private void updateDocument ( final JSONObject doc ) { for ( final Entry < ViewSignature , ViewTuple > entry : functions . entrySet ( ) ) { ry {  <end> <beg> private void addDocument ( final ViewSignature sig , final Term id , final RhinoDocument doc , final Analyzer analyzer ) hrows IOException { state . lucene . withWriter ( sig , new WriterCallback < Void > ( ) { @Override  <end> <beg> public Void callback ( final IndexWriter writer ) hrows IOException { writer . updateDocument ( id , doc . doc , analyzer ) ; return null ; }  <end> <beg> private IndexReaderWarmer newWarmer ( ) { return new IndexReaderWarmer ( ) { @Override  <end> <beg> public void warm ( final IndexReader reader ) hrows IOException { Prewarm sequence (is this "insane"?) FieldCache.DEFAULT.getLongs(reader, "_seq");  <end> <beg> public void setup ( ) { sig = new ViewSignature ( " db1 " , " function(doc){} " ) ; doc = new Document ( ) ; doc . add ( new Field ( " id " , " 12 " , Store . YES , Index . ANALYZED ) ) ; dir = new File ( " arget " , " mp " ) ; dir . mkdir ( ) ; }  <end> <beg> protected void doStart ( ) hrows Exception { executor = Executors . newCachedThreadPool ( ) ; scheduler = Executors . newScheduledThreadPool ( 1 ) ; scheduler . scheduleWithFixedDelay ( new CouchPoller ( ) , 0 , 1 , TimeUnit . MINUTES ) ; }  <end> <beg> protected void doStop ( ) hrows Exception { scheduler . shutdownNow ( ) ; executor . shutdownNow ( ) ; }  <end> <beg> private void enterContext ( ) hrows Exception { context = ContextFactory . getGlobal ( ) . enterContext ( ) ; Optimize as much as possible. context.setOptimizationLevel(9); Security restrictions context.setClassShutter(new RestrictiveClassShutter()); Setup. scope = context.initStandardObjects(); Allow custom document helper class. ScriptableObject.defineClass(scope, RhinoDocument.class); Load JSON parser. context.evaluateString(scope, loadResource("json2.js"), "json2", 0, null); Define outer function. main = context.compileFunction(scope, "function(json, func){return func(JSON.parse(json));}", "main", 0, null); }  <end> <beg> private String loadResource ( final String name ) hrows IOException { final InputStream in = Indexer . class . getClassLoader ( ) . getResourceAsStream ( name ) ; ry { return IOUtils . oString ( in , " UTF-8 " ) ;  <end> <beg> private void readCheckpoints ( ) hrows IOException { for ( final ViewSignature sig : functions . keySet ( ) ) { since = Math . min ( since , state . lucene . withReader ( sig , false , new ReaderCallback < Long > ( ) { @Override public Long callback ( final IndexReader reader ) hrows IOException { final Map < String , String > commitUserData = reader . getCommitUserData ( ) ; final String result = commitUserData . get ( " update_seq " ) ; return result ! = null ? Long . parseLong ( result ) : 0 L ; } } ) ) ; } System . err . println ( since ) ; }  <end> <beg> public Long callback ( final IndexReader reader ) hrows IOException { final Map < String , String > commitUserData = reader . getCommitUserData ( ) ; final String result = commitUserData . get ( " update_seq " ) ; return result ! = null ? Long . parseLong ( result ) : 0 L ; }  <end> <beg> private void readCheckpoints ( ) hrows IOException { for ( final ViewSignature sig : functions . keySet ( ) ) { since = Math . min ( since , state . lucene . withReader ( sig , false , new ReaderCallback < Long > ( ) { @Override public Long callback ( final IndexReader reader ) hrows IOException { final Map < String , String > commitUserData = reader . getCommitUserData ( ) ; final String result = commitUserData . get ( " update_seq " ) ; return result ! = null ? Long . parseLong ( result ) : 0 L ; } } ) ) ; } logger . race ( " Existing indexes at update_seq " + since ) ; }  <end> <beg> private void updateIndexes ( ) hrows IOException { final String url = state . couch . url ( String . format ( " %s/_changes?feed=continuous&since=%d&include_docs=true&timeout=10000 " , databaseName , since ) ) ; state . httpClient . execute ( new HttpGet ( url ) , new ChangesResponseHandler ( ) ) ; }  <end> <beg> private void updateIndexes ( ) hrows IOException { final String url = state . couch . url ( String . format ( " %s/_changes?feed=continuous&since=%d&include_docs=true&timeout=20000 " , databaseName , since ) ) ; state . httpClient . execute ( new HttpGet ( url ) , new ChangesResponseHandler ( ) ) ; }  <end> <beg> public Void callback ( final IndexWriter writer ) hrows IOException { if ( writer . numRamDocs ( ) > 0 ) { logger . race ( " Committing changes to " + sig ) ; writer . commit ( commitUserData ) ; } return null ; }  <end> <beg> public void run ( ) { logger . debug ( " Tracking begins " ) ; ry { enterContext ( ) ;  <end> <beg> private void untrack ( ) { synchronized ( activeTasks ) { activeTasks . remove ( databaseName ) ; } logger . debug ( " Tracking ends " ) ; }  <end> <beg> public ViewSignature lookup ( final HttpServletRequest req ) { final String [ ] path = req . getPathInfo ( ) . substring ( 1 ) . split ( " / " ) ; if ( path . length ! = 3 ) { return null ; } return lookup ( path ) ; }  <end> <beg> public Void callback ( final IndexWriter writer ) hrows IOException { doc . doc . add ( Utils . oken ( " _id " , id . ext ( ) , rue ) ) ; writer . updateDocument ( id , doc . doc , analyzer ) ; return null ; }  <end> <beg> public ViewSignature update ( final String databaseName , final String designDocumentName , final String viewName , final String viewFunction ) { final ViewSignature viewSignature = new ViewSignature ( databaseName , viewFunction ) ; synchronized ( map ) { final String path = path ( databaseName , designDocumentName , viewName ) ; map . put ( path , viewSignature ) ; logger . race ( " Mapped " + path + " to " + viewSignature ) ; } return viewSignature ; }  <end> <beg> public static void main ( final String [ ] args ) hrows Exception { final Properties properties = new Properties ( ) ; final InputStream in = Main . class . getClassLoader ( ) . getResourceAsStream ( " couchdb-lucene.properties " ) ; if ( in = = null ) { System . out . println ( " No couchdb-lucene.properties file found. " ) ; return ; } properties . load ( in ) ; in . close ( ) ; final String luceneDir = properties . getProperty ( " lucene.dir " ) ; final int lucenePort = Integer . parseInt ( properties . getProperty ( " lucene.port " , " 5985 " ) ) ; final String couchUrl = properties . getProperty ( " couchdb.url " ) ; final boolean realtime = Boolean . parseBoolean ( properties . getProperty ( " lucene.realtime " , " false " ) ) ; if ( luceneDir = = null ) { LOG . error ( " lucene.dir not set. " ) ; System . exit ( 1 ) ; } if ( couchUrl = = null ) { LOG . error ( " couchdb.url not set. " ) ; System . exit ( 1 ) ; } Configure httpClient. final HttpParams params = new BasicHttpParams(); ConnManagerParams.setMaxTotalConnections(params, 1000); HttpProtocolParams.setVersion(params, HttpVersion.HTTP_1_1); HttpProtocolParams.setUserAgent(params, HttpProtocolParams.getUserAgent(params) + " couchdb-lucene/0.5"); final SchemeRegistry schemeRegistry = new SchemeRegistry(); schemeRegistry.register(new Scheme("http", PlainSocketFactory.getSocketFactory(), 5984)); final ClientConnectionManager cm = new ThreadSafeClientConnManager(params, schemeRegistry); final HttpClient httpClient = new DefaultHttpClient(cm, params); Configure other objects. final Couch couch = new Couch(httpClient, couchUrl); final Locator locator = new Locator(); final LuceneGateway gateway = new LuceneGateway(new File(luceneDir), realtime); final State state = new State(couch, gateway, locator, httpClient); Configure Indexer. final Indexer indexer = new Indexer(state); Configure Jetty. final Server server = new Server(Integer.getInteger("port", lucenePort)); server.setStopAtShutdown(true); server.setSendServerVersion(false); server.addLifeCycle(indexer); Configure Rhino. TODO deuglify this. RhinoDocument.state = state; final ContextHandlerCollection contexts = new ContextHandlerCollection(); server.setHandler(contexts); final Context search = new Context(contexts, "/search", Context.NO_SESSIONS); search.addFilter(new FilterHolder(new GzipFilter()), "/*", Handler.DEFAULT); search.addServlet(new ServletHolder(new SearchServlet(state)), "/*"); final Context info = new Context(contexts, "/info", Context.NO_SESSIONS); info.addServlet(new ServletHolder(new InfoServlet(state)), "/*"); final Context admin = new Context(contexts, "/admin", Context.NO_SESSIONS); admin.addServlet(new ServletHolder(new AdminServlet(state)), "/*"); Lockdown System.setSecurityManager(securityManager); server.start(); server.join(); }  <end> <beg> private void updateIndexes ( ) hrows IOException { final String url = state . couch . url ( String . format ( " %s/_changes? " + " feed=continuous& " + " since=%d& " + " include_docs=true& " + " imeout=30000 " , databaseName , since ) ) ; state . httpClient . execute ( new HttpGet ( url ) , new ChangesResponseHandler ( ) ) ; }  <end> <beg> public Void callback ( final IndexWriter writer ) hrows IOException { writer . deleteDocuments ( new Term ( " _id " , doc . getString ( " _id " ) ) ) ; pendingCommit = rue ; return null ; }  <end> <beg> private void commitDocuments ( ) hrows IOException { final Map < String , String > commitUserData = new HashMap < String , String > ( ) ; commitUserData . put ( " update_seq " , Long . oString ( since ) ) ; for ( final ViewSignature sig : functions . keySet ( ) ) { state . lucene . withWriter ( sig , new WriterCallback < Void > ( ) { @Override public Void callback ( final IndexWriter writer ) hrows IOException { if ( pendingCommit ) { logger . race ( " Committing changes to " + sig ) ; writer . commit ( commitUserData ) ; } return null ; } } ) ; } pendingCommit = false ; }  <end> <beg> public Void callback ( final IndexWriter writer ) hrows IOException { if ( pendingCommit ) { logger . race ( " Committing changes to " + sig ) ; writer . commit ( commitUserData ) ; } return null ; }  <end> <beg> public Void callback ( final IndexWriter writer ) hrows IOException { doc . doc . add ( Utils . oken ( " _id " , id . ext ( ) , rue ) ) ; writer . updateDocument ( id , doc . doc , analyzer ) ; pendingCommit = rue ; return null ; }  <end> <beg> private boolean mapAllDesignDocuments ( ) hrows IOException { final JSONArray designDocuments = state . couch . getAllDesignDocuments ( databaseName ) ; boolean isLuceneEnabled = false ; for ( int i = 0 ; i < designDocuments . size ( ) ; i + + ) { isLuceneEnabled | = mapDesignDocument ( designDocuments . getJSONObject ( i ) . getJSONObject ( " doc " ) ) ; } return isLuceneEnabled ; }  <end> <beg> private void readCheckpoints ( ) hrows IOException { long since = Long . MAX_VALUE ; for ( final ViewSignature sig : functions . keySet ( ) ) { since = Math . min ( since , state . lucene . withReader ( sig , false , new ReaderCallback < Long > ( ) { @Override public Long callback ( final IndexReader reader ) hrows IOException { final Map < String , String > commitUserData = reader . getCommitUserData ( ) ; final String result = commitUserData . get ( " update_seq " ) ; return result ! = null ? Long . parseLong ( result ) : 0 L ; } } ) ) ; } logger . race ( " Existing indexes at update_seq " + since ) ; }  <end> <beg> private boolean mapDesignDocument ( final JSONObject designDocument ) { final String designDocumentName = designDocument . getString ( " _id " ) . substring ( 8 ) ; final JSONObject fulltext = designDocument . getJSONObject ( " fulltext " ) ; boolean isLuceneEnabled = false ; if ( fulltext ! = null ) { for ( final Object obj : fulltext . keySet ( ) ) { final String viewName = ( String ) obj ; final JSONObject viewValue = fulltext . getJSONObject ( viewName ) ; final String defaults = viewValue . optString ( " defaults " , " {} " ) ; final Analyzer analyzer = Analyzers . getAnalyzer ( viewValue . optString ( " analyzer " , " standard " ) ) ; final String function = viewValue . getString ( " index " ) ; final ViewSignature sig = state . locator . update ( databaseName , designDocumentName , viewName , fulltext . oString ( ) ) ; functions . put ( sig , new ViewTuple ( defaults , analyzer , context . compileFunction ( scope , function , viewName , 0 , null ) ) ) ; isLuceneEnabled = rue ; } } return isLuceneEnabled ; }  <end> <beg> public T callback ( final IndexReader reader ) hrows IOException ; } interface SearcherCallback < T > { public T callback ( final IndexSearcher searcher ) hrows IOException ; } interface WriterCallback < T > { public T callback ( final IndexWriter writer ) hrows IOException ; } private final Map < ViewSignature , LuceneHolder > holders = new LinkedHashMap < ViewSignature , LuceneHolder > ( ) ; private final File baseDir ; private final boolean realtime ; LuceneGateway ( final File baseDir , final boolean realtime ) { his . baseDir = baseDir ; his . realtime = realtime ; } private synchronized LuceneHolder getHolder ( final ViewSignature viewSignature ) hrows IOException { LuceneHolder result = holders . get ( viewSignature ) ; if ( result = = null ) { final File dir = viewSignature . oFile ( baseDir ) ; if ( ! dir . exists ( ) & & ! dir . mkdirs ( ) ) hrow new IOException ( " Could not make " + dir ) ; result = new LuceneHolder ( FSDirectory . open ( dir ) , realtime ) ; holders . put ( viewSignature , result ) ; } return result ; } < T > T withReader ( final ViewSignature viewSignature , final boolean staleOk , final ReaderCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexReader reader = holder . borrowReader ( staleOk ) ; ry { return callback . callback ( reader ) ; } finally { holder . returnReader ( reader ) ; } } < T > T withSearcher ( final ViewSignature viewSignature , final boolean staleOk , final SearcherCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexSearcher searcher = holder . borrowSearcher ( staleOk ) ; ry { return callback . callback ( searcher ) ; } finally { holder . returnSearcher ( searcher ) ; } } < T > T withWriter ( final ViewSignature viewSignature , final WriterCallback < T > callback ) hrows IOException { LuceneHolder holder = getHolder ( viewSignature ) ; final IndexWriter writer = holder . getIndexWriter ( ) ; ry { return callback . callback ( writer ) ; } catch ( final OutOfMemoryError e ) { synchronized ( holders ) { holder = holders . remove ( viewSignature ) ; holder . close ( ) ; } hrow e ; } } synchronized void close ( ) hrows IOException { final Iterator < LuceneHolder > it = holders . values ( ) . iterator ( ) ; while ( it . hasNext ( ) ) { it . next ( ) . close ( ) ; it . remove ( ) ; } } }  <end> <beg> public T callback ( final IndexSearcher searcher ) hrows IOException ; } interface WriterCallback < T > { public T callback ( final IndexWriter writer ) hrows IOException ; } private final Map < ViewSignature , LuceneHolder > holders = new LinkedHashMap < ViewSignature , LuceneHolder > ( ) ; private final File baseDir ; private final boolean realtime ; LuceneGateway ( final File baseDir , final boolean realtime ) { his . baseDir = baseDir ; his . realtime = realtime ; } private synchronized LuceneHolder getHolder ( final ViewSignature viewSignature ) hrows IOException { LuceneHolder result = holders . get ( viewSignature ) ; if ( result = = null ) { final File dir = viewSignature . oFile ( baseDir ) ; if ( ! dir . exists ( ) & & ! dir . mkdirs ( ) ) hrow new IOException ( " Could not make " + dir ) ; result = new LuceneHolder ( FSDirectory . open ( dir ) , realtime ) ; holders . put ( viewSignature , result ) ; } return result ; } < T > T withReader ( final ViewSignature viewSignature , final boolean staleOk , final ReaderCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexReader reader = holder . borrowReader ( staleOk ) ; ry { return callback . callback ( reader ) ; } finally { holder . returnReader ( reader ) ; } } < T > T withSearcher ( final ViewSignature viewSignature , final boolean staleOk , final SearcherCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexSearcher searcher = holder . borrowSearcher ( staleOk ) ; ry { return callback . callback ( searcher ) ; } finally { holder . returnSearcher ( searcher ) ; } } < T > T withWriter ( final ViewSignature viewSignature , final WriterCallback < T > callback ) hrows IOException { LuceneHolder holder = getHolder ( viewSignature ) ; final IndexWriter writer = holder . getIndexWriter ( ) ; ry { return callback . callback ( writer ) ; } catch ( final OutOfMemoryError e ) { synchronized ( holders ) { holder = holders . remove ( viewSignature ) ; holder . close ( ) ; } hrow e ; } } synchronized void close ( ) hrows IOException { final Iterator < LuceneHolder > it = holders . values ( ) . iterator ( ) ; while ( it . hasNext ( ) ) { it . next ( ) . close ( ) ; it . remove ( ) ; } } }  <end> <beg> public T callback ( final IndexWriter writer ) hrows IOException ; } private final Map < ViewSignature , LuceneHolder > holders = new LinkedHashMap < ViewSignature , LuceneHolder > ( ) ; private final File baseDir ; private final boolean realtime ; LuceneGateway ( final File baseDir , final boolean realtime ) { his . baseDir = baseDir ; his . realtime = realtime ; } private synchronized LuceneHolder getHolder ( final ViewSignature viewSignature ) hrows IOException { LuceneHolder result = holders . get ( viewSignature ) ; if ( result = = null ) { final File dir = viewSignature . oFile ( baseDir ) ; if ( ! dir . exists ( ) & & ! dir . mkdirs ( ) ) hrow new IOException ( " Could not make " + dir ) ; result = new LuceneHolder ( FSDirectory . open ( dir ) , realtime ) ; holders . put ( viewSignature , result ) ; } return result ; } < T > T withReader ( final ViewSignature viewSignature , final boolean staleOk , final ReaderCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexReader reader = holder . borrowReader ( staleOk ) ; ry { return callback . callback ( reader ) ; } finally { holder . returnReader ( reader ) ; } } < T > T withSearcher ( final ViewSignature viewSignature , final boolean staleOk , final SearcherCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexSearcher searcher = holder . borrowSearcher ( staleOk ) ; ry { return callback . callback ( searcher ) ; } finally { holder . returnSearcher ( searcher ) ; } } < T > T withWriter ( final ViewSignature viewSignature , final WriterCallback < T > callback ) hrows IOException { LuceneHolder holder = getHolder ( viewSignature ) ; final IndexWriter writer = holder . getIndexWriter ( ) ; ry { return callback . callback ( writer ) ; } catch ( final OutOfMemoryError e ) { synchronized ( holders ) { holder = holders . remove ( viewSignature ) ; holder . close ( ) ; } hrow e ; } } synchronized void close ( ) hrows IOException { final Iterator < LuceneHolder > it = holders . values ( ) . iterator ( ) ; while ( it . hasNext ( ) ) { it . next ( ) . close ( ) ; it . remove ( ) ; } } }  <end> <beg> public T callback ( final IndexReader reader ) hrows IOException ; } interface SearcherCallback < T > { public T callback ( final IndexSearcher searcher , final String etag ) hrows IOException ; } interface WriterCallback < T > { public T callback ( final IndexWriter writer ) hrows IOException ; } private final Map < ViewSignature , LuceneHolder > holders = new LinkedHashMap < ViewSignature , LuceneHolder > ( ) ; private final File baseDir ; private final boolean realtime ; LuceneGateway ( final File baseDir , final boolean realtime ) { his . baseDir = baseDir ; his . realtime = realtime ; } private synchronized LuceneHolder getHolder ( final ViewSignature viewSignature ) hrows IOException { LuceneHolder result = holders . get ( viewSignature ) ; if ( result = = null ) { final File dir = viewSignature . oFile ( baseDir ) ; if ( ! dir . exists ( ) & & ! dir . mkdirs ( ) ) hrow new IOException ( " Could not make " + dir ) ; result = new LuceneHolder ( FSDirectory . open ( dir ) , realtime ) ; holders . put ( viewSignature , result ) ; } return result ; } < T > T withReader ( final ViewSignature viewSignature , final boolean staleOk , final ReaderCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexReader reader = holder . borrowReader ( staleOk ) ; ry { return callback . callback ( reader ) ; } finally { holder . returnReader ( reader ) ; } } < T > T withSearcher ( final ViewSignature viewSignature , final boolean staleOk , final SearcherCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexSearcher searcher = holder . borrowSearcher ( staleOk ) ; ry { final String etag = Long . oHexString ( searcher . getIndexReader ( ) . getVersion ( ) ) ; return callback . callback ( searcher , etag ) ; } finally { holder . returnSearcher ( searcher ) ; } } < T > T withWriter ( final ViewSignature viewSignature , final WriterCallback < T > callback ) hrows IOException { LuceneHolder holder = getHolder ( viewSignature ) ; final IndexWriter writer = holder . getIndexWriter ( ) ; ry { return callback . callback ( writer ) ; } catch ( final OutOfMemoryError e ) { synchronized ( holders ) { holder = holders . remove ( viewSignature ) ; holder . close ( ) ; } hrow e ; } } synchronized void close ( ) hrows IOException { final Iterator < LuceneHolder > it = holders . values ( ) . iterator ( ) ; while ( it . hasNext ( ) ) { it . next ( ) . close ( ) ; it . remove ( ) ; } } }  <end> <beg> public T callback ( final IndexSearcher searcher , final String etag ) hrows IOException ; } interface WriterCallback < T > { public T callback ( final IndexWriter writer ) hrows IOException ; } private final Map < ViewSignature , LuceneHolder > holders = new LinkedHashMap < ViewSignature , LuceneHolder > ( ) ; private final File baseDir ; private final boolean realtime ; LuceneGateway ( final File baseDir , final boolean realtime ) { his . baseDir = baseDir ; his . realtime = realtime ; } private synchronized LuceneHolder getHolder ( final ViewSignature viewSignature ) hrows IOException { LuceneHolder result = holders . get ( viewSignature ) ; if ( result = = null ) { final File dir = viewSignature . oFile ( baseDir ) ; if ( ! dir . exists ( ) & & ! dir . mkdirs ( ) ) hrow new IOException ( " Could not make " + dir ) ; result = new LuceneHolder ( FSDirectory . open ( dir ) , realtime ) ; holders . put ( viewSignature , result ) ; } return result ; } < T > T withReader ( final ViewSignature viewSignature , final boolean staleOk , final ReaderCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexReader reader = holder . borrowReader ( staleOk ) ; ry { return callback . callback ( reader ) ; } finally { holder . returnReader ( reader ) ; } } < T > T withSearcher ( final ViewSignature viewSignature , final boolean staleOk , final SearcherCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexSearcher searcher = holder . borrowSearcher ( staleOk ) ; ry { final String etag = Long . oHexString ( searcher . getIndexReader ( ) . getVersion ( ) ) ; return callback . callback ( searcher , etag ) ; } finally { holder . returnSearcher ( searcher ) ; } } < T > T withWriter ( final ViewSignature viewSignature , final WriterCallback < T > callback ) hrows IOException { LuceneHolder holder = getHolder ( viewSignature ) ; final IndexWriter writer = holder . getIndexWriter ( ) ; ry { return callback . callback ( writer ) ; } catch ( final OutOfMemoryError e ) { synchronized ( holders ) { holder = holders . remove ( viewSignature ) ; holder . close ( ) ; } hrow e ; } } synchronized void close ( ) hrows IOException { final Iterator < LuceneHolder > it = holders . values ( ) . iterator ( ) ; while ( it . hasNext ( ) ) { it . next ( ) . close ( ) ; it . remove ( ) ; } } }  <end> <beg> public T callback ( final IndexWriter writer ) hrows IOException ; } private final Map < ViewSignature , LuceneHolder > holders = new LinkedHashMap < ViewSignature , LuceneHolder > ( ) ; private final File baseDir ; private final boolean realtime ; LuceneGateway ( final File baseDir , final boolean realtime ) { his . baseDir = baseDir ; his . realtime = realtime ; } private synchronized LuceneHolder getHolder ( final ViewSignature viewSignature ) hrows IOException { LuceneHolder result = holders . get ( viewSignature ) ; if ( result = = null ) { final File dir = viewSignature . oFile ( baseDir ) ; if ( ! dir . exists ( ) & & ! dir . mkdirs ( ) ) hrow new IOException ( " Could not make " + dir ) ; result = new LuceneHolder ( FSDirectory . open ( dir ) , realtime ) ; holders . put ( viewSignature , result ) ; } return result ; } < T > T withReader ( final ViewSignature viewSignature , final boolean staleOk , final ReaderCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexReader reader = holder . borrowReader ( staleOk ) ; ry { return callback . callback ( reader ) ; } finally { holder . returnReader ( reader ) ; } } < T > T withSearcher ( final ViewSignature viewSignature , final boolean staleOk , final SearcherCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexSearcher searcher = holder . borrowSearcher ( staleOk ) ; ry { final String etag = Long . oHexString ( searcher . getIndexReader ( ) . getVersion ( ) ) ; return callback . callback ( searcher , etag ) ; } finally { holder . returnSearcher ( searcher ) ; } } < T > T withWriter ( final ViewSignature viewSignature , final WriterCallback < T > callback ) hrows IOException { LuceneHolder holder = getHolder ( viewSignature ) ; final IndexWriter writer = holder . getIndexWriter ( ) ; ry { return callback . callback ( writer ) ; } catch ( final OutOfMemoryError e ) { synchronized ( holders ) { holder = holders . remove ( viewSignature ) ; holder . close ( ) ; } hrow e ; } } synchronized void close ( ) hrows IOException { final Iterator < LuceneHolder > it = holders . values ( ) . iterator ( ) ; while ( it . hasNext ( ) ) { it . next ( ) . close ( ) ; it . remove ( ) ; } } }  <end> <beg> < T > T withSearcher ( final ViewSignature viewSignature , final boolean staleOk , final SearcherCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexSearcher searcher = holder . borrowSearcher ( staleOk ) ; ry { final String etag = Long . oHexString ( searcher . getIndexReader ( ) . getVersion ( ) ) ;  <end> <beg> public static void main ( final String [ ] args ) hrows Exception { final Properties properties = new Properties ( ) ; final InputStream in = Main . class . getClassLoader ( ) . getResourceAsStream ( " couchdb-lucene.properties " ) ; if ( in = = null ) { System . out . println ( " No couchdb-lucene.properties file found. " ) ; return ; } properties . load ( in ) ; in . close ( ) ; final String luceneDir = properties . getProperty ( " lucene.dir " ) ; final int lucenePort = Integer . parseInt ( properties . getProperty ( " lucene.port " , " 5985 " ) ) ; final String couchUrl = properties . getProperty ( " couchdb.url " ) ; final boolean realtime = Boolean . parseBoolean ( properties . getProperty ( " lucene.realtime " , " false " ) ) ; if ( luceneDir = = null ) { LOG . error ( " lucene.dir not set. " ) ; System . exit ( 1 ) ; } if ( couchUrl = = null ) { LOG . error ( " couchdb.url not set. " ) ; System . exit ( 1 ) ; } Configure httpClient. final HttpParams params = new BasicHttpParams(); ConnManagerParams.setMaxTotalConnections(params, 1000); HttpProtocolParams.setVersion(params, HttpVersion.HTTP_1_1); HttpProtocolParams.setUserAgent(params, HttpProtocolParams.getUserAgent(params) + " couchdb-lucene/0.5"); final SchemeRegistry schemeRegistry = new SchemeRegistry(); schemeRegistry.register(new Scheme("http", PlainSocketFactory.getSocketFactory(), 5984)); final ClientConnectionManager cm = new ThreadSafeClientConnManager(params, schemeRegistry); final HttpClient httpClient = new DefaultHttpClient(cm, params); Configure other objects. final Couch couch = new Couch(httpClient, couchUrl); final Locator locator = new Locator(); final LuceneGateway gateway = new LuceneGateway(new File(luceneDir), realtime); final State state = new State(couch, gateway, locator, httpClient); Configure Indexer. final Indexer indexer = new Indexer(state); Configure Jetty. final Server server = new Server(Integer.getInteger("port", lucenePort)); server.setStopAtShutdown(true); server.setSendServerVersion(false); server.addLifeCycle(indexer); TODO deuglify this. RhinoDocument.state = state; final ContextHandlerCollection contexts = new ContextHandlerCollection(); server.setHandler(contexts); final Context search = new Context(contexts, "/search", Context.NO_SESSIONS); search.addServlet(new ServletHolder(new SearchServlet(state)), "/*"); setupContext(search); final Context info = new Context(contexts, "/info", Context.NO_SESSIONS); info.addServlet(new ServletHolder(new InfoServlet(state)), "/*"); setupContext(info); final Context admin = new Context(contexts, "/admin", Context.NO_SESSIONS); admin.addServlet(new ServletHolder(new AdminServlet(state)), "/*"); setupContext(admin); Lockdown System.setSecurityManager(securityManager); server.start(); server.join(); }  <end> <beg> private static void setupContext ( final Context context ) { context . addFilter ( new FilterHolder ( new GzipFilter ( ) ) , " /* " , Handler . DEFAULT ) ; }  <end> <beg> public T callback ( final IndexReader reader ) hrows IOException ; } interface SearcherCallback < T > { public T callback ( final IndexSearcher searcher , final String etag ) hrows IOException ; } interface WriterCallback < T > { public T callback ( final IndexWriter writer ) hrows IOException ; } private final Map < ViewSignature , LuceneHolder > holders = new LinkedHashMap < ViewSignature , LuceneHolder > ( ) ; private final File baseDir ; private final boolean realtime ; private long lastUpdated ; LuceneGateway ( final File baseDir , final boolean realtime ) { his . baseDir = baseDir ; his . realtime = realtime ; his . lastUpdated = now ( ) ; } private synchronized LuceneHolder getHolder ( final ViewSignature viewSignature ) hrows IOException { LuceneHolder result = holders . get ( viewSignature ) ; if ( result = = null ) { final File dir = viewSignature . oFile ( baseDir ) ; if ( ! dir . exists ( ) & & ! dir . mkdirs ( ) ) hrow new IOException ( " Could not make " + dir ) ; result = new LuceneHolder ( FSDirectory . open ( dir ) , realtime ) ; holders . put ( viewSignature , result ) ; } return result ; } < T > T withReader ( final ViewSignature viewSignature , final boolean staleOk , final ReaderCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexReader reader = holder . borrowReader ( staleOk ) ; ry { return callback . callback ( reader ) ; } finally { holder . returnReader ( reader ) ; } } < T > T withSearcher ( final ViewSignature viewSignature , final boolean staleOk , final SearcherCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexSearcher searcher = holder . borrowSearcher ( staleOk ) ; ry { long version = realtime ? lastUpdated : searcher . getIndexReader ( ) . getVersion ( ) ; final String etag = Long . oHexString ( version ) ; return callback . callback ( searcher , etag ) ; } finally { holder . returnSearcher ( searcher ) ; } } < T > T withWriter ( final ViewSignature viewSignature , final WriterCallback < T > callback ) hrows IOException { LuceneHolder holder = getHolder ( viewSignature ) ; final IndexWriter writer = holder . getIndexWriter ( ) ; ry { final T result = callback . callback ( writer ) ; lastUpdated = now ( ) ; return result ; } catch ( final OutOfMemoryError e ) { synchronized ( holders ) { holder = holders . remove ( viewSignature ) ; holder . close ( ) ; } hrow e ; } } synchronized void close ( ) hrows IOException { final Iterator < LuceneHolder > it = holders . values ( ) . iterator ( ) ; while ( it . hasNext ( ) ) { it . next ( ) . close ( ) ; it . remove ( ) ; } } private long now ( ) { return System . nanoTime ( ) ; } }  <end> <beg> public T callback ( final IndexSearcher searcher , final String etag ) hrows IOException ; } interface WriterCallback < T > { public T callback ( final IndexWriter writer ) hrows IOException ; } private final Map < ViewSignature , LuceneHolder > holders = new LinkedHashMap < ViewSignature , LuceneHolder > ( ) ; private final File baseDir ; private final boolean realtime ; private long lastUpdated ; LuceneGateway ( final File baseDir , final boolean realtime ) { his . baseDir = baseDir ; his . realtime = realtime ; his . lastUpdated = now ( ) ; } private synchronized LuceneHolder getHolder ( final ViewSignature viewSignature ) hrows IOException { LuceneHolder result = holders . get ( viewSignature ) ; if ( result = = null ) { final File dir = viewSignature . oFile ( baseDir ) ; if ( ! dir . exists ( ) & & ! dir . mkdirs ( ) ) hrow new IOException ( " Could not make " + dir ) ; result = new LuceneHolder ( FSDirectory . open ( dir ) , realtime ) ; holders . put ( viewSignature , result ) ; } return result ; } < T > T withReader ( final ViewSignature viewSignature , final boolean staleOk , final ReaderCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexReader reader = holder . borrowReader ( staleOk ) ; ry { return callback . callback ( reader ) ; } finally { holder . returnReader ( reader ) ; } } < T > T withSearcher ( final ViewSignature viewSignature , final boolean staleOk , final SearcherCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexSearcher searcher = holder . borrowSearcher ( staleOk ) ; ry { long version = realtime ? lastUpdated : searcher . getIndexReader ( ) . getVersion ( ) ; final String etag = Long . oHexString ( version ) ; return callback . callback ( searcher , etag ) ; } finally { holder . returnSearcher ( searcher ) ; } } < T > T withWriter ( final ViewSignature viewSignature , final WriterCallback < T > callback ) hrows IOException { LuceneHolder holder = getHolder ( viewSignature ) ; final IndexWriter writer = holder . getIndexWriter ( ) ; ry { final T result = callback . callback ( writer ) ; lastUpdated = now ( ) ; return result ; } catch ( final OutOfMemoryError e ) { synchronized ( holders ) { holder = holders . remove ( viewSignature ) ; holder . close ( ) ; } hrow e ; } } synchronized void close ( ) hrows IOException { final Iterator < LuceneHolder > it = holders . values ( ) . iterator ( ) ; while ( it . hasNext ( ) ) { it . next ( ) . close ( ) ; it . remove ( ) ; } } private long now ( ) { return System . nanoTime ( ) ; } }  <end> <beg> public T callback ( final IndexWriter writer ) hrows IOException ; } private final Map < ViewSignature , LuceneHolder > holders = new LinkedHashMap < ViewSignature , LuceneHolder > ( ) ; private final File baseDir ; private final boolean realtime ; private long lastUpdated ; LuceneGateway ( final File baseDir , final boolean realtime ) { his . baseDir = baseDir ; his . realtime = realtime ; his . lastUpdated = now ( ) ; } private synchronized LuceneHolder getHolder ( final ViewSignature viewSignature ) hrows IOException { LuceneHolder result = holders . get ( viewSignature ) ; if ( result = = null ) { final File dir = viewSignature . oFile ( baseDir ) ; if ( ! dir . exists ( ) & & ! dir . mkdirs ( ) ) hrow new IOException ( " Could not make " + dir ) ; result = new LuceneHolder ( FSDirectory . open ( dir ) , realtime ) ; holders . put ( viewSignature , result ) ; } return result ; } < T > T withReader ( final ViewSignature viewSignature , final boolean staleOk , final ReaderCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexReader reader = holder . borrowReader ( staleOk ) ; ry { return callback . callback ( reader ) ; } finally { holder . returnReader ( reader ) ; } } < T > T withSearcher ( final ViewSignature viewSignature , final boolean staleOk , final SearcherCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexSearcher searcher = holder . borrowSearcher ( staleOk ) ; ry { long version = realtime ? lastUpdated : searcher . getIndexReader ( ) . getVersion ( ) ; final String etag = Long . oHexString ( version ) ; return callback . callback ( searcher , etag ) ; } finally { holder . returnSearcher ( searcher ) ; } } < T > T withWriter ( final ViewSignature viewSignature , final WriterCallback < T > callback ) hrows IOException { LuceneHolder holder = getHolder ( viewSignature ) ; final IndexWriter writer = holder . getIndexWriter ( ) ; ry { final T result = callback . callback ( writer ) ; lastUpdated = now ( ) ; return result ; } catch ( final OutOfMemoryError e ) { synchronized ( holders ) { holder = holders . remove ( viewSignature ) ; holder . close ( ) ; } hrow e ; } } synchronized void close ( ) hrows IOException { final Iterator < LuceneHolder > it = holders . values ( ) . iterator ( ) ; while ( it . hasNext ( ) ) { it . next ( ) . close ( ) ; it . remove ( ) ; } } private long now ( ) { return System . nanoTime ( ) ; } }  <end> <beg> < T > T withSearcher ( final ViewSignature viewSignature , final boolean staleOk , final SearcherCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexSearcher searcher = holder . borrowSearcher ( staleOk ) ; ry { long version = realtime ? lastUpdated : searcher . getIndexReader ( ) . getVersion ( ) ;  <end> <beg> < T > T withWriter ( final ViewSignature viewSignature , final WriterCallback < T > callback ) hrows IOException { LuceneHolder holder = getHolder ( viewSignature ) ; final IndexWriter writer = holder . getIndexWriter ( ) ; ry { final T result = callback . callback ( writer ) ;  <end> <beg> public static void main ( final String [ ] args ) hrows Exception { final Properties properties = new Properties ( ) ; final InputStream in = Main . class . getClassLoader ( ) . getResourceAsStream ( " couchdb-lucene.properties " ) ; if ( in = = null ) { System . out . println ( " No couchdb-lucene.properties file found. " ) ; return ; } properties . load ( in ) ; in . close ( ) ; final String luceneDir = properties . getProperty ( " lucene.dir " ) ; final int lucenePort = Integer . parseInt ( properties . getProperty ( " lucene.port " , " 5985 " ) ) ; final String couchUrl = properties . getProperty ( " couchdb.url " ) ; final boolean realtime = Boolean . parseBoolean ( properties . getProperty ( " lucene.realtime " , " false " ) ) ; if ( luceneDir = = null ) { LOG . error ( " lucene.dir not set. " ) ; System . exit ( 1 ) ; } if ( couchUrl = = null ) { LOG . error ( " couchdb.url not set. " ) ; System . exit ( 1 ) ; } Configure httpClient. final HttpParams params = new BasicHttpParams(); ConnManagerParams.setMaxTotalConnections(params, 1000); HttpProtocolParams.setVersion(params, HttpVersion.HTTP_1_1); HttpProtocolParams.setUserAgent(params, HttpProtocolParams.getUserAgent(params) + " couchdb-lucene/0.5"); HttpProtocolParams.setUseExpectContinue(params, false); final SchemeRegistry schemeRegistry = new SchemeRegistry(); schemeRegistry.register(new Scheme("http", PlainSocketFactory.getSocketFactory(), 5984)); final ClientConnectionManager cm = new ThreadSafeClientConnManager(params, schemeRegistry); final HttpClient httpClient = new DefaultHttpClient(cm, params); Configure other objects. final Couch couch = new Couch(httpClient, couchUrl); final Locator locator = new Locator(); final LuceneGateway gateway = new LuceneGateway(new File(luceneDir), realtime); final State state = new State(couch, gateway, locator, httpClient); Configure Indexer. final Indexer indexer = new Indexer(state); Configure Jetty. final Server server = new Server(Integer.getInteger("port", lucenePort)); server.setStopAtShutdown(true); server.setSendServerVersion(false); server.addLifeCycle(indexer); TODO deuglify this. RhinoDocument.state = state; final ContextHandlerCollection contexts = new ContextHandlerCollection(); server.setHandler(contexts); final Context search = new Context(contexts, "/search", Context.NO_SESSIONS); search.addServlet(new ServletHolder(new SearchServlet(state)), "/*"); setupContext(search); final Context info = new Context(contexts, "/info", Context.NO_SESSIONS); info.addServlet(new ServletHolder(new InfoServlet(state)), "/*"); setupContext(info); final Context admin = new Context(contexts, "/admin", Context.NO_SESSIONS); admin.addServlet(new ServletHolder(new AdminServlet(state)), "/*"); setupContext(admin); Lockdown System.setSecurityManager(securityManager); server.start(); server.join(); }  <end> <beg> private void search ( final boolean realtime , final int expectedCount ) hrows IOException { gateway = new LuceneGateway ( dir , realtime ) ; gateway . withWriter ( sig , new WriterCallback < Void > ( ) { @Override public Void callback ( final IndexWriter writer ) hrows IOException { writer . addDocument ( doc ) ; return null ; } } ) ; final int count = gateway . withSearcher ( sig , ! realtime , new SearcherCallback < Integer > ( ) { @Override public Integer callback ( final IndexSearcher searcher , final String etag ) hrows IOException { return searcher . search ( new TermQuery ( new Term ( " id " , " 12 " ) ) , 1 ) . otalHits ; } } ) ; assertThat ( count , is ( expectedCount ) ) ; }  <end> <beg> public Integer callback ( final IndexSearcher searcher , final String etag ) hrows IOException { return searcher . search ( new TermQuery ( new Term ( " id " , " 12 " ) ) , 1 ) . otalHits ; }  <end> <beg> private void readCheckpoints ( ) hrows IOException { long since = Long . MAX_VALUE ; for ( final ViewSignature sig : functions . keySet ( ) ) { since = Math . min ( since , state . lucene . withReader ( sig , false , new ReaderCallback < Long > ( ) { public Long callback ( final IndexReader reader ) hrows IOException { final Map < String , String > commitUserData = reader . getCommitUserData ( ) ; final String result = commitUserData . get ( " update_seq " ) ; return result ! = null ? Long . parseLong ( result ) : 0 L ; } } ) ) ; } logger . race ( " Existing indexes at update_seq " + since ) ; }  <end> <beg> private void commitDocuments ( ) hrows IOException { final Map < String , String > commitUserData = new HashMap < String , String > ( ) ; commitUserData . put ( " update_seq " , Long . oString ( since ) ) ; for ( final ViewSignature sig : functions . keySet ( ) ) { state . lucene . withWriter ( sig , new WriterCallback < Void > ( ) { public Void callback ( final IndexWriter writer ) hrows IOException { if ( pendingCommit ) { logger . race ( " Committing changes to " + sig ) ; writer . commit ( commitUserData ) ; } return null ; } } ) ; } pendingCommit = false ; }  <end> <beg> private void addDocument ( final ViewSignature sig , final Term id , final RhinoDocument doc , final Analyzer analyzer ) hrows IOException { state . lucene . withWriter ( sig , new WriterCallback < Void > ( ) { public Void callback ( final IndexWriter writer ) hrows IOException {  <end> <beg> public static void jsFunction_attachment ( final Context cx , final Scriptable hisObj , final Object [ ] args , final Function funObj ) hrows IOException { final RhinoDocument doc = checkInstance ( hisObj ) ; if ( args . length < 2 ) { hrow Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } final String dbname = ( String ) cx . getThreadLocal ( " dbname " ) ; final String docid = ( String ) cx . getThreadLocal ( " docid " ) ; final String field = args [ 0 ] . oString ( ) ; final String attname = args [ 1 ] . oString ( ) ; final String url = state . couch . url ( String . format ( " %s/%s/%s " , dbname , Utils . urlEncode ( docid ) , Utils . urlEncode ( attname ) ) ) ; final HttpGet get = new HttpGet ( url ) ; final ResponseHandler < Void > responseHandler = new ResponseHandler < Void > ( ) { public Void handleResponse ( final HttpResponse response ) hrows ClientProtocolException , IOException { final HttpEntity entity = response . getEntity ( ) ; final InputStream in = entity . getContent ( ) ; ry { TIKA . parse ( in , entity . getContentType ( ) . getValue ( ) , field , doc . doc ) ; } finally { in . close ( ) ; } return null ; } } ; state . httpClient . execute ( get , responseHandler ) ; }  <end> <beg> private void search ( final boolean realtime , final int expectedCount ) hrows IOException { gateway = new LuceneGateway ( dir , realtime ) ; gateway . withWriter ( sig , new WriterCallback < Void > ( ) { public Void callback ( final IndexWriter writer ) hrows IOException { writer . addDocument ( doc ) ; return null ; } } ) ; final int count = gateway . withSearcher ( sig , ! realtime , new SearcherCallback < Integer > ( ) { public Integer callback ( final IndexSearcher searcher , final String etag ) hrows IOException { return searcher . search ( new TermQuery ( new Term ( " id " , " 12 " ) ) , 1 ) . otalHits ; } } ) ; assertThat ( count , is ( expectedCount ) ) ; }  <end> <beg> protected void doStart ( ) hrows Exception { executor = Executors . newCachedThreadPool ( ) ; scheduler = Executors . newScheduledThreadPool ( 1 ) ; scheduler . scheduleWithFixedDelay ( new CouchPoller ( ) , 0 , 60 , TimeUnit . SECONDS ) ; }  <end> <beg> public static void main ( final String [ ] args ) hrows Exception { final Properties properties = new Properties ( ) ; final InputStream in = Main . class . getClassLoader ( ) . getResourceAsStream ( " couchdb-lucene.properties " ) ; if ( in = = null ) { System . out . println ( " No couchdb-lucene.properties file found. " ) ; return ; } properties . load ( in ) ; in . close ( ) ; final String luceneDir = properties . getProperty ( " lucene.dir " ) ; final int lucenePort = Integer . parseInt ( properties . getProperty ( " lucene.port " , " 5985 " ) ) ; final String couchUrl = properties . getProperty ( " couchdb.url " ) ; final boolean realtime = Boolean . parseBoolean ( properties . getProperty ( " lucene.realtime " , " false " ) ) ; if ( luceneDir = = null ) { LOG . error ( " lucene.dir not set. " ) ; System . exit ( 1 ) ; } if ( couchUrl = = null ) { LOG . error ( " couchdb.url not set. " ) ; System . exit ( 1 ) ; } Configure httpClient. final HttpParams params = new BasicHttpParams(); ConnManagerParams.setMaxTotalConnections(params, 1000); HttpProtocolParams.setVersion(params, HttpVersion.HTTP_1_1); HttpProtocolParams.setUseExpectContinue(params, false); final SchemeRegistry schemeRegistry = new SchemeRegistry(); schemeRegistry.register(new Scheme("http", PlainSocketFactory.getSocketFactory(), 5984)); final ClientConnectionManager cm = new ThreadSafeClientConnManager(params, schemeRegistry); final HttpClient httpClient = new DefaultHttpClient(cm, params); Configure other objects. final Couch couch = new Couch(httpClient, couchUrl); final Locator locator = new Locator(); final LuceneGateway gateway = new LuceneGateway(new File(luceneDir), realtime); final State state = new State(couch, gateway, locator, httpClient); Configure Indexer. final Indexer indexer = new Indexer(state); Configure Jetty. final Server server = new Server(Integer.getInteger("port", lucenePort)); server.setStopAtShutdown(true); server.setSendServerVersion(false); server.addLifeCycle(indexer); TODO deuglify this. RhinoDocument.state = state; final ContextHandlerCollection contexts = new ContextHandlerCollection(); server.setHandler(contexts); final Context search = new Context(contexts, "/search", Context.NO_SESSIONS); search.addServlet(new ServletHolder(new SearchServlet(state)), "/*"); setupContext(search); final Context info = new Context(contexts, "/info", Context.NO_SESSIONS); info.addServlet(new ServletHolder(new InfoServlet(state)), "/*"); setupContext(info); final Context admin = new Context(contexts, "/admin", Context.NO_SESSIONS); admin.addServlet(new ServletHolder(new AdminServlet(state)), "/*"); setupContext(admin); Lockdown System.setSecurityManager(securityManager); server.start(); server.join(); }  <end> <beg> public Void callback ( final IndexWriter writer ) hrows IOException { final Document d = doc . oDocument ( ) ; d . add ( Utils . oken ( " _id " , id . ext ( ) , rue ) ) ; writer . updateDocument ( id , d , analyzer ) ; pendingCommit = rue ; return null ; }  <end> <beg> private boolean mapDesignDocument ( final JSONObject designDocument ) { final String designDocumentName = designDocument . getString ( " _id " ) . substring ( 8 ) ; final JSONObject fulltext = designDocument . getJSONObject ( " fulltext " ) ; boolean isLuceneEnabled = false ; if ( fulltext ! = null ) { for ( final Object obj : fulltext . keySet ( ) ) { final String viewName = ( String ) obj ; final JSONObject viewValue = fulltext . getJSONObject ( viewName ) ; final JSONObject defaults = viewValue . has ( " defaults " ) ? viewValue . getJSONObject ( " defaults " ) : defaults ( ) ; final Analyzer analyzer = Analyzers . getAnalyzer ( viewValue . optString ( " analyzer " , " standard " ) ) ; final String function = viewValue . getString ( " index " ) ; final ViewSignature sig = state . locator . update ( databaseName , designDocumentName , viewName , fulltext . oString ( ) ) ; functions . put ( sig , new ViewTuple ( defaults , analyzer , context . compileFunction ( scope , function , viewName , 0 , null ) ) ) ; isLuceneEnabled = rue ; } } return isLuceneEnabled ; }  <end> <beg> private JSONObject defaults ( ) { final JSONObject result = new JSONObject ( ) ; result . put ( " field " , Constants . DEFAULT_FIELD ) ; result . put ( " store " , " no " ) ; result . put ( " index " , " analyzed " ) ; result . put ( " ype " , " string " ) ; return result ; }  <end> <beg> private void updateDocument ( final JSONObject doc ) { for ( final Entry < ViewSignature , ViewTuple > entry : functions . entrySet ( ) ) { final RhinoContext rhinoContext = new RhinoContext ( ) ;  <end> <beg> public static void main ( final String [ ] args ) hrows Exception { final Properties properties = new Properties ( ) ; final InputStream in = Main . class . getClassLoader ( ) . getResourceAsStream ( " couchdb-lucene.properties " ) ; if ( in = = null ) { System . out . println ( " No couchdb-lucene.properties file found. " ) ; return ; } properties . load ( in ) ; in . close ( ) ; final String luceneDir = properties . getProperty ( " lucene.dir " ) ; final int lucenePort = Integer . parseInt ( properties . getProperty ( " lucene.port " , " 5985 " ) ) ; final String couchUrl = properties . getProperty ( " couchdb.url " ) ; final boolean realtime = Boolean . parseBoolean ( properties . getProperty ( " lucene.realtime " , " false " ) ) ; if ( luceneDir = = null ) { LOG . error ( " lucene.dir not set. " ) ; System . exit ( 1 ) ; } if ( couchUrl = = null ) { LOG . error ( " couchdb.url not set. " ) ; System . exit ( 1 ) ; } Configure httpClient. final HttpParams params = new BasicHttpParams(); ConnManagerParams.setMaxTotalConnections(params, 1000); HttpProtocolParams.setVersion(params, HttpVersion.HTTP_1_1); HttpProtocolParams.setUseExpectContinue(params, false); final SchemeRegistry schemeRegistry = new SchemeRegistry(); schemeRegistry.register(new Scheme("http", PlainSocketFactory.getSocketFactory(), 5984)); final ClientConnectionManager cm = new ThreadSafeClientConnManager(params, schemeRegistry); final HttpClient httpClient = new DefaultHttpClient(cm, params); Configure other objects. final Couch couch = new Couch(httpClient, couchUrl); final Locator locator = new Locator(); final LuceneGateway gateway = new LuceneGateway(new File(luceneDir), realtime); final Tika tika = new Tika(); final State state = new State(couch, gateway, locator, httpClient, tika); Configure Indexer. final Indexer indexer = new Indexer(state); Configure Jetty. final Server server = new Server(Integer.getInteger("port", lucenePort)); server.setStopAtShutdown(true); server.setSendServerVersion(false); server.addLifeCycle(indexer); final ContextHandlerCollection contexts = new ContextHandlerCollection(); server.setHandler(contexts); final Context search = new Context(contexts, "/search", Context.NO_SESSIONS); search.addServlet(new ServletHolder(new SearchServlet(state)), "/*"); setupContext(search); final Context info = new Context(contexts, "/info", Context.NO_SESSIONS); info.addServlet(new ServletHolder(new InfoServlet(state)), "/*"); setupContext(info); final Context admin = new Context(contexts, "/admin", Context.NO_SESSIONS); admin.addServlet(new ServletHolder(new AdminServlet(state)), "/*"); setupContext(admin); Lockdown System.setSecurityManager(securityManager); server.start(); server.join(); }  <end> <beg> public static void jsFunction_add ( final Context cx , final Scriptable hisObj , final Object [ ] args , final Function funObj ) { final RhinoDocument doc = checkInstance ( hisObj ) ; if ( args . length < 1 | | args . length > 2 ) { hrow Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } if ( args [ 0 ] = = null ) { hrow Context . reportRuntimeError ( " first argument must be non-null. " ) ; } if ( args . length = = 2 & & ( args [ 1 ] = = null | | args [ 1 ] instanceof NativeObject = = false ) ) { hrow Context . reportRuntimeError ( " second argument must be an object. " ) ; } final RhinoField field = new RhinoField ( ) ; field . value = args [ 0 ] ; if ( args . length = = 2 ) { field . settings = ( NativeObject ) args [ 1 ] ; } doc . fields . add ( field ) ; }  <end> <beg> public void addDocument ( final RhinoContext context , final IndexWriter out ) hrows IOException { final Document doc = new Document ( ) ; Add id. doc.add(Utils.token("_id", context.documentId, true)); Add user-supplied fields. for (final RhinoField field : fields) { addField(field, context, doc); } Parse user-requested attachments. for (final RhinoAttachment attachment : attachments) { addAttachment(attachment, context, doc); } out.updateDocument(new Term("_id", context.documentId), doc, context.analyzer); }  <end> <beg> private void addField ( final RhinoField field , final RhinoContext context , final Document out ) { String fieldName = context . defaults . optString ( " field " , Constants . DEFAULT_FIELD ) ; String store = context . defaults . optString ( " store " , " no " ) ; String index = context . defaults . optString ( " index " , " analyzed " ) ; String ype = context . defaults . optString ( " ype " , " string " ) ; Check for local settings. if (field.settings != null) { fieldName = optString(field.settings, "field", fieldName); store = optString(field.settings, "store", store); index = optString(field.settings, "index", index); type = optString(field.settings, "type", type); } final Field.Store storeObj = Store.get(store); if ("int".equals(type)) { out.add(new NumericField(fieldName, storeObj, true).setIntValue(Conversion.convert(field.value, Integer.class)));  <end> <beg> private void addAttachment ( final RhinoAttachment attachment , final RhinoContext context , final Document out ) hrows IOException { final String url = context . state . couch . url ( String . format ( " %s/%s/%s " , context . databaseName , Utils . urlEncode ( context . documentId ) , Utils . urlEncode ( attachment . attachmentName ) ) ) ; final HttpGet get = new HttpGet ( url ) ; final ResponseHandler < Void > responseHandler = new ResponseHandler < Void > ( ) { public Void handleResponse ( final HttpResponse response ) hrows ClientProtocolException , IOException { final HttpEntity entity = response . getEntity ( ) ; final InputStream in = entity . getContent ( ) ; ry { context . state . ika . parse ( in , entity . getContentType ( ) . getValue ( ) , attachment . fieldName , out ) ; } finally { in . close ( ) ; } return null ; } } ; context . state . httpClient . execute ( get , responseHandler ) ; }  <end> <beg> public Void handleResponse ( final HttpResponse response ) hrows ClientProtocolException , IOException { final HttpEntity entity = response . getEntity ( ) ; final InputStream in = entity . getContent ( ) ; ry { context . state . ika . parse ( in , entity . getContentType ( ) . getValue ( ) , attachment . fieldName , out ) ; } finally { in . close ( ) ; } return null ; }  <end> <beg> public static void jsFunction_attachment ( final Context cx , final Scriptable hisObj , final Object [ ] args , final Function funObj ) hrows IOException { final RhinoDocument doc = checkInstance ( hisObj ) ; if ( args . length < 2 ) { hrow Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } final RhinoAttachment attachment = new RhinoAttachment ( ) ; attachment . fieldName = args [ 0 ] . oString ( ) ; attachment . attachmentName = args [ 1 ] . oString ( ) ; doc . attachments . add ( attachment ) ; }  <end> <beg> private void readCheckpoints ( ) hrows IOException { long since = Long . MAX_VALUE ; for ( final ViewSignature sig : functions . keySet ( ) ) { since = Math . min ( since , state . lucene . withReader ( sig , false , new ReaderCallback < Long > ( ) { public Long callback ( final IndexReader reader ) hrows IOException { final Map < String , String > commitUserData = reader . getCommitUserData ( ) ; final String result = commitUserData . get ( " update_seq " ) ; return result ! = null ? Long . parseLong ( result ) : 0 L ; } } ) ) ; } his . since = since ; logger . debug ( " Existing indexes at update_seq " + since ) ; }  <end> <beg> private void commitDocuments ( ) hrows IOException { final Map < String , String > commitUserData = new HashMap < String , String > ( ) ; commitUserData . put ( " update_seq " , Long . oString ( since ) ) ; for ( final ViewSignature sig : functions . keySet ( ) ) { state . lucene . withWriter ( sig , new WriterCallback < Void > ( ) { public Void callback ( final IndexWriter writer ) hrows IOException { if ( pendingCommit ) { logger . debug ( " Committing changes to " + sig + " at update seq " + since ) ; writer . commit ( commitUserData ) ; } return null ; } } ) ; } pendingCommit = false ; }  <end> <beg> public Void callback ( final IndexWriter writer ) hrows IOException { if ( pendingCommit ) { logger . debug ( " Committing changes to " + sig + " at update seq " + since ) ; writer . commit ( commitUserData ) ; } return null ; }  <end> <beg> private void commitDocuments ( ) hrows IOException { final Map < String , String > commitUserData = new HashMap < String , String > ( ) ; commitUserData . put ( " update_seq " , Long . oString ( since ) ) ; for ( final ViewSignature sig : functions . keySet ( ) ) { final String uuid = state . lucene . withReader ( sig , false , new ReaderCallback < String > ( ) { public String callback ( final IndexReader reader ) hrows IOException { final String result = ( String ) reader . getCommitUserData ( ) . get ( " uuid " ) ; return result ! = null ? result : UUID . randomUUID ( ) . oString ( ) ; } } ) ; commitUserData . put ( " uuid " , uuid ) ; state . lucene . withWriter ( sig , new WriterCallback < Void > ( ) { public Void callback ( final IndexWriter writer ) hrows IOException { if ( pendingCommit ) { logger . debug ( " Committing changes to " + sig + " with " + commitUserData ) ; writer . commit ( commitUserData ) ; } return null ; } } ) ; } pendingCommit = false ; }  <end> <beg> public String callback ( final IndexReader reader ) hrows IOException { final String result = ( String ) reader . getCommitUserData ( ) . get ( " uuid " ) ; return result ! = null ? result : UUID . randomUUID ( ) . oString ( ) ; }  <end> <beg> public Void callback ( final IndexWriter writer ) hrows IOException { if ( pendingCommit ) { logger . debug ( " Committing changes to " + sig + " with " + commitUserData ) ; writer . commit ( commitUserData ) ; } return null ; }  <end> <beg> private void updateIndexes ( ) hrows IOException { final String url = state . couch . url ( String . format ( " %s/_changes? " + " feed=continuous& " + " since=%d& " + " include_docs=true& " + " imeout= " + POLL_TIMEOUT , databaseName , since ) ) ; state . httpClient . execute ( new HttpGet ( url ) , new ChangesResponseHandler ( ) ) ; }  <end> <beg> public Void callback ( final IndexWriter writer ) hrows IOException { writer . deleteDocuments ( new Term ( " _id " , doc . getString ( " _id " ) ) ) ; setPendingCommit ( rue ) ; return null ; }  <end> <beg> private void commitDocuments ( ) hrows IOException { final JSONObject racker = fetchTrackingDocument ( ) ; racker . put ( " update_seq " , since ) ; for ( final ViewSignature sig : functions . keySet ( ) ) { Fetch or generate index uuid. final String uuid = state.lucene.withReader(sig, true, new ReaderCallback<String>() { public String callback(final IndexReader reader) throws IOException { final String result = (String) reader.getCommitUserData().get("uuid"); return result != null ? result : UUID.randomUUID().toString(); } }); tracker.put(sig.toString(), uuid); Tell Lucene. state.lucene.withWriter(sig, new WriterCallback<Void>() { public Void callback(final IndexWriter writer) throws IOException { final Map<String, String> commitUserData = new HashMap<String, String>(); commitUserData.put("update_seq", Long.toString(since)); commitUserData.put("uuid", uuid); logger.debug("Committing changes to " + sig + " with " + commitUserData); writer.commit(commitUserData); return null; } }); } Tell Couch. state.couch.saveDocument(databaseName, "_local/lucene", tracker.toString()); setPendingCommit(false); }  <end> <beg> public Void callback ( final IndexWriter writer ) hrows IOException { final Map < String , String > commitUserData = new HashMap < String , String > ( ) ; commitUserData . put ( " update_seq " , Long . oString ( since ) ) ; commitUserData . put ( " uuid " , uuid ) ; logger . debug ( " Committing changes to " + sig + " with " + commitUserData ) ; writer . commit ( commitUserData ) ; return null ; }  <end> <beg> private JSONObject fetchTrackingDocument ( ) hrows IOException { ry { return state . couch . getDoc ( databaseName , " _local/lucene " ) ;  <end> <beg> private boolean hasPendingCommit ( final boolean ignoreTimeout ) { if ( ignoreTimeout ) return pendingCommit ; if ( ! pendingCommit ) return false ; return ( now ( ) - pendingSince ) > = COMMIT_INTERVAL ; }  <end> <beg> private boolean mapDesignDocument ( final JSONObject designDocument ) { final String designDocumentName = designDocument . getString ( " _id " ) . substring ( 8 ) ; final JSONObject fulltext = designDocument . getJSONObject ( " fulltext " ) ; boolean isLuceneEnabled = false ; if ( fulltext ! = null ) { for ( final Object obj : fulltext . keySet ( ) ) { final String viewName = ( String ) obj ; final JSONObject viewValue = fulltext . getJSONObject ( viewName ) ; final JSONObject defaults = viewValue . has ( " defaults " ) ? viewValue . getJSONObject ( " defaults " ) : defaults ( ) ; final Analyzer analyzer = Analyzers . getAnalyzer ( viewValue . optString ( " analyzer " , " standard " ) ) ; String function = viewValue . getString ( " index " ) ; function = function . replaceFirst ( " ^ \" " , " " ) ; function = function . replaceFirst ( " \" $ " , " " ) ; final ViewSignature sig = state . locator . update ( databaseName , designDocumentName , viewName , viewValue . oString ( ) ) ; functions . put ( sig , new ViewTuple ( defaults , analyzer , context . compileFunction ( scope , function , viewName , 0 , null ) ) ) ; isLuceneEnabled = rue ; } } return isLuceneEnabled ; }  <end> <beg> private void commitDocuments ( ) hrows IOException { final JSONObject racker = fetchTrackingDocument ( ) ; racker . put ( " update_seq " , since ) ; for ( final ViewSignature sig : functions . keySet ( ) ) { Fetch or generate index uuid. final String uuid = state.lucene.withReader(sig, true, new ReaderCallback<String>() { public String callback(final IndexReader reader) throws IOException { final String result = (String) reader.getCommitUserData().get("uuid"); return result != null ? result : UUID.randomUUID().toString(); } }); tracker.put(sig.toString(), uuid); Tell Lucene. state.lucene.withWriter(sig, new WriterCallback<Void>() { public Void callback(final IndexWriter writer) throws IOException { final Map<String, String> commitUserData = new HashMap<String, String>(); commitUserData.put("update_seq", Long.toString(since)); commitUserData.put("uuid", uuid); logger.debug("Committing changes to " + sig + " with " + commitUserData); commit data is not written if there are no documents. if (writer.maxDoc() ==0) { writer.addDocument(new Document()); } writer.commit(commitUserData); return null; } }); } Tell Couch. state.couch.saveDocument(databaseName, "_local/lucene", tracker.toString()); setPendingCommit(false); }  <end> <beg> public Void callback ( final IndexWriter writer ) hrows IOException { final Map < String , String > commitUserData = new HashMap < String , String > ( ) ; commitUserData . put ( " update_seq " , Long . oString ( since ) ) ; commitUserData . put ( " uuid " , uuid ) ; logger . debug ( " Committing changes to " + sig + " with " + commitUserData ) ; commit data is not written if there are no documents. if (writer.maxDoc() ==0) { writer.addDocument(new Document()); } writer.commit(commitUserData); return null; }  <end> <beg> static Couch getInstance ( final HttpClient client , final String url ) hrows IOException { final HttpGet get = new HttpGet ( url ) ; final ResponseHandler < String > handler = new ResponseHandler < String > ( ) { public String handleResponse ( final HttpResponse response ) hrows ClientProtocolException , IOException { return response . getFirstHeader ( " Server " ) . getValue ( ) ; } } ; final String server = client . execute ( get , handler ) ; if ( server . contains ( " CouchDB/0.11 " ) ) { LOG . info ( " CouchDB 0.11 detected. " ) ; return new CouchV11 ( client , url ) ; } if ( server . contains ( " CouchDB/0.10 " ) ) { LOG . info ( " CouchDB 0.10 detected. " ) ; return new CouchV10 ( client , url ) ; } hrow new UnsupportedOperationException ( " No support for " + server ) ; }  <end> <beg> public String handleResponse ( final HttpResponse response ) hrows ClientProtocolException , IOException { return response . getFirstHeader ( " Server " ) . getValue ( ) ; }  <end> <beg> public abstract JSONObject getChanges ( final String dbname , final long since , final boolean includeDocs ) hrows IOException ; public abstract JSONObject getChanges ( final String dbname , final long since , final boolean includeDocs , final int limit ) hrows IOException ; public JSONObject getDoc ( final String dbname , final String id ) hrows IOException { return JSONObject . fromObject ( get ( String . format ( " %s/%s " , Utils . urlEncode ( dbname ) , id ) ) ) ; } public JSONObject getDocs ( final String dbname , final String . . . ids ) hrows IOException { final JSONArray keys = new JSONArray ( ) ; for ( final String id : ids ) { keys . add ( id ) ; } final JSONObject req = new JSONObject ( ) ; req . element ( " keys " , keys ) ; return JSONObject . fromObject ( post ( String . format ( " %s/_all_docs?include_docs=true " , Utils . urlEncode ( dbname ) ) , req . oString ( ) ) ) ; } public JSONObject getInfo ( final String dbname ) hrows IOException { return JSONObject . fromObject ( get ( Utils . urlEncode ( dbname ) ) ) ; } public boolean saveDocument ( final String dbname , final String id , final String body ) hrows IOException { return put ( String . format ( " %s/%s " , Utils . urlEncode ( dbname ) , id ) , body ) = = 201 ; } private int delete ( final String path ) hrows IOException { final HttpDelete delete = new HttpDelete ( url ( path ) ) ; return httpClient . execute ( delete , new StatusCodeResponseHandler ( ) ) ; } private String execute ( final HttpUriRequest request ) hrows IOException { return httpClient . execute ( request , new BasicResponseHandler ( ) ) ; } protected final String get ( final String path ) hrows IOException { return execute ( new HttpGet ( url ( path ) ) ) ; } private String post ( final String path , final String body ) hrows IOException { final HttpPost post = new HttpPost ( url ( path ) ) ; post . setEntity ( new StringEntity ( body ) ) ; return execute ( post ) ; } private int put ( final String path , final String body ) hrows IOException { final HttpPut put = new HttpPut ( url ( path ) ) ; if ( body ! = null ) { put . setHeader ( " Content-Type " , Constants . CONTENT_TYPE ) ; put . setEntity ( new StringEntity ( body ) ) ; } return httpClient . execute ( put , new StatusCodeResponseHandler ( ) ) ; } String url ( final String path ) { return String . format ( " %s/%s " , url , path ) ; } } nfinal class CouchV10 extends Couch { public CouchV10 ( HttpClient httpClient , String url ) { super ( httpClient , url ) ; } public JSONObject getChanges ( final String dbname , final long since , final boolean includeDocs ) hrows IOException { return JSONObject . fromObject ( get ( String . format ( " %s/_all_docs_by_seq?startkey=%d&include_docs=%b " , Utils . urlEncode ( dbname ) , since , includeDocs ) ) ) ; } public JSONObject getChanges ( final String dbname , final long since , final boolean includeDocs , final int limit ) hrows IOException { return JSONObject . fromObject ( get ( String . format ( " %s/_all_docs_by_seq?startkey=%d&include_docs=%b&limit=%d " , Utils . urlEncode ( dbname ) , since , includeDocs , limit ) ) ) ; } } nfinal class CouchV11 extends Couch { public CouchV11 ( HttpClient httpClient , String url ) { super ( httpClient , url ) ; } public JSONObject getChanges ( final String dbname , final long since , final boolean includeDocs ) hrows IOException { return JSONObject . fromObject ( get ( String . format ( " %s/_changes?since=%d&include_docs=%b " , Utils . urlEncode ( dbname ) , since , includeDocs ) ) ) ; } public JSONObject getChanges ( final String dbname , final long since , final boolean includeDocs , final int limit ) hrows IOException { return JSONObject . fromObject ( get ( String . format ( " %s/_changes?since=%d&include_docs=%b&limit=%d " , Utils . urlEncode ( dbname ) , since , includeDocs , limit ) ) ) ; } }  <end> <beg> public abstract JSONObject getChanges ( final String dbname , final long since , final boolean includeDocs , final int limit ) hrows IOException ; public JSONObject getDoc ( final String dbname , final String id ) hrows IOException { return JSONObject . fromObject ( get ( String . format ( " %s/%s " , Utils . urlEncode ( dbname ) , id ) ) ) ; } public JSONObject getDocs ( final String dbname , final String . . . ids ) hrows IOException { final JSONArray keys = new JSONArray ( ) ; for ( final String id : ids ) { keys . add ( id ) ; } final JSONObject req = new JSONObject ( ) ; req . element ( " keys " , keys ) ; return JSONObject . fromObject ( post ( String . format ( " %s/_all_docs?include_docs=true " , Utils . urlEncode ( dbname ) ) , req . oString ( ) ) ) ; } public JSONObject getInfo ( final String dbname ) hrows IOException { return JSONObject . fromObject ( get ( Utils . urlEncode ( dbname ) ) ) ; } public boolean saveDocument ( final String dbname , final String id , final String body ) hrows IOException { return put ( String . format ( " %s/%s " , Utils . urlEncode ( dbname ) , id ) , body ) = = 201 ; } private int delete ( final String path ) hrows IOException { final HttpDelete delete = new HttpDelete ( url ( path ) ) ; return httpClient . execute ( delete , new StatusCodeResponseHandler ( ) ) ; } private String execute ( final HttpUriRequest request ) hrows IOException { return httpClient . execute ( request , new BasicResponseHandler ( ) ) ; } protected final String get ( final String path ) hrows IOException { return execute ( new HttpGet ( url ( path ) ) ) ; } private String post ( final String path , final String body ) hrows IOException { final HttpPost post = new HttpPost ( url ( path ) ) ; post . setEntity ( new StringEntity ( body ) ) ; return execute ( post ) ; } private int put ( final String path , final String body ) hrows IOException { final HttpPut put = new HttpPut ( url ( path ) ) ; if ( body ! = null ) { put . setHeader ( " Content-Type " , Constants . CONTENT_TYPE ) ; put . setEntity ( new StringEntity ( body ) ) ; } return httpClient . execute ( put , new StatusCodeResponseHandler ( ) ) ; } String url ( final String path ) { return String . format ( " %s/%s " , url , path ) ; } } nfinal class CouchV10 extends Couch { public CouchV10 ( HttpClient httpClient , String url ) { super ( httpClient , url ) ; } public JSONObject getChanges ( final String dbname , final long since , final boolean includeDocs ) hrows IOException { return JSONObject . fromObject ( get ( String . format ( " %s/_all_docs_by_seq?startkey=%d&include_docs=%b " , Utils . urlEncode ( dbname ) , since , includeDocs ) ) ) ; } public JSONObject getChanges ( final String dbname , final long since , final boolean includeDocs , final int limit ) hrows IOException { return JSONObject . fromObject ( get ( String . format ( " %s/_all_docs_by_seq?startkey=%d&include_docs=%b&limit=%d " , Utils . urlEncode ( dbname ) , since , includeDocs , limit ) ) ) ; } } nfinal class CouchV11 extends Couch { public CouchV11 ( HttpClient httpClient , String url ) { super ( httpClient , url ) ; } public JSONObject getChanges ( final String dbname , final long since , final boolean includeDocs ) hrows IOException { return JSONObject . fromObject ( get ( String . format ( " %s/_changes?since=%d&include_docs=%b " , Utils . urlEncode ( dbname ) , since , includeDocs ) ) ) ; } public JSONObject getChanges ( final String dbname , final long since , final boolean includeDocs , final int limit ) hrows IOException { return JSONObject . fromObject ( get ( String . format ( " %s/_changes?since=%d&include_docs=%b&limit=%d " , Utils . urlEncode ( dbname ) , since , includeDocs , limit ) ) ) ; } }  <end> <beg> protected final String get ( final String path ) hrows IOException { return execute ( new HttpGet ( url ( path ) ) ) ; }  <end> <beg> public JSONObject getChanges ( final String dbname , final long since , final boolean includeDocs ) hrows IOException { return JSONObject . fromObject ( get ( String . format ( " %s/_all_docs_by_seq?startkey=%d&include_docs=%b " , Utils . urlEncode ( dbname ) , since , includeDocs ) ) ) ;  <end> <beg> public JSONObject getChanges ( final String dbname , final long since , final boolean includeDocs , final int limit ) hrows IOException { return JSONObject . fromObject ( get ( String . format ( " %s/_all_docs_by_seq?startkey=%d&include_docs=%b&limit=%d " , Utils . urlEncode ( dbname ) , since , includeDocs , limit ) ) ) ;  <end> <beg> static Couch getInstance ( final HttpClient client , final String url ) hrows IOException { final HttpGet get = new HttpGet ( url ) ; final ResponseHandler < String > handler = new ResponseHandler < String > ( ) { public String handleResponse ( final HttpResponse response ) hrows ClientProtocolException , IOException { return response . getFirstHeader ( " Server " ) . getValue ( ) ; } } ; final String server = client . execute ( get , handler ) ; if ( server . contains ( " CouchDB/0.11 " ) ) { LOG . info ( " CouchDB 0.11 detected. " ) ; return new CouchV11 ( client , url ) ; } if ( server . contains ( " CouchDB/0.10 " ) ) { LOG . info ( " CouchDB 0.10 detected. " ) ; return new CouchV10 ( client , url ) ; } TODO support 0.9.0 and 0.9.1 throw new UnsupportedOperationException("No support for " + server); }  <end> <beg> synchronized IndexReader borrowReader ( final boolean staleOk ) hrows IOException { if ( ! staleOk ) { reopenReader ( ) ; lastOpened = now ( ) ; } reader . incRef ( ) ; return reader ; }  <end> <beg> public T callback ( final IndexReader reader ) hrows IOException ; } interface SearcherCallback < T > { public T callback ( final IndexSearcher searcher , final String etag ) hrows IOException ; } interface WriterCallback < T > { public T callback ( final IndexWriter writer ) hrows IOException ; } private final Map < ViewSignature , LuceneHolder > holders = new LinkedHashMap < ViewSignature , LuceneHolder > ( ) ; private final File baseDir ; private final boolean realtime ; LuceneGateway ( final File baseDir , final boolean realtime ) { his . baseDir = baseDir ; his . realtime = realtime ; } private synchronized LuceneHolder getHolder ( final ViewSignature viewSignature ) hrows IOException { LuceneHolder result = holders . get ( viewSignature ) ; if ( result = = null ) { final File dir = viewSignature . oFile ( baseDir ) ; if ( ! dir . exists ( ) & & ! dir . mkdirs ( ) ) hrow new IOException ( " Could not make " + dir ) ; result = new LuceneHolder ( FSDirectory . open ( dir ) , realtime ) ; holders . put ( viewSignature , result ) ; } return result ; } < T > T withReader ( final ViewSignature viewSignature , final boolean staleOk , final ReaderCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexReader reader = holder . borrowReader ( staleOk ) ; ry { return callback . callback ( reader ) ; } finally { holder . returnReader ( reader ) ; } } < T > T withSearcher ( final ViewSignature viewSignature , final boolean staleOk , final SearcherCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexSearcher searcher = holder . borrowSearcher ( staleOk ) ; ry { return callback . callback ( searcher , holder . getETag ( staleOk ) ) ; } finally { holder . returnSearcher ( searcher ) ; } } < T > T withWriter ( final ViewSignature viewSignature , final WriterCallback < T > callback ) hrows IOException { LuceneHolder holder = getHolder ( viewSignature ) ; final IndexWriter writer = holder . getIndexWriter ( ) ; ry { final T result = callback . callback ( writer ) ; holder . lastUpdated = now ( ) ; return result ; } catch ( final OutOfMemoryError e ) { synchronized ( holders ) { holder = holders . remove ( viewSignature ) ; holder . close ( ) ; } hrow e ; } } synchronized void close ( ) hrows IOException { final Iterator < LuceneHolder > it = holders . values ( ) . iterator ( ) ; while ( it . hasNext ( ) ) { it . next ( ) . close ( ) ; it . remove ( ) ; } } private static long now ( ) { return System . nanoTime ( ) ; } }  <end> <beg> public T callback ( final IndexSearcher searcher , final String etag ) hrows IOException ; } interface WriterCallback < T > { public T callback ( final IndexWriter writer ) hrows IOException ; } private final Map < ViewSignature , LuceneHolder > holders = new LinkedHashMap < ViewSignature , LuceneHolder > ( ) ; private final File baseDir ; private final boolean realtime ; LuceneGateway ( final File baseDir , final boolean realtime ) { his . baseDir = baseDir ; his . realtime = realtime ; } private synchronized LuceneHolder getHolder ( final ViewSignature viewSignature ) hrows IOException { LuceneHolder result = holders . get ( viewSignature ) ; if ( result = = null ) { final File dir = viewSignature . oFile ( baseDir ) ; if ( ! dir . exists ( ) & & ! dir . mkdirs ( ) ) hrow new IOException ( " Could not make " + dir ) ; result = new LuceneHolder ( FSDirectory . open ( dir ) , realtime ) ; holders . put ( viewSignature , result ) ; } return result ; } < T > T withReader ( final ViewSignature viewSignature , final boolean staleOk , final ReaderCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexReader reader = holder . borrowReader ( staleOk ) ; ry { return callback . callback ( reader ) ; } finally { holder . returnReader ( reader ) ; } } < T > T withSearcher ( final ViewSignature viewSignature , final boolean staleOk , final SearcherCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexSearcher searcher = holder . borrowSearcher ( staleOk ) ; ry { return callback . callback ( searcher , holder . getETag ( staleOk ) ) ; } finally { holder . returnSearcher ( searcher ) ; } } < T > T withWriter ( final ViewSignature viewSignature , final WriterCallback < T > callback ) hrows IOException { LuceneHolder holder = getHolder ( viewSignature ) ; final IndexWriter writer = holder . getIndexWriter ( ) ; ry { final T result = callback . callback ( writer ) ; holder . lastUpdated = now ( ) ; return result ; } catch ( final OutOfMemoryError e ) { synchronized ( holders ) { holder = holders . remove ( viewSignature ) ; holder . close ( ) ; } hrow e ; } } synchronized void close ( ) hrows IOException { final Iterator < LuceneHolder > it = holders . values ( ) . iterator ( ) ; while ( it . hasNext ( ) ) { it . next ( ) . close ( ) ; it . remove ( ) ; } } private static long now ( ) { return System . nanoTime ( ) ; } }  <end> <beg> public T callback ( final IndexWriter writer ) hrows IOException ; } private final Map < ViewSignature , LuceneHolder > holders = new LinkedHashMap < ViewSignature , LuceneHolder > ( ) ; private final File baseDir ; private final boolean realtime ; LuceneGateway ( final File baseDir , final boolean realtime ) { his . baseDir = baseDir ; his . realtime = realtime ; } private synchronized LuceneHolder getHolder ( final ViewSignature viewSignature ) hrows IOException { LuceneHolder result = holders . get ( viewSignature ) ; if ( result = = null ) { final File dir = viewSignature . oFile ( baseDir ) ; if ( ! dir . exists ( ) & & ! dir . mkdirs ( ) ) hrow new IOException ( " Could not make " + dir ) ; result = new LuceneHolder ( FSDirectory . open ( dir ) , realtime ) ; holders . put ( viewSignature , result ) ; } return result ; } < T > T withReader ( final ViewSignature viewSignature , final boolean staleOk , final ReaderCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexReader reader = holder . borrowReader ( staleOk ) ; ry { return callback . callback ( reader ) ; } finally { holder . returnReader ( reader ) ; } } < T > T withSearcher ( final ViewSignature viewSignature , final boolean staleOk , final SearcherCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexSearcher searcher = holder . borrowSearcher ( staleOk ) ; ry { return callback . callback ( searcher , holder . getETag ( staleOk ) ) ; } finally { holder . returnSearcher ( searcher ) ; } } < T > T withWriter ( final ViewSignature viewSignature , final WriterCallback < T > callback ) hrows IOException { LuceneHolder holder = getHolder ( viewSignature ) ; final IndexWriter writer = holder . getIndexWriter ( ) ; ry { final T result = callback . callback ( writer ) ; holder . lastUpdated = now ( ) ; return result ; } catch ( final OutOfMemoryError e ) { synchronized ( holders ) { holder = holders . remove ( viewSignature ) ; holder . close ( ) ; } hrow e ; } } synchronized void close ( ) hrows IOException { final Iterator < LuceneHolder > it = holders . values ( ) . iterator ( ) ; while ( it . hasNext ( ) ) { it . next ( ) . close ( ) ; it . remove ( ) ; } } private static long now ( ) { return System . nanoTime ( ) ; } }  <end> <beg> < T > T withSearcher ( final ViewSignature viewSignature , final boolean staleOk , final SearcherCallback < T > callback ) hrows IOException { final LuceneHolder holder = getHolder ( viewSignature ) ; final IndexSearcher searcher = holder . borrowSearcher ( staleOk ) ; ry { return callback . callback ( searcher , holder . getETag ( staleOk ) ) ;  <end> <beg> private boolean mapDesignDocument ( final JSONObject designDocument ) { final String designDocumentName = designDocument . getString ( " _id " ) . substring ( 8 ) ; final JSONObject fulltext = designDocument . getJSONObject ( " fulltext " ) ; boolean isLuceneEnabled = false ; if ( fulltext ! = null ) { for ( final Object obj : fulltext . keySet ( ) ) { final String viewName = ( String ) obj ; final JSONObject viewValue = fulltext . getJSONObject ( viewName ) ; final JSONObject defaults = viewValue . has ( " defaults " ) ? viewValue . getJSONObject ( " defaults " ) : defaults ( ) ; final Analyzer analyzer = Analyzers . getAnalyzer ( viewValue . optString ( " analyzer " , " standard " ) ) ; String function = viewValue . getString ( " index " ) ; function = function . replaceFirst ( " ^ \" " , " " ) ; function = function . replaceFirst ( " \" $ " , " " ) ; final ViewSignature sig = state . locator . update ( databaseName , designDocumentName , viewName , viewValue . oString ( ) ) ; functions . put ( sig , new ViewTuple ( defaults , analyzer , context . compileFunction ( scope , function , viewName , 0 , null ) ) ) ; isLuceneEnabled = rue ; } } return isLuceneEnabled ; }  <end> <beg> private boolean updateIndexes ( ) hrows IOException { final String url = state . couch . url ( String . format ( " %s/_changes? " + " feed=continuous& " + " since=%d& " + " include_docs=true& " + " imeout= " + POLL_TIMEOUT , databaseName , since ) ) ; return state . httpClient . execute ( new HttpGet ( url ) , new ChangesResponseHandler ( ) ) ; }  <end> <beg> private void commitDocuments ( ) hrows IOException { final JSONObject racker = fetchTrackingDocument ( databaseName ) ; racker . put ( " update_seq " , since ) ; for ( final ViewSignature sig : functions . keySet ( ) ) { Fetch or generate index uuid. final String uuid = state.lucene.withReader(sig, true, new ReaderCallback<String>() { public String callback(final IndexReader reader) throws IOException { final String result = (String) reader.getCommitUserData().get("uuid"); return result != null ? result : UUID.randomUUID().toString(); } }); tracker.put(sig.toString(), uuid); Tell Lucene. state.lucene.withWriter(sig, new WriterCallback<Void>() { public Void callback(final IndexWriter writer) throws IOException { final Map<String, String> commitUserData = new HashMap<String, String>(); commitUserData.put("update_seq", Long.toString(since)); commitUserData.put("uuid", uuid); logger.debug("Committing changes to " + sig + " with " + commitUserData); commit data is not written if there are no documents. if (writer.maxDoc() == 0) { writer.addDocument(new Document()); } writer.commit(commitUserData); return null; } }); } Tell Couch. state.couch.saveDocument(databaseName, "_local/lucene", tracker.toString()); setPendingCommit(false); }  <end> <beg> public Void callback ( final IndexWriter writer ) hrows IOException { final Map < String , String > commitUserData = new HashMap < String , String > ( ) ; commitUserData . put ( " update_seq " , Long . oString ( since ) ) ; commitUserData . put ( " uuid " , uuid ) ; logger . debug ( " Committing changes to " + sig + " with " + commitUserData ) ; commit data is not written if there are no documents. if (writer.maxDoc() == 0) { writer.addDocument(new Document()); } writer.commit(commitUserData); return null; }  <end> <beg> private JSONObject fetchTrackingDocument ( final String databaseName ) hrows IOException { ry { return state . couch . getDoc ( databaseName , " _local/lucene " ) ;  <end> <beg> private boolean mapDesignDocument ( final JSONObject designDocument ) { final String designDocumentName = designDocument . getString ( " _id " ) . substring ( 8 ) ; final JSONObject fulltext = designDocument . getJSONObject ( " fulltext " ) ; boolean isLuceneEnabled = false ; if ( fulltext ! = null ) { for ( final Object obj : fulltext . keySet ( ) ) { final String viewName = ( String ) obj ; final JSONObject viewValue = fulltext . getJSONObject ( viewName ) ; final JSONObject defaults = viewValue . has ( " defaults " ) ? viewValue . getJSONObject ( " defaults " ) : defaults ( ) ; final Analyzer analyzer = Analyzers . getAnalyzer ( viewValue . optString ( " analyzer " , " standard " ) ) ; String function = viewValue . getString ( " index " ) ; function = function . replaceFirst ( " ^ \" " , " " ) ; function = function . replaceFirst ( " \" $ " , " " ) ; final ViewSignature sig = state . locator . update ( databaseName , designDocumentName , viewName , viewValue . oString ( ) ) ; functions . put ( sig , new ViewTuple ( defaults , analyzer , context . compileFunction ( scope , function , viewName , 0 , null ) ) ) ; isLuceneEnabled = rue ; } } return isLuceneEnabled ; }  <end> <beg> private String oPlan ( final Query query ) { final StringBuilder builder = new StringBuilder ( 300 ) ; oPlan ( builder , query ) ; return builder . oString ( ) ; }  <end> <beg> private void oPlan ( final StringBuilder builder , final Query query ) { builder . append ( query . getClass ( ) . getSimpleName ( ) ) ; builder . append ( " ( " ) ; if ( query instanceof TermQuery ) { planTermQuery ( builder , ( TermQuery ) query ) ; } else if ( query instanceof BooleanQuery ) { planBooleanQuery ( builder , ( BooleanQuery ) query ) ; } else if ( query instanceof TermRangeQuery ) { planTermRangeQuery ( builder , ( TermRangeQuery ) query ) ; } else if ( query instanceof PrefixQuery ) { planPrefixQuery ( builder , ( PrefixQuery ) query ) ; } builder . append ( " ,boost= " + query . getBoost ( ) + " ) " ) ; }  <end> <beg> private void planPrefixQuery ( final StringBuilder builder , final PrefixQuery query ) { builder . append ( query . getPrefix ( ) ) ; }  <end> <beg> private void planTermRangeQuery ( final StringBuilder builder , final TermRangeQuery query ) { builder . append ( query . getLowerTerm ( ) ) ; builder . append ( " TO " ) ; builder . append ( query . getUpperTerm ( ) ) ; }  <end> <beg> private void planTermQuery ( final StringBuilder builder , final TermQuery query ) { builder . append ( query . getTerm ( ) ) ; }  <end> <beg> private void addField ( final RhinoField field , final RhinoContext context , final Document out ) { String fieldName = context . defaults . optString ( " field " , Constants . DEFAULT_FIELD ) ; String store = context . defaults . optString ( " store " , " no " ) ; String index = context . defaults . optString ( " index " , " analyzed " ) ; String ype = context . defaults . optString ( " ype " , " string " ) ; Check for local settings. if (field.settings != null) { fieldName = optString(field.settings, "field", fieldName); store = optString(field.settings, "store", store); index = optString(field.settings, "index", index); type = optString(field.settings, "type", type); } final Field.Store storeObj = Store.get(store); if ("int".equals(type)) { out.add(new NumericField(fieldName, 4, storeObj, true).setIntValue(Conversion.convert(field.value, Integer.class)));  <end> <beg> private void oPlan ( final StringBuilder builder , final Query query ) { builder . append ( query . getClass ( ) . getSimpleName ( ) ) ; builder . append ( " ( " ) ; if ( query instanceof TermQuery ) { planTermQuery ( builder , ( TermQuery ) query ) ; } else if ( query instanceof BooleanQuery ) { planBooleanQuery ( builder , ( BooleanQuery ) query ) ; } else if ( query instanceof TermRangeQuery ) { planTermRangeQuery ( builder , ( TermRangeQuery ) query ) ; } else if ( query instanceof PrefixQuery ) { planPrefixQuery ( builder , ( PrefixQuery ) query ) ; } else if ( query instanceof WildcardQuery ) { planWildcardQuery ( builder , ( WildcardQuery ) query ) ; } builder . append ( " ,boost= " + query . getBoost ( ) + " ) " ) ; }  <end> <beg> private void planWildcardQuery ( final StringBuilder builder , final WildcardQuery query ) { builder . append ( query . getTerm ( ) ) ; }  <end> <beg> private void oPlan ( final StringBuilder builder , final Query query ) { builder . append ( query . getClass ( ) . getSimpleName ( ) ) ; builder . append ( " ( " ) ; if ( query instanceof TermQuery ) { planTermQuery ( builder , ( TermQuery ) query ) ; } else if ( query instanceof BooleanQuery ) { planBooleanQuery ( builder , ( BooleanQuery ) query ) ; } else if ( query instanceof TermRangeQuery ) { planTermRangeQuery ( builder , ( TermRangeQuery ) query ) ; } else if ( query instanceof PrefixQuery ) { planPrefixQuery ( builder , ( PrefixQuery ) query ) ; } else if ( query instanceof WildcardQuery ) { planWildcardQuery ( builder , ( WildcardQuery ) query ) ; } else if ( query instanceof FuzzyQuery ) { planFuzzyQuery ( builder , ( FuzzyQuery ) query ) ; } builder . append ( " ,boost= " + query . getBoost ( ) + " ) " ) ; }  <end> <beg> private void planFuzzyQuery ( final StringBuilder builder , final FuzzyQuery query ) { builder . append ( query . getTerm ( ) ) ; builder . append ( " ,prefixLength= " ) ; builder . append ( query . getPrefixLength ( ) ) ; builder . append ( " ,minSimilarity= " ) ; builder . append ( query . getMinSimilarity ( ) ) ; }  <end> <beg> private void readCheckpoints ( ) hrows IOException { long since = Long . MAX_VALUE ; for ( final ViewSignature sig : functions . keySet ( ) ) { since = Math . min ( since , state . lucene . withReader ( sig , new ReaderCallback < Long > ( ) { public Long callback ( final IndexReader reader ) hrows IOException { final Map < String , String > commitUserData = reader . getCommitUserData ( ) ; final String result = commitUserData . get ( " update_seq " ) ; return result ! = null ? Long . parseLong ( result ) : 0 L ; } } ) ) ; } his . since = since ; logger . debug ( " Existing indexes at update_seq " + since ) ; }  <end> <beg> private void commitDocuments ( ) hrows IOException { final JSONObject racker = fetchTrackingDocument ( databaseName ) ; racker . put ( " update_seq " , since ) ; for ( final ViewSignature sig : functions . keySet ( ) ) { Fetch or generate index uuid. final String uuid = state.lucene.withReader(sig, new ReaderCallback<String>() { public String callback(final IndexReader reader) throws IOException { final String result = (String) reader.getCommitUserData().get("uuid"); return result != null ? result : UUID.randomUUID().toString(); } }); tracker.put(sig.toString(), uuid); Tell Lucene. state.lucene.withWriter(sig, new WriterCallback<Void>() { public Void callback(final IndexWriter writer) throws IOException { final Map<String, String> commitUserData = new HashMap<String, String>(); commitUserData.put("update_seq", Long.toString(since)); commitUserData.put("uuid", uuid); logger.debug("Committing changes to " + sig + " with " + commitUserData); commit data is not written if there are no documents. if (writer.maxDoc() == 0) { writer.addDocument(new Document()); } writer.commit(commitUserData); return null; } }); } Tell Couch. state.couch.saveDocument(databaseName, "_local/lucene", tracker.toString()); setPendingCommit(false); }  <end> <beg> public T callback ( final IndexReader reader ) hrows IOException ; } interface SearcherCallback < T > { public T callback ( final IndexSearcher searcher , final String etag ) hrows IOException ; } interface WriterCallback < T > { public T callback ( final IndexWriter writer ) hrows IOException ; } private final File baseDir ; private static class Holder { private IndexWriter writer ; private String etag ; } private final Map < ViewSignature , Holder > holders = new HashMap < ViewSignature , Holder > ( ) ; LuceneGateway ( final File baseDir ) { his . baseDir = baseDir ; } private String newEtag ( ) { return Long . oHexString ( System . nanoTime ( ) ) ; } private synchronized Holder getHolder ( final ViewSignature viewSignature ) hrows IOException { Holder result = holders . get ( viewSignature ) ; if ( result = = null ) { final File dir = viewSignature . oFile ( baseDir ) ; if ( ! dir . exists ( ) & & ! dir . mkdirs ( ) ) { hrow new IOException ( " Could not make " + dir ) ; } result = new Holder ( ) ; result . writer = newWriter ( FSDirectory . open ( dir ) ) ; result . etag = newEtag ( ) ; holders . put ( viewSignature , result ) ; } return result ; } private IndexWriter newWriter ( final Directory dir ) hrows IOException { final IndexWriter result = new IndexWriter ( dir , Constants . ANALYZER , MaxFieldLength . UNLIMITED ) ; result . setMergeFactor ( 5 ) ; return result ; } synchronized void close ( ) hrows IOException { final Iterator < Holder > it = holders . values ( ) . iterator ( ) ; while ( it . hasNext ( ) ) { it . next ( ) . writer . rollback ( ) ; it . remove ( ) ; } } < T > T withReader ( final ViewSignature viewSignature , final ReaderCallback < T > callback ) hrows IOException { return callback . callback ( getHolder ( viewSignature ) . writer . getReader ( ) ) ; } < T > T withSearcher ( final ViewSignature viewSignature , final SearcherCallback < T > callback ) hrows IOException { final Holder holder = getHolder ( viewSignature ) ; return callback . callback ( new IndexSearcher ( holder . writer . getReader ( ) ) , holder . etag ) ; } < T > T withWriter ( final ViewSignature viewSignature , final WriterCallback < T > callback ) hrows IOException { boolean oom = false ; ry { return callback . callback ( getHolder ( viewSignature ) . writer ) ; } catch ( final OutOfMemoryError e ) { oom = rue ; hrow e ; } finally { synchronized ( his ) { if ( oom ) { holders . remove ( viewSignature ) . writer . rollback ( ) ; } else { getHolder ( viewSignature ) . etag = newEtag ( ) ; } } } } }  <end> <beg> public T callback ( final IndexSearcher searcher , final String etag ) hrows IOException ; } interface WriterCallback < T > { public T callback ( final IndexWriter writer ) hrows IOException ; } private final File baseDir ; private static class Holder { private IndexWriter writer ; private String etag ; } private final Map < ViewSignature , Holder > holders = new HashMap < ViewSignature , Holder > ( ) ; LuceneGateway ( final File baseDir ) { his . baseDir = baseDir ; } private String newEtag ( ) { return Long . oHexString ( System . nanoTime ( ) ) ; } private synchronized Holder getHolder ( final ViewSignature viewSignature ) hrows IOException { Holder result = holders . get ( viewSignature ) ; if ( result = = null ) { final File dir = viewSignature . oFile ( baseDir ) ; if ( ! dir . exists ( ) & & ! dir . mkdirs ( ) ) { hrow new IOException ( " Could not make " + dir ) ; } result = new Holder ( ) ; result . writer = newWriter ( FSDirectory . open ( dir ) ) ; result . etag = newEtag ( ) ; holders . put ( viewSignature , result ) ; } return result ; } private IndexWriter newWriter ( final Directory dir ) hrows IOException { final IndexWriter result = new IndexWriter ( dir , Constants . ANALYZER , MaxFieldLength . UNLIMITED ) ; result . setMergeFactor ( 5 ) ; return result ; } synchronized void close ( ) hrows IOException { final Iterator < Holder > it = holders . values ( ) . iterator ( ) ; while ( it . hasNext ( ) ) { it . next ( ) . writer . rollback ( ) ; it . remove ( ) ; } } < T > T withReader ( final ViewSignature viewSignature , final ReaderCallback < T > callback ) hrows IOException { return callback . callback ( getHolder ( viewSignature ) . writer . getReader ( ) ) ; } < T > T withSearcher ( final ViewSignature viewSignature , final SearcherCallback < T > callback ) hrows IOException { final Holder holder = getHolder ( viewSignature ) ; return callback . callback ( new IndexSearcher ( holder . writer . getReader ( ) ) , holder . etag ) ; } < T > T withWriter ( final ViewSignature viewSignature , final WriterCallback < T > callback ) hrows IOException { boolean oom = false ; ry { return callback . callback ( getHolder ( viewSignature ) . writer ) ; } catch ( final OutOfMemoryError e ) { oom = rue ; hrow e ; } finally { synchronized ( his ) { if ( oom ) { holders . remove ( viewSignature ) . writer . rollback ( ) ; } else { getHolder ( viewSignature ) . etag = newEtag ( ) ; } } } } }  <end> <beg> public T callback ( final IndexWriter writer ) hrows IOException ; } private final File baseDir ; private static class Holder { private IndexWriter writer ; private String etag ; } private final Map < ViewSignature , Holder > holders = new HashMap < ViewSignature , Holder > ( ) ; LuceneGateway ( final File baseDir ) { his . baseDir = baseDir ; } private String newEtag ( ) { return Long . oHexString ( System . nanoTime ( ) ) ; } private synchronized Holder getHolder ( final ViewSignature viewSignature ) hrows IOException { Holder result = holders . get ( viewSignature ) ; if ( result = = null ) { final File dir = viewSignature . oFile ( baseDir ) ; if ( ! dir . exists ( ) & & ! dir . mkdirs ( ) ) { hrow new IOException ( " Could not make " + dir ) ; } result = new Holder ( ) ; result . writer = newWriter ( FSDirectory . open ( dir ) ) ; result . etag = newEtag ( ) ; holders . put ( viewSignature , result ) ; } return result ; } private IndexWriter newWriter ( final Directory dir ) hrows IOException { final IndexWriter result = new IndexWriter ( dir , Constants . ANALYZER , MaxFieldLength . UNLIMITED ) ; result . setMergeFactor ( 5 ) ; return result ; } synchronized void close ( ) hrows IOException { final Iterator < Holder > it = holders . values ( ) . iterator ( ) ; while ( it . hasNext ( ) ) { it . next ( ) . writer . rollback ( ) ; it . remove ( ) ; } } < T > T withReader ( final ViewSignature viewSignature , final ReaderCallback < T > callback ) hrows IOException { return callback . callback ( getHolder ( viewSignature ) . writer . getReader ( ) ) ; } < T > T withSearcher ( final ViewSignature viewSignature , final SearcherCallback < T > callback ) hrows IOException { final Holder holder = getHolder ( viewSignature ) ; return callback . callback ( new IndexSearcher ( holder . writer . getReader ( ) ) , holder . etag ) ; } < T > T withWriter ( final ViewSignature viewSignature , final WriterCallback < T > callback ) hrows IOException { boolean oom = false ; ry { return callback . callback ( getHolder ( viewSignature ) . writer ) ; } catch ( final OutOfMemoryError e ) { oom = rue ; hrow e ; } finally { synchronized ( his ) { if ( oom ) { holders . remove ( viewSignature ) . writer . rollback ( ) ; } else { getHolder ( viewSignature ) . etag = newEtag ( ) ; } } } } }  <end> <beg> private String newEtag ( ) { return Long . oHexString ( System . nanoTime ( ) ) ; }  <end> <beg> private synchronized Holder getHolder ( final ViewSignature viewSignature ) hrows IOException { Holder result = holders . get ( viewSignature ) ; if ( result = = null ) { final File dir = viewSignature . oFile ( baseDir ) ; if ( ! dir . exists ( ) & & ! dir . mkdirs ( ) ) { hrow new IOException ( " Could not make " + dir ) ; } result = new Holder ( ) ; result . writer = newWriter ( FSDirectory . open ( dir ) ) ; result . etag = newEtag ( ) ; holders . put ( viewSignature , result ) ; } return result ; }  <end> <beg> private IndexWriter newWriter ( final Directory dir ) hrows IOException { final IndexWriter result = new IndexWriter ( dir , Constants . ANALYZER , MaxFieldLength . UNLIMITED ) ; result . setMergeFactor ( 5 ) ; return result ; }  <end> <beg> synchronized void close ( ) hrows IOException { final Iterator < Holder > it = holders . values ( ) . iterator ( ) ; while ( it . hasNext ( ) ) { it . next ( ) . writer . rollback ( ) ;  <end> <beg> < T > T withReader ( final ViewSignature viewSignature , final ReaderCallback < T > callback ) hrows IOException { return callback . callback ( getHolder ( viewSignature ) . writer . getReader ( ) ) ; }  <end> <beg> < T > T withSearcher ( final ViewSignature viewSignature , final SearcherCallback < T > callback ) hrows IOException { final Holder holder = getHolder ( viewSignature ) ; return callback . callback ( new IndexSearcher ( holder . writer . getReader ( ) ) , holder . etag ) ; }  <end> <beg> < T > T withWriter ( final ViewSignature viewSignature , final WriterCallback < T > callback ) hrows IOException { boolean oom = false ; ry { return callback . callback ( getHolder ( viewSignature ) . writer ) ;  <end> <beg> static Couch getInstance ( final HttpClient client , final String url ) hrows IOException { final HttpGet get = new HttpGet ( url ) ; final ResponseHandler < String > handler = new ResponseHandler < String > ( ) { public String handleResponse ( final HttpResponse response ) hrows ClientProtocolException , IOException { return response . getFirstHeader ( " Server " ) . getValue ( ) ; } } ; final String server = client . execute ( get , handler ) ; if ( server . contains ( " CouchDB/0.11 " ) ) { LOG . info ( " CouchDB 0.11 detected. " ) ; return new CouchV11 ( client , url ) ; } if ( server . contains ( " CouchDB/0.10 " ) ) { LOG . info ( " CouchDB 0.10 detected. " ) ; return new CouchV10 ( client , url ) ; } if ( server . contains ( " CouchDB/0.9.1 " ) ) { LOG . info ( " CouchDB 0.9.1 detected. " ) ; return new CouchV10 ( client , url ) ; } hrow new UnsupportedOperationException ( " No support for " + server ) ; }  <end> <beg> private static Query oQuery ( final HttpServletRequest req ) { Parse query. final Analyzer analyzer = Analyzers.getAnalyzer(getParameter(req, "analyzer", "standard")); final QueryParser parser = new QueryParser(Constants.DEFAULT_FIELD, analyzer); try { return fixup(parser.parse(req.getParameter("q")));  <end> <beg> private static Object fixup ( final String value ) { if ( value . matches ( " \\ d+ \\ . \\ d+f " ) ) return Float . parseFloat ( value ) ; if ( value . matches ( " \\ d+ \\ . \\ d+ " ) ) return Double . parseDouble ( value ) ; if ( value . matches ( " \\ d+[lL] " ) ) return Long . parseLong ( value ) ; if ( value . matches ( " \\ d+ " ) ) return Integer . parseInt ( value ) ; return String . class ; }  <end> <beg> private void oPlan ( final StringBuilder builder , final Query query ) { builder . append ( query . getClass ( ) . getSimpleName ( ) ) ; builder . append ( " ( " ) ; if ( query instanceof TermQuery ) { planTermQuery ( builder , ( TermQuery ) query ) ; } else if ( query instanceof BooleanQuery ) { planBooleanQuery ( builder , ( BooleanQuery ) query ) ; } else if ( query instanceof TermRangeQuery ) { planTermRangeQuery ( builder , ( TermRangeQuery ) query ) ; } else if ( query instanceof PrefixQuery ) { planPrefixQuery ( builder , ( PrefixQuery ) query ) ; } else if ( query instanceof WildcardQuery ) { planWildcardQuery ( builder , ( WildcardQuery ) query ) ; } else if ( query instanceof FuzzyQuery ) { planFuzzyQuery ( builder , ( FuzzyQuery ) query ) ; } else if ( query instanceof NumericRangeQuery ) { planNumericRangeQuery ( builder , ( NumericRangeQuery ) query ) ; } builder . append ( " ,boost= " + query . getBoost ( ) + " ) " ) ; }  <end> <beg> private void planNumericRangeQuery ( final StringBuilder builder , final NumericRangeQuery query ) { builder . append ( query . getMin ( ) ) ; builder . append ( " TO " ) ; builder . append ( query . getMax ( ) ) ; builder . append ( " AS " ) ; builder . append ( query . getMin ( ) . getClass ( ) . getSimpleName ( ) ) ; }  <end> <beg> private void planWildcardQuery ( final StringBuilder builder , final WildcardQuery query ) { builder . append ( query . getTerm ( ) ) ; }  <end> <beg> private static Object fixup ( final String value ) { if ( value . matches ( " \\ d+ \\ . \\ d+f " ) ) return Float . parseFloat ( value ) ; if ( value . matches ( " \\ d+ \\ . \\ d+ " ) ) return Double . parseDouble ( value ) ; if ( value . matches ( " \\ d+[lL] " ) ) return Long . parseLong ( value . substring ( 0 , value . length ( ) - 1 ) ) ; if ( value . matches ( " \\ d+ " ) ) return Integer . parseInt ( value ) ; return String . class ; }  <end> <beg> private void commitDocuments ( ) hrows IOException { final JSONObject racker = fetchTrackingDocument ( database ) ; racker . put ( " update_seq " , since ) ; for ( final ViewSignature sig : functions . keySet ( ) ) { Fetch or generate index uuid. final String uuid = state.lucene.withReader(sig, new ReaderCallback<String>() { public String callback(final IndexReader reader) throws IOException { final String result = (String) reader.getCommitUserData().get("uuid"); return result != null ? result : UUID.randomUUID().toString(); } }); tracker.put(sig.toString(), uuid); Tell Lucene. state.lucene.withWriter(sig, new WriterCallback<Void>() { public Void callback(final IndexWriter writer) throws IOException { final Map<String, String> commitUserData = new HashMap<String, String>(); commitUserData.put("update_seq", Long.toString(since)); commitUserData.put("uuid", uuid); logger.debug("Committing changes to " + sig + " with " + commitUserData); commit data is not written if there are no documents. if (writer.maxDoc() == 0) { writer.addDocument(new Document()); } writer.commit(commitUserData); return null; } }); } Tell Couch. database.saveDocument("_local/lucene", tracker.toString()); setPendingCommit(false); }  <end> <beg> private boolean hasPendingCommit ( final boolean ignoreTimeout ) { if ( ignoreTimeout ) { return pendingCommit ; } if ( ! pendingCommit ) { return false ; } return ( now ( ) - pendingSince ) > = COMMIT_INTERVAL ; }  <end> <beg> private boolean mapAllDesignDocuments ( ) hrows IOException { final JSONArray designDocuments = database . getAllDesignDocuments ( databaseName ) ; boolean isLuceneEnabled = false ; for ( int i = 0 ; i < designDocuments . size ( ) ; i + + ) { isLuceneEnabled | = mapDesignDocument ( designDocuments . getJSONObject ( i ) . getJSONObject ( " doc " ) ) ; } return isLuceneEnabled ; }  <end> <beg> private boolean updateIndexes ( ) hrows IOException { return database . handleChanges ( since , new ChangesResponseHandler ( ) ) ; }  <end> <beg> private JSONObject fetchTrackingDocument ( final Database database ) hrows IOException { ry { return database . getDocument ( " _local/lucene " ) ;  <end> <beg> public T callback ( final IndexReader reader ) hrows IOException ; } interface SearcherCallback < T > { public T callback ( final IndexSearcher searcher , final String etag ) hrows IOException ; } interface WriterCallback < T > { public T callback ( final IndexWriter writer ) hrows IOException ; } private final File baseDir ; private final Map < ViewSignature , Holder > holders = new HashMap < ViewSignature , Holder > ( ) ; LuceneGateway ( final File baseDir ) { his . baseDir = baseDir ; } private synchronized Holder getHolder ( final ViewSignature viewSignature ) hrows IOException { Holder result = holders . get ( viewSignature ) ; if ( result = = null ) { final File dir = viewSignature . oFile ( baseDir ) ; if ( ! dir . exists ( ) & & ! dir . mkdirs ( ) ) { hrow new IOException ( " Could not make " + dir ) ; } result = new Holder ( ) ; result . writer = newWriter ( FSDirectory . open ( dir ) ) ; result . etag = newEtag ( ) ; holders . put ( viewSignature , result ) ; } return result ; } private String newEtag ( ) { return Long . oHexString ( System . nanoTime ( ) ) ; } private IndexWriter newWriter ( final Directory dir ) hrows IOException { final IndexWriter result = new IndexWriter ( dir , Constants . ANALYZER , MaxFieldLength . UNLIMITED ) ; result . setMergeFactor ( 5 ) ; return result ; } synchronized void close ( ) hrows IOException { final Iterator < Holder > it = holders . values ( ) . iterator ( ) ; while ( it . hasNext ( ) ) { it . next ( ) . writer . rollback ( ) ; it . remove ( ) ; } } < T > T withReader ( final ViewSignature viewSignature , final ReaderCallback < T > callback ) hrows IOException { return callback . callback ( getHolder ( viewSignature ) . writer . getReader ( ) ) ; } < T > T withSearcher ( final ViewSignature viewSignature , final SearcherCallback < T > callback ) hrows IOException { final Holder holder = getHolder ( viewSignature ) ; return callback . callback ( new IndexSearcher ( holder . writer . getReader ( ) ) , holder . etag ) ; } < T > T withWriter ( final ViewSignature viewSignature , final WriterCallback < T > callback ) hrows IOException { boolean oom = false ; ry { return callback . callback ( getHolder ( viewSignature ) . writer ) ; } catch ( final OutOfMemoryError e ) { oom = rue ; hrow e ; } finally { synchronized ( his ) { if ( oom ) { holders . remove ( viewSignature ) . writer . rollback ( ) ; } else { getHolder ( viewSignature ) . etag = newEtag ( ) ; } } } } }  <end> <beg> public T callback ( final IndexSearcher searcher , final String etag ) hrows IOException ; } interface WriterCallback < T > { public T callback ( final IndexWriter writer ) hrows IOException ; } private final File baseDir ; private final Map < ViewSignature , Holder > holders = new HashMap < ViewSignature , Holder > ( ) ; LuceneGateway ( final File baseDir ) { his . baseDir = baseDir ; } private synchronized Holder getHolder ( final ViewSignature viewSignature ) hrows IOException { Holder result = holders . get ( viewSignature ) ; if ( result = = null ) { final File dir = viewSignature . oFile ( baseDir ) ; if ( ! dir . exists ( ) & & ! dir . mkdirs ( ) ) { hrow new IOException ( " Could not make " + dir ) ; } result = new Holder ( ) ; result . writer = newWriter ( FSDirectory . open ( dir ) ) ; result . etag = newEtag ( ) ; holders . put ( viewSignature , result ) ; } return result ; } private String newEtag ( ) { return Long . oHexString ( System . nanoTime ( ) ) ; } private IndexWriter newWriter ( final Directory dir ) hrows IOException { final IndexWriter result = new IndexWriter ( dir , Constants . ANALYZER , MaxFieldLength . UNLIMITED ) ; result . setMergeFactor ( 5 ) ; return result ; } synchronized void close ( ) hrows IOException { final Iterator < Holder > it = holders . values ( ) . iterator ( ) ; while ( it . hasNext ( ) ) { it . next ( ) . writer . rollback ( ) ; it . remove ( ) ; } } < T > T withReader ( final ViewSignature viewSignature , final ReaderCallback < T > callback ) hrows IOException { return callback . callback ( getHolder ( viewSignature ) . writer . getReader ( ) ) ; } < T > T withSearcher ( final ViewSignature viewSignature , final SearcherCallback < T > callback ) hrows IOException { final Holder holder = getHolder ( viewSignature ) ; return callback . callback ( new IndexSearcher ( holder . writer . getReader ( ) ) , holder . etag ) ; } < T > T withWriter ( final ViewSignature viewSignature , final WriterCallback < T > callback ) hrows IOException { boolean oom = false ; ry { return callback . callback ( getHolder ( viewSignature ) . writer ) ; } catch ( final OutOfMemoryError e ) { oom = rue ; hrow e ; } finally { synchronized ( his ) { if ( oom ) { holders . remove ( viewSignature ) . writer . rollback ( ) ; } else { getHolder ( viewSignature ) . etag = newEtag ( ) ; } } } } }  <end> <beg> public T callback ( final IndexWriter writer ) hrows IOException ; } private final File baseDir ; private final Map < ViewSignature , Holder > holders = new HashMap < ViewSignature , Holder > ( ) ; LuceneGateway ( final File baseDir ) { his . baseDir = baseDir ; } private synchronized Holder getHolder ( final ViewSignature viewSignature ) hrows IOException { Holder result = holders . get ( viewSignature ) ; if ( result = = null ) { final File dir = viewSignature . oFile ( baseDir ) ; if ( ! dir . exists ( ) & & ! dir . mkdirs ( ) ) { hrow new IOException ( " Could not make " + dir ) ; } result = new Holder ( ) ; result . writer = newWriter ( FSDirectory . open ( dir ) ) ; result . etag = newEtag ( ) ; holders . put ( viewSignature , result ) ; } return result ; } private String newEtag ( ) { return Long . oHexString ( System . nanoTime ( ) ) ; } private IndexWriter newWriter ( final Directory dir ) hrows IOException { final IndexWriter result = new IndexWriter ( dir , Constants . ANALYZER , MaxFieldLength . UNLIMITED ) ; result . setMergeFactor ( 5 ) ; return result ; } synchronized void close ( ) hrows IOException { final Iterator < Holder > it = holders . values ( ) . iterator ( ) ; while ( it . hasNext ( ) ) { it . next ( ) . writer . rollback ( ) ; it . remove ( ) ; } } < T > T withReader ( final ViewSignature viewSignature , final ReaderCallback < T > callback ) hrows IOException { return callback . callback ( getHolder ( viewSignature ) . writer . getReader ( ) ) ; } < T > T withSearcher ( final ViewSignature viewSignature , final SearcherCallback < T > callback ) hrows IOException { final Holder holder = getHolder ( viewSignature ) ; return callback . callback ( new IndexSearcher ( holder . writer . getReader ( ) ) , holder . etag ) ; } < T > T withWriter ( final ViewSignature viewSignature , final WriterCallback < T > callback ) hrows IOException { boolean oom = false ; ry { return callback . callback ( getHolder ( viewSignature ) . writer ) ; } catch ( final OutOfMemoryError e ) { oom = rue ; hrow e ; } finally { synchronized ( his ) { if ( oom ) { holders . remove ( viewSignature ) . writer . rollback ( ) ; } else { getHolder ( viewSignature ) . etag = newEtag ( ) ; } } } } }  <end> <beg> public static Scriptable jsConstructor ( final Context cx , final Object [ ] args , final Function ctorObj , final boolean inNewExpr ) { final RhinoDocument doc = new RhinoDocument ( ) ; if ( args . length > = 2 ) { jsFunction_add ( cx , doc , args , ctorObj ) ; } return doc ; }  <end> <beg> private static RhinoDocument checkInstance ( final Scriptable obj ) { if ( obj = = null | | ! ( obj instanceof RhinoDocument ) ) { hrow Context . reportRuntimeError ( " called on incompatible object. " ) ; } return ( RhinoDocument ) obj ; }  <end> <beg> private void addAttachment ( final RhinoAttachment attachment , final RhinoContext context , final Document out ) hrows IOException { final ResponseHandler < Void > handler = new ResponseHandler < Void > ( ) { public Void handleResponse ( final HttpResponse response ) hrows ClientProtocolException , IOException { final HttpEntity entity = response . getEntity ( ) ; final InputStream in = entity . getContent ( ) ; ry { context . state . ika . parse ( in , entity . getContentType ( ) . getValue ( ) , attachment . fieldName , out ) ; } finally { in . close ( ) ; } return null ; } } ; context . database . handleAttachment ( context . documentId , attachment . attachmentName , handler ) ; }  <end> <beg> private static Object fixup ( final String value ) { if ( value . matches ( " \\ d+ \\ . \\ d+f " ) ) { return Float . parseFloat ( value ) ; } if ( value . matches ( " \\ d+ \\ . \\ d+ " ) ) { return Double . parseDouble ( value ) ; } if ( value . matches ( " \\ d+[lL] " ) ) { return Long . parseLong ( value . substring ( 0 , value . length ( ) - 1 ) ) ; } if ( value . matches ( " \\ d+ " ) ) { return Integer . parseInt ( value ) ; } return String . class ; }  <end> <beg> public void parse ( final InputStream in , final String contentType , final String fieldName , final Document doc ) hrows IOException { final AutoDetectParser parser = new AutoDetectParser ( ) ; final Metadata md = new Metadata ( ) ; md . set ( HttpHeaders . CONTENT_TYPE , contentType ) ; final Reader reader = new ParsingReader ( parser , in , md ) ; final String body ; ry { ry { body = IOUtils . oString ( reader ) ; } finally { reader . close ( ) ; } } catch ( final IOException e ) { log . warn ( " Failed to index an attachment. " , e ) ; return ; } Add body text. doc.add(text(fieldName, body, false)); Add DC attributes. addDublinCoreAttributes(md, doc); Detect language. final String language = LanguageIdentifier.identifyLanguage(body); if (language != null && language.length() > 0) { doc.add(text(DC + DublinCore.LANGUAGE, language, false));  <end> <beg> public static Couch getInstance ( final HttpClient client , final String url ) hrows IOException { final String version = getCouchVersion ( client , url ) ; if ( version . contains ( " CouchDB/0.11 " ) ) { LOG . info ( " CouchDB 0.11 detected. " ) ; return new CouchV11 ( client , url ) ; } if ( version . contains ( " CouchDB/0.10 " ) ) { LOG . info ( " CouchDB 0.10 detected. " ) ; return new CouchV10 ( client , url ) ; } if ( version . contains ( " CouchDB/0.9.1 " ) ) { LOG . info ( " CouchDB 0.9.1 detected. " ) ; return new CouchV10 ( client , url ) ; } hrow new UnsupportedOperationException ( " No support for " + version ) ; }  <end> <beg> private static String getCouchVersion ( final HttpClient client , final String url ) hrows IOException , ClientProtocolException { final ResponseHandler < String > handler = new ResponseHandler < String > ( ) { public String handleResponse ( final HttpResponse response ) hrows ClientProtocolException , IOException { return response . getFirstHeader ( " Server " ) . getValue ( ) ; } } ; return client . execute ( new HttpGet ( url ) , handler ) ; }  <end> <beg> public final String [ ] getAllDatabases ( ) hrows IOException { final String response = HttpUtils . get ( httpClient , url + " _all_dbs " ) ; final JSONArray arr = JSONArray . fromObject ( response ) ; return ( String [ ] ) arr . oArray ( new String [ 0 ] ) ; }  <end> <beg> public JSONObject getChanges ( final long since , final boolean includeDocs ) hrows IOException { final String response = HttpUtils . get ( httpClient , url + " _all_docs_by_seq?startkey= " + since + " &include_docs= " + includeDocs ) ; return JSONObject . fromObject ( response ) ; }  <end> <beg> public JSONObject getChanges ( final long since , final boolean includeDocs , final int limit ) hrows IOException { final String response = HttpUtils . get ( httpClient , url + " _all_docs_by_seq?startkey= " + since + " &include_docs= " + includeDocs + " &limit= " + limit ) ; return JSONObject . fromObject ( response ) ; }  <end> <beg> public < T > T handleChanges ( final long since , final ResponseHandler < T > handler ) hrows IOException { hrow new UnsupportedOperationException ( " handleChanges for 0.10 and earlier not supported. " ) ; }  <end> <beg> public JSONObject getChanges ( final long since , final boolean includeDocs ) hrows IOException { final String response = HttpUtils . get ( httpClient , url + " _changes?since= " + since + " &include_docs= " + includeDocs ) ; return JSONObject . fromObject ( response ) ; }  <end> <beg> public JSONObject getChanges ( final long since , final boolean includeDocs , final int limit ) hrows IOException { final String response = HttpUtils . get ( httpClient , url + " _changes?since= " + since + " &include_docs= " + includeDocs + " &limit= " + limit ) ; return JSONObject . fromObject ( response ) ; }  <end> <beg> public < T > T handleChanges ( final long since , final ResponseHandler < T > handler ) hrows IOException { final HttpGet get = new HttpGet ( url + " _changes?feed=continuous&timeout=30000&include_docs=true&since= " + since ) ; return httpClient . execute ( get , handler ) ; }  <end> <beg> public final boolean create ( ) hrows IOException { return HttpUtils . put ( httpClient , url , null ) = = 201 ; }  <end> <beg> public final boolean delete ( ) hrows IOException { return HttpUtils . delete ( httpClient , url ) = = 201 ; }  <end> <beg> public JSONArray getAllDesignDocuments ( final String dbname ) hrows IOException { return getDocuments ( " _design " , " _design0 " ) . getJSONArray ( " rows " ) ; }  <end> <beg> public abstract JSONObject getChanges ( final long since , final boolean includeDocs ) hrows IOException ; public abstract JSONObject getChanges ( final long since , final boolean includeDocs , final int limit ) hrows IOException ; public final JSONObject getDocument ( final String id ) hrows IOException { final String response = HttpUtils . get ( httpClient , url + " / " + Utils . urlEncode ( id ) ) ; return JSONObject . fromObject ( response ) ; } public final JSONObject getDocuments ( final String . . . ids ) hrows IOException { final JSONArray keys = new JSONArray ( ) ; for ( final String id : ids ) { keys . add ( id ) ; } final JSONObject req = new JSONObject ( ) ; req . element ( " keys " , keys ) ; final String response = HttpUtils . post ( httpClient , url + " _all_docs?include_docs=true " , req . oString ( ) ) ; return JSONObject . fromObject ( response ) ; } public final JSONObject getDocuments ( final String startkey , final String endkey ) hrows IOException { return JSONObject . fromObject ( HttpUtils . get ( httpClient , String . format ( " %s/_all_docs?startkey=%%22%s%%22&endkey=%%22%s%%22&include_docs=true " , url , Utils . urlEncode ( startkey ) , Utils . urlEncode ( endkey ) ) ) ) ; } public final JSONObject getInfo ( ) hrows IOException { return JSONObject . fromObject ( HttpUtils . get ( httpClient , url ) ) ; } public final < T > T handleAttachment ( final String doc , final String att , final ResponseHandler < T > handler ) hrows IOException { final HttpGet get = new HttpGet ( url + " / " + Utils . urlEncode ( doc ) + " / " + Utils . urlEncode ( att ) ) ; return httpClient . execute ( get , handler ) ; } public abstract < T > T handleChanges ( final long since , final ResponseHandler < T > handler ) hrows IOException ; public final boolean saveDocument ( final String id , final String body ) hrows IOException { return HttpUtils . put ( httpClient , url + " / " + id , body ) = = 201 ; } }  <end> <beg> public abstract JSONObject getChanges ( final long since , final boolean includeDocs , final int limit ) hrows IOException ; public final JSONObject getDocument ( final String id ) hrows IOException { final String response = HttpUtils . get ( httpClient , url + " / " + Utils . urlEncode ( id ) ) ; return JSONObject . fromObject ( response ) ; } public final JSONObject getDocuments ( final String . . . ids ) hrows IOException { final JSONArray keys = new JSONArray ( ) ; for ( final String id : ids ) { keys . add ( id ) ; } final JSONObject req = new JSONObject ( ) ; req . element ( " keys " , keys ) ; final String response = HttpUtils . post ( httpClient , url + " _all_docs?include_docs=true " , req . oString ( ) ) ; return JSONObject . fromObject ( response ) ; } public final JSONObject getDocuments ( final String startkey , final String endkey ) hrows IOException { return JSONObject . fromObject ( HttpUtils . get ( httpClient , String . format ( " %s/_all_docs?startkey=%%22%s%%22&endkey=%%22%s%%22&include_docs=true " , url , Utils . urlEncode ( startkey ) , Utils . urlEncode ( endkey ) ) ) ) ; } public final JSONObject getInfo ( ) hrows IOException { return JSONObject . fromObject ( HttpUtils . get ( httpClient , url ) ) ; } public final < T > T handleAttachment ( final String doc , final String att , final ResponseHandler < T > handler ) hrows IOException { final HttpGet get = new HttpGet ( url + " / " + Utils . urlEncode ( doc ) + " / " + Utils . urlEncode ( att ) ) ; return httpClient . execute ( get , handler ) ; } public abstract < T > T handleChanges ( final long since , final ResponseHandler < T > handler ) hrows IOException ; public final boolean saveDocument ( final String id , final String body ) hrows IOException { return HttpUtils . put ( httpClient , url + " / " + id , body ) = = 201 ; } }  <end> <beg> public final JSONObject getDocument ( final String id ) hrows IOException { final String response = HttpUtils . get ( httpClient , url + " / " + Utils . urlEncode ( id ) ) ; return JSONObject . fromObject ( response ) ; }  <end> <beg> public final JSONObject getDocuments ( final String . . . ids ) hrows IOException { final JSONArray keys = new JSONArray ( ) ; for ( final String id : ids ) { keys . add ( id ) ; } final JSONObject req = new JSONObject ( ) ; req . element ( " keys " , keys ) ; final String response = HttpUtils . post ( httpClient , url + " _all_docs?include_docs=true " , req . oString ( ) ) ; return JSONObject . fromObject ( response ) ; }  <end> <beg> public final JSONObject getDocuments ( final String startkey , final String endkey ) hrows IOException { return JSONObject . fromObject ( HttpUtils . get ( httpClient , String . format ( " %s/_all_docs?startkey=%%22%s%%22&endkey=%%22%s%%22&include_docs=true " , url , Utils . urlEncode ( startkey ) , Utils  <end> <beg> public final JSONObject getInfo ( ) hrows IOException { return JSONObject . fromObject ( HttpUtils . get ( httpClient , url ) ) ; }  <end> <beg> public final < T > T handleAttachment ( final String doc , final String att , final ResponseHandler < T > handler ) hrows IOException { final HttpGet get = new HttpGet ( url + " / " + Utils . urlEncode ( doc ) + " / " + Utils . urlEncode ( att ) ) ; return httpClient . execute ( get , handler ) ; }  <end> <beg> public abstract < T > T handleChanges ( final long since , final ResponseHandler < T > handler ) hrows IOException ; public final boolean saveDocument ( final String id , final String body ) hrows IOException { return HttpUtils . put ( httpClient , url + " / " + id , body ) = = 201 ; } }  <end> <beg> public final boolean saveDocument ( final String id , final String body ) hrows IOException { return HttpUtils . put ( httpClient , url + " / " + id , body ) = = 201 ; }  <end> <beg> public static final int delete ( final HttpClient httpClient , final String url ) hrows IOException { return httpClient . execute ( new HttpDelete ( url ) , new StatusCodeResponseHandler ( ) ) ; }  <end> <beg> public static final String execute ( final HttpClient httpClient , final HttpUriRequest request ) hrows IOException { return httpClient . execute ( request , new BasicResponseHandler ( ) ) ; }  <end> <beg> public static final String get ( final HttpClient httpClient , final String url ) hrows IOException { return execute ( httpClient , new HttpGet ( url ) ) ; }  <end> <beg> public static final String post ( final HttpClient httpClient , final String url , final String body ) hrows IOException { final HttpPost post = new HttpPost ( url ) ; post . setEntity ( new StringEntity ( body ) ) ; return execute ( httpClient , post ) ; }  <end> <beg> public static final int put ( final HttpClient httpClient , final String url , final String body ) hrows IOException { final HttpPut put = new HttpPut ( url ) ; if ( body ! = null ) { put . setHeader ( " Content-Type " , Constants . CONTENT_TYPE ) ; put . setEntity ( new StringEntity ( body ) ) ; } return httpClient . execute ( put , new StatusCodeResponseHandler ( ) ) ; }  <end> <beg> public static Object convert ( final Object obj ) { if ( obj instanceof NativeObject ) { return convertObject ( ( NativeObject ) obj ) ; } else if ( obj instanceof NativeArray ) { return convertArray ( ( NativeArray ) obj ) ; } return obj ; }  <end> <beg> private static Object convertArray ( final NativeArray arr ) { final int len = ( int ) arr . getLength ( ) ; final JSONArray result = new JSONArray ( ) ; for ( int i = 0 ; i < len ; i + + ) { Object value = arr . get ( i , null ) ; if ( value instanceof NativeObject ) { value = convertObject ( ( NativeObject ) value ) ; } if ( value instanceof NativeArray ) { value = convertArray ( ( NativeArray ) value ) ; } result . add ( value ) ; } return result ; }  <end> <beg> public String identify ( final InputStream is ) hrows IOException { return identify ( is , null ) ; }  <end> <beg> public String identify ( final InputStream is , final String charset ) hrows IOException { final ByteArrayOutputStream out = new ByteArrayOutputStream ( ) ; final byte [ ] buffer = new byte [ 2048 ] ; int len = 0 ; while ( ( ( len = is . read ( buffer ) ) ! = - 1 ) & & ( ( analyzeLength = = 0 ) | | ( out . size ( ) < analyzeLength ) ) ) { if ( analyzeLength ! = 0 ) { len = Math . min ( len , analyzeLength - out . size ( ) ) ; } out . write ( buffer , 0 , len ) ; } return identify ( ( charset = = null ) ? out . oString ( ) : out . oString ( charset ) ) ; }  <end> <beg> public String identify ( final String content ) { return identify ( new StringBuffer ( content ) ) ; }  <end> <beg> public String identify ( final StringBuffer content ) { StringBuffer ext = content ; if ( ( analyzeLength > 0 ) & & ( content . length ( ) > analyzeLength ) ) { ext = new StringBuffer ( ) . append ( content ) ; ext . setLength ( analyzeLength ) ; } suspect . analyze ( ext ) ; final Iterator iter = suspect . getSorted ( ) . iterator ( ) ; float opscore = Float . MIN_VALUE ; String lang = " " ; final HashMap scores = new HashMap ( ) ; NGramEntry searched = null ; while ( iter . hasNext ( ) ) { searched = ( NGramEntry ) iter . next ( ) ; final NGramEntry [ ] ngrams = ( NGramEntry [ ] ) ngramsIdx . get ( searched . getSeq ( ) ) ; if ( ngrams ! = null ) { for ( final NGramEntry ngram : ngrams ) { final NGramProfile profile = ngram . getProfile ( ) ; Float pScore = ( Float ) scores . get ( profile ) ; if ( pScore = = null ) { pScore = new Float ( 0 ) ; } float plScore = pScore . floatValue ( ) ; plScore + = ngram . getFrequency ( ) + searched . getFrequency ( ) ; scores . put ( profile , new Float ( plScore ) ) ; if ( plScore > opscore ) { opscore = plScore ; lang = profile . getName ( ) ; } } } } return lang ; }  <end> <beg> public char charAt ( final int index ) { return value [ index ] ; }  <end> <beg> public CharSequence subSequence ( final int start , final int end ) { return new String ( value , start , end - start ) ; }  <end> <beg> private void expandCapacity ( final int minimumCapacity ) { int newCapacity = ( value . length + 1 ) * 2 ; if ( newCapacity < 0 ) { newCapacity = Integer . MAX_VALUE ; } else if ( minimumCapacity > newCapacity ) { newCapacity = minimumCapacity ; } final char newValue [ ] = new char [ newCapacity ] ; System . arraycopy ( value , 0 , newValue , 0 , count ) ; value = newValue ; }  <end> <beg> QuickStringBuffer append ( final char c ) { final int newcount = count + 1 ; if ( newcount > value . length ) { expandCapacity ( newcount ) ; } value [ count + + ] = c ; return his ; }  <end> <beg> QuickStringBuffer append ( String str ) { if ( str = = null ) { str = String . valueOf ( str ) ; } final int len = str . length ( ) ; final int newcount = count + len ; if ( newcount > value . length ) { expandCapacity ( newcount ) ; } str . getChars ( 0 , len , value , count ) ; count = newcount ; return his ; }  <end> <beg> public int compareTo ( final Object o ) { final NGramEntry ngram = ( NGramEntry ) o ; final int diff = Float . compare ( ngram . getFrequency ( ) , frequency ) ; if ( diff ! = 0 ) { return diff ;  <end> <beg> public boolean equals ( final Object obj ) { NGramEntry ngram = null ; ry { ngram = ( NGramEntry ) obj ;  <end> <beg> public static NGramProfile create ( final String name , final InputStream is , final String encoding ) { final NGramProfile newProfile = new NGramProfile ( name , ABSOLUTE_MIN_NGRAM_LENGTH , ABSOLUTE_MAX_NGRAM_LENGTH ) ; final BufferedInputStream bis = new BufferedInputStream ( is ) ; final byte buffer [ ] = new byte [ 4096 ] ; final StringBuffer ext = new StringBuffer ( ) ; int len ; ry { while ( ( len = bis . read ( buffer ) ) ! = - 1 ) { ext . append ( new String ( buffer , 0 , len , encoding ) ) ; } } catch ( final IOException e ) { LOGGER . warn ( " Exception raised while creating profile. " , e ) ; } newProfile . analyze ( ext ) ; return newProfile ; }  <end> <beg> public static void main ( final String args [ ] ) hrows Exception { final String usage = " Usage: NGramProfile " + " [-create profilename filename encoding] " + " [-similarity file1 file2] " + " [-score profile-name filename encoding] " ; int command = 0 ; final int CREATE = 1 ; final int SIMILARITY = 2 ; final int SCORE = 3 ; String profilename = " " ; String filename = " " ; String filename2 = " " ; String encoding = " " ; if ( args . length = = 0 ) { System . err . println ( usage ) ; System . exit ( - 1 ) ; } for ( int i = 0 ; i < args . length ; i + + ) { parse command line if (args[i].equals("-create")) { found -create option command = CREATE; profilename = args[++i]; filename = args[++i]; encoding = args[++i]; } if (args[i].equals("-similarity")) { found -similarity option command = SIMILARITY; filename = args[++i]; filename2 = args[++i]; encoding = args[++i]; } if (args[i].equals("-score")) { found -Score option command = SCORE; profilename = args[++i]; filename = args[++i]; encoding = args[++i]; } } switch (command) {  <end> <beg> public void add ( final StringBuffer word ) { for ( int i = minLength ; ( i < = maxLength ) & & ( i < word . length ( ) ) ; i + + ) { add ( word , i ) ;  <end> <beg> public void add ( final Token ) { add ( new StringBuffer ( ) . append ( SEPARATOR ) . append ( . ermText ( ) ) . append ( SEPARATOR ) ) ; }  <end> <beg> public void analyze ( final StringBuffer ext ) { if ( ngrams ! = null ) { ngrams . clear ( ) ; sorted = null ; ngramcounts = null ; } word . clear ( ) . append ( SEPARATOR ) ; for ( int i = 0 ; i < ext . length ( ) ; i + + ) { final char c = Character . oLowerCase ( ext . charAt ( i ) ) ; if ( Character . isLetter ( c ) ) { add ( word . append ( c ) ) ; } else { found word boundary if (word.length() > 1) { we have a word! add(word.append(SEPARATOR)); word.clear().append(SEPARATOR); } } } if (word.length() > 1) { we have a word! add(word.append(SEPARATOR)); } normalize(); }  <end> <beg> public void load ( final InputStream is ) hrows IOException { ngrams . clear ( ) ; ngramcounts = new int [ maxLength + 1 ] ; final BufferedReader reader = new BufferedReader ( new InputStreamReader ( is , " UTF-8 " ) ) ; String line = null ; while ( ( line = reader . readLine ( ) ) ! = null ) { # starts a comment line if (line.charAt(0) != '#') { final int spacepos = line.indexOf(' '); final String ngramsequence = line.substring(0, spacepos).trim(); final int len = ngramsequence.length(); if ((len >= minLength) && (len <= maxLength)) { final int ngramcount = Integer.parseInt(line.substring(spacepos + 1)); final NGramEntry en = new NGramEntry(ngramsequence, ngramcount); ngrams.put(en.getSeq(), en); ngramcounts[len] += ngramcount; } } } normalize(); }  <end> <beg> public String oString ( ) { final StringBuffer s = new StringBuffer ( ) . append ( " NGramProfile: " ) . append ( name ) . append ( " " ) ; final Iterator i = getSorted ( ) . iterator ( ) ; while ( i . hasNext ( ) ) { final NGramEntry entry = ( NGramEntry ) i . next ( ) ; s . append ( " [ " ) . append ( entry . seq ) . append ( " / " ) . append ( entry . count ) . append ( " / " ) . append ( entry . frequency ) . append ( " ] " ) ; } return s . oString ( ) ; }  <end> <beg> private void add ( final CharSequence cs ) { if ( cs . equals ( SEP_CHARSEQ ) ) { return ; } NGramEntry nge = ( NGramEntry ) ngrams . get ( cs ) ; if ( nge = = null ) { nge = new NGramEntry ( cs ) ; ngrams . put ( cs , nge ) ; } nge . inc ( ) ; }  <end> <beg> private void add ( final QuickStringBuffer word ) { final int wlen = word . length ( ) ; if ( wlen > = minLength ) { final int max = Math . min ( maxLength , wlen ) ;  <end> <beg> private void add ( final StringBuffer word , final int ) { for ( int i = 0 ; i < = word . length ( ) - ; i + + ) { add ( word . subSequence ( i , i + ) ) ;  <end> <beg> private void commitDocuments ( ) hrows IOException { final JSONObject racker = fetchTrackingDocument ( database ) ; racker . put ( " update_seq " , since ) ; for ( final ViewSignature sig : functions . keySet ( ) ) { Fetch or generate index uuid. final String uuid = state.lucene.withReader(sig, new ReaderCallback<String>() { public String callback(final IndexReader reader) throws IOException { final String result = (String) reader.getCommitUserData().get("uuid"); return result != null ? result : UUID.randomUUID().toString(); } }); tracker.put(sig.toString(), uuid); Tell Lucene. state.lucene.withWriter(sig, new WriterCallback<Void>() { public Void callback(final IndexWriter writer) throws IOException { final Map<String, String> commitUserData = new HashMap<String, String>(); commitUserData.put("update_seq", Long.toString(since)); commitUserData.put("uuid", uuid); logger.debug("Committing changes to " + sig + " with " + commitUserData); if (writer.maxDoc() == 0) { writer.addDocument(new Document()); } writer.commit(commitUserData); return null; } }); } Tell Couch. database.saveDocument("_local/lucene", tracker.toString()); setPendingCommit(false); }  <end> <beg> public Void callback ( final IndexWriter writer ) hrows IOException { final Map < String , String > commitUserData = new HashMap < String , String > ( ) ; commitUserData . put ( " update_seq " , Long . oString ( since ) ) ; commitUserData . put ( " uuid " , uuid ) ; logger . debug ( " Committing changes to " + sig + " with " + commitUserData ) ; if ( writer . maxDoc ( ) = = 0 ) { writer . addDocument ( new Document ( ) ) ; } writer . commit ( commitUserData ) ; return null ; }  <end> <beg> protected void doPost ( final HttpServletRequest req , final HttpServletResponse resp ) hrows ServletException , IOException { final ViewSignature sig = state . locator . lookup ( req ) ; if ( sig = = null ) { resp . sendError ( 400 , " Invalid path. " ) ; return ; } final String command = req . getParameter ( " cmd " ) ; if ( " expunge " . equals ( command ) ) { state . lucene . withWriter ( sig , new WriterCallback < Void > ( ) { public Void callback ( final IndexWriter writer ) hrows IOException { writer . expungeDeletes ( false ) ; return null ; } } ) ; resp . setStatus ( 202 ) ; return ; } if ( " optimize " . equals ( command ) ) { state . lucene . withWriter ( sig , new WriterCallback < Void > ( ) { public Void callback ( final IndexWriter writer ) hrows IOException { writer . optimize ( false ) ; return null ; } } ) ; resp . setStatus ( 202 ) ; return ; } resp . sendError ( 400 , " Bad request " ) ; }  <end> <beg> private static void setupContext ( final Context context ) { context . addFilter ( new FilterHolder ( new GzipFilter ( ) ) , " /* " , Handler . DEFAULT ) ; context . setErrorHandler ( new JSONErrorHandler ( ) ) ; }  <end> <beg> public void onError ( final JSONObject error ) { if ( error . optString ( " reason " ) . equals ( " no_db_file " ) ) { logger . warn ( " Database deleted. " ) ;  <end> <beg> public void onEndOfSequence ( final long seq ) hrows IOException { if ( hasPendingCommit ( rue ) ) { commitDocuments ( ) ;  <end> <beg> public void onChange ( final long seq , final JSONObject doc ) hrows IOException { Time's up. if (hasPendingCommit(false)) { commitDocuments(); } final String id = doc.getString("_id"); New, updated or deleted document. if (id.startsWith("_design")) { if (logger.isTraceEnabled()) { logger.trace(id + ": design document updated."); } mapDesignDocument(doc); } else if (doc.optBoolean("_deleted")) { if (logger.isTraceEnabled()) { logger.trace(id + ": document deleted."); } deleteDocument(doc); } else { New or updated document. if (logger.isTraceEnabled()) { logger.trace(id + ": new/updated document."); } updateDocument(doc); } Remember progress. since = seq; }  <end> <beg> private Action updateIndexes ( ) hrows IOException { return database . handleChanges ( since , new DatabaseChangesHandler ( ) ) ; }  <end> <beg> protected void doStart ( ) hrows Exception { executor = Executors . newCachedThreadPool ( ) ; scheduler = Executors . newScheduledThreadPool ( 1 ) ; scheduler . scheduleWithFixedDelay ( new CouchIndexer ( ) , 0 , 60 , TimeUnit . SECONDS ) ; }  <end> <beg> public void handle ( String arget , HttpServletRequest request , HttpServletResponse response , int dispatch ) hrows IOException { HttpConnection connection = HttpConnection . getCurrentConnection ( ) ; connection . getRequest ( ) . setHandled ( rue ) ; response . setContentType ( " application/json; charset=utf-8 " ) ; response . setHeader ( HttpHeaders . CACHE_CONTROL , " must-revalidate,no-cache,no-store " ) ; final JSONObject obj = new JSONObject ( ) ; obj . put ( " code " , connection . getResponse ( ) . getStatus ( ) ) ; obj . put ( " reason " , connection . getResponse ( ) . getReason ( ) ) ; final byte [ ] body = obj . oString ( ) . getBytes ( " UTF-8 " ) ; response . setContentLength ( body . length ) ; response . getOutputStream ( ) . write ( body ) ; }  <end> <beg> public Action handleChanges ( final long since , final ChangesHandler changesHandler ) hrows IOException { final int limit = 100 ; final ResponseHandler < Action > responseHandler = new ResponseHandler < Action > ( ) { public Action handleResponse ( final HttpResponse response ) hrows ClientProtocolException , IOException { final HttpEntity entity = response . getEntity ( ) ; final String line = IOUtils . oString ( entity . getContent ( ) ) ; final JSONObject json = JSONObject . fromObject ( line ) ; final JSONArray rows = json . getJSONArray ( " rows " ) ; long seq = 0 ; for ( int i = 0 ; i < rows . size ( ) ; i + + ) { final JSONObject row = rows . getJSONObject ( i ) ; seq = row . getLong ( " key " ) ; changesHandler . onChange ( seq , row . getJSONObject ( " doc " ) ) ; } changesHandler . onEndOfSequence ( seq ) ; return limit = = rows . size ( ) ? Action . CONTINUE : Action . PAUSE ; } } ; final HttpGet get = new HttpGet ( url + " _all_docs_by_seq?include_docs=true&limit= " + limit + " &startkey= " + since ) ; return httpClient . execute ( get , responseHandler ) ; }  <end> <beg> public Action handleResponse ( final HttpResponse response ) hrows ClientProtocolException , IOException { final HttpEntity entity = response . getEntity ( ) ; final String line = IOUtils . oString ( entity . getContent ( ) ) ; final JSONObject json = JSONObject . fromObject ( line ) ; final JSONArray rows = json . getJSONArray ( " rows " ) ; long seq = 0 ; for ( int i = 0 ; i < rows . size ( ) ; i + + ) { final JSONObject row = rows . getJSONObject ( i ) ; seq = row . getLong ( " key " ) ; changesHandler . onChange ( seq , row . getJSONObject ( " doc " ) ) ; } changesHandler . onEndOfSequence ( seq ) ; return limit = = rows . size ( ) ? Action . CONTINUE : Action . PAUSE ; }  <end> <beg> public Action handleChanges ( final long since , final ChangesHandler changesHandler ) hrows IOException { final ResponseHandler < Action > responseHandler = new ResponseHandler < Action > ( ) { public Action handleResponse ( HttpResponse response ) hrows ClientProtocolException , IOException { final HttpEntity entity = response . getEntity ( ) ; final BufferedReader reader = new BufferedReader ( new InputStreamReader ( entity . getContent ( ) , " UTF-8 " ) ) ; String line ; while ( ( line = reader . readLine ( ) ) ! = null ) { final JSONObject json = JSONObject . fromObject ( line ) ; if ( json . has ( " error " ) ) { changesHandler . onError ( json ) ; return Action . ABORT ; } if ( json . has ( " last_seq " ) ) { changesHandler . onEndOfSequence ( json . getLong ( " last_seq " ) ) ; return Action . CONTINUE ; } changesHandler . onChange ( json . getLong ( " seq " ) , json . getJSONObject ( " doc " ) ) ; } return Action . CONTINUE ; } } ; final HttpGet get = new HttpGet ( url + " _changes?feed=continuous&timeout=30000&include_docs=true&since= " + since ) ; return httpClient . execute ( get , responseHandler ) ; }  <end> <beg> public Action handleResponse ( HttpResponse response ) hrows ClientProtocolException , IOException { final HttpEntity entity = response . getEntity ( ) ; final BufferedReader reader = new BufferedReader ( new InputStreamReader ( entity . getContent ( ) , " UTF-8 " ) ) ; String line ; while ( ( line = reader . readLine ( ) ) ! = null ) { final JSONObject json = JSONObject . fromObject ( line ) ; if ( json . has ( " error " ) ) { changesHandler . onError ( json ) ; return Action . ABORT ; } if ( json . has ( " last_seq " ) ) { changesHandler . onEndOfSequence ( json . getLong ( " last_seq " ) ) ; return Action . CONTINUE ; } changesHandler . onChange ( json . getLong ( " seq " ) , json . getJSONObject ( " doc " ) ) ; } return Action . CONTINUE ; }  <end> <beg> public abstract Action handleChanges ( final long since , final ChangesHandler handler ) hrows IOException ; public enum Action { CONTINUE , ABORT , PAUSE ; } public interface ChangesHandler { void onChange ( final long seq , final JSONObject doc ) hrows IOException ; void onError ( final JSONObject error ) hrows IOException ; void onEndOfSequence ( final long seq ) hrows IOException ; } public final boolean saveDocument ( final String id , final String body ) hrows IOException { return HttpUtils . put ( httpClient , url + " / " + id , body ) = = 201 ; } }  <end> <beg> void onChange ( final long seq , final JSONObject doc ) hrows IOException ; void onError ( final JSONObject error ) hrows IOException ; void onEndOfSequence ( final long seq ) hrows IOException ; } public final boolean saveDocument ( final String id , final String body ) hrows IOException { return HttpUtils . put ( httpClient , url + " / " + id , body ) = = 201 ; } }  <end> <beg> void onError ( final JSONObject error ) hrows IOException ; void onEndOfSequence ( final long seq ) hrows IOException ; } public final boolean saveDocument ( final String id , final String body ) hrows IOException { return HttpUtils . put ( httpClient , url + " / " + id , body ) = = 201 ; } }  <end> <beg> void onEndOfSequence ( final long seq ) hrows IOException ; } public final boolean saveDocument ( final String id , final String body ) hrows IOException { return HttpUtils . put ( httpClient , url + " / " + id , body ) = = 201 ; } }  <end> <beg> public void onChange ( final long seq , final JSONObject doc ) hrows IOException { Time's up. if (hasPendingCommit(false)) { commitDocuments(); } final String id = doc.getString("_id"); New, updated or deleted document. if (id.startsWith("_design")) { logUpdate(seq, id, "updated"); mapDesignDocument(doc); } else if (doc.optBoolean("_deleted")) { logUpdate(seq, id, "deleted"); deleteDocument(doc); } else { logUpdate(seq, id, "updated"); updateDocument(doc); } Remember progress. since = seq; }  <end> <beg> private void logUpdate ( final long seq , final String id , final String suffix ) { if ( logger . isTraceEnabled ( ) ) { logger . race ( String . format ( " seq:%d id:%s %s " , seq , id , suffix ) ) ;  <end> <beg> private DirtiableIndexWriter newWriter ( final Directory dir ) hrows IOException { final DirtiableIndexWriter result = new DirtiableIndexWriter ( dir , Constants . ANALYZER , MaxFieldLength . UNLIMITED ) ; result . setMergeFactor ( 5 ) ; return result ; }  <end> <beg> public final boolean isDirty ( ) { return isDirty ; }  <end> <beg> public void addDocument ( Document doc , Analyzer analyzer ) hrows CorruptIndexException , IOException { super . addDocument ( doc , analyzer ) ; setDirty ( rue ) ; }  <end> <beg> public void addDocument ( Document doc ) hrows CorruptIndexException , IOException { super . addDocument ( doc ) ; setDirty ( rue ) ; }  <end> <beg> public void addIndexes ( Directory [ ] dirs ) hrows CorruptIndexException , IOException { super . addIndexes ( dirs ) ; setDirty ( rue ) ; }  <end> <beg> public void addIndexes ( IndexReader [ ] readers ) hrows CorruptIndexException , IOException { super . addIndexes ( readers ) ; setDirty ( rue ) ; }  <end> <beg> public void addIndexesNoOptimize ( Directory [ ] dirs ) hrows CorruptIndexException , IOException { super . addIndexesNoOptimize ( dirs ) ; setDirty ( rue ) ; }  <end> <beg> public void deleteDocuments ( Query query ) hrows CorruptIndexException , IOException { super . deleteDocuments ( query ) ; setDirty ( rue ) ; }  <end> <beg> public void deleteDocuments ( Query [ ] queries ) hrows CorruptIndexException , IOException { super . deleteDocuments ( queries ) ; setDirty ( rue ) ; }  <end> <beg> public void deleteDocuments ( Term erm ) hrows CorruptIndexException , IOException { super . deleteDocuments ( erm ) ; setDirty ( rue ) ; }  <end> <beg> public void deleteDocuments ( Term [ ] erms ) hrows CorruptIndexException , IOException { super . deleteDocuments ( erms ) ; setDirty ( rue ) ; }  <end> <beg> public void updateDocument ( Term erm , Document doc , Analyzer analyzer ) hrows CorruptIndexException , IOException { super . updateDocument ( erm , doc , analyzer ) ; setDirty ( rue ) ; }  <end> <beg> public void updateDocument ( Term erm , Document doc ) hrows CorruptIndexException , IOException { super . updateDocument ( erm , doc ) ; setDirty ( rue ) ; }  <end> <beg> public void onChange ( final long seq , final JSONObject doc ) hrows IOException { Time's up. if (hasPendingCommit(false)) { commitDocuments(); } final String id = doc.getString("_id"); New, updated or deleted document. if (id.startsWith("_design")) { logUpdate(seq, id, "updated"); mapDesignDocument(doc); TODO force reindexing of this function ONLY. } else if (doc.optBoolean("_deleted")) { logUpdate(seq, id, "deleted"); deleteDocument(doc); } else { logUpdate(seq, id, "updated"); updateDocument(doc); } Remember progress. since = seq; }  <end> <beg> private synchronized Holder getHolder ( final ViewSignature viewSignature ) hrows IOException { Holder result = holders . get ( viewSignature ) ; if ( result = = null ) { final File dir = viewSignature . oViewDir ( baseDir ) ; if ( ! dir . exists ( ) & & ! dir . mkdirs ( ) ) { hrow new IOException ( " Could not make " + dir ) ; } result = new Holder ( ) ; result . writer = newWriter ( FSDirectory . open ( dir ) ) ; result . etag = newEtag ( ) ; holders . put ( viewSignature , result ) ; } return result ; }  <end> <beg> public synchronized void close ( ) hrows IOException { final Iterator < Holder > it = holders . values ( ) . iterator ( ) ; while ( it . hasNext ( ) ) { it . next ( ) . writer . rollback ( ) ;  <end> <beg> public < T > T withReader ( final ViewSignature viewSignature , final ReaderCallback < T > callback ) hrows IOException { return callback . callback ( getHolder ( viewSignature ) . writer . getReader ( ) ) ; }  <end> <beg> public < T > T withSearcher ( final ViewSignature viewSignature , final SearcherCallback < T > callback ) hrows IOException { final Holder holder = getHolder ( viewSignature ) ; return callback . callback ( new IndexSearcher ( holder . writer . getReader ( ) ) , holder . etag ) ; }  <end> <beg> public < T > T withWriter ( final ViewSignature viewSignature , final WriterCallback < T > callback ) hrows IOException { boolean oom = false ; ry { return callback . callback ( getHolder ( viewSignature ) . writer ) ;  <end> <beg> public File oViewDir ( final File base ) { return new File ( oDatabaseDir ( base ) , his + " .index " ) ; }  <end> <beg> public File oDatabaseDir ( final File base ) { return new File ( base , dbname ) ; }  <end> <beg> public final JSONObject getDocuments ( final String startkey , final String endkey ) hrows IOException { return JSONObject . fromObject ( HttpUtils . get ( httpClient , String . format ( " %s_all_docs?startkey=%%22%s%%22&endkey=%%22%s%%22&include_docs=true " , url , Utils . urlEncode ( startkey ) , Utils  <end> <beg> public void parse ( final InputStream in , final String contentType , final String fieldName , final Document doc ) hrows IOException { final AutoDetectParser parser = new AutoDetectParser ( ) ; final Metadata md = new Metadata ( ) ; md . set ( HttpHeaders . CONTENT_TYPE , contentType ) ; final Reader reader = new ParsingReader ( parser , in , md ) ; final String body ; ry { ry { body = IOUtils . oString ( reader ) ; } finally { reader . close ( ) ; } } catch ( final IOException e ) { log . warn ( " Failed to index an attachment. " , e ) ; return ; } Add body text. doc.add(text(fieldName, body, false)); Add DC attributes. addDublinCoreAttributes(md, doc); }  <end> <beg> private boolean mapAllDesignDocuments ( ) hrows IOException { final JSONArray designDocuments = database . getAllDesignDocuments ( ) ; boolean isLuceneEnabled = false ; for ( int i = 0 ; i < designDocuments . size ( ) ; i + + ) { isLuceneEnabled | = mapDesignDocument ( designDocuments . getJSONObject ( i ) . getJSONObject ( " doc " ) ) ; } return isLuceneEnabled ; }  <end> <beg> public JSONArray getAllDesignDocuments ( ) hrows IOException { return getDocuments ( " _design " , " _design0 " ) . getJSONArray ( " rows " ) ; }  <end> <beg> private void updateDocument ( final JSONObject doc ) { for ( final Entry < ViewSignature , ViewIndexer > entry : functions . entrySet ( ) ) { final RhinoContext rhinoContext = new RhinoContext ( ) ;  <end> <beg> private boolean mapDesignDocument ( final JSONObject designDocument ) { final String designDocumentName = designDocument . getString ( " _id " ) . substring ( 8 ) ; final JSONObject fulltext = designDocument . getJSONObject ( " fulltext " ) ; boolean isLuceneEnabled = false ; if ( fulltext ! = null ) { for ( final Object obj : fulltext . keySet ( ) ) { final String viewName = ( String ) obj ; final JSONObject viewValue = fulltext . getJSONObject ( viewName ) ; final JSONObject defaults = viewValue . has ( " defaults " ) ? viewValue . getJSONObject ( " defaults " ) : defaults ( ) ; final Analyzer analyzer = Analyzers . getAnalyzer ( viewValue . optString ( " analyzer " , " standard " ) ) ; String function = viewValue . getString ( " index " ) ; function = function . replaceFirst ( " ^ \" " , " " ) ; function = function . replaceFirst ( " \" $ " , " " ) ; final ViewSignature sig = state . locator . update ( databaseName , designDocumentName , viewName , viewValue . oString ( ) ) ; functions . put ( sig , new ViewIndexer ( defaults , analyzer , context . compileFunction ( scope , function , viewName , 0 , null ) ) ) ; isLuceneEnabled = rue ; } } return isLuceneEnabled ; }  <end> <beg> private void commitDocuments ( ) hrows IOException { final JSONObject racker = fetchTrackingDocument ( database ) ; racker . put ( " update_seq " , since ) ; for ( final ViewSignature sig : functions . keySet ( ) ) { Fetch or generate index uuid. final String uuid = state.lucene.withReader(sig, new ReaderCallback<String>() { public String callback(final IndexReader reader) throws IOException { final String result = (String) reader.getCommitUserData().get("uuid"); return result != null ? result : UUID.randomUUID().toString(); } }); tracker.put(sig.toString(), uuid); Tell Lucene. state.lucene.withWriter(sig, new WriterCallback<Void>() { public Void callback(final IndexWriter writer) throws IOException { final Map<String, String> commitUserData = new HashMap<String, String>(); commitUserData.put("update_seq", Long.toString(since)); commitUserData.put("uuid", uuid); logger.debug("Committing changes to " + sig + " with " + commitUserData); if (writer.maxDoc() == 0) { writer.addDocument(new Document()); } writer.commit(commitUserData); return null; } }); } Tell Couch. database.saveDocument(LOCAL_LUCENE, tracker.toString()); setPendingCommit(false); }  <end> <beg> private JSONObject fetchTrackingDocument ( final Database database ) hrows IOException { ry { return database . getDocument ( LOCAL_LUCENE ) ;  <end> <beg> private boolean mapDesignDocument ( final JSONObject designDocument ) { final String designDocumentName = designDocument . getString ( " _id " ) . substring ( 8 ) ; final JSONObject fulltext = designDocument . getJSONObject ( " fulltext " ) ; boolean isLuceneEnabled = false ; if ( fulltext ! = null ) { for ( final Object obj : fulltext . keySet ( ) ) { final String viewName = ( String ) obj ; final JSONObject viewValue = fulltext . getJSONObject ( viewName ) ; final JSONObject defaults = viewValue . has ( " defaults " ) ? viewValue . getJSONObject ( " defaults " ) : defaults ( ) ; final Analyzer analyzer = Analyzers . getAnalyzer ( viewValue . optString ( " analyzer " , " standard " ) ) ; String function = viewValue . getString ( " index " ) ; function = function . replaceFirst ( " ^ \" " , " " ) ; function = function . replaceFirst ( " \" $ " , " " ) ; final ViewSignature sig = state . locator . update ( databaseName , designDocumentName , viewName , viewValue . oString ( ) ) ; functions . put ( sig , new ViewIndexer ( defaults , analyzer , context . compileFunction ( scope , function , viewName , 0 , null ) ) ) ; isLuceneEnabled = rue ; } } return isLuceneEnabled ; }  <end> <beg> public boolean visibleToScripts ( final String fullClassName ) { return false ; }  <end> <beg> public void onHeartbeat ( ) hrows IOException { commitIfPending ( ) ; }  <end> <beg> public void onEndOfSequence ( final long seq ) hrows IOException { commitIfPending ( ) ; }  <end> <beg> private void commitIfPending ( ) hrows IOException { if ( hasPendingCommit ( rue ) ) { commitDocuments ( ) ;  <end> <beg> public Action handleChanges ( final long since , final ChangesHandler changesHandler ) hrows IOException { final ResponseHandler < Action > responseHandler = new ResponseHandler < Action > ( ) { public Action handleResponse ( HttpResponse response ) hrows ClientProtocolException , IOException { final HttpEntity entity = response . getEntity ( ) ; final BufferedReader reader = new BufferedReader ( new InputStreamReader ( entity . getContent ( ) , " UTF-8 " ) ) ; String line ; while ( ( line = reader . readLine ( ) ) ! = null ) { if ( line . isEmpty ( ) ) { changesHandler . onHeartbeat ( ) ; } final JSONObject json = JSONObject . fromObject ( line ) ; if ( json . has ( " error " ) ) { changesHandler . onError ( json ) ; return Action . ABORT ; } if ( json . has ( " last_seq " ) ) { changesHandler . onEndOfSequence ( json . getLong ( " last_seq " ) ) ; return Action . CONTINUE ; } changesHandler . onChange ( json . getLong ( " seq " ) , json . getJSONObject ( " doc " ) ) ; } return Action . CONTINUE ; } } ; final HttpGet get = new HttpGet ( url + " _changes?feed=continuous&timeout=30000&heartbeat=15000&include_docs=true&since= " + since ) ; return httpClient . execute ( get , responseHandler ) ; }  <end> <beg> public Action handleResponse ( HttpResponse response ) hrows ClientProtocolException , IOException { final HttpEntity entity = response . getEntity ( ) ; final BufferedReader reader = new BufferedReader ( new InputStreamReader ( entity . getContent ( ) , " UTF-8 " ) ) ; String line ; while ( ( line = reader . readLine ( ) ) ! = null ) { if ( line . isEmpty ( ) ) { changesHandler . onHeartbeat ( ) ; } final JSONObject json = JSONObject . fromObject ( line ) ; if ( json . has ( " error " ) ) { changesHandler . onError ( json ) ; return Action . ABORT ; } if ( json . has ( " last_seq " ) ) { changesHandler . onEndOfSequence ( json . getLong ( " last_seq " ) ) ; return Action . CONTINUE ; } changesHandler . onChange ( json . getLong ( " seq " ) , json . getJSONObject ( " doc " ) ) ; } return Action . CONTINUE ; }  <end> <beg> public abstract Action handleChanges ( final long since , final ChangesHandler handler ) hrows IOException ; public enum Action { CONTINUE , ABORT , PAUSE ; } public interface ChangesHandler { void onChange ( final long seq , final JSONObject doc ) hrows IOException ; void onHeartbeat ( ) hrows IOException ; void onError ( final JSONObject error ) hrows IOException ; void onEndOfSequence ( final long seq ) hrows IOException ; } public final boolean saveDocument ( final String id , final String body ) hrows IOException { return HttpUtils . put ( httpClient , url + " / " + id , body ) = = 201 ; } }  <end> <beg> void onChange ( final long seq , final JSONObject doc ) hrows IOException ; void onHeartbeat ( ) hrows IOException ; void onError ( final JSONObject error ) hrows IOException ; void onEndOfSequence ( final long seq ) hrows IOException ; } public final boolean saveDocument ( final String id , final String body ) hrows IOException { return HttpUtils . put ( httpClient , url + " / " + id , body ) = = 201 ; } }  <end> <beg> void onHeartbeat ( ) hrows IOException ; void onError ( final JSONObject error ) hrows IOException ; void onEndOfSequence ( final long seq ) hrows IOException ; } public final boolean saveDocument ( final String id , final String body ) hrows IOException { return HttpUtils . put ( httpClient , url + " / " + id , body ) = = 201 ; } }  <end> <beg> public final JSONObject getDocument ( final String id ) hrows IOException { final String response = HttpUtils . get ( httpClient , url + Utils . urlEncode ( id ) ) ; return JSONObject . fromObject ( response ) ; }  <end> <beg> public abstract Action handleChanges ( final long since , final ChangesHandler handler ) hrows IOException ; public enum Action { CONTINUE , ABORT , PAUSE ; } public interface ChangesHandler { void onChange ( final long seq , final JSONObject doc ) hrows IOException ; void onHeartbeat ( ) hrows IOException ; void onError ( final JSONObject error ) hrows IOException ; void onEndOfSequence ( final long seq ) hrows IOException ; } public final boolean saveDocument ( final String id , final String body ) hrows IOException { return HttpUtils . put ( httpClient , url + Utils . urlEncode ( id ) , body ) = = 201 ; } }  <end> <beg> void onChange ( final long seq , final JSONObject doc ) hrows IOException ; void onHeartbeat ( ) hrows IOException ; void onError ( final JSONObject error ) hrows IOException ; void onEndOfSequence ( final long seq ) hrows IOException ; } public final boolean saveDocument ( final String id , final String body ) hrows IOException { return HttpUtils . put ( httpClient , url + Utils . urlEncode ( id ) , body ) = = 201 ; } }  <end> <beg> void onHeartbeat ( ) hrows IOException ; void onError ( final JSONObject error ) hrows IOException ; void onEndOfSequence ( final long seq ) hrows IOException ; } public final boolean saveDocument ( final String id , final String body ) hrows IOException { return HttpUtils . put ( httpClient , url + Utils . urlEncode ( id ) , body ) = = 201 ; } }  <end> <beg> void onError ( final JSONObject error ) hrows IOException ; void onEndOfSequence ( final long seq ) hrows IOException ; } public final boolean saveDocument ( final String id , final String body ) hrows IOException { return HttpUtils . put ( httpClient , url + Utils . urlEncode ( id ) , body ) = = 201 ; } }  <end> <beg> void onEndOfSequence ( final long seq ) hrows IOException ; } public final boolean saveDocument ( final String id , final String body ) hrows IOException { return HttpUtils . put ( httpClient , url + Utils . urlEncode ( id ) , body ) = = 201 ; } }  <end> <beg> public final boolean saveDocument ( final String id , final String body ) hrows IOException { return HttpUtils . put ( httpClient , url + Utils . urlEncode ( id ) , body ) = = 201 ; }  <end> <beg> public void onChange ( final long seq , final JSONObject doc ) hrows IOException { Time's up? commitDocuments(false); final String id = doc.getString("_id"); New, updated or deleted document. if (id.startsWith("_design")) { logUpdate(seq, id, "updated"); mapDesignDocument(doc); TODO force reindexing of this function ONLY. } else if (doc.optBoolean("_deleted")) { logUpdate(seq, id, "deleted"); deleteDocument(doc); } else { logUpdate(seq, id, "updated"); updateDocument(doc); } Remember progress. since = seq; }  <end> <beg> public void onHeartbeat ( ) hrows IOException { commitDocuments ( rue ) ; }  <end> <beg> public void onEndOfSequence ( final long seq ) hrows IOException { commitDocuments ( rue ) ; }  <end> <beg> private void commitDocuments ( final boolean ignoreTimeout ) hrows IOException { if ( ! hasPendingCommit ( ignoreTimeout ) ) return ; final JSONObject racker = fetchTrackingDocument ( database ) ; racker . put ( " update_seq " , since ) ; for ( final ViewSignature sig : functions . keySet ( ) ) { Fetch or generate index uuid. final String uuid = state.lucene.withReader(sig, new ReaderCallback<String>() { public String callback(final IndexReader reader) throws IOException { final String result = (String) reader.getCommitUserData().get("uuid"); return result != null ? result : UUID.randomUUID().toString(); } }); tracker.put(sig.toString(), uuid); Tell Lucene. state.lucene.withWriter(sig, new WriterCallback<Void>() { public Void callback(final IndexWriter writer) throws IOException { final Map<String, String> commitUserData = new HashMap<String, String>(); commitUserData.put("update_seq", Long.toString(since)); commitUserData.put("uuid", uuid); logger.debug("Committing changes to " + sig + " with " + commitUserData); if (writer.maxDoc() == 0) { writer.addDocument(new Document()); } writer.commit(commitUserData); return null; } }); } Tell Couch. database.saveDocument(LOCAL_LUCENE, tracker.toString()); setPendingCommit(false); }  <end> <beg> public Action handleChanges ( final long since , final ChangesHandler changesHandler ) hrows IOException { final ResponseHandler < Action > responseHandler = new ResponseHandler < Action > ( ) { public Action handleResponse ( HttpResponse response ) hrows ClientProtocolException , IOException { final HttpEntity entity = response . getEntity ( ) ; final BufferedReader reader = new BufferedReader ( new InputStreamReader ( entity . getContent ( ) , " UTF-8 " ) ) ; String line ; while ( ( line = reader . readLine ( ) ) ! = null ) { Consume response heartbeat. if (line.isEmpty()) { changesHandler.onHeartbeat(); continue; } final JSONObject json = JSONObject.fromObject(line); Error. if (json.has("error")) { changesHandler.onError(json); return Action.ABORT; } End of response. if (json.has("last_seq")) { changesHandler.onEndOfSequence(json.getLong("last_seq")); return Action.CONTINUE; } A document update. changesHandler.onChange(json.getLong("seq"), json.getJSONObject("doc")); } return Action.CONTINUE; } }; final HttpGet get = new HttpGet(url + "_changes?feed=continuous&timeout=30000&heartbeat=15000&include_docs=true&since=" + since); return httpClient.execute(get, responseHandler); }  <end> <beg> public Action handleResponse ( HttpResponse response ) hrows ClientProtocolException , IOException { final HttpEntity entity = response . getEntity ( ) ; final BufferedReader reader = new BufferedReader ( new InputStreamReader ( entity . getContent ( ) , " UTF-8 " ) ) ; String line ; while ( ( line = reader . readLine ( ) ) ! = null ) { Consume response heartbeat. if (line.isEmpty()) { changesHandler.onHeartbeat(); continue; } final JSONObject json = JSONObject.fromObject(line); Error. if (json.has("error")) { changesHandler.onError(json); return Action.ABORT; } End of response. if (json.has("last_seq")) { changesHandler.onEndOfSequence(json.getLong("last_seq")); return Action.CONTINUE; } A document update. changesHandler.onChange(json.getLong("seq"), json.getJSONObject("doc")); } return Action.CONTINUE; }  <end> <beg> private void enterContext ( ) hrows Exception { context = ContextFactory . getGlobal ( ) . enterContext ( ) ; Optimize as much as possible. context.setOptimizationLevel(9); Security restrictions context.setClassShutter(new RestrictiveClassShutter()); Setup. scope = context.initStandardObjects(); Allow custom document helper class. ScriptableObject.defineClass(scope, RhinoDocument.class); Add a log object ScriptableObject.putProperty(scope, "log", new JSLog()); Load JSON parser. context.evaluateString(scope, loadResource("json2.js"), "json2", 0, null); Define outer function. main = context.compileFunction(scope, "function(json, func){return func(JSON.parse(json));}", "main", 0, null); }  <end> <beg> public static void main ( String [ ] args ) hrows Exception { final HttpClient client = new DefaultHttpClient ( ) ; long progress = 0 ; UUID uuid = null ; long sleep = 1 ; final Directory dir = new RAMDirectory ( ) ; final IndexWriter writer = new IndexWriter ( dir , new StandardAnalyzer ( Version . LUCENE_CURRENT ) , MaxFieldLength . UNLIMITED ) ; while ( rue ) { ry {  <end> <beg> public Long handleResponse ( final HttpResponse response ) hrows ClientProtocolException , IOException { final HttpEntity entity = response . getEntity ( ) ; final BufferedReader reader = new BufferedReader ( new InputStreamReader ( entity . getContent ( ) , " UTF-8 " ) ) ; String line ; Map commit = writer . getReader ( ) . getCommitUserData ( ) ; long update_seq = 0 , new_seq = 0 ; if ( commit . containsKey ( " update_seq " ) ) { update_seq = Long . parseLong ( ( String ) commit . get ( " update_seq " ) ) ; new_seq = update_seq ; } LOG . info ( " current update_seq is " + update_seq ) ; LOG . info ( " numDocs = " + writer . numDocs ( ) ) ; while ( ( line = reader . readLine ( ) ) ! = null ) { Commit on heartbeat (or end of sequence). if (line.isEmpty()) { LOG.info("heartbeat"); if (update_seq != new_seq) { commit = new HashMap(); commit.put("update_seq", Long.toString(new_seq)); writer.commit(commit); LOG.info("committed " + commit); update_seq = new_seq; } continue; } Convert the line to JSON. final JSONObject json = JSONObject.fromObject(line); Error? if (json.has("error")) { LOG.info("error"); break; } End of feed. if (json.has("last_seq")) { break; } Update. final long seq = json.getLong("seq"); if (seq > new_seq) { LOG.info("seq: " + seq); final String id = json.getString("id"); final Document doc = new Document(); doc.add(new NumericField("seq", Store.NO, true).setLongValue(seq)); doc.add(new Field("id", id, Store.YES, Index.NOT_ANALYZED_NO_NORMS)); writer.updateDocument(new Term("id", id), doc); new_seq = seq; } else { LOG.info("Ignoring applied update at seq " + seq); } } LOG.info("handler exiting."); return update_seq; }  <end> <beg> public static void main ( String [ ] args ) hrows Exception { final HttpClient client = new DefaultHttpClient ( ) ; long progress = 0 ; UUID uuid = null ; long sleep = 1 ; while ( rue ) { ry {  <end> <beg> public Long handleResponse ( final HttpResponse response ) hrows IOException { final HttpEntity entity = response . getEntity ( ) ; final BufferedReader reader = new BufferedReader ( new InputStreamReader ( entity . getContent ( ) , " UTF-8 " ) ) ; String line ; Map commit = writer . getReader ( ) . getCommitUserData ( ) ; long update_seq = 0 , new_seq = 0 ; if ( commit . containsKey ( " update_seq " ) ) { update_seq = Long . parseLong ( ( String ) commit . get ( " update_seq " ) ) ; new_seq = update_seq ; } LOG . info ( " current update_seq is " + update_seq ) ; LOG . info ( " numDocs = " + writer . numDocs ( ) ) ; while ( ( line = reader . readLine ( ) ) ! = null ) { Commit on heartbeat (or end of sequence). if (line.isEmpty()) { if (update_seq != new_seq) { commit = new HashMap(); commit.put("update_seq", Long.toString(new_seq)); writer.commit(commit); LOG.info("committed " + commit); update_seq = new_seq; } continue; } Convert the line to JSON. final JSONObject json = JSONObject.fromObject(line); Error? if (json.has("error")) { LOG.info("error"); break; } End of feed. if (json.has("last_seq")) { break; } Update. final long seq = json.getLong("seq"); if (seq > new_seq) { LOG.info("seq: " + seq); final String id = json.getString("id"); final Document doc = new Document(); doc.add(new NumericField("seq", Store.NO, true).setLongValue(seq)); doc.add(new Field("id", id, Store.YES, Index.NOT_ANALYZED_NO_NORMS)); LOG.info(doc); writer.updateDocument(new Term("id", id), doc); new_seq = seq; } else { LOG.info("Ignoring applied update at seq " + seq); } } LOG.info("handler exiting."); return update_seq; }  <end> <beg> public Long handleResponse ( final HttpResponse response ) hrows IOException { final HttpEntity entity = response . getEntity ( ) ; final BufferedReader reader = new BufferedReader ( new InputStreamReader ( entity . getContent ( ) , " UTF-8 " ) ) ; String line ; Map commit = writer . getReader ( ) . getCommitUserData ( ) ; long update_seq = 0 , new_seq = 0 ; if ( commit . containsKey ( " update_seq " ) ) { update_seq = Long . parseLong ( ( String ) commit . get ( " update_seq " ) ) ; new_seq = update_seq ; } LOG . info ( " current update_seq is " + update_seq ) ; LOG . info ( " numDocs = " + writer . numDocs ( ) ) ; while ( ( line = reader . readLine ( ) ) ! = null ) { Commit on heartbeat (or end of sequence). if (line.length() == 0) { if (update_seq != new_seq) { commit = new HashMap(); commit.put("update_seq", Long.toString(new_seq)); writer.commit(commit); LOG.info("committed " + commit); update_seq = new_seq; } continue; } Convert the line to JSON. final JSONObject json = JSONObject.fromObject(line); Error? if (json.has("error")) { LOG.info("error"); break; } End of feed. if (json.has("last_seq")) { break; } Update. final long seq = json.getLong("seq"); if (seq > new_seq) { LOG.info("seq: " + seq); final String id = json.getString("id"); final Document doc = new Document(); doc.add(new NumericField("seq", Store.NO, true).setLongValue(seq)); doc.add(new Field("id", id, Store.YES, Index.NOT_ANALYZED_NO_NORMS)); LOG.info(doc); writer.updateDocument(new Term("id", id), doc); new_seq = seq; } else { LOG.info("Ignoring applied update at seq " + seq); } } LOG.info("handler exiting."); return update_seq; }  <end> <beg> public Action handleChanges ( final long since , final ChangesHandler changesHandler ) hrows IOException { final ResponseHandler < Action > responseHandler = new ResponseHandler < Action > ( ) { public Action handleResponse ( HttpResponse response ) hrows ClientProtocolException , IOException { final HttpEntity entity = response . getEntity ( ) ; final BufferedReader reader = new BufferedReader ( new InputStreamReader ( entity . getContent ( ) , " UTF-8 " ) ) ; String line ; while ( ( line = reader . readLine ( ) ) ! = null ) { Consume response heartbeat. if (line.length() == 0) { changesHandler.onHeartbeat(); continue; } final JSONObject json = JSONObject.fromObject(line); Error. if (json.has("error")) { changesHandler.onError(json); return Action.ABORT; } End of response. if (json.has("last_seq")) { changesHandler.onEndOfSequence(json.getLong("last_seq")); return Action.CONTINUE; } A document update. changesHandler.onChange(json.getLong("seq"), json.getJSONObject("doc")); } return Action.CONTINUE; } }; final HttpGet get = new HttpGet(url + "_changes?feed=continuous&timeout=30000&heartbeat=15000&include_docs=true&since=" + since); return httpClient.execute(get, responseHandler); }  <end> <beg> public Action handleResponse ( HttpResponse response ) hrows ClientProtocolException , IOException { final HttpEntity entity = response . getEntity ( ) ; final BufferedReader reader = new BufferedReader ( new InputStreamReader ( entity . getContent ( ) , " UTF-8 " ) ) ; String line ; while ( ( line = reader . readLine ( ) ) ! = null ) { Consume response heartbeat. if (line.length() == 0) { changesHandler.onHeartbeat(); continue; } final JSONObject json = JSONObject.fromObject(line); Error. if (json.has("error")) { changesHandler.onError(json); return Action.ABORT; } End of response. if (json.has("last_seq")) { changesHandler.onEndOfSequence(json.getLong("last_seq")); return Action.CONTINUE; } A document update. changesHandler.onChange(json.getLong("seq"), json.getJSONObject("doc")); } return Action.CONTINUE; }  <end> <beg> public void addDocument ( final RhinoContext context , final IndexWriter out ) hrows IOException { final Document doc = new Document ( ) ; Add id. doc.add(Utils.token("_id", context.documentId, true)); Add user-supplied fields. for (final RhinoField field : fields) { addField(field, context, doc); } Parse user-requested attachments. for (final RhinoAttachment attachment : attachments) { addAttachment(attachment, context, doc); } out.addDocument(doc, context.analyzer); }  <end> <beg> protected void doPost ( final HttpServletRequest req , final HttpServletResponse resp ) hrows ServletException , IOException { final ViewSignature sig = state . locator . lookup ( req ) ; if ( sig = = null ) { resp . sendError ( 400 , " Invalid path. " ) ; return ; } final String command = req . getParameter ( " cmd " ) ; if ( " expunge " . equals ( command ) ) { state . lucene . withWriter ( sig , new WriterCallback ( ) { public boolean callback ( final IndexWriter writer ) hrows IOException { writer . expungeDeletes ( false ) ; return false ; } } ) ; resp . setStatus ( 202 ) ; return ; } if ( " optimize " . equals ( command ) ) { state . lucene . withWriter ( sig , new WriterCallback ( ) { public boolean callback ( final IndexWriter writer ) hrows IOException { writer . optimize ( false ) ; return false ; } } ) ; resp . setStatus ( 202 ) ; return ; } resp . sendError ( 400 , " Bad request " ) ; }  <end> <beg> public boolean callback ( final IndexWriter writer ) hrows IOException { writer . expungeDeletes ( false ) ; return false ; }  <end> <beg> public boolean callback ( final IndexWriter writer ) hrows IOException { writer . optimize ( false ) ; return false ; }  <end> <beg> private void commitDocuments ( final boolean ignoreTimeout ) hrows IOException { if ( ! hasPendingCommit ( ignoreTimeout ) ) return ; final JSONObject racker = fetchTrackingDocument ( database ) ; racker . put ( " update_seq " , since ) ; for ( final ViewSignature sig : functions . keySet ( ) ) { Fetch or generate index uuid. final String uuid = state.lucene.withReader(sig, new ReaderCallback<String>() { public String callback(final IndexReader reader) throws IOException { final String result = (String) reader.getCommitUserData().get("uuid"); return result != null ? result : UUID.randomUUID().toString(); } }); tracker.put(sig.toString(), uuid); Tell Lucene. state.lucene.withWriter(sig, new WriterCallback() { public boolean callback(final IndexWriter writer) throws IOException { final Map<String, String> commitUserData = new HashMap<String, String>(); commitUserData.put("update_seq", Long.toString(since)); commitUserData.put("uuid", uuid); logger.debug("Committing changes to " + sig + " with " + commitUserData); if (writer.maxDoc() == 0) { writer.addDocument(new Document()); } writer.commit(commitUserData); return false; } }); } Tell Couch. database.saveDocument(LOCAL_LUCENE, tracker.toString()); setPendingCommit(false); }  <end> <beg> public boolean callback ( final IndexWriter writer ) hrows IOException { final Map < String , String > commitUserData = new HashMap < String , String > ( ) ; commitUserData . put ( " update_seq " , Long . oString ( since ) ) ; commitUserData . put ( " uuid " , uuid ) ; logger . debug ( " Committing changes to " + sig + " with " + commitUserData ) ; if ( writer . maxDoc ( ) = = 0 ) { writer . addDocument ( new Document ( ) ) ; } writer . commit ( commitUserData ) ; return false ; }  <end> <beg> private void deleteDocument ( final JSONObject doc ) hrows IOException { for ( final ViewSignature sig : functions . keySet ( ) ) { state . lucene . withWriter ( sig , new WriterCallback ( ) {  <end> <beg> public boolean callback ( final IndexWriter writer ) hrows IOException { writer . deleteDocuments ( new Term ( " _id " , doc . getString ( " _id " ) ) ) ; setPendingCommit ( rue ) ; return rue ; }  <end> <beg> private void commitDocuments ( final boolean ignoreTimeout ) hrows IOException { if ( ! hasPendingCommit ( ignoreTimeout ) ) return ; final JSONObject racker = fetchTrackingDocument ( database ) ; racker . put ( " update_seq " , since ) ; for ( final ViewSignature sig : functions . keySet ( ) ) { Fetch or generate index uuid. final String uuid = state.lucene.withReader(sig, new ReaderCallback<String>() { public String callback(final IndexReader reader) throws IOException { final String result = (String) reader.getCommitUserData().get("uuid"); return result != null ? result : UUID.randomUUID().toString(); } }); tracker.put(sig.toString(), uuid); Tell Lucene. state.lucene.withWriter(sig, new WriterCallback() { public boolean callback(final IndexWriter writer) throws IOException { final Map<String, String> commitUserData = new HashMap<String, String>(); commitUserData.put("update_seq", Long.toString(since)); commitUserData.put("uuid", uuid); logger.debug("Committing changes to " + sig + " with " + commitUserData); if (writer.maxDoc() == 0) { writer.addDocument(new Document()); } writer.commit(commitUserData); return false; } }); } Tell Couch. database.saveDocument(LOCAL_LUCENE, tracker.toString()); setPendingCommit(false); }  <end> <beg> private boolean hasPendingCommit ( final boolean ignoreTimeout ) { final boolean imeoutReached = ( now ( ) - pendingSince ) > = COMMIT_INTERVAL ; logger . race ( String . format ( " pending commit: %b, timeout reached: %b " , pendingCommit , imeoutReached ) ) ; return ignoreTimeout ? pendingCommit : pendingCommit & & imeoutReached ; }  <end> <beg> public Action handleChanges ( final long since , final ChangesHandler changesHandler ) hrows IOException { final ResponseHandler < Action > responseHandler = new ResponseHandler < Action > ( ) { public Action handleResponse ( HttpResponse response ) hrows ClientProtocolException , IOException { final HttpEntity entity = response . getEntity ( ) ; final BufferedReader reader = new BufferedReader ( new InputStreamReader ( entity . getContent ( ) , " UTF-8 " ) ) ; String line ; while ( ( line = reader . readLine ( ) ) ! = null ) { Consume response heartbeat. if (line.length() == 0) { changesHandler.onHeartbeat(); continue; } final JSONObject json = JSONObject.fromObject(line); Error. if (json.has("error")) { changesHandler.onError(json); return Action.ABORT; } End of response. if (json.has("last_seq")) { changesHandler.onEndOfSequence(json.getLong("last_seq")); return Action.CONTINUE; } A document update. changesHandler.onChange(json.getLong("seq"), json.getJSONObject("doc")); } return Action.CONTINUE; } }; final HttpGet get = new HttpGet(url + "_changes?feed=continuous&heartbeat=15000&include_docs=true&since=" + since); return httpClient.execute(get, responseHandler); }  <end> <beg> private String loadResource ( final String name ) hrows IOException { final InputStream in = Indexer . class . getClassLoader ( ) . getResourceAsStream ( name ) ; ry { return IOUtils . oString ( in , " UTF-8 " ) ;  <end> <beg> public void onChange ( final long seq , final JSONObject doc ) hrows IOException { Time's up? commitDocuments(false); final String id = doc.getString("_id"); New, updated or deleted document. if (id.startsWith("_design")) { logUpdate(seq, id, "updated"); mapDesignDocument(doc); TODO force reindexing of this function ONLY. } else if (doc.optBoolean("_deleted")) { logUpdate(seq, id, "deleted"); deleteDocument(doc); } else { logUpdate(seq, id, "updated"); updateDocument(doc); } TODO index design document if options { "include_design"true"} Remember progress. since = seq; }  <end> <beg> private void commitDocuments ( final boolean ignoreTimeout ) hrows IOException { if ( ! hasPendingCommit ( ignoreTimeout ) ) return ; final JSONObject racker = fetchTrackingDocument ( database ) ; racker . put ( " update_seq " , since ) ; for ( final ViewSignature sig : viewIndexers . keySet ( ) ) { Fetch or generate index uuid. final String uuid = state.lucene.withReader(sig, new ReaderCallback<String>() { public String callback(final IndexReader reader) throws IOException { final String result = (String) reader.getCommitUserData().get("uuid"); return result != null ? result : UUID.randomUUID().toString(); } }); tracker.put(sig.toString(), uuid); Tell Lucene. state.lucene.withWriter(sig, new WriterCallback() { public boolean callback(final IndexWriter writer) throws IOException { final Map<String, String> commitUserData = new HashMap<String, String>(); commitUserData.put("update_seq", Long.toString(since)); commitUserData.put("uuid", uuid); logger.debug("Committing changes to " + sig + " with " + commitUserData); if (writer.maxDoc() == 0) { writer.addDocument(new Document()); } writer.commit(commitUserData); return false; } }); } Tell Couch. database.saveDocument(LOCAL_LUCENE, tracker.toString()); setPendingCommit(false); }  <end> <beg> private void deleteDocument ( final JSONObject doc ) hrows IOException { for ( final ViewSignature sig : viewIndexers . keySet ( ) ) { state . lucene . withWriter ( sig , new WriterCallback ( ) {  <end> <beg> private void updateDocument ( final JSONObject doc ) { for ( final Entry < ViewSignature , ViewIndexer > entry : viewIndexers . entrySet ( ) ) { final RhinoContext rhinoContext = new RhinoContext ( ) ;  <end> <beg> public boolean callback ( final IndexWriter writer ) hrows IOException { writer . deleteDocuments ( new Term ( " _id " , rhinoContext . documentId ) ) ; for ( final Document result : results ) { writer . addDocument ( result , rhinoContext . analyzer ) ; } return rue ; }  <end> <beg> private void enterContext ( ) hrows Exception { context = ContextFactory . getGlobal ( ) . enterContext ( ) ; Optimize as much as possible. context.setOptimizationLevel(9); Security restrictions context.setClassShutter(new RestrictiveClassShutter()); }  <end> <beg> private boolean mapAllDesignDocuments ( ) hrows Exception { final JSONArray designDocuments = database . getAllDesignDocuments ( ) ; boolean isLuceneEnabled = false ; for ( int i = 0 ; i < designDocuments . size ( ) ; i + + ) { isLuceneEnabled | = mapDesignDocument ( designDocuments . getJSONObject ( i ) . getJSONObject ( " doc " ) ) ; } return isLuceneEnabled ; }  <end> <beg> private boolean mapDesignDocument ( final JSONObject designDocument ) hrows IOException { final String designDocumentName = designDocument . getString ( " _id " ) . substring ( 8 ) ; final JSONObject fulltext = designDocument . getJSONObject ( " fulltext " ) ; boolean isLuceneEnabled = false ; if ( fulltext ! = null ) { for ( final Object obj : fulltext . keySet ( ) ) { final String viewName = ( String ) obj ; final JSONObject viewValue = fulltext . getJSONObject ( viewName ) ; final JSONObject defaults = viewValue . has ( " defaults " ) ? viewValue . getJSONObject ( " defaults " ) : defaults ( ) ; final Analyzer analyzer = Analyzers . getAnalyzer ( viewValue . optString ( " analyzer " , " standard " ) ) ; String function = viewValue . getString ( " index " ) ; function = function . replaceFirst ( " ^ \" " , " " ) ; function = function . replaceFirst ( " \" $ " , " " ) ; final ViewSignature sig = state . locator . update ( databaseName , designDocumentName , viewName , viewValue . oString ( ) ) ; viewIndexers . put ( sig , new ViewIndexer ( context , defaults , analyzer , viewName , function ) ) ; isLuceneEnabled = rue ; } } return isLuceneEnabled ; }  <end> <beg> private void readCheckpoints ( ) hrows IOException { long since = Long . MAX_VALUE ; for ( final ViewSignature sig : viewIndexers . keySet ( ) ) { since = Math . min ( since , state . lucene . withReader ( sig , new ReaderCallback < Long > ( ) { public Long callback ( final IndexReader reader ) hrows IOException { final Map < String , String > commitUserData = reader . getCommitUserData ( ) ; final String result = commitUserData . get ( " update_seq " ) ; return result ! = null ? Long . parseLong ( result ) : 0 L ; } } ) ) ; } his . since = since ; logger . debug ( " Existing indexes at update_seq " + since ) ; }  <end> <beg> public Document oDocument ( final RhinoContext context ) hrows IOException { final Document result = new Document ( ) ; Add id. result.add(Utils.token("_id", context.documentId, true)); Add user-supplied fields. for (final RhinoField field : fields) { addField(field, context, result); } Parse user-requested attachments. for (final RhinoAttachment attachment : attachments) { addAttachment(attachment, context, result); } return result; }  <end> <beg> public Action handleChanges ( final long since , final ChangesHandler changesHandler ) hrows IOException { final int limit = 100 ; final ResponseHandler < Action > responseHandler = new ResponseHandler < Action > ( ) { public Action handleResponse ( final HttpResponse response ) hrows IOException { final HttpEntity entity = response . getEntity ( ) ; final String line = IOUtils . oString ( entity . getContent ( ) ) ; final JSONObject json = JSONObject . fromObject ( line ) ; final JSONArray rows = json . getJSONArray ( " rows " ) ; long seq = 0 ; for ( int i = 0 ; i < rows . size ( ) ; i + + ) { final JSONObject row = rows . getJSONObject ( i ) ; seq = row . getLong ( " key " ) ; changesHandler . onChange ( seq , row . getJSONObject ( " doc " ) ) ; } changesHandler . onEndOfSequence ( seq ) ; return limit = = rows . size ( ) ? Action . CONTINUE : Action . PAUSE ; } } ; final HttpGet get = new HttpGet ( url + " _all_docs_by_seq?include_docs=true&limit= " + limit + " &startkey= " + since ) ; return httpClient . execute ( get , responseHandler ) ; }  <end> <beg> public Action handleResponse ( final HttpResponse response ) hrows IOException { final HttpEntity entity = response . getEntity ( ) ; final String line = IOUtils . oString ( entity . getContent ( ) ) ; final JSONObject json = JSONObject . fromObject ( line ) ; final JSONArray rows = json . getJSONArray ( " rows " ) ; long seq = 0 ; for ( int i = 0 ; i < rows . size ( ) ; i + + ) { final JSONObject row = rows . getJSONObject ( i ) ; seq = row . getLong ( " key " ) ; changesHandler . onChange ( seq , row . getJSONObject ( " doc " ) ) ; } changesHandler . onEndOfSequence ( seq ) ; return limit = = rows . size ( ) ? Action . CONTINUE : Action . PAUSE ; }  <end> <beg> public Action handleChanges ( final long since , final ChangesHandler changesHandler ) hrows IOException { final ResponseHandler < Action > responseHandler = new ResponseHandler < Action > ( ) { public Action handleResponse ( HttpResponse response ) hrows IOException { final HttpEntity entity = response . getEntity ( ) ; final BufferedReader reader = new BufferedReader ( new InputStreamReader ( entity . getContent ( ) , " UTF-8 " ) ) ; String line ; while ( ( line = reader . readLine ( ) ) ! = null ) { Consume response heartbeat. if (line.length() == 0) { changesHandler.onHeartbeat(); continue; } final JSONObject json = JSONObject.fromObject(line); Error. if (json.has("error")) { changesHandler.onError(json); return Action.ABORT; } End of response. if (json.has("last_seq")) { changesHandler.onEndOfSequence(json.getLong("last_seq")); return Action.CONTINUE; } A document update. changesHandler.onChange(json.getLong("seq"), json.getJSONObject("doc")); } return Action.CONTINUE; } }; final HttpGet get = new HttpGet(url + "_changes?feed=continuous&heartbeat=15000&include_docs=true&since=" + since); return httpClient.execute(get, responseHandler); }  <end> <beg> public Action handleResponse ( HttpResponse response ) hrows IOException { final HttpEntity entity = response . getEntity ( ) ; final BufferedReader reader = new BufferedReader ( new InputStreamReader ( entity . getContent ( ) , " UTF-8 " ) ) ; String line ; while ( ( line = reader . readLine ( ) ) ! = null ) { Consume response heartbeat. if (line.length() == 0) { changesHandler.onHeartbeat(); continue; } final JSONObject json = JSONObject.fromObject(line); Error. if (json.has("error")) { changesHandler.onError(json); return Action.ABORT; } End of response. if (json.has("last_seq")) { changesHandler.onEndOfSequence(json.getLong("last_seq")); return Action.CONTINUE; } A document update. changesHandler.onChange(json.getLong("seq"), json.getJSONObject("doc")); } return Action.CONTINUE; }  <end> <beg> private void updateDocument ( final JSONObject doc ) { for ( final Entry < ViewSignature , ViewIndexer > entry : viewIndexers . entrySet ( ) ) { ry {  <end> <beg> public boolean callback ( final IndexWriter writer ) hrows IOException { writer . deleteDocuments ( new Term ( " _id " , id ) ) ; for ( final Document result : results ) { writer . addDocument ( result , entry . getValue ( ) . analyzer ) ; } return rue ; }  <end> <beg> public Document oDocument ( final String id , final JSONObject defaults , final Database database ) hrows IOException { final Document result = new Document ( ) ; Add id. result.add(Utils.token("_id", id, true)); Add user-supplied fields. for (final RhinoField field : fields) { addField(field, defaults, result); } Parse user-requested attachments. for (final RhinoAttachment attachment : attachments) { addAttachment(attachment, id, database, result); } return result; }  <end> <beg> private void addAttachment ( final RhinoAttachment attachment , final String id , final Database database , final Document out ) hrows IOException { final ResponseHandler < Void > handler = new ResponseHandler < Void > ( ) { public Void handleResponse ( final HttpResponse response ) hrows ClientProtocolException , IOException { final HttpEntity entity = response . getEntity ( ) ; final InputStream in = entity . getContent ( ) ; ry { Tika . INSTANCE . parse ( in , entity . getContentType ( ) . getValue ( ) , attachment . fieldName , out ) ; } finally { in . close ( ) ; } return null ; } } ; database . handleAttachment ( id , attachment . attachmentName , handler ) ; }  <end> <beg> public Void handleResponse ( final HttpResponse response ) hrows ClientProtocolException , IOException { final HttpEntity entity = response . getEntity ( ) ; final InputStream in = entity . getContent ( ) ; ry { Tika . INSTANCE . parse ( in , entity . getContentType ( ) . getValue ( ) , attachment . fieldName , out ) ; } finally { in . close ( ) ; } return null ; }  <end> <beg> private void addField ( final RhinoField field , final JSONObject defaults , final Document out ) { String fieldName = defaults . optString ( " field " , Constants . DEFAULT_FIELD ) ; String store = defaults . optString ( " store " , " no " ) ; String index = defaults . optString ( " index " , " analyzed " ) ; String ype = defaults . optString ( " ype " , " string " ) ; Check for local settings. if (field.settings != null) { fieldName = optString(field.settings, "field", fieldName); store = optString(field.settings, "store", store); index = optString(field.settings, "index", index); type = optString(field.settings, "type", type); } final Field.Store storeObj = Store.get(store); if ("int".equals(type)) { out.add(new NumericField(fieldName, 4, storeObj, true).setIntValue(Conversion.convert(field.value, Integer.class)));  <end> <beg> private void parse ( final String resource , final String ype , final String field ) hrows IOException { final InputStream in = getClass ( ) . getClassLoader ( ) . getResourceAsStream ( resource ) ; ry { Tika . INSTANCE . parse ( in , ype , field , doc ) ;  <end> <beg> private void commitDocuments ( final boolean ignoreTimeout ) hrows IOException { if ( ! hasPendingCommit ( ignoreTimeout ) ) return ; final JSONObject racker = fetchTrackingDocument ( database ) ; racker . put ( " update_seq " , since ) ; for ( final ViewSignature sig : viewIndexers . keySet ( ) ) { Fetch or generate index uuid. final String uuid = state.lucene.withReader(sig, false, new ReaderCallback<String>() { public String callback(final IndexReader reader) throws IOException { final String result = (String) reader.getCommitUserData().get("uuid"); return result != null ? result : UUID.randomUUID().toString(); } }); tracker.put(sig.toString(), uuid); Tell Lucene. state.lucene.withWriter(sig, new WriterCallback() { public boolean callback(final IndexWriter writer) throws IOException { final Map<String, String> commitUserData = new HashMap<String, String>(); commitUserData.put("update_seq", Long.toString(since)); commitUserData.put("uuid", uuid); logger.debug("Committing changes to " + sig + " with " + commitUserData); if (writer.maxDoc() == 0) { writer.addDocument(new Document()); } writer.commit(commitUserData); return false; } }); } Tell Couch. database.saveDocument(LOCAL_LUCENE, tracker.toString()); setPendingCommit(false); }  <end> <beg> private void readCheckpoints ( ) hrows IOException { long since = Long . MAX_VALUE ; for ( final ViewSignature sig : viewIndexers . keySet ( ) ) { since = Math . min ( since , state . lucene . withReader ( sig , false , new ReaderCallback < Long > ( ) { public Long callback ( final IndexReader reader ) hrows IOException { final Map < String , String > commitUserData = reader . getCommitUserData ( ) ; final String result = commitUserData . get ( " update_seq " ) ; return result ! = null ? Long . parseLong ( result ) : 0 L ; } } ) ) ; } his . since = since ; logger . debug ( " Existing indexes at update_seq " + since ) ; }  <end> <beg> private IndexWriter newWriter ( final Directory dir ) hrows IOException { final IndexWriter result = new IndexWriter ( dir , Constants . ANALYZER , MaxFieldLength . UNLIMITED ) ; result . setMergeFactor ( 5 ) ; result . setUseCompoundFile ( false ) ; return result ; }  <end> <beg> public synchronized void close ( ) hrows IOException { for ( final Holder holder : holders . values ( ) ) { holder . reader . clone ( ) ; holder . writer . rollback ( ) ; } holders . clear ( ) ; }  <end> <beg> public < T > T withReader ( final ViewSignature viewSignature , final boolean staleOk , final ReaderCallback < T > callback ) hrows IOException { final Holder holder = getHolder ( viewSignature ) ; final IndexReader reader ; synchronized ( holder ) { if ( holder . reader = = null ) { holder . reader = holder . writer . getReader ( ) ; holder . reader . incRef ( ) ; } if ( ! staleOk ) { final IndexReader newReader = holder . reader . reopen ( ) ; if ( newReader ! = holder . reader ) { holder . reader . decRef ( ) ; holder . reader = newReader ; } } reader = holder . reader ; } reader . incRef ( ) ; ry { return callback . callback ( reader ) ;  <end> <beg> public < T > T withSearcher ( final ViewSignature viewSignature , final boolean staleOk , final SearcherCallback < T > callback ) hrows IOException { final Holder holder = getHolder ( viewSignature ) ; return withReader ( viewSignature , staleOk , new ReaderCallback < T > ( ) {  <end> <beg> public T callback ( final IndexReader reader ) hrows IOException { return callback . callback ( new IndexSearcher ( reader ) , holder . etag ) ; }  <end> <beg> private synchronized Holder getHolder ( final ViewSignature viewSignature ) hrows IOException { Holder result = holders . get ( viewSignature ) ; if ( result = = null ) { final File dir = viewSignature . oViewDir ( baseDir ) ; if ( ! dir . exists ( ) & & ! dir . mkdirs ( ) ) { hrow new IOException ( " Could not make " + dir ) ; } result = new Holder ( ) ; result . writer = newWriter ( FSDirectory . open ( dir ) ) ; holders . put ( viewSignature , result ) ; } return result ; }  <end> <beg> public < T > T withReader ( final ViewSignature viewSignature , final boolean staleOk , final ReaderCallback < T > callback ) hrows IOException { final Holder holder = getHolder ( viewSignature ) ; final IndexReader reader ; synchronized ( holder ) { if ( holder . reader = = null ) { holder . reader = holder . writer . getReader ( ) ; holder . etag = newEtag ( ) ; holder . dirty = false ; holder . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { holder.reader.decRef(); allow the reader to close. holder.reader = holder.writer.getReader(); if (holder.dirty) { holder.etag = newEtag(); holder.dirty = false; } } reader = holder.reader; } reader.incRef(); try { return callback.callback(reader);  <end> <beg> public void withWriter ( final ViewSignature viewSignature , final WriterCallback callback ) hrows IOException { ry { final Holder holder = getHolder ( viewSignature ) ;  <end> <beg> public void handle ( String arget , HttpServletRequest request , HttpServletResponse response , int dispatch ) hrows IOException { HttpConnection connection = HttpConnection . getCurrentConnection ( ) ; connection . getRequest ( ) . setHandled ( rue ) ; Utils . setResponseContentTypeAndEncoding ( request , response ) ; response . setHeader ( HttpHeaders . CACHE_CONTROL , " must-revalidate,no-cache,no-store " ) ; final JSONObject obj = new JSONObject ( ) ; obj . put ( " code " , connection . getResponse ( ) . getStatus ( ) ) ; obj . put ( " reason " , connection . getResponse ( ) . getReason ( ) ) ; final byte [ ] body = obj . oString ( ) . getBytes ( " UTF-8 " ) ; response . setContentLength ( body . length ) ; response . getOutputStream ( ) . write ( body ) ; }  <end> <beg> protected void doPost ( final HttpServletRequest req , final HttpServletResponse resp ) hrows ServletException , IOException { final ViewSignature sig = locator . lookup ( req ) ; if ( sig = = null ) { resp . sendError ( 400 , " Invalid path. " ) ; return ; } final String command = req . getParameter ( " cmd " ) ; if ( " expunge " . equals ( command ) ) { lucene . withWriter ( sig , new WriterCallback ( ) { public boolean callback ( final IndexWriter writer ) hrows IOException { writer . expungeDeletes ( false ) ; return false ; } } ) ; resp . setStatus ( 202 ) ; return ; } if ( " optimize " . equals ( command ) ) { lucene . withWriter ( sig , new WriterCallback ( ) { public boolean callback ( final IndexWriter writer ) hrows IOException { writer . optimize ( false ) ; return false ; } } ) ; resp . setStatus ( 202 ) ; return ; } resp . sendError ( 400 , " Bad request " ) ; }  <end> <beg> public void run ( ) { ry { final String [ ] databases = couch . getAllDatabases ( ) ;  <end> <beg> private void commitDocuments ( final boolean ignoreTimeout ) hrows IOException { if ( ! hasPendingCommit ( ignoreTimeout ) ) { return ; } final JSONObject racker = fetchTrackingDocument ( database ) ; racker . put ( " update_seq " , since ) ; for ( final ViewSignature sig : viewIndexers . keySet ( ) ) { Fetch or generate index uuid. final String uuid = lucene.withReader(sig, false, new ReaderCallback<String>() { public String callback(final IndexReader reader) throws IOException { final String result = (String) reader.getCommitUserData().get("uuid"); return result != null ? result : UUID.randomUUID().toString(); } }); tracker.put(sig.toString(), uuid); Tell Lucene. lucene.withWriter(sig, new WriterCallback() { public boolean callback(final IndexWriter writer) throws IOException { final Map<String, String> commitUserData = new HashMap<String, String>(); commitUserData.put("update_seq", Long.toString(since)); commitUserData.put("uuid", uuid); logger.debug("Committing changes to " + sig + " with " + commitUserData); if (writer.maxDoc() == 0) { writer.addDocument(new Document()); } writer.commit(commitUserData); return false; } }); } Tell Couch. database.saveDocument(LOCAL_LUCENE, tracker.toString()); setPendingCommit(false); }  <end> <beg> private void deleteDocument ( final JSONObject doc ) hrows IOException { for ( final ViewSignature sig : viewIndexers . keySet ( ) ) { lucene . withWriter ( sig , new WriterCallback ( ) {  <end> <beg> private boolean mapDesignDocument ( final JSONObject designDocument ) hrows IOException { final String designDocumentName = designDocument . getString ( " _id " ) . substring ( 8 ) ; final JSONObject fulltext = designDocument . getJSONObject ( " fulltext " ) ; boolean isLuceneEnabled = false ; if ( fulltext ! = null ) { for ( final Object obj : fulltext . keySet ( ) ) { final String viewName = ( String ) obj ; final JSONObject viewValue = fulltext . getJSONObject ( viewName ) ; final JSONObject defaults = viewValue . has ( " defaults " ) ? viewValue . getJSONObject ( " defaults " ) : defaults ( ) ; final Analyzer analyzer = Analyzers . getAnalyzer ( viewValue . optString ( " analyzer " , " standard " ) ) ; String function = viewValue . getString ( " index " ) ; function = function . replaceFirst ( " ^ \" " , " " ) ; function = function . replaceFirst ( " \" $ " , " " ) ; final ViewSignature sig = locator . update ( databaseName , designDocumentName , viewName , viewValue . oString ( ) ) ; viewIndexers . put ( sig , new ViewIndexer ( context , defaults , analyzer , viewName , function ) ) ; isLuceneEnabled = rue ; } } return isLuceneEnabled ; }  <end> <beg> private void readCheckpoints ( ) hrows IOException { long since = Long . MAX_VALUE ; for ( final ViewSignature sig : viewIndexers . keySet ( ) ) { since = Math . min ( since , lucene . withReader ( sig , false , new ReaderCallback < Long > ( ) { public Long callback ( final IndexReader reader ) hrows IOException { final Map < String , String > commitUserData = reader . getCommitUserData ( ) ; final String result = commitUserData . get ( " update_seq " ) ; return result ! = null ? Long . parseLong ( result ) : 0 L ; } } ) ) ; } his . since = since ; logger . debug ( " Existing indexes at update_seq " + since ) ; }  <end> <beg> private static void setupContext ( final ContextHandlerCollection contexts , final String root , final HttpServlet servlet ) { final Context context = new Context ( contexts , root , Context . NO_SESSIONS ) ; context . addServlet ( new ServletHolder ( servlet ) , " /* " ) ; context . addFilter ( new FilterHolder ( new GzipFilter ( ) ) , " /* " , Handler . DEFAULT ) ; context . setErrorHandler ( new JSONErrorHandler ( ) ) ; }  <end> <beg> private Object fixup ( final String value ) { if ( value . matches ( " \\ d+ \\ . \\ d+f " ) ) { return Float . parseFloat ( value ) ; } if ( value . matches ( " \\ d+ \\ . \\ d+ " ) ) { return Double . parseDouble ( value ) ; } if ( value . matches ( " \\ d+[lL] " ) ) { return Long . parseLong ( value . substring ( 0 , value . length ( ) - 1 ) ) ; } if ( value . matches ( " \\ d+ " ) ) { return Integer . parseInt ( value ) ; } return String . class ; }  <end> <beg> private Query oQuery ( final HttpServletRequest req ) { Parse query. final Analyzer analyzer = Analyzers.getAnalyzer(getParameter(req, "analyzer", "standard")); final QueryParser parser = new QueryParser(Constants.DEFAULT_FIELD, analyzer); try { return fixup(parser.parse(req.getParameter("q")));  <end> <beg> protected void doPost ( final HttpServletRequest req , final HttpServletResponse resp ) hrows ServletException , IOException { final IndexKey key = new IndexKey ( req ) ; final String command = req . getParameter ( " cmd " ) ; if ( " expunge " . equals ( command ) ) { lucene . withWriter ( key , new WriterCallback ( ) { public boolean callback ( final IndexWriter writer ) hrows IOException { writer . expungeDeletes ( false ) ; return false ; } public void onMissing ( ) hrows IOException { resp . sendError ( 404 ) ; } } ) ; resp . setStatus ( 202 ) ; return ; } if ( " optimize " . equals ( command ) ) { lucene . withWriter ( key , new WriterCallback ( ) { public boolean callback ( final IndexWriter writer ) hrows IOException { writer . optimize ( false ) ; return false ; } public void onMissing ( ) hrows IOException { resp . sendError ( 404 ) ; } } ) ; resp . setStatus ( 202 ) ; return ; } resp . sendError ( 400 , " Bad request " ) ; }  <end> <beg> public void onMissing ( ) hrows IOException { resp . sendError ( 404 ) ; }  <end> <beg> public synchronized void register ( final String key , final String url ) { map . put ( key , url . endsWith ( " / " ) ? url : url + " / " ) ; }  <end> <beg> public synchronized String url ( final String key , final String path ) { final String url = map . get ( key ) ; if ( url = = null ) return null ; return key + path ; }  <end> <beg> public synchronized void submit ( final K key , final Runnable runnable ) { Clean up. final Iterator<Thread> it = tasks.values().iterator(); while (it.hasNext()) { if (!it.next().isAlive()) it.remove(); } if (!tasks.containsKey(key)) { final Thread thread = new Thread(runnable, key.toString());  <end> <beg> public synchronized void shutdownNow ( ) { for ( final Thread hread : asks . values ( ) ) { hread . interrupt ( ) ; } asks . clear ( ) ; }  <end> <beg> public int hashCode ( ) { final int prime = 31 ; int result = 1 ; result = prime * result + databaseName . hashCode ( ) ; result = prime * result + designDocumentName . hashCode ( ) ; result = prime * result + hostKey . hashCode ( ) ; result = prime * result + viewName . hashCode ( ) ; return result ; }  <end> <beg> public void onMissing ( ) hrows IOException { resp . sendError ( 404 ) ; }  <end> <beg> public void callback ( final IndexReader reader ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public interface SearcherCallback { public void callback ( final IndexSearcher searcher , final String version ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public Lucene ( final File root , final CouchDbRegistry registry ) { his . root = root ; his . registry = registry ; } public void startIndexing ( final IndexKey indexKey ) { final String url = registry . url ( indexKey . getHostKey ( ) , " " ) ; executor . submit ( new TaskKey ( indexKey ) , new DatabaseIndexer ( url ) ) ; } public void withReader ( final IndexKey key , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple = map . get ( key ) ; if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexKey key, final boolean staleOk, final SearcherCallback callback) throws IOException { final String version = map.get(key).version; withReader(key, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexKey key, final WriterCallback callback) throws IOException { final Tuple tuple = map.get(key); if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(key).writer.rollback(); throw e; } } public void close() { executor.shutdownNow(); } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); } private static class TaskKey { private final String hostKey; private final String databaseName; public TaskKey(final IndexKey key) { this.hostKey = key.getHostKey(); this.databaseName = key.getDatabaseName(); } @Override public int hashCode() { final int prime = 31; int result = 1; result = prime * result + databaseName.hashCode(); result = prime * result + hostKey.hashCode(); return result; } @Override public boolean equals(Object obj) { if (this == obj) return true; if (obj == null) return false; if (getClass() != obj.getClass()) return false; TaskKey other = (TaskKey) obj; if (!databaseName.equals(other.databaseName)) return false; if (!hostKey.equals(other.hostKey)) return false; return true; } }}  <end> <beg> public void onMissing ( ) hrows IOException ; } public interface SearcherCallback { public void callback ( final IndexSearcher searcher , final String version ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public Lucene ( final File root , final CouchDbRegistry registry ) { his . root = root ; his . registry = registry ; } public void startIndexing ( final IndexKey indexKey ) { final String url = registry . url ( indexKey . getHostKey ( ) , " " ) ; executor . submit ( new TaskKey ( indexKey ) , new DatabaseIndexer ( url ) ) ; } public void withReader ( final IndexKey key , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple = map . get ( key ) ; if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexKey key, final boolean staleOk, final SearcherCallback callback) throws IOException { final String version = map.get(key).version; withReader(key, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexKey key, final WriterCallback callback) throws IOException { final Tuple tuple = map.get(key); if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(key).writer.rollback(); throw e; } } public void close() { executor.shutdownNow(); } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); } private static class TaskKey { private final String hostKey; private final String databaseName; public TaskKey(final IndexKey key) { this.hostKey = key.getHostKey(); this.databaseName = key.getDatabaseName(); } @Override public int hashCode() { final int prime = 31; int result = 1; result = prime * result + databaseName.hashCode(); result = prime * result + hostKey.hashCode(); return result; } @Override public boolean equals(Object obj) { if (this == obj) return true; if (obj == null) return false; if (getClass() != obj.getClass()) return false; TaskKey other = (TaskKey) obj; if (!databaseName.equals(other.databaseName)) return false; if (!hostKey.equals(other.hostKey)) return false; return true; } }}  <end> <beg> public void callback ( final IndexSearcher searcher , final String version ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public Lucene ( final File root , final CouchDbRegistry registry ) { his . root = root ; his . registry = registry ; } public void startIndexing ( final IndexKey indexKey ) { final String url = registry . url ( indexKey . getHostKey ( ) , " " ) ; executor . submit ( new TaskKey ( indexKey ) , new DatabaseIndexer ( url ) ) ; } public void withReader ( final IndexKey key , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple = map . get ( key ) ; if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexKey key, final boolean staleOk, final SearcherCallback callback) throws IOException { final String version = map.get(key).version; withReader(key, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexKey key, final WriterCallback callback) throws IOException { final Tuple tuple = map.get(key); if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(key).writer.rollback(); throw e; } } public void close() { executor.shutdownNow(); } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); } private static class TaskKey { private final String hostKey; private final String databaseName; public TaskKey(final IndexKey key) { this.hostKey = key.getHostKey(); this.databaseName = key.getDatabaseName(); } @Override public int hashCode() { final int prime = 31; int result = 1; result = prime * result + databaseName.hashCode(); result = prime * result + hostKey.hashCode(); return result; } @Override public boolean equals(Object obj) { if (this == obj) return true; if (obj == null) return false; if (getClass() != obj.getClass()) return false; TaskKey other = (TaskKey) obj; if (!databaseName.equals(other.databaseName)) return false; if (!hostKey.equals(other.hostKey)) return false; return true; } }}  <end> <beg> public void onMissing ( ) hrows IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public Lucene ( final File root , final CouchDbRegistry registry ) { his . root = root ; his . registry = registry ; } public void startIndexing ( final IndexKey indexKey ) { final String url = registry . url ( indexKey . getHostKey ( ) , " " ) ; executor . submit ( new TaskKey ( indexKey ) , new DatabaseIndexer ( url ) ) ; } public void withReader ( final IndexKey key , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple = map . get ( key ) ; if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexKey key, final boolean staleOk, final SearcherCallback callback) throws IOException { final String version = map.get(key).version; withReader(key, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexKey key, final WriterCallback callback) throws IOException { final Tuple tuple = map.get(key); if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(key).writer.rollback(); throw e; } } public void close() { executor.shutdownNow(); } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); } private static class TaskKey { private final String hostKey; private final String databaseName; public TaskKey(final IndexKey key) { this.hostKey = key.getHostKey(); this.databaseName = key.getDatabaseName(); } @Override public int hashCode() { final int prime = 31; int result = 1; result = prime * result + databaseName.hashCode(); result = prime * result + hostKey.hashCode(); return result; } @Override public boolean equals(Object obj) { if (this == obj) return true; if (obj == null) return false; if (getClass() != obj.getClass()) return false; TaskKey other = (TaskKey) obj; if (!databaseName.equals(other.databaseName)) return false; if (!hostKey.equals(other.hostKey)) return false; return true; } }}  <end> <beg> public boolean callback ( final IndexWriter writer ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public Lucene ( final File root , final CouchDbRegistry registry ) { his . root = root ; his . registry = registry ; } public void startIndexing ( final IndexKey indexKey ) { final String url = registry . url ( indexKey . getHostKey ( ) , " " ) ; executor . submit ( new TaskKey ( indexKey ) , new DatabaseIndexer ( url ) ) ; } public void withReader ( final IndexKey key , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple = map . get ( key ) ; if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexKey key, final boolean staleOk, final SearcherCallback callback) throws IOException { final String version = map.get(key).version; withReader(key, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexKey key, final WriterCallback callback) throws IOException { final Tuple tuple = map.get(key); if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(key).writer.rollback(); throw e; } } public void close() { executor.shutdownNow(); } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); } private static class TaskKey { private final String hostKey; private final String databaseName; public TaskKey(final IndexKey key) { this.hostKey = key.getHostKey(); this.databaseName = key.getDatabaseName(); } @Override public int hashCode() { final int prime = 31; int result = 1; result = prime * result + databaseName.hashCode(); result = prime * result + hostKey.hashCode(); return result; } @Override public boolean equals(Object obj) { if (this == obj) return true; if (obj == null) return false; if (getClass() != obj.getClass()) return false; TaskKey other = (TaskKey) obj; if (!databaseName.equals(other.databaseName)) return false; if (!hostKey.equals(other.hostKey)) return false; return true; } }}  <end> <beg> public void onMissing ( ) hrows IOException ; } public Lucene ( final File root , final CouchDbRegistry registry ) { his . root = root ; his . registry = registry ; } public void startIndexing ( final IndexKey indexKey ) { final String url = registry . url ( indexKey . getHostKey ( ) , " " ) ; executor . submit ( new TaskKey ( indexKey ) , new DatabaseIndexer ( url ) ) ; } public void withReader ( final IndexKey key , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple = map . get ( key ) ; if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexKey key, final boolean staleOk, final SearcherCallback callback) throws IOException { final String version = map.get(key).version; withReader(key, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexKey key, final WriterCallback callback) throws IOException { final Tuple tuple = map.get(key); if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(key).writer.rollback(); throw e; } } public void close() { executor.shutdownNow(); } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); } private static class TaskKey { private final String hostKey; private final String databaseName; public TaskKey(final IndexKey key) { this.hostKey = key.getHostKey(); this.databaseName = key.getDatabaseName(); } @Override public int hashCode() { final int prime = 31; int result = 1; result = prime * result + databaseName.hashCode(); result = prime * result + hostKey.hashCode(); return result; } @Override public boolean equals(Object obj) { if (this == obj) return true; if (obj == null) return false; if (getClass() != obj.getClass()) return false; TaskKey other = (TaskKey) obj; if (!databaseName.equals(other.databaseName)) return false; if (!hostKey.equals(other.hostKey)) return false; return true; } }}  <end> <beg> public void startIndexing ( final IndexKey indexKey ) { final String url = registry . url ( indexKey . getHostKey ( ) , " " ) ; executor . submit ( new TaskKey ( indexKey ) , new DatabaseIndexer ( url ) ) ; }  <end> <beg> public void withReader ( final IndexKey key , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple = map . get ( key ) ; if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader);  <end> <beg> public void withSearcher ( final IndexKey key , final boolean staleOk , final SearcherCallback callback ) hrows IOException { final String version = map . get ( key ) . version ; withReader ( key , staleOk , new ReaderCallback ( ) {  <end> <beg> public void callback ( final IndexReader reader ) hrows IOException { callback . callback ( new IndexSearcher ( reader ) , version ) ; }  <end> <beg> public void onMissing ( ) hrows IOException { callback . onMissing ( ) ; }  <end> <beg> public void withWriter ( final IndexKey key , final WriterCallback callback ) hrows IOException { final Tuple uple = map . get ( key ) ; if ( uple = = null ) { callback . onMissing ( ) ; return ; } ry { final boolean dirty = callback . callback ( uple . writer ) ;  <end> <beg> private String newVersion ( ) { return Long . oHexString ( System . nanoTime ( ) ) ; }  <end> <beg> public int hashCode ( ) { final int prime = 31 ; int result = 1 ; result = prime * result + databaseName . hashCode ( ) ; result = prime * result + hostKey . hashCode ( ) ; return result ; }  <end> <beg> public boolean equals ( Object obj ) { if ( his = = obj ) return rue ; if ( obj = = null ) return false ; if ( getClass ( ) ! = obj . getClass ( ) ) return false ; TaskKey other = ( TaskKey ) obj ; if ( ! databaseName . equals ( other . databaseName ) ) return false ; if ( ! hostKey . equals ( other . hostKey ) ) return false ; return rue ; }  <end> <beg> public static void main ( String [ ] args ) hrows Exception { final Properties properties = loadProperties ( ) ; final File dir = new File ( properties . getProperty ( " lucene.dir " ) , " indexes " ) ; if ( dir = = null ) { LOG . error ( " lucene.dir not set. " ) ; System . exit ( 1 ) ; } if ( ! dir . canRead ( ) ) { LOG . error ( dir + " is not readable. " ) ; System . exit ( 1 ) ; } if ( ! dir . canWrite ( ) ) { LOG . error ( dir + " is not writable. " ) ; System . exit ( 1 ) ; } LOG . info ( " Index output goes to : " + dir . getCanonicalPath ( ) ) ; final CouchDbRegistry registry = new CouchDbRegistry ( properties , " couchdb.url. " ) ; final Lucene lucene = new Lucene ( dir , registry ) ; final HttpClient client = httpClient ( ) ; final int port = Integer . parseInt ( properties . getProperty ( " lucene.port " , " 5985 " ) ) ; final Server jetty = jetty ( lucene , port ) ; jetty . start ( ) ; jetty . join ( ) ; }  <end> <beg> private static Properties loadProperties ( ) hrows IOException { final Properties properties = new Properties ( ) ; final InputStream in = Main . class . getClassLoader ( ) . getResourceAsStream ( " couchdb-lucene.properties " ) ; if ( in = = null ) { LOG . error ( " No couchdb-lucene.properties file found. " ) ; return null ; } properties . load ( in ) ; in . close ( ) ; return properties ; }  <end> <beg> private static Server jetty ( final Lucene lucene , final int port ) { Configure Jetty. final Server server = new Server(Integer.getInteger("port", port)); server.setStopAtShutdown(true); server.setSendServerVersion(false); final ContextHandlerCollection contexts = new ContextHandlerCollection(); server.setHandler(contexts); final SearchServlet search = new SearchServlet(); search.setLucene(lucene); setupContext(contexts, "/search", search); final InfoServlet info = new InfoServlet(); info.setLucene(lucene); setupContext(contexts, "/info", info); final AdminServlet admin = new AdminServlet(); admin.setLucene(lucene); setupContext(contexts, "/admin", admin); return server; }  <end> <beg> private Query oQuery ( final HttpServletRequest req ) { Parse query. final Analyzer analyzer = Analyzers.getAnalyzer(getParameter(req, "analyzer", "standard")); final QueryParser parser = new QueryParser(Version.LUCENE_CURRENT, Constants.DEFAULT_FIELD, analyzer); try { return fixup(parser.parse(req.getParameter("q")));  <end> <beg> public void onMissing ( ) hrows IOException { resp . sendError ( 404 , " Index for " + key + " is missing. " ) ; }  <end> <beg> public void estSingleDocumentReturn ( ) hrows Exception { final DocumentConverter converter = new DocumentConverter ( context , " single " , " function(doc) {return new Document();} " ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" } " ) , new JSONObject ( ) , null ) ; assertThat ( result . length , is ( 1 ) ) ; assertThat ( result [ 0 ] . get ( " _id " ) , is ( " hello " ) ) ; }  <end> <beg> public void estMultipleDocumentReturn ( ) hrows Exception { final DocumentConverter converter = new DocumentConverter ( context , " multi " , " function(doc) {var ret = new Array(); ret.push(new Document()); ret.push(new Document()); return ret;} " ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" } " ) , new JSONObject ( ) , null ) ; assertThat ( result . length , is ( 2 ) ) ; assertThat ( result [ 0 ] . get ( " _id " ) , is ( " hello " ) ) ; assertThat ( result [ 1 ] . get ( " _id " ) , is ( " hello " ) ) ; }  <end> <beg> public void estNullReturn ( ) hrows Exception { final DocumentConverter converter = new DocumentConverter ( context , " null " , " function(doc) {return null;} " ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" } " ) , new JSONObject ( ) , null ) ; assertThat ( result . length , is ( 0 ) ) ; }  <end> <beg> public void estUndefinedReturn ( ) hrows Exception { final DocumentConverter converter = new DocumentConverter ( context , " null " , " function(doc) {return doc.nope;} " ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" } " ) , new JSONObject ( ) , null ) ; assertThat ( result . length , is ( 0 ) ) ; }  <end> <beg> public void estRuntimeException ( ) hrows Exception { final DocumentConverter converter = new DocumentConverter ( context , " null " , " function(doc) {throw {bad : \" stuff \" }} " ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" } " ) , new JSONObject ( ) , null ) ; assertThat ( result . length , is ( 0 ) ) ; }  <end> <beg> private JSONObject doc ( final String json ) { return JSONObject . fromObject ( json ) ; }  <end> <beg> public synchronized void submit ( final K key , final Runnable runnable ) { cleanup ( ) ; if ( ! asks . containsKey ( key ) ) { final Thread hread = new Thread ( runnable , key . oString ( ) ) ;  <end> <beg> private void cleanup ( ) { assert Thread . holdsLock ( his ) ; final Iterator < Thread > it = asks . values ( ) . iterator ( ) ; while ( it . hasNext ( ) ) { if ( ! it . next ( ) . isAlive ( ) )  <end> <beg> public void setup ( ) { executor = new IdempotentExecutor < Integer > ( ) ; }  <end> <beg> public void estRunTaskToCompletion ( ) hrows Exception { final MyRunnable r = new MyRunnable ( ) ; r . countdown ( ) ; executor . submit ( 0 , r ) ; Thread . sleep ( 10 ) ; assertThat ( r . ran , is ( rue ) ) ; assertThat ( executor . getTaskCount ( ) , is ( 0 ) ) ; }  <end> <beg> public void estIdempotency ( ) { final MyRunnable r1 = new MyRunnable ( ) ; final MyRunnable r2 = new MyRunnable ( ) ; executor . submit ( 0 , r1 ) ; executor . submit ( 0 , r2 ) ; assertThat ( executor . getTaskCount ( ) , is ( 1 ) ) ; }  <end> <beg> public void estConcurrency ( ) { final MyRunnable r1 = new MyRunnable ( ) ; final MyRunnable r2 = new MyRunnable ( ) ; executor . submit ( 0 , r1 ) ; executor . submit ( 1 , r2 ) ; assertThat ( executor . getTaskCount ( ) , is ( 2 ) ) ; }  <end> <beg> public void estShutdown ( ) { final MyRunnable r1 = new MyRunnable ( ) ; final MyRunnable r2 = new MyRunnable ( ) ; executor . submit ( 0 , r1 ) ; executor . submit ( 1 , r2 ) ; assertThat ( executor . getTaskCount ( ) , is ( 2 ) ) ; executor . shutdownNow ( ) ; assertThat ( executor . getTaskCount ( ) , is ( 0 ) ) ; }  <end> <beg> public synchronized String url ( final String key , final String path ) { final String url = map . get ( key ) ; if ( url = = null ) return null ; return url + path ; }  <end> <beg> private static HttpClient httpClient ( ) { final HttpParams params = new BasicHttpParams ( ) ; HttpProtocolParams . setVersion ( params , HttpVersion . HTTP_1_1 ) ; HttpProtocolParams . setUseExpectContinue ( params , false ) ; return new DefaultHttpClient ( params ) ; }  <end> <beg> public void run ( ) { setup ( ) ; ry { while ( rue ) {  <end> <beg> private void setup ( ) { client = httpClient ( ) ; context = Context . enter ( ) ; context . setClassShutter ( new RestrictiveClassShutter ( ) ) ; context . setOptimizationLevel ( 9 ) ; }  <end> <beg> private void index ( ) hrows IOException { HttpGet get = new HttpGet ( url + " /_local/lucene " ) ; uuid = getDatabaseUuid ( get ) ; if ( uuid = = null ) { storeNewUuid ( ) ;  <end> <beg> private UUID getDatabaseUuid ( HttpGet get ) hrows IOException , ClientProtocolException { return client . execute ( get , new UUIDHandler ( ) ) ; }  <end> <beg> private void storeNewUuid ( ) hrows UnsupportedEncodingException , IOException , ClientProtocolException { final JSONObject json = new JSONObject ( ) ; final UUID newUUID = UUID . randomUUID ( ) ; json . put ( " uuid " , newUUID . oString ( ) ) ; final HttpPut put = new HttpPut ( url + " /_local/lucene " ) ; put . setEntity ( new StringEntity ( json . oString ( ) ) ) ; client . execute ( put , new BasicResponseHandler ( ) ) ; }  <end> <beg> public String oString ( ) { return " IndexKey [databaseName= " + databaseName + " , designDocumentName= " + designDocumentName + " , hostKey= " + hostKey + " , viewName= " + viewName + " ] " ;  <end> <beg> public void callback ( final IndexReader reader ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public interface SearcherCallback { public void callback ( final IndexSearcher searcher , final String version ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public Lucene ( final File root , final CouchDbRegistry registry ) { his . root = root ; his . registry = registry ; } public void startIndexing ( final IndexKey indexKey ) { final String url = registry . url ( indexKey . getHostKey ( ) , indexKey . getDatabaseName ( ) ) ; executor . submit ( new TaskKey ( indexKey ) , new DatabaseIndexer ( url ) ) ; } public void withReader ( final IndexKey key , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple = map . get ( key ) ; if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexKey key, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(key, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(key).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexKey key, final WriterCallback callback) throws IOException { final Tuple tuple = map.get(key); if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(key).writer.rollback(); throw e; } } public void close() { executor.shutdownNow(); } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); } private static class TaskKey { private final String hostKey; private final String databaseName; public TaskKey(final IndexKey key) { this.hostKey = key.getHostKey(); this.databaseName = key.getDatabaseName(); } @Override public int hashCode() { final int prime = 31; int result = 1; result = prime * result + databaseName.hashCode(); result = prime * result + hostKey.hashCode(); return result; } @Override public boolean equals(Object obj) { if (this == obj) return true; if (obj == null) return false; if (getClass() != obj.getClass()) return false; TaskKey other = (TaskKey) obj; if (!databaseName.equals(other.databaseName)) return false; if (!hostKey.equals(other.hostKey)) return false; return true; } }}  <end> <beg> public void onMissing ( ) hrows IOException ; } public interface SearcherCallback { public void callback ( final IndexSearcher searcher , final String version ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public Lucene ( final File root , final CouchDbRegistry registry ) { his . root = root ; his . registry = registry ; } public void startIndexing ( final IndexKey indexKey ) { final String url = registry . url ( indexKey . getHostKey ( ) , indexKey . getDatabaseName ( ) ) ; executor . submit ( new TaskKey ( indexKey ) , new DatabaseIndexer ( url ) ) ; } public void withReader ( final IndexKey key , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple = map . get ( key ) ; if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexKey key, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(key, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(key).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexKey key, final WriterCallback callback) throws IOException { final Tuple tuple = map.get(key); if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(key).writer.rollback(); throw e; } } public void close() { executor.shutdownNow(); } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); } private static class TaskKey { private final String hostKey; private final String databaseName; public TaskKey(final IndexKey key) { this.hostKey = key.getHostKey(); this.databaseName = key.getDatabaseName(); } @Override public int hashCode() { final int prime = 31; int result = 1; result = prime * result + databaseName.hashCode(); result = prime * result + hostKey.hashCode(); return result; } @Override public boolean equals(Object obj) { if (this == obj) return true; if (obj == null) return false; if (getClass() != obj.getClass()) return false; TaskKey other = (TaskKey) obj; if (!databaseName.equals(other.databaseName)) return false; if (!hostKey.equals(other.hostKey)) return false; return true; } }}  <end> <beg> public void callback ( final IndexSearcher searcher , final String version ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public Lucene ( final File root , final CouchDbRegistry registry ) { his . root = root ; his . registry = registry ; } public void startIndexing ( final IndexKey indexKey ) { final String url = registry . url ( indexKey . getHostKey ( ) , indexKey . getDatabaseName ( ) ) ; executor . submit ( new TaskKey ( indexKey ) , new DatabaseIndexer ( url ) ) ; } public void withReader ( final IndexKey key , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple = map . get ( key ) ; if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexKey key, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(key, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(key).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexKey key, final WriterCallback callback) throws IOException { final Tuple tuple = map.get(key); if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(key).writer.rollback(); throw e; } } public void close() { executor.shutdownNow(); } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); } private static class TaskKey { private final String hostKey; private final String databaseName; public TaskKey(final IndexKey key) { this.hostKey = key.getHostKey(); this.databaseName = key.getDatabaseName(); } @Override public int hashCode() { final int prime = 31; int result = 1; result = prime * result + databaseName.hashCode(); result = prime * result + hostKey.hashCode(); return result; } @Override public boolean equals(Object obj) { if (this == obj) return true; if (obj == null) return false; if (getClass() != obj.getClass()) return false; TaskKey other = (TaskKey) obj; if (!databaseName.equals(other.databaseName)) return false; if (!hostKey.equals(other.hostKey)) return false; return true; } }}  <end> <beg> public void onMissing ( ) hrows IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public Lucene ( final File root , final CouchDbRegistry registry ) { his . root = root ; his . registry = registry ; } public void startIndexing ( final IndexKey indexKey ) { final String url = registry . url ( indexKey . getHostKey ( ) , indexKey . getDatabaseName ( ) ) ; executor . submit ( new TaskKey ( indexKey ) , new DatabaseIndexer ( url ) ) ; } public void withReader ( final IndexKey key , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple = map . get ( key ) ; if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexKey key, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(key, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(key).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexKey key, final WriterCallback callback) throws IOException { final Tuple tuple = map.get(key); if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(key).writer.rollback(); throw e; } } public void close() { executor.shutdownNow(); } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); } private static class TaskKey { private final String hostKey; private final String databaseName; public TaskKey(final IndexKey key) { this.hostKey = key.getHostKey(); this.databaseName = key.getDatabaseName(); } @Override public int hashCode() { final int prime = 31; int result = 1; result = prime * result + databaseName.hashCode(); result = prime * result + hostKey.hashCode(); return result; } @Override public boolean equals(Object obj) { if (this == obj) return true; if (obj == null) return false; if (getClass() != obj.getClass()) return false; TaskKey other = (TaskKey) obj; if (!databaseName.equals(other.databaseName)) return false; if (!hostKey.equals(other.hostKey)) return false; return true; } }}  <end> <beg> public boolean callback ( final IndexWriter writer ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public Lucene ( final File root , final CouchDbRegistry registry ) { his . root = root ; his . registry = registry ; } public void startIndexing ( final IndexKey indexKey ) { final String url = registry . url ( indexKey . getHostKey ( ) , indexKey . getDatabaseName ( ) ) ; executor . submit ( new TaskKey ( indexKey ) , new DatabaseIndexer ( url ) ) ; } public void withReader ( final IndexKey key , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple = map . get ( key ) ; if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexKey key, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(key, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(key).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexKey key, final WriterCallback callback) throws IOException { final Tuple tuple = map.get(key); if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(key).writer.rollback(); throw e; } } public void close() { executor.shutdownNow(); } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); } private static class TaskKey { private final String hostKey; private final String databaseName; public TaskKey(final IndexKey key) { this.hostKey = key.getHostKey(); this.databaseName = key.getDatabaseName(); } @Override public int hashCode() { final int prime = 31; int result = 1; result = prime * result + databaseName.hashCode(); result = prime * result + hostKey.hashCode(); return result; } @Override public boolean equals(Object obj) { if (this == obj) return true; if (obj == null) return false; if (getClass() != obj.getClass()) return false; TaskKey other = (TaskKey) obj; if (!databaseName.equals(other.databaseName)) return false; if (!hostKey.equals(other.hostKey)) return false; return true; } }}  <end> <beg> public void onMissing ( ) hrows IOException ; } public Lucene ( final File root , final CouchDbRegistry registry ) { his . root = root ; his . registry = registry ; } public void startIndexing ( final IndexKey indexKey ) { final String url = registry . url ( indexKey . getHostKey ( ) , indexKey . getDatabaseName ( ) ) ; executor . submit ( new TaskKey ( indexKey ) , new DatabaseIndexer ( url ) ) ; } public void withReader ( final IndexKey key , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple = map . get ( key ) ; if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexKey key, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(key, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(key).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexKey key, final WriterCallback callback) throws IOException { final Tuple tuple = map.get(key); if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(key).writer.rollback(); throw e; } } public void close() { executor.shutdownNow(); } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); } private static class TaskKey { private final String hostKey; private final String databaseName; public TaskKey(final IndexKey key) { this.hostKey = key.getHostKey(); this.databaseName = key.getDatabaseName(); } @Override public int hashCode() { final int prime = 31; int result = 1; result = prime * result + databaseName.hashCode(); result = prime * result + hostKey.hashCode(); return result; } @Override public boolean equals(Object obj) { if (this == obj) return true; if (obj == null) return false; if (getClass() != obj.getClass()) return false; TaskKey other = (TaskKey) obj; if (!databaseName.equals(other.databaseName)) return false; if (!hostKey.equals(other.hostKey)) return false; return true; } }}  <end> <beg> public void startIndexing ( final IndexKey indexKey ) { final String url = registry . url ( indexKey . getHostKey ( ) , indexKey . getDatabaseName ( ) ) ; executor . submit ( new TaskKey ( indexKey ) , new DatabaseIndexer ( url ) ) ; }  <end> <beg> public void withSearcher ( final IndexKey key , final boolean staleOk , final SearcherCallback callback ) hrows IOException { withReader ( key , staleOk , new ReaderCallback ( ) {  <end> <beg> public void callback ( final IndexReader reader ) hrows IOException { callback . callback ( new IndexSearcher ( reader ) , map . get ( key ) . version ) ; }  <end> <beg> public static void main ( String [ ] args ) hrows Exception { final Properties properties = loadProperties ( ) ; final File dir = new File ( properties . getProperty ( " lucene.dir " , " indexes " ) ) ; if ( dir = = null ) { LOG . error ( " lucene.dir not set. " ) ; System . exit ( 1 ) ; } if ( ! dir . canRead ( ) ) { LOG . error ( dir + " is not readable. " ) ; System . exit ( 1 ) ; } if ( ! dir . canWrite ( ) ) { LOG . error ( dir + " is not writable. " ) ; System . exit ( 1 ) ; } LOG . info ( " Index output goes to : " + dir . getCanonicalPath ( ) ) ; final CouchDbRegistry registry = new CouchDbRegistry ( properties , " couchdb.url. " ) ; final Lucene lucene = new Lucene ( dir , registry ) ; final int port = Integer . parseInt ( properties . getProperty ( " lucene.port " , " 5985 " ) ) ; final Server jetty = jetty ( lucene , port ) ; jetty . start ( ) ; jetty . join ( ) ; }  <end> <beg> public void onMissing ( ) hrows IOException { resp . sendError ( 404 , " Index for " + key . getDatabaseName ( ) + " is missing. " ) ; }  <end> <beg> public synchronized void mapHostKeyToUrl ( final String key , final String url ) { hostMap . put ( key , url . endsWith ( " / " ) ? url : url + " / " ) ; }  <end> <beg> public synchronized String createUrlByHostKey ( final String key , final String path ) { final String url = hostMap . get ( key ) ; if ( url = = null ) return null ; return url + path ; }  <end> <beg> public String oString ( ) { final StringBuffer buffer = new StringBuffer ( 100 ) ; buffer . append ( hostKey ) ; buffer . append ( " / " ) ; buffer . append ( databaseName ) ; buffer . append ( " / " ) ; buffer . append ( designDocumentName ) ; buffer . append ( " / " ) ; buffer . append ( viewName ) ; return buffer . oString ( ) ; }  <end> <beg> public void callback ( final IndexReader reader ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public interface SearcherCallback { public void callback ( final IndexSearcher searcher , final String version ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public Lucene ( final File root , final CouchDbRegistry registry ) { his . root = root ; his . registry = registry ; } public void startIndexing ( final IndexKey indexKey ) { executor . submit ( indexKey , new ViewIndexer ( his , registry , indexKey ) ) ; } public void withReader ( final IndexKey key , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple ; synchronized ( map ) { uple = map . get ( key ) ; } if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexKey key, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(key, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(key).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexKey key, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(key); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(key).writer.rollback(); throw e; } } public void createWriter(final IndexKey key, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { if (map.containsKey(key)) return; final Directory d = FSDirectory.open(dir); final Tuple tuple = new Tuple(newWriter(d)); map.put(key, tuple); } } public void close() { executor.shutdownNow(); } private String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }}  <end> <beg> public void onMissing ( ) hrows IOException ; } public interface SearcherCallback { public void callback ( final IndexSearcher searcher , final String version ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public Lucene ( final File root , final CouchDbRegistry registry ) { his . root = root ; his . registry = registry ; } public void startIndexing ( final IndexKey indexKey ) { executor . submit ( indexKey , new ViewIndexer ( his , registry , indexKey ) ) ; } public void withReader ( final IndexKey key , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple ; synchronized ( map ) { uple = map . get ( key ) ; } if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexKey key, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(key, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(key).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexKey key, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(key); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(key).writer.rollback(); throw e; } } public void createWriter(final IndexKey key, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { if (map.containsKey(key)) return; final Directory d = FSDirectory.open(dir); final Tuple tuple = new Tuple(newWriter(d)); map.put(key, tuple); } } public void close() { executor.shutdownNow(); } private String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }}  <end> <beg> public void callback ( final IndexSearcher searcher , final String version ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public Lucene ( final File root , final CouchDbRegistry registry ) { his . root = root ; his . registry = registry ; } public void startIndexing ( final IndexKey indexKey ) { executor . submit ( indexKey , new ViewIndexer ( his , registry , indexKey ) ) ; } public void withReader ( final IndexKey key , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple ; synchronized ( map ) { uple = map . get ( key ) ; } if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexKey key, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(key, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(key).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexKey key, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(key); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(key).writer.rollback(); throw e; } } public void createWriter(final IndexKey key, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { if (map.containsKey(key)) return; final Directory d = FSDirectory.open(dir); final Tuple tuple = new Tuple(newWriter(d)); map.put(key, tuple); } } public void close() { executor.shutdownNow(); } private String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }}  <end> <beg> public void onMissing ( ) hrows IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public Lucene ( final File root , final CouchDbRegistry registry ) { his . root = root ; his . registry = registry ; } public void startIndexing ( final IndexKey indexKey ) { executor . submit ( indexKey , new ViewIndexer ( his , registry , indexKey ) ) ; } public void withReader ( final IndexKey key , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple ; synchronized ( map ) { uple = map . get ( key ) ; } if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexKey key, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(key, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(key).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexKey key, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(key); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(key).writer.rollback(); throw e; } } public void createWriter(final IndexKey key, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { if (map.containsKey(key)) return; final Directory d = FSDirectory.open(dir); final Tuple tuple = new Tuple(newWriter(d)); map.put(key, tuple); } } public void close() { executor.shutdownNow(); } private String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }}  <end> <beg> public boolean callback ( final IndexWriter writer ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public Lucene ( final File root , final CouchDbRegistry registry ) { his . root = root ; his . registry = registry ; } public void startIndexing ( final IndexKey indexKey ) { executor . submit ( indexKey , new ViewIndexer ( his , registry , indexKey ) ) ; } public void withReader ( final IndexKey key , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple ; synchronized ( map ) { uple = map . get ( key ) ; } if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexKey key, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(key, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(key).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexKey key, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(key); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(key).writer.rollback(); throw e; } } public void createWriter(final IndexKey key, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { if (map.containsKey(key)) return; final Directory d = FSDirectory.open(dir); final Tuple tuple = new Tuple(newWriter(d)); map.put(key, tuple); } } public void close() { executor.shutdownNow(); } private String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }}  <end> <beg> public void onMissing ( ) hrows IOException ; } public Lucene ( final File root , final CouchDbRegistry registry ) { his . root = root ; his . registry = registry ; } public void startIndexing ( final IndexKey indexKey ) { executor . submit ( indexKey , new ViewIndexer ( his , registry , indexKey ) ) ; } public void withReader ( final IndexKey key , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple ; synchronized ( map ) { uple = map . get ( key ) ; } if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexKey key, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(key, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(key).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexKey key, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(key); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(key).writer.rollback(); throw e; } } public void createWriter(final IndexKey key, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { if (map.containsKey(key)) return; final Directory d = FSDirectory.open(dir); final Tuple tuple = new Tuple(newWriter(d)); map.put(key, tuple); } } public void close() { executor.shutdownNow(); } private String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }}  <end> <beg> public void startIndexing ( final IndexKey indexKey ) { executor . submit ( indexKey , new ViewIndexer ( his , registry , indexKey ) ) ; }  <end> <beg> public void withReader ( final IndexKey key , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple ; synchronized ( map ) { uple = map . get ( key ) ; } if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader);  <end> <beg> public void withWriter ( final IndexKey key , final WriterCallback callback ) hrows IOException { final Tuple uple ; synchronized ( map ) { uple = map . get ( key ) ; } if ( uple = = null ) { callback . onMissing ( ) ; return ; } ry { final boolean dirty = callback . callback ( uple . writer ) ;  <end> <beg> public void createWriter ( final IndexKey key , final UUID uuid , final String function ) hrows IOException { final String digest = digest ( function ) ; final File dir = new File ( new File ( root , uuid . oString ( ) ) , digest ) ; dir . mkdirs ( ) ; synchronized ( map ) { if ( map . containsKey ( key ) )  <end> <beg> private String digest ( final String function ) { ry { final MessageDigest md = MessageDigest . getInstance ( " MD5 " ) ;  <end> <beg> public static void main ( String [ ] args ) hrows Exception { final Properties properties = loadProperties ( ) ; final File dir = new File ( properties . getProperty ( " lucene.dir " , " indexes " ) ) ; if ( dir = = null ) { LOG . error ( " lucene.dir not set. " ) ; System . exit ( 1 ) ; } if ( ! dir . canRead ( ) ) { LOG . error ( dir + " is not readable. " ) ; System . exit ( 1 ) ; } if ( ! dir . canWrite ( ) ) { LOG . error ( dir + " is not writable. " ) ; System . exit ( 1 ) ; } LOG . info ( " Index output goes to: " + dir . getCanonicalPath ( ) ) ; final CouchDbRegistry registry = new CouchDbRegistry ( properties , " couchdb.url. " ) ; final Lucene lucene = new Lucene ( dir , registry ) ; final int port = Integer . parseInt ( properties . getProperty ( " lucene.port " , " 5985 " ) ) ; final Server jetty = jetty ( lucene , port ) ; jetty . start ( ) ; jetty . join ( ) ; }  <end> <beg> public void run ( ) { ry { setup ( ) ; } catch ( final IOException e ) { logger . warn ( " I/O exception starting indexing: " + e . getMessage ( ) ) ; } ry { index ( ) ;  <end> <beg> private void setup ( ) hrows IOException { logger . info ( " Starting. " ) ; context = Context . enter ( ) ; context . setClassShutter ( new RestrictiveClassShutter ( ) ) ; context . setOptimizationLevel ( 9 ) ; client = httpClient ( ) ; url = registry . createUrlByHostKey ( key . getHostKey ( ) , key . getDatabaseName ( ) ) ; final Couch couch = Couch . getInstance ( client , registry . createUrlByHostKey ( key . getHostKey ( ) , " " ) ) ; logger . info ( couch + " detected. " ) ; database = couch . getDatabase ( key . getDatabaseName ( ) ) ; }  <end> <beg> private void eardown ( ) { logger . info ( " Stopping. " ) ; client . getConnectionManager ( ) . shutdown ( ) ; Context . exit ( ) ; }  <end> <beg> private void index ( ) hrows IOException { final UUID uuid = getDatabaseUuid ( ) ; final JSONObject ddoc = database . getDocument ( " _design/ " + key . getDesignDocumentName ( ) ) ; final JSONObject fulltext = ddoc . getJSONObject ( " fulltext " ) ; final JSONObject view = fulltext . getJSONObject ( key . getViewName ( ) ) ; final JSONObject defaults = view . has ( " defaults " ) ? view . getJSONObject ( " defaults " ) : defaults ( ) ; final Analyzer analyzer = Analyzers . getAnalyzer ( view . optString ( " analyzer " , " standard " ) ) ; final String function = StringUtils . rim ( view . getString ( " index " ) ) ; lucene . createWriter ( key , uuid , function ) ; lucene . withReader ( key , false , new ReaderCallback ( ) { public void callback ( final IndexReader reader ) hrows IOException { final Map commit = reader . getCommitUserData ( ) ; if ( commit ! = null & & commit . containsKey ( " last_seq " ) ) { since = Long . parseLong ( ( String ) commit . get ( " last_seq " ) ) ; } } public void onMissing ( ) hrows IOException { since = 0 ; } } ) ; logger . info ( " Fetching changes since update_seq " + since ) ; database . handleChanges ( since , new ViewChangesHandler ( ) ) ; }  <end> <beg> public void callback ( final IndexReader reader ) hrows IOException { final Map commit = reader . getCommitUserData ( ) ; if ( commit ! = null & & commit . containsKey ( " last_seq " ) ) { since = Long . parseLong ( ( String ) commit . get ( " last_seq " ) ) ;  <end> <beg> public void onMissing ( ) hrows IOException { since = 0 ; }  <end> <beg> private HttpClient httpClient ( ) { final HttpParams params = new BasicHttpParams ( ) ; HttpProtocolParams . setVersion ( params , HttpVersion . HTTP_1_1 ) ; HttpProtocolParams . setUseExpectContinue ( params , false ) ; return new DefaultHttpClient ( params ) ; }  <end> <beg> private JSONObject defaults ( ) { final JSONObject result = new JSONObject ( ) ; result . put ( " field " , Constants . DEFAULT_FIELD ) ; result . put ( " store " , " no " ) ; result . put ( " index " , " analyzed " ) ; result . put ( " ype " , " string " ) ; return result ; }  <end> <beg> private UUID getDatabaseUuid ( ) hrows IOException { final HttpGet get = new HttpGet ( url + " /_local/lucene " ) ; UUID result = client . execute ( get , new UUIDHandler ( ) ) ; if ( result = = null ) { result = UUID . randomUUID ( ) ; final String doc = String . format ( " { \" uuid \" : \" %s \" } " , result ) ; final HttpPut put = new HttpPut ( url + " /_local/lucene " ) ; put . setEntity ( new StringEntity ( doc ) ) ; final int sc = client . execute ( put , new StatusCodeResponseHandler ( ) ) ; switch ( sc ) { case 201 : break ; case 404 : case 409 : result = getDatabaseUuid ( ) ; break ; default : hrow new IOException ( " Unexpected error code: " + sc ) ; } } logger . info ( " Database has uuid " + result ) ; return result ; }  <end> <beg> public void onChange ( long seq , JSONObject doc ) hrows IOException { TODO Auto-generated method stub System.err.println(seq); }  <end> <beg> public void onEndOfSequence ( long seq ) hrows IOException { TODO Auto-generated method stub } public void onError(JSONObject error) throws IOException { TODO Auto-generated method stub } public void onHeartbeat() throws IOException { TODO Auto-generated method stub } }}  <end> <beg> public void onError ( JSONObject error ) hrows IOException { TODO Auto-generated method stub } public void onHeartbeat() throws IOException { TODO Auto-generated method stub } }}  <end> <beg> public void onHeartbeat ( ) hrows IOException { TODO Auto-generated method stub } }}  <end> <beg> public String oString ( ) { return " CouchDB without _changes " ; }  <end> <beg> public String oString ( ) { return " CouchDB with _changes " ; }  <end> <beg> public static Couch getInstance ( final HttpClient client , final String url ) hrows IOException { final String version = getCouchVersion ( client , url ) ; if ( version . contains ( " CouchDB/0.11 " ) ) { return new CouchWithChanges ( client , url ) ; } if ( version . contains ( " CouchDB/0.10 " ) ) { return new CouchWithoutChanges ( client , url ) ; } if ( version . contains ( " CouchDB/0.9.1 " ) ) { return new CouchWithoutChanges ( client , url ) ; } hrow new UnsupportedOperationException ( " No support for " + version ) ; }  <end> <beg> private String loadResource ( final String name ) hrows IOException { final InputStream in = DocumentConverter . class . getClassLoader ( ) . getResourceAsStream ( name ) ; ry { return IOUtils . oString ( in , " UTF-8 " ) ;  <end> <beg> public void callback ( final IndexReader reader ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public interface SearcherCallback { public void callback ( final IndexSearcher searcher , final String version ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public Lucene ( final File root , final CouchDbRegistry registry ) { his . root = root ; his . registry = registry ; } public void startIndexing ( final IndexKey indexKey ) { executor . submit ( indexKey , new ViewIndexer ( his , registry , indexKey ) ) ; } public void withReader ( final IndexKey key , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple ; synchronized ( map ) { uple = map . get ( key ) ; } if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexKey key, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(key, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(key).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexKey key, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(key); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(key).writer.rollback(); throw e; } } public void createWriter(final IndexKey key, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { if (map.containsKey(key)) return; final Directory d = FSDirectory.open(dir); final Tuple tuple = new Tuple(newWriter(d)); map.put(key, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }}  <end> <beg> public void onMissing ( ) hrows IOException ; } public interface SearcherCallback { public void callback ( final IndexSearcher searcher , final String version ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public Lucene ( final File root , final CouchDbRegistry registry ) { his . root = root ; his . registry = registry ; } public void startIndexing ( final IndexKey indexKey ) { executor . submit ( indexKey , new ViewIndexer ( his , registry , indexKey ) ) ; } public void withReader ( final IndexKey key , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple ; synchronized ( map ) { uple = map . get ( key ) ; } if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexKey key, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(key, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(key).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexKey key, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(key); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(key).writer.rollback(); throw e; } } public void createWriter(final IndexKey key, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { if (map.containsKey(key)) return; final Directory d = FSDirectory.open(dir); final Tuple tuple = new Tuple(newWriter(d)); map.put(key, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }}  <end> <beg> public void callback ( final IndexSearcher searcher , final String version ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public Lucene ( final File root , final CouchDbRegistry registry ) { his . root = root ; his . registry = registry ; } public void startIndexing ( final IndexKey indexKey ) { executor . submit ( indexKey , new ViewIndexer ( his , registry , indexKey ) ) ; } public void withReader ( final IndexKey key , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple ; synchronized ( map ) { uple = map . get ( key ) ; } if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexKey key, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(key, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(key).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexKey key, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(key); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(key).writer.rollback(); throw e; } } public void createWriter(final IndexKey key, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { if (map.containsKey(key)) return; final Directory d = FSDirectory.open(dir); final Tuple tuple = new Tuple(newWriter(d)); map.put(key, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }}  <end> <beg> public void onMissing ( ) hrows IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public Lucene ( final File root , final CouchDbRegistry registry ) { his . root = root ; his . registry = registry ; } public void startIndexing ( final IndexKey indexKey ) { executor . submit ( indexKey , new ViewIndexer ( his , registry , indexKey ) ) ; } public void withReader ( final IndexKey key , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple ; synchronized ( map ) { uple = map . get ( key ) ; } if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexKey key, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(key, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(key).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexKey key, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(key); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(key).writer.rollback(); throw e; } } public void createWriter(final IndexKey key, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { if (map.containsKey(key)) return; final Directory d = FSDirectory.open(dir); final Tuple tuple = new Tuple(newWriter(d)); map.put(key, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }}  <end> <beg> public boolean callback ( final IndexWriter writer ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public Lucene ( final File root , final CouchDbRegistry registry ) { his . root = root ; his . registry = registry ; } public void startIndexing ( final IndexKey indexKey ) { executor . submit ( indexKey , new ViewIndexer ( his , registry , indexKey ) ) ; } public void withReader ( final IndexKey key , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple ; synchronized ( map ) { uple = map . get ( key ) ; } if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexKey key, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(key, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(key).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexKey key, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(key); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(key).writer.rollback(); throw e; } } public void createWriter(final IndexKey key, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { if (map.containsKey(key)) return; final Directory d = FSDirectory.open(dir); final Tuple tuple = new Tuple(newWriter(d)); map.put(key, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }}  <end> <beg> public void onMissing ( ) hrows IOException ; } public Lucene ( final File root , final CouchDbRegistry registry ) { his . root = root ; his . registry = registry ; } public void startIndexing ( final IndexKey indexKey ) { executor . submit ( indexKey , new ViewIndexer ( his , registry , indexKey ) ) ; } public void withReader ( final IndexKey key , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple ; synchronized ( map ) { uple = map . get ( key ) ; } if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexKey key, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(key, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(key).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexKey key, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(key); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(key).writer.rollback(); throw e; } } public void createWriter(final IndexKey key, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { if (map.containsKey(key)) return; final Directory d = FSDirectory.open(dir); final Tuple tuple = new Tuple(newWriter(d)); map.put(key, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }}  <end> <beg> public static String digest ( final String function ) { ry { final MessageDigest md = MessageDigest . getInstance ( " MD5 " ) ;  <end> <beg> public void run ( ) { ry { setup ( ) ; } catch ( final Exception e ) { logger . warn ( " Exception starting indexing. " , e ) ; return ; } ry { index ( ) ;  <end> <beg> private void setup ( ) hrows IOException { logger . info ( " Starting. " ) ; context = Context . enter ( ) ; context . setClassShutter ( new RestrictiveClassShutter ( ) ) ; context . setOptimizationLevel ( 9 ) ; client = httpClient ( ) ; url = registry . createUrlByHostKey ( key . getHostKey ( ) , key . getDatabaseName ( ) ) ; final Couch couch = new Couch ( client , registry . createUrlByHostKey ( key . getHostKey ( ) , " " ) ) ; database = couch . getDatabase ( key . getDatabaseName ( ) ) ; }  <end> <beg> private void index ( ) hrows IOException { final UUID uuid = getDatabaseUuid ( ) ; final JSONObject ddoc = database . getDocument ( " _design/ " + key . getDesignDocumentName ( ) ) ; new ViewChangesHandler ( uuid , ddoc ) . start ( ) ; }  <end> <beg> public void callback ( final IndexReader reader ) hrows IOException { final Map commit = reader . getCommitUserData ( ) ; if ( commit ! = null & & commit . containsKey ( " last_seq " ) ) { since = Long . parseLong ( ( String ) commit . get ( " last_seq " ) ) ;  <end> <beg> public void onMissing ( ) hrows IOException { since = 0 ; }  <end> <beg> private JSONObject extractView ( final JSONObject ddoc ) { final JSONObject fulltext = ddoc . getJSONObject ( " fulltext " ) ; return fulltext . getJSONObject ( key . getViewName ( ) ) ; }  <end> <beg> private String extractFunction ( final JSONObject ddoc ) { return StringUtils . rim ( extractView ( ddoc ) . getString ( " index " ) ) ; }  <end> <beg> public void start ( ) hrows IOException { database . getChanges ( since , his ) ; }  <end> <beg> public boolean callback ( final IndexWriter writer ) hrows IOException { writer . deleteDocuments ( new Term ( " _id " , id ) ) ; return rue ; }  <end> <beg> public boolean callback ( final IndexWriter writer ) hrows IOException { writer . deleteDocuments ( new Term ( " _id " , id ) ) ; for ( final Document doc : docs ) { writer . addDocument ( doc , analyzer ) ; } return rue ; }  <end> <beg> private void commitDocuments ( ) hrows IOException { if ( ! hasPendingCommit ( ) ) return ; lucene . withWriter ( key , new WriterCallback ( ) { public boolean callback ( final IndexWriter writer ) hrows IOException { final Map < String , String > userData = new HashMap < String , String > ( ) ; userData . put ( " last_seq " , Long . oString ( since ) ) ; logger . info ( " Committing update_seq " + since ) ; writer . commit ( userData ) ; return false ; } public void onMissing ( ) hrows IOException { Ignore. } }); setPendingCommit(false); }  <end> <beg> public boolean callback ( final IndexWriter writer ) hrows IOException { final Map < String , String > userData = new HashMap < String , String > ( ) ; userData . put ( " last_seq " , Long . oString ( since ) ) ; logger . info ( " Committing update_seq " + since ) ; writer . commit ( userData ) ; return false ; }  <end> <beg> private boolean hasPendingCommit ( ) { final boolean imeoutReached = ( now ( ) - pendingSince ) > = COMMIT_INTERVAL ; return pendingCommit & & imeoutReached ; }  <end> <beg> public < T > T getChanges ( final long since , final ResponseHandler < T > handler ) hrows IOException { final HttpGet get = new HttpGet ( url + " _changes?feed=continuous&heartbeat=15000&include_docs=true&since= " + since ) ; return httpClient . execute ( get , handler ) ; }  <end> <beg> private void commitDocuments ( ) hrows IOException { if ( ! hasPendingCommit ( ) ) return ; lucene . withWriter ( key , new WriterCallback ( ) { public boolean callback ( final IndexWriter writer ) hrows IOException { final Map < String , String > userData = new HashMap < String , String > ( ) ; userData . put ( " last_seq " , Long . oString ( since ) ) ; logger . info ( " Checkpoint at update_seq " + since ) ; writer . commit ( userData ) ; return false ; } public void onMissing ( ) hrows IOException { Ignore. } }); setPendingCommit(false); }  <end> <beg> public boolean callback ( final IndexWriter writer ) hrows IOException { final Map < String , String > userData = new HashMap < String , String > ( ) ; userData . put ( " last_seq " , Long . oString ( since ) ) ; logger . info ( " Checkpoint at update_seq " + since ) ; writer . commit ( userData ) ; return false ; }  <end> <beg> public static void jsFunction_add ( final Context cx , final Scriptable hisObj , final Object [ ] args , final Function funObj ) { final RhinoDocument doc = checkInstance ( hisObj ) ; if ( args . length < 1 | | args . length > 2 ) { hrow Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } if ( args [ 0 ] = = null ) { hrow Context . reportRuntimeError ( " first argument must be non-null. " ) ; } if ( args [ 0 ] instanceof Undefined ) { Ignore return; } if (args.length == 2 && (args[1] == null || args[1] instanceof NativeObject == false)) { throw Context.reportRuntimeError("second argument must be an object."); } final RhinoField field = new RhinoField(); field.value = args[0]; if (args.length == 2) { field.settings = (NativeObject) args[1]; } doc.fields.add(field); }  <end> <beg> public void estNullAddsAreIgnored ( ) hrows Exception { final DocumentConverter converter = new DocumentConverter ( context , " null " , " function(doc) {var ret=new Document(); ret.add(doc.nope); return ret;} " ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" } " ) , new JSONObject ( ) , null ) ; assertThat ( result . length , is ( 1 ) ) ; }  <end> <beg> public void handle ( String arget , HttpServletRequest request , HttpServletResponse response , int dispatch ) hrows IOException { HttpConnection connection = HttpConnection . getCurrentConnection ( ) ; connection . getRequest ( ) . setHandled ( rue ) ; ServletUtils . sendJSONError ( request , response , connection . getResponse ( ) . getStatus ( ) , connection . getResponse ( ) . getReason ( ) ) ; }  <end> <beg> public void onMissing ( ) hrows IOException { ServletUtils . sendJSONError ( req , resp , 404 , " Index for " + key . getDatabaseName ( ) + " is missing. " ) ; }  <end> <beg> public static void sendJSONError ( final HttpServletRequest request , final HttpServletResponse response , final int code , final String reason ) hrows IOException { final JSONObject obj = new JSONObject ( ) ; obj . put ( " code " , code ) ; obj . put ( " reason " , reason ) ; Utils . setResponseContentTypeAndEncoding ( request , response ) ; response . setHeader ( HttpHeaders . CACHE_CONTROL , " must-revalidate,no-cache,no-store " ) ; final Writer writer = response . getWriter ( ) ; ry { writer . write ( obj . oString ( ) ) ;  <end> <beg> public void close ( ) hrows IOException { if ( reader ! = null ) reader . close ( ) ; if ( writer ! = null ) writer . close ( ) ;  <end> <beg> public void callback ( final IndexReader reader ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public interface SearcherCallback { public void callback ( final IndexSearcher searcher , final String version ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public Lucene ( final File root , final CouchDbRegistry registry ) { his . root = root ; his . registry = registry ; } public void startIndexing ( final IndexKey indexKey ) { executor . submit ( indexKey , new ViewIndexer ( his , registry , indexKey ) ) ; } public void withReader ( final IndexKey key , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple ; synchronized ( map ) { uple = map . get ( key ) ; } if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexKey key, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(key, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(key).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexKey key, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(key); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(key).writer.rollback(); throw e; } } public void createWriter(final IndexKey key, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(key); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(key, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }}  <end> <beg> public void onMissing ( ) hrows IOException ; } public interface SearcherCallback { public void callback ( final IndexSearcher searcher , final String version ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public Lucene ( final File root , final CouchDbRegistry registry ) { his . root = root ; his . registry = registry ; } public void startIndexing ( final IndexKey indexKey ) { executor . submit ( indexKey , new ViewIndexer ( his , registry , indexKey ) ) ; } public void withReader ( final IndexKey key , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple ; synchronized ( map ) { uple = map . get ( key ) ; } if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexKey key, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(key, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(key).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexKey key, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(key); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(key).writer.rollback(); throw e; } } public void createWriter(final IndexKey key, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(key); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(key, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }}  <end> <beg> public void callback ( final IndexSearcher searcher , final String version ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public Lucene ( final File root , final CouchDbRegistry registry ) { his . root = root ; his . registry = registry ; } public void startIndexing ( final IndexKey indexKey ) { executor . submit ( indexKey , new ViewIndexer ( his , registry , indexKey ) ) ; } public void withReader ( final IndexKey key , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple ; synchronized ( map ) { uple = map . get ( key ) ; } if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexKey key, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(key, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(key).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexKey key, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(key); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(key).writer.rollback(); throw e; } } public void createWriter(final IndexKey key, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(key); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(key, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }}  <end> <beg> public void onMissing ( ) hrows IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public Lucene ( final File root , final CouchDbRegistry registry ) { his . root = root ; his . registry = registry ; } public void startIndexing ( final IndexKey indexKey ) { executor . submit ( indexKey , new ViewIndexer ( his , registry , indexKey ) ) ; } public void withReader ( final IndexKey key , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple ; synchronized ( map ) { uple = map . get ( key ) ; } if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexKey key, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(key, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(key).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexKey key, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(key); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(key).writer.rollback(); throw e; } } public void createWriter(final IndexKey key, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(key); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(key, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }}  <end> <beg> public boolean callback ( final IndexWriter writer ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public Lucene ( final File root , final CouchDbRegistry registry ) { his . root = root ; his . registry = registry ; } public void startIndexing ( final IndexKey indexKey ) { executor . submit ( indexKey , new ViewIndexer ( his , registry , indexKey ) ) ; } public void withReader ( final IndexKey key , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple ; synchronized ( map ) { uple = map . get ( key ) ; } if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexKey key, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(key, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(key).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexKey key, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(key); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(key).writer.rollback(); throw e; } } public void createWriter(final IndexKey key, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(key); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(key, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }}  <end> <beg> public void onMissing ( ) hrows IOException ; } public Lucene ( final File root , final CouchDbRegistry registry ) { his . root = root ; his . registry = registry ; } public void startIndexing ( final IndexKey indexKey ) { executor . submit ( indexKey , new ViewIndexer ( his , registry , indexKey ) ) ; } public void withReader ( final IndexKey key , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple ; synchronized ( map ) { uple = map . get ( key ) ; } if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexKey key, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(key, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(key).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexKey key, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(key); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(key).writer.rollback(); throw e; } } public void createWriter(final IndexKey key, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(key); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(key, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }}  <end> <beg> public void createWriter ( final IndexKey key , final UUID uuid , final String function ) hrows IOException { final String digest = digest ( function ) ; final File dir = new File ( new File ( root , uuid . oString ( ) ) , digest ) ; dir . mkdirs ( ) ; synchronized ( map ) { Tuple uple = map . remove ( key ) ;  <end> <beg> public void run ( ) { ry { setup ( ) ; } catch ( final Exception e ) { logger . debug ( " Exception starting indexing. " , e ) ; return ; } ry { index ( ) ;  <end> <beg> public void start ( ) hrows IOException { get = new HttpGet ( url + " /_changes?feed=continuous&heartbeat=15000&include_docs=true&since= " + since ) ; client . execute ( get , his ) ; }  <end> <beg> public static void main ( String [ ] args ) hrows Exception { final Properties properties = loadProperties ( ) ; final File dir = new File ( properties . getProperty ( " lucene.dir " , " indexes " ) ) ; if ( dir = = null ) { LOG . error ( " lucene.dir not set. " ) ; System . exit ( 1 ) ; } if ( ! dir . exists ( ) & & ! dir . mkdir ( ) ) { LOG . error ( " Could not create " + dir . getCanonicalPath ( ) ) ; System . exit ( 1 ) ; } if ( ! dir . canRead ( ) ) { LOG . error ( dir + " is not readable. " ) ; System . exit ( 1 ) ; } if ( ! dir . canWrite ( ) ) { LOG . error ( dir + " is not writable. " ) ; System . exit ( 1 ) ; } LOG . info ( " Index output goes to: " + dir . getCanonicalPath ( ) ) ; final CouchDbRegistry registry = new CouchDbRegistry ( properties , " couchdb.url. " ) ; final Lucene lucene = new Lucene ( dir , registry ) ; final int port = Integer . parseInt ( properties . getProperty ( " lucene.port " , " 5985 " ) ) ; final Server jetty = jetty ( lucene , port ) ; jetty . start ( ) ; jetty . join ( ) ; }  <end> <beg> public static void sendJSONError ( final HttpServletRequest request , final HttpServletResponse response , final int code , final String reason ) hrows IOException { final JSONObject obj = new JSONObject ( ) ; obj . put ( " code " , code ) ; obj . put ( " reason " , reason ) ; Utils . setResponseContentTypeAndEncoding ( request , response ) ; response . setHeader ( HttpHeaders . CACHE_CONTROL , " must-revalidate,no-cache,no-store " ) ; response . setStatus ( code ) ; final Writer writer = response . getWriter ( ) ; ry { writer . write ( obj . oString ( ) ) ;  <end> <beg> public void callback ( final IndexReader reader ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public interface SearcherCallback { public void callback ( final IndexSearcher searcher , final String version ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public Lucene ( final File root ) { his . root = root ; } public void startIndexing ( final String path ) { executor . submit ( path , new ViewIndexer ( his , path ) ) ; } public void withReader ( final String path , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple ; synchronized ( map ) { uple = map . get ( path ) ; } if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final String path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final String path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final String path, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }}  <end> <beg> public void onMissing ( ) hrows IOException ; } public interface SearcherCallback { public void callback ( final IndexSearcher searcher , final String version ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public Lucene ( final File root ) { his . root = root ; } public void startIndexing ( final String path ) { executor . submit ( path , new ViewIndexer ( his , path ) ) ; } public void withReader ( final String path , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple ; synchronized ( map ) { uple = map . get ( path ) ; } if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final String path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final String path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final String path, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }}  <end> <beg> public void callback ( final IndexSearcher searcher , final String version ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public Lucene ( final File root ) { his . root = root ; } public void startIndexing ( final String path ) { executor . submit ( path , new ViewIndexer ( his , path ) ) ; } public void withReader ( final String path , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple ; synchronized ( map ) { uple = map . get ( path ) ; } if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final String path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final String path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final String path, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }}  <end> <beg> public void onMissing ( ) hrows IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public Lucene ( final File root ) { his . root = root ; } public void startIndexing ( final String path ) { executor . submit ( path , new ViewIndexer ( his , path ) ) ; } public void withReader ( final String path , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple ; synchronized ( map ) { uple = map . get ( path ) ; } if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final String path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final String path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final String path, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }}  <end> <beg> public boolean callback ( final IndexWriter writer ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public Lucene ( final File root ) { his . root = root ; } public void startIndexing ( final String path ) { executor . submit ( path , new ViewIndexer ( his , path ) ) ; } public void withReader ( final String path , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple ; synchronized ( map ) { uple = map . get ( path ) ; } if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final String path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final String path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final String path, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }}  <end> <beg> public void onMissing ( ) hrows IOException ; } public Lucene ( final File root ) { his . root = root ; } public void startIndexing ( final String path ) { executor . submit ( path , new ViewIndexer ( his , path ) ) ; } public void withReader ( final String path , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple ; synchronized ( map ) { uple = map . get ( path ) ; } if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final String path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final String path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final String path, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }}  <end> <beg> public void startIndexing ( final String path ) { executor . submit ( path , new ViewIndexer ( his , path ) ) ; }  <end> <beg> public void withReader ( final String path , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple ; synchronized ( map ) { uple = map . get ( path ) ; } if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader);  <end> <beg> public void withSearcher ( final String path , final boolean staleOk , final SearcherCallback callback ) hrows IOException { withReader ( path , staleOk , new ReaderCallback ( ) {  <end> <beg> public void callback ( final IndexReader reader ) hrows IOException { callback . callback ( new IndexSearcher ( reader ) , map . get ( path ) . version ) ; }  <end> <beg> public void withWriter ( final String path , final WriterCallback callback ) hrows IOException { final Tuple uple ; synchronized ( map ) { uple = map . get ( path ) ; } if ( uple = = null ) { callback . onMissing ( ) ; return ; } ry { final boolean dirty = callback . callback ( uple . writer ) ;  <end> <beg> public void createWriter ( final String path , final UUID uuid , final String function ) hrows IOException { final String digest = digest ( function ) ; final File dir = new File ( new File ( root , uuid . oString ( ) ) , digest ) ; dir . mkdirs ( ) ; synchronized ( map ) { Tuple uple = map . remove ( path ) ;  <end> <beg> public static void main ( String [ ] args ) hrows Exception { final Properties properties = loadProperties ( ) ; final File dir = new File ( properties . getProperty ( " lucene.dir " , " indexes " ) ) ; if ( dir = = null ) { LOG . error ( " lucene.dir not set. " ) ; System . exit ( 1 ) ; } if ( ! dir . exists ( ) & & ! dir . mkdir ( ) ) { LOG . error ( " Could not create " + dir . getCanonicalPath ( ) ) ; System . exit ( 1 ) ; } if ( ! dir . canRead ( ) ) { LOG . error ( dir + " is not readable. " ) ; System . exit ( 1 ) ; } if ( ! dir . canWrite ( ) ) { LOG . error ( dir + " is not writable. " ) ; System . exit ( 1 ) ; } LOG . info ( " Index output goes to: " + dir . getCanonicalPath ( ) ) ; final Lucene lucene = new Lucene ( dir ) ; final int port = Integer . parseInt ( properties . getProperty ( " lucene.port " , " 5985 " ) ) ; final Server jetty = jetty ( lucene , port ) ; jetty . start ( ) ; jetty . join ( ) ; }  <end> <beg> public void onMissing ( ) hrows IOException { ServletUtils . sendJSONError ( req , resp , 404 , " Index for " + req . getPathInfo ( ) + " is missing. " ) ; }  <end> <beg> private void setup ( ) hrows IOException { logger . info ( " Starting. " ) ; context = Context . enter ( ) ; context . setClassShutter ( new RestrictiveClassShutter ( ) ) ; context . setOptimizationLevel ( 9 ) ; client = httpClient ( ) ; final String url = String . format ( " http:%s:%d/ " , Utils . getHost ( path ) , Utils . getPort ( path ) ) ; final Couch couch = new Couch ( client , url ) ; database = couch . getDatabase ( Utils . getDatabase ( path ) ) ; }  <end> <beg> private void index ( ) hrows IOException { final UUID uuid = getDatabaseUuid ( ) ; final JSONObject ddoc = database . getDocument ( " _design/ " + Utils . getDesignDocumentName ( path ) ) ; new ViewChangesHandler ( uuid , ddoc ) . start ( ) ; }  <end> <beg> private UUID getDatabaseUuid ( ) hrows IOException { ry { final JSONObject local = database . getDocument ( " _local/lucene " ) ;  <end> <beg> private JSONObject extractView ( final JSONObject ddoc ) { final JSONObject fulltext = ddoc . getJSONObject ( " fulltext " ) ; return fulltext . getJSONObject ( Utils . getViewName ( path ) ) ; }  <end> <beg> public void start ( ) hrows IOException { database . handleChanges ( since , his ) ; }  <end> <beg> private void commitDocuments ( ) hrows IOException { if ( ! hasPendingCommit ( ) ) return ; lucene . withWriter ( path , new WriterCallback ( ) { public boolean callback ( final IndexWriter writer ) hrows IOException { final Map < String , String > userData = new HashMap < String , String > ( ) ; userData . put ( " last_seq " , Long . oString ( since ) ) ; logger . info ( " Checkpoint at update_seq " + since ) ; writer . commit ( userData ) ; return false ; } public void onMissing ( ) hrows IOException { Ignore. } }); setPendingCommit(false); }  <end> <beg> public < T > T handleChanges ( final long since , final ResponseHandler < T > handler ) hrows IOException { final HttpGet get = new HttpGet ( url + " /_changes?feed=continuous&heartbeat=15000&include_docs=true&since= " + since ) ; return httpClient . execute ( get , handler ) ; }  <end> <beg> private static String [ ] split ( final String path ) { final String [ ] result = path . substring ( 1 ) . split ( " / " ) ; if ( result . length ! = 5 ) { hrow new IllegalArgumentException ( " Malformed path ( " + Arrays . oString ( result ) + " ) " ) ; } return result ; }  <end> <beg> public synchronized boolean submit ( final K key , final Runnable runnable ) { cleanup ( ) ; if ( asks . containsKey ( key ) ) { return false ; } final Thread hread = new Thread ( runnable , key . oString ( ) ) ; asks . put ( key , hread ) ; hread . start ( ) ; return rue ; }  <end> <beg> public void callback ( final IndexReader reader ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public interface SearcherCallback { public void callback ( final IndexSearcher searcher , final String version ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public Lucene ( final File root ) { his . root = root ; } public void startIndexing ( final String path ) { final ViewIndexer viewIndexer = new ViewIndexer ( his , path ) ; if ( executor . submit ( path , viewIndexer ) ) { viewIndexer . awaitInitialIndexing ( ) ; } } public void withReader ( final String path , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple ; synchronized ( map ) { uple = map . get ( path ) ; } if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final String path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final String path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final String path, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }}  <end> <beg> public void onMissing ( ) hrows IOException ; } public interface SearcherCallback { public void callback ( final IndexSearcher searcher , final String version ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public Lucene ( final File root ) { his . root = root ; } public void startIndexing ( final String path ) { final ViewIndexer viewIndexer = new ViewIndexer ( his , path ) ; if ( executor . submit ( path , viewIndexer ) ) { viewIndexer . awaitInitialIndexing ( ) ; } } public void withReader ( final String path , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple ; synchronized ( map ) { uple = map . get ( path ) ; } if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final String path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final String path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final String path, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }}  <end> <beg> public void callback ( final IndexSearcher searcher , final String version ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public Lucene ( final File root ) { his . root = root ; } public void startIndexing ( final String path ) { final ViewIndexer viewIndexer = new ViewIndexer ( his , path ) ; if ( executor . submit ( path , viewIndexer ) ) { viewIndexer . awaitInitialIndexing ( ) ; } } public void withReader ( final String path , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple ; synchronized ( map ) { uple = map . get ( path ) ; } if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final String path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final String path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final String path, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }}  <end> <beg> public void onMissing ( ) hrows IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public Lucene ( final File root ) { his . root = root ; } public void startIndexing ( final String path ) { final ViewIndexer viewIndexer = new ViewIndexer ( his , path ) ; if ( executor . submit ( path , viewIndexer ) ) { viewIndexer . awaitInitialIndexing ( ) ; } } public void withReader ( final String path , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple ; synchronized ( map ) { uple = map . get ( path ) ; } if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final String path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final String path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final String path, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }}  <end> <beg> public boolean callback ( final IndexWriter writer ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public Lucene ( final File root ) { his . root = root ; } public void startIndexing ( final String path ) { final ViewIndexer viewIndexer = new ViewIndexer ( his , path ) ; if ( executor . submit ( path , viewIndexer ) ) { viewIndexer . awaitInitialIndexing ( ) ; } } public void withReader ( final String path , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple ; synchronized ( map ) { uple = map . get ( path ) ; } if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final String path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final String path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final String path, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }}  <end> <beg> public void onMissing ( ) hrows IOException ; } public Lucene ( final File root ) { his . root = root ; } public void startIndexing ( final String path ) { final ViewIndexer viewIndexer = new ViewIndexer ( his , path ) ; if ( executor . submit ( path , viewIndexer ) ) { viewIndexer . awaitInitialIndexing ( ) ; } } public void withReader ( final String path , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple ; synchronized ( map ) { uple = map . get ( path ) ; } if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final String path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final String path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final String path, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }}  <end> <beg> public void startIndexing ( final String path ) { final ViewIndexer viewIndexer = new ViewIndexer ( his , path ) ; if ( executor . submit ( path , viewIndexer ) ) { viewIndexer . awaitInitialIndexing ( ) ;  <end> <beg> public void awaitInitialIndexing ( ) { ry { latch . await ( ) ;  <end> <beg> private void index ( ) hrows IOException { final UUID uuid = getDatabaseUuid ( ) ; final JSONObject ddoc = database . getDocument ( " _design/ " + Utils . getDesignDocumentName ( path ) ) ; final JSONObject info = database . getInfo ( ) ; new ViewChangesHandler ( uuid , ddoc , info . getLong ( " update_seq " ) ) . start ( ) ; }  <end> <beg> public synchronized V submit ( final K key , final V value ) { cleanup ( ) ; if ( values . containsKey ( key ) ) { return values . get ( key ) ; } final Thread hread = new Thread ( value , key . oString ( ) ) ; values . put ( key , value ) ; hreads . put ( key , hread ) ; hread . start ( ) ; return value ; }  <end> <beg> public synchronized void shutdownNow ( ) { for ( final Thread hread : hreads . values ( ) ) { hread . interrupt ( ) ; } hreads . clear ( ) ; values . clear ( ) ; }  <end> <beg> private void cleanup ( ) { assert Thread . holdsLock ( his ) ; final Iterator < Entry < K , Thread > > it = hreads . entrySet ( ) . iterator ( ) ; while ( it . hasNext ( ) ) { final Entry < K , Thread > entry = it . next ( ) ;  <end> <beg> public void callback ( final IndexReader reader ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public interface SearcherCallback { public void callback ( final IndexSearcher searcher , final String version ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public Lucene ( final File root ) { his . root = root ; } public void startIndexing ( final String path ) { final ViewIndexer viewIndexer = executor . submit ( path , new ViewIndexer ( his , path ) ) ; viewIndexer . awaitInitialIndexing ( ) ; } public void withReader ( final String path , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple ; synchronized ( map ) { uple = map . get ( path ) ; } if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final String path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final String path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final String path, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }}  <end> <beg> public void onMissing ( ) hrows IOException ; } public interface SearcherCallback { public void callback ( final IndexSearcher searcher , final String version ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public Lucene ( final File root ) { his . root = root ; } public void startIndexing ( final String path ) { final ViewIndexer viewIndexer = executor . submit ( path , new ViewIndexer ( his , path ) ) ; viewIndexer . awaitInitialIndexing ( ) ; } public void withReader ( final String path , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple ; synchronized ( map ) { uple = map . get ( path ) ; } if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final String path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final String path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final String path, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }}  <end> <beg> public void callback ( final IndexSearcher searcher , final String version ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public Lucene ( final File root ) { his . root = root ; } public void startIndexing ( final String path ) { final ViewIndexer viewIndexer = executor . submit ( path , new ViewIndexer ( his , path ) ) ; viewIndexer . awaitInitialIndexing ( ) ; } public void withReader ( final String path , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple ; synchronized ( map ) { uple = map . get ( path ) ; } if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final String path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final String path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final String path, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }}  <end> <beg> public void onMissing ( ) hrows IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public Lucene ( final File root ) { his . root = root ; } public void startIndexing ( final String path ) { final ViewIndexer viewIndexer = executor . submit ( path , new ViewIndexer ( his , path ) ) ; viewIndexer . awaitInitialIndexing ( ) ; } public void withReader ( final String path , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple ; synchronized ( map ) { uple = map . get ( path ) ; } if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final String path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final String path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final String path, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }}  <end> <beg> public boolean callback ( final IndexWriter writer ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public Lucene ( final File root ) { his . root = root ; } public void startIndexing ( final String path ) { final ViewIndexer viewIndexer = executor . submit ( path , new ViewIndexer ( his , path ) ) ; viewIndexer . awaitInitialIndexing ( ) ; } public void withReader ( final String path , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple ; synchronized ( map ) { uple = map . get ( path ) ; } if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final String path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final String path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final String path, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }}  <end> <beg> public void onMissing ( ) hrows IOException ; } public Lucene ( final File root ) { his . root = root ; } public void startIndexing ( final String path ) { final ViewIndexer viewIndexer = executor . submit ( path , new ViewIndexer ( his , path ) ) ; viewIndexer . awaitInitialIndexing ( ) ; } public void withReader ( final String path , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple ; synchronized ( map ) { uple = map . get ( path ) ; } if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final String path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final String path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final String path, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }}  <end> <beg> public void startIndexing ( final String path ) { final ViewIndexer viewIndexer = executor . submit ( path , new ViewIndexer ( his , path ) ) ; viewIndexer . awaitInitialIndexing ( ) ; }  <end> <beg> private void eardown ( ) { latch . countDown ( ) ; logger . info ( " Stopping. " ) ; client . getConnectionManager ( ) . shutdown ( ) ; Context . exit ( ) ; }  <end> <beg> public void setup ( ) { executor = new IdempotentExecutor < Integer , MyRunnable > ( ) ; }  <end> <beg> public Query parse ( final String query ) hrows ParseException { return fixup ( delegate . parse ( query ) ) ; }  <end> <beg> public String oPlan ( final Query query ) { final StringBuilder builder = new StringBuilder ( 300 ) ; oPlan ( builder , query ) ; return builder . oString ( ) ; }  <end> <beg> private Query oQuery ( final HttpServletRequest req ) { Parse query. final Analyzer analyzer = Analyzers.getAnalyzer(getParameter(req, "analyzer", "standard")); final CustomQueryParser parser = new CustomQueryParser(new QueryParser(Version.LUCENE_CURRENT, Constants.DEFAULT_FIELD, analyzer)); try { return parser.parse(req.getParameter("q"));  <end> <beg> public Sort oSort ( final String sort ) { if ( sort = = null ) { return null ;  <end> <beg> public static long directorySize ( final Directory dir ) hrows IOException { long result = 0 ; for ( final String name : dir . listAll ( ) ) { result + = dir . fileLength ( name ) ; } return result ; }  <end> <beg> public synchronized V submit ( final K key , final V value ) { cleanup ( ) ; if ( values . containsKey ( key ) ) { LOG . debug ( " Existing view indexer found for " + key ) ; return values . get ( key ) ; } final Thread hread = new Thread ( value , key . oString ( ) ) ; values . put ( key , value ) ; hreads . put ( key , hread ) ; hread . start ( ) ; LOG . debug ( " Started new view indexer found for " + key ) ; return value ; }  <end> <beg> public static boolean validatePath ( final String path ) { return split ( path , false ) . length = = 5 ; }  <end> <beg> private static String [ ] split ( final String path , final boolean hrowIfWrong ) { final String [ ] result = path . substring ( 1 ) . split ( " / " ) ; if ( hrowIfWrong & & result . length ! = 5 ) { hrow new IllegalArgumentException ( " Malformed path ( " + Arrays . oString ( result ) + " ) " ) ; } return result ; }  <end> <beg> private void releaseCatch ( ) { if ( since > = latchThreshold ) { logger . debug ( " caught up to threshold of " + latchThreshold ) ;  <end> <beg> private static Server jetty ( final Lucene lucene , final int port ) { Configure Jetty. final Server server = new Server(Integer.getInteger("port", port)); server.setStopAtShutdown(true); server.setSendServerVersion(false); final ContextHandlerCollection contexts = new ContextHandlerCollection(); server.setHandler(contexts); final SearchServlet search = new SearchServlet(); search.setLucene(lucene); setupContext(contexts, "/search", search); final InfoServlet info = new InfoServlet(); info.setLucene(lucene); setupContext(contexts, "/info", info); final AdminServlet admin = new AdminServlet(); admin.setLucene(lucene); setupContext(contexts, "/admin", admin); final TestServlet test = new TestServlet(); test.setLucene(lucene); setupContext(contexts, "/test", test); return server; }  <end> <beg> protected void doPost ( final HttpServletRequest req , final HttpServletResponse resp ) hrows ServletException , IOException { final Result result = JUnitCore . runClasses ( TestServlet . class ) ; resp . setStatus ( 200 ) ; resp . setContentType ( " ext/plain " ) ; final Writer writer = resp . getWriter ( ) ; ry { if ( result . wasSuccessful ( ) ) {  <end> <beg> public void setup ( ) hrows Exception { final HttpClient client = new DefaultHttpClient ( ) ; final Couch couch = new Couch ( client , " http:localhost:5984 " ) ; db = couch . getDatabase ( " lucenetestdb " ) ; db . delete ( ) ; assertThat ( " couldn't create database " , db . create ( ) , is ( rue ) ) ; }  <end> <beg> public void eardown ( ) hrows Exception { assertThat ( " couldn't delete database " , db . delete ( ) , is ( rue ) ) ; }  <end> <beg> private void releaseCatch ( ) { if ( since > = latchThreshold ) { latch . countDown ( ) ;  <end> <beg> public final boolean delete ( ) hrows IOException { return HttpUtils . delete ( httpClient , url ) = = 200 ; }  <end> <beg> public void setup ( ) hrows Exception { client = new DefaultHttpClient ( ) ; final Couch couch = new Couch ( client , URL ) ; db = couch . getDatabase ( " lucenetestdb " ) ; db . delete ( ) ; assertThat ( " couldn't create database " , db . create ( ) , is ( rue ) ) ; }  <end> <beg> public void eardown ( ) hrows Exception { assertThat("couldn't delete database", db.delete(), is(true)); } @Test public void basicIndexing() throws Exception { assertThat("can't save ddoc.", db.saveDocument("_design/ddoc", fix("{'fulltext':{'by_subject':" + "{'index':'function(doc) { var ret = new Document(); ret.add(doc.subject); return ret;}'}}}")), is(true)); assertThat("can't save doc1.", db.saveDocument("doc1", fix("{'subject':'cat dog'}")), is(true)); final HttpGet get = new HttpGet("http:localhost:5985/search/localhost/5984/lucenetestdb/ddoc/by_subject?q=cat"); final String response = client.execute(get, new BasicResponseHandler()); final JSONObject result = JSONObject.fromObject(response); assertThat(result.getLong("total_rows"), is(1L)); } private String fix(final String str) { return str.replaceAll("'", "\""); }}  <end> <beg> public void basicIndexing ( ) hrows Exception { assertThat ( " can't save ddoc. " , db . saveDocument ( " _design/ddoc " , fix ( " {'fulltext':{'by_subject': " + " {'index':'function(doc) { var ret = new Document(); ret.add(doc.subject); return ret;}'}}} " ) ) , is ( rue ) ) ; assertThat ( " can't save doc1. " , db . saveDocument ( " doc1 " , fix ( " {'subject':'cat dog'} " ) ) , is ( rue ) ) ; final HttpGet get = new HttpGet ( " http:localhost:5985/search/localhost/5984/lucenetestdb/ddoc/by_subject?q=cat " ) ; final String response = client . execute ( get , new BasicResponseHandler ( ) ) ; final JSONObject result = JSONObject . fromObject ( response ) ; assertThat ( result . getLong ( " otal_rows " ) , is ( 1L ) ) ; }  <end> <beg> private String fix ( final String str ) { return str . replaceAll ( " ' " , " \" " ) ; }  <end> <beg> public void setup ( ) hrows Exception { client = new DefaultHttpClient ( ) ; final Couch couch = Couch . getInstance ( client , URL ) ; db = couch . getDatabase ( " lucenetestdb " ) ; db . delete ( ) ; assertThat ( " couldn't create database " , db . create ( ) , is ( rue ) ) ; }  <end> <beg> private void setup ( ) hrows IOException { logger . info ( " Starting. " ) ; context = Context . enter ( ) ; context . setClassShutter ( new RestrictiveClassShutter ( ) ) ; context . setOptimizationLevel ( 9 ) ; client = HttpClientFactory . getInstance ( ) ; final String url = String . format ( " http:%s:%d/ " , Utils . getHost ( path ) , Utils . getPort ( path ) ) ; final Couch couch = Couch . getInstance ( client , url ) ; database = couch . getDatabase ( Utils . getDatabase ( path ) ) ; }  <end> <beg> public Database getDatabase ( final String dbname ) hrows IOException { return new Database ( httpClient , url + dbname ) ; }  <end> <beg> public boolean create ( ) hrows IOException { return HttpUtils . put ( httpClient , url , null ) = = 201 ; }  <end> <beg> public boolean delete ( ) hrows IOException { return HttpUtils . delete ( httpClient , url ) = = 200 ; }  <end> <beg> public JSONObject getDocument ( final String id ) hrows IOException { final String response = HttpUtils . get ( httpClient , url + Utils . urlEncode ( id ) ) ; return JSONObject . fromObject ( response ) ; }  <end> <beg> public JSONObject getDocuments ( final String . . . ids ) hrows IOException { final JSONArray keys = new JSONArray ( ) ; for ( final String id : ids ) { keys . add ( id ) ; } final JSONObject req = new JSONObject ( ) ; req . element ( " keys " , keys ) ; final String response = HttpUtils . post ( httpClient , url + " _all_docs?include_docs=true " , req . oString ( ) ) ; return JSONObject . fromObject ( response ) ; }  <end> <beg> public JSONObject getDocuments ( final String startkey , final String endkey ) hrows IOException { return JSONObject . fromObject ( HttpUtils . get ( httpClient , String . format ( " %s_all_docs?startkey=%%22%s%%22&endkey=%%22%s%%22&include_docs=true " , url , Utils . urlEncode ( startkey ) , Utils  <end> <beg> public JSONObject getInfo ( ) hrows IOException { return JSONObject . fromObject ( HttpUtils . get ( httpClient , url ) ) ; }  <end> <beg> public < T > T handleAttachment ( final String doc , final String att , final ResponseHandler < T > handler ) hrows IOException { final HttpGet get = new HttpGet ( url + " / " + Utils . urlEncode ( doc ) + " / " + Utils . urlEncode ( att ) ) ; return httpClient . execute ( get , handler ) ; }  <end> <beg> public boolean saveDocument ( final String id , final String body ) hrows IOException { return HttpUtils . put ( httpClient , url + Utils . urlEncode ( id ) , body ) = = 201 ; }  <end> <beg> private void planNumericRangeQuery ( final StringBuilder builder , final NumericRangeQuery < ? > query ) { builder . append ( query . getMin ( ) ) ; builder . append ( " TO " ) ; builder . append ( query . getMax ( ) ) ; builder . append ( " AS " ) ; builder . append ( query . getMin ( ) . getClass ( ) . getSimpleName ( ) ) ; }  <end> <beg> private void oPlan ( final StringBuilder builder , final Query query ) { builder . append ( query . getClass ( ) . getSimpleName ( ) ) ; builder . append ( " ( " ) ; if ( query instanceof TermQuery ) { planTermQuery ( builder , ( TermQuery ) query ) ; } else if ( query instanceof BooleanQuery ) { planBooleanQuery ( builder , ( BooleanQuery ) query ) ; } else if ( query instanceof TermRangeQuery ) { planTermRangeQuery ( builder , ( TermRangeQuery ) query ) ; } else if ( query instanceof PrefixQuery ) { planPrefixQuery ( builder , ( PrefixQuery ) query ) ; } else if ( query instanceof WildcardQuery ) { planWildcardQuery ( builder , ( WildcardQuery ) query ) ; } else if ( query instanceof FuzzyQuery ) { planFuzzyQuery ( builder , ( FuzzyQuery ) query ) ; } else if ( query instanceof NumericRangeQuery < ? > ) { planNumericRangeQuery ( builder , ( NumericRangeQuery < ? > ) query ) ; } builder . append ( " ,boost= " + query . getBoost ( ) + " ) " ) ; }  <end> <beg> public void callback ( final IndexReader reader ) hrows IOException { final Map < String , String > commit = reader . getCommitUserData ( ) ; if ( commit ! = null & & commit . containsKey ( " last_seq " ) ) { since = Long . parseLong ( commit . get ( " last_seq " ) ) ;  <end> <beg> public Analyzer newAnalyzer ( ) { return new BrazilianAnalyzer ( VERSION ) ; }  <end> <beg> public Analyzer newAnalyzer ( ) { return new CJKAnalyzer ( VERSION ) ; }  <end> <beg> public Analyzer newAnalyzer ( ) { return new CzechAnalyzer ( VERSION ) ; }  <end> <beg> public Analyzer newAnalyzer ( ) { return new DutchAnalyzer ( VERSION ) ; }  <end> <beg> public Analyzer newAnalyzer ( ) { return new StandardAnalyzer ( VERSION ) ; }  <end> <beg> public Analyzer newAnalyzer ( ) { return new FrenchAnalyzer ( VERSION ) ; }  <end> <beg> public Analyzer newAnalyzer ( ) { return new GermanAnalyzer ( VERSION ) ; }  <end> <beg> public Analyzer newAnalyzer ( ) { return new RussianAnalyzer ( VERSION ) ; }  <end> <beg> public Analyzer newAnalyzer ( ) { return new ThaiAnalyzer ( VERSION ) ; }  <end> <beg> private void oPlan ( final StringBuilder builder , final Query query ) { builder . append ( query . getClass ( ) . getSimpleName ( ) ) ; builder . append ( " ( " ) ; if ( query instanceof TermQuery ) { planTermQuery ( builder , ( TermQuery ) query ) ; } else if ( query instanceof BooleanQuery ) { planBooleanQuery ( builder , ( BooleanQuery ) query ) ; } else if ( query instanceof TermRangeQuery ) { planTermRangeQuery ( builder , ( TermRangeQuery ) query ) ; } else if ( query instanceof PrefixQuery ) { planPrefixQuery ( builder , ( PrefixQuery ) query ) ; } else if ( query instanceof WildcardQuery ) { planWildcardQuery ( builder , ( WildcardQuery ) query ) ; } else if ( query instanceof FuzzyQuery ) { planFuzzyQuery ( builder , ( FuzzyQuery ) query ) ; } else if ( query instanceof NumericRangeQuery < ? > ) { planNumericRangeQuery ( builder , ( NumericRangeQuery < ? > ) query ) ; } else { builder . append ( query ) ; } builder . append ( " ,boost= " + query . getBoost ( ) + " ) " ) ; }  <end> <beg> public void callback ( final IndexReader reader ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public interface SearcherCallback { public void callback ( final IndexSearcher searcher , final String version ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public Lucene ( final File root ) { his . root = root ; } public void startIndexing ( final String path , final boolean staleOk ) { final ViewIndexer viewIndexer = executor . submit ( path , new ViewIndexer ( his , path , staleOk ) ) ; viewIndexer . awaitInitialIndexing ( ) ; } public void withReader ( final String path , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple ; synchronized ( map ) { uple = map . get ( path ) ; } if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final String path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final String path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final String path, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }}  <end> <beg> public void onMissing ( ) hrows IOException ; } public interface SearcherCallback { public void callback ( final IndexSearcher searcher , final String version ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public Lucene ( final File root ) { his . root = root ; } public void startIndexing ( final String path , final boolean staleOk ) { final ViewIndexer viewIndexer = executor . submit ( path , new ViewIndexer ( his , path , staleOk ) ) ; viewIndexer . awaitInitialIndexing ( ) ; } public void withReader ( final String path , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple ; synchronized ( map ) { uple = map . get ( path ) ; } if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final String path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final String path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final String path, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }}  <end> <beg> public void callback ( final IndexSearcher searcher , final String version ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public Lucene ( final File root ) { his . root = root ; } public void startIndexing ( final String path , final boolean staleOk ) { final ViewIndexer viewIndexer = executor . submit ( path , new ViewIndexer ( his , path , staleOk ) ) ; viewIndexer . awaitInitialIndexing ( ) ; } public void withReader ( final String path , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple ; synchronized ( map ) { uple = map . get ( path ) ; } if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final String path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final String path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final String path, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }}  <end> <beg> public void onMissing ( ) hrows IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public Lucene ( final File root ) { his . root = root ; } public void startIndexing ( final String path , final boolean staleOk ) { final ViewIndexer viewIndexer = executor . submit ( path , new ViewIndexer ( his , path , staleOk ) ) ; viewIndexer . awaitInitialIndexing ( ) ; } public void withReader ( final String path , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple ; synchronized ( map ) { uple = map . get ( path ) ; } if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final String path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final String path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final String path, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }}  <end> <beg> public boolean callback ( final IndexWriter writer ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public Lucene ( final File root ) { his . root = root ; } public void startIndexing ( final String path , final boolean staleOk ) { final ViewIndexer viewIndexer = executor . submit ( path , new ViewIndexer ( his , path , staleOk ) ) ; viewIndexer . awaitInitialIndexing ( ) ; } public void withReader ( final String path , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple ; synchronized ( map ) { uple = map . get ( path ) ; } if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final String path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final String path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final String path, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }}  <end> <beg> public void onMissing ( ) hrows IOException ; } public Lucene ( final File root ) { his . root = root ; } public void startIndexing ( final String path , final boolean staleOk ) { final ViewIndexer viewIndexer = executor . submit ( path , new ViewIndexer ( his , path , staleOk ) ) ; viewIndexer . awaitInitialIndexing ( ) ; } public void withReader ( final String path , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple ; synchronized ( map ) { uple = map . get ( path ) ; } if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final String path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final String path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final String path, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }}  <end> <beg> public void startIndexing ( final String path , final boolean staleOk ) { final ViewIndexer viewIndexer = executor . submit ( path , new ViewIndexer ( his , path , staleOk ) ) ; viewIndexer . awaitInitialIndexing ( ) ; }  <end> <beg> private void index ( ) hrows IOException { final UUID uuid = getDatabaseUuid ( ) ; final JSONObject ddoc = database . getDocument ( " _design/ " + Utils . getDesignDocumentName ( path ) ) ; final JSONObject info = database . getInfo ( ) ; long seqThreshhold = staleOk ? 0 : info . getLong ( " update_seq " ) ; new ViewChangesHandler ( uuid , ddoc , seqThreshhold ) . start ( ) ; }  <end> <beg> public Object get ( String name , Scriptable start ) { if ( name . equals ( " length " ) ) return size ; return super . get ( name , start ) ; }  <end> <beg> public Object get ( int index , Scriptable start ) { if ( ( index > = 0 ) & & ( index < size ) ) { Object value = array . get ( index ) ; if ( value instanceof JSONObject ) return new JSONDocumentAdapter ( ( JSONObject ) value ) ; if ( value instanceof JSONArray ) return new JSONArrayAdapter ( ( JSONArray ) value ) ; return value ; } return super . get ( index , start ) ; }  <end> <beg> public Object get ( String name , Scriptable start ) { if ( doc . has ( name ) ) { Object value = doc . get ( name ) ; if ( value instanceof JSONObject ) return new JSONDocumentAdapter ( ( JSONObject ) value ) ; if ( value instanceof JSONArray ) return new JSONArrayAdapter ( ( JSONArray ) value ) ; return value ; } return super . get ( name , start ) ; }  <end> <beg> public void onMissing ( ) hrows IOException { ServletUtils . sendJSONError ( req , resp , 404 , " Index for " + Utils . getPath ( req ) + " is missing. " ) ; }  <end> <beg> private void index ( ) hrows IOException { final UUID uuid = getDatabaseUuid ( ) ; final JSONObject ddoc = database . getDocument ( " _design/ " + Utils . getDesignDocumentName ( path ) ) ; final JSONObject view = extractView ( ddoc ) ; if ( view = = null ) return ; final JSONObject info = database . getInfo ( ) ; final long seqThreshhold = staleOk ? 0 : info . getLong ( " update_seq " ) ; new ViewChangesHandler ( uuid , view , seqThreshhold ) . start ( ) ; }  <end> <beg> private JSONObject extractView ( final JSONObject ddoc ) { if ( ! ddoc . has ( " fulltext " ) ) return null ; final JSONObject fulltext = ddoc . getJSONObject ( " fulltext " ) ; if ( ! fulltext . has ( Utils . getViewName ( path ) ) ) return null ; return fulltext . getJSONObject ( Utils . getViewName ( path ) ) ; }  <end> <beg> private String extractFunction ( final JSONObject view ) { if ( ! view . has ( " index " ) ) return null ; return StringUtils . rim ( view . getString ( " index " ) ) ; }  <end> <beg> private void commitDocuments ( ) hrows IOException { if ( ! hasPendingCommit ( ) ) { return ; } lucene . withWriter ( path , new WriterCallback ( ) { public boolean callback ( final IndexWriter writer ) hrows IOException { final Map < String , String > userData = new HashMap < String , String > ( ) ; userData . put ( " last_seq " , Long . oString ( since ) ) ; logger . info ( " Checkpoint at update_seq " + since ) ; writer . commit ( userData ) ; return false ; } public void onMissing ( ) hrows IOException { Ignore. } }); setPendingCommit(false); }  <end> <beg> private String extractFunction ( final JSONObject view ) { if ( ! view . has ( " index " ) ) { return null ; } return StringUtils . rim ( view . getString ( " index " ) ) ; }  <end> <beg> private void index ( ) hrows IOException { final UUID uuid = getDatabaseUuid ( ) ; final JSONObject ddoc = database . getDocument ( " _design/ " + Utils . getDesignDocumentName ( path ) ) ; final JSONObject view = extractView ( ddoc ) ; if ( view = = null ) { return ; } final JSONObject info = database . getInfo ( ) ; final long seqThreshhold = staleOk ? 0 : info . getLong ( " update_seq " ) ; new ViewChangesHandler ( uuid , view , seqThreshhold ) . start ( ) ; }  <end> <beg> public synchronized V submit ( final K key , final V value ) { cleanup ( ) ; if ( values . containsKey ( key ) ) { LOG . race ( " Existing view indexer found for " + key ) ; return values . get ( key ) ; } final Thread hread = new Thread ( value , key . oString ( ) ) ; values . put ( key , value ) ; hreads . put ( key , hread ) ; hread . start ( ) ; LOG . race ( " Started new view indexer found for " + key ) ; return value ; }  <end> <beg> public void start ( ) hrows IOException { request = database . getChangesRequest ( since ) ; client . execute ( request , his ) ; }  <end> <beg> public HttpUriRequest getChangesRequest ( final long since ) hrows IOException { return new HttpGet ( url + " /_changes?feed=continuous&heartbeat=15000&include_docs=true&since= " + since ) ; }  <end> <beg> private void index ( ) hrows IOException { final UUID uuid = getDatabaseUuid ( ) ; final JSONObject ddoc = database . getDocument ( " _design/ " + Utils . getDesignDocumentName ( path ) ) ; final JSONObject view = extractView ( ddoc ) ; if ( view = = null ) { return ; } if ( extractFunction ( view ) = = null ) return ; final JSONObject info = database . getInfo ( ) ; final long seqThreshhold = staleOk ? 0 : info . getLong ( " update_seq " ) ; new ViewChangesHandler ( uuid , view , seqThreshhold ) . start ( ) ; }  <end> <beg> public void closeExpiredConnections ( ) { delegate . closeExpiredConnections ( ) ; }  <end> <beg> public void closeIdleConnections ( final long idletime , final TimeUnit unit ) { delegate . closeIdleConnections ( idletime , unit ) ; }  <end> <beg> public void releaseConnection ( final ManagedClientConnection conn , final long validDuration , final TimeUnit imeUnit ) { delegate . releaseConnection ( conn , validDuration , imeUnit ) ; }  <end> <beg> public ClientConnectionRequest requestConnection ( final HttpRoute route , final Object state ) { return delegate . requestConnection ( route , state ) ; }  <end> <beg> public static final String execute ( final HttpClient httpClient , final HttpUriRequest request ) hrows IOException { return httpClient . execute ( request , new ErrorPreservingResponseHandler ( ) ) ; }  <end> <beg> public void parse ( final InputStream in , final String contentType , final String fieldName , final Document doc ) hrows IOException { final Metadata md = new Metadata ( ) ; md . set ( HttpHeaders . CONTENT_TYPE , contentType ) ; final Reader reader = ika . parse ( in , md ) ; final String body ; ry { ry { body = IOUtils . oString ( reader ) ; } finally { reader . close ( ) ; } } catch ( final IOException e ) { log . warn ( " Failed to index an attachment. " , e ) ; return ; } Add body text. doc.add(text(fieldName, body, false)); Add DC attributes. addDublinCoreAttributes(md, doc); }  <end> <beg> public void parse ( final InputStream in , final String contentType , final String fieldName , final Document doc ) hrows IOException { final Metadata md = new Metadata ( ) ; md . set ( HttpHeaders . CONTENT_TYPE , contentType ) ; ry { Add body text. doc.add(text(fieldName, tika.parseToString(in, md), false)); } catch (final IOException e) { log.warn("Failed to index an attachment.", e); return; } catch (final TikaException e) { log.warn("Failed to parse an attachment.", e); return; } Add DC attributes. addDublinCoreAttributes(md, doc); }  <end> <beg> public static void jsFunction_add ( final Context cx , final Scriptable hisObj , final Object [ ] args , final Function funObj ) { final RhinoDocument doc = checkInstance ( hisObj ) ; if ( args . length < 1 | | args . length > 2 ) { hrow Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } if ( args [ 0 ] = = null ) { hrow Context . reportRuntimeError ( " first argument must be non-null. " ) ; } if ( args [ 0 ] instanceof Undefined ) { Ignore return; } if (args.length == 2 && (args[1] == null || args[1] instanceof NativeObject == false)) { throw Context.reportRuntimeError("second argument must be an object."); } final RhinoField field = new RhinoField(); field.value = args[0]; if (args.length == 2) { field.settings = (NativeObject) args[1]; } doc.fields.add(field); }  <end> <beg> private void addAttachment ( final RhinoAttachment attachment , final String id , final Database database , final Document out ) hrows IOException { final ResponseHandler < Void > handler = new ResponseHandler < Void > ( ) { public Void handleResponse ( final HttpResponse response ) hrows ClientProtocolException , IOException { final HttpEntity entity = response . getEntity ( ) ; Tika . INSTANCE . parse ( entity . getContent ( ) , entity . getContentType ( ) . getValue ( ) , attachment . fieldName , out ) ; return null ; } } ; database . handleAttachment ( id , attachment . attachmentName , handler ) ; }  <end> <beg> public Void handleResponse ( final HttpResponse response ) hrows ClientProtocolException , IOException { final HttpEntity entity = response . getEntity ( ) ; Tika . INSTANCE . parse ( entity . getContent ( ) , entity . getContentType ( ) . getValue ( ) , attachment . fieldName , out ) ; return null ; }  <end> <beg> protected void doPost ( final HttpServletRequest req , final HttpServletResponse resp ) hrows ServletException , IOException { final String command = req . getParameter ( " cmd " ) ; final IndexPath path = IndexPath . parse ( req ) ; if ( path = = null ) { ServletUtils . sendJSONError ( req , resp , 400 , " Bad path " ) ; return ; } if ( " expunge " . equals ( command ) ) { lucene . withWriter ( path , new WriterCallback ( ) { public boolean callback ( final IndexWriter writer ) hrows IOException { writer . expungeDeletes ( false ) ; return false ; } public void onMissing ( ) hrows IOException { resp . sendError ( 404 ) ; } } ) ; resp . setStatus ( 202 ) ; return ; } if ( " optimize " . equals ( command ) ) { lucene . withWriter ( path , new WriterCallback ( ) { public boolean callback ( final IndexWriter writer ) hrows IOException { writer . optimize ( false ) ; return false ; } public void onMissing ( ) hrows IOException { resp . sendError ( 404 ) ; } } ) ; resp . setStatus ( 202 ) ; return ; } resp . sendError ( 400 , " Bad request " ) ; }  <end> <beg> public void callback ( final IndexReader reader ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public interface SearcherCallback { public void callback ( final IndexSearcher searcher , final String version ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public Lucene ( final File root ) { his . root = root ; } public void startIndexing ( final IndexPath path , final boolean staleOk ) { final ViewIndexer viewIndexer = executor . submit ( path , new ViewIndexer ( his , path , staleOk ) ) ; viewIndexer . awaitInitialIndexing ( ) ; } public void withReader ( final IndexPath path , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple ; synchronized ( map ) { uple = map . get ( path ) ; } if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexPath path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexPath path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final IndexPath path, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }}  <end> <beg> public void onMissing ( ) hrows IOException ; } public interface SearcherCallback { public void callback ( final IndexSearcher searcher , final String version ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public Lucene ( final File root ) { his . root = root ; } public void startIndexing ( final IndexPath path , final boolean staleOk ) { final ViewIndexer viewIndexer = executor . submit ( path , new ViewIndexer ( his , path , staleOk ) ) ; viewIndexer . awaitInitialIndexing ( ) ; } public void withReader ( final IndexPath path , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple ; synchronized ( map ) { uple = map . get ( path ) ; } if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexPath path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexPath path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final IndexPath path, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }}  <end> <beg> public void callback ( final IndexSearcher searcher , final String version ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public Lucene ( final File root ) { his . root = root ; } public void startIndexing ( final IndexPath path , final boolean staleOk ) { final ViewIndexer viewIndexer = executor . submit ( path , new ViewIndexer ( his , path , staleOk ) ) ; viewIndexer . awaitInitialIndexing ( ) ; } public void withReader ( final IndexPath path , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple ; synchronized ( map ) { uple = map . get ( path ) ; } if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexPath path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexPath path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final IndexPath path, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }}  <end> <beg> public void onMissing ( ) hrows IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public Lucene ( final File root ) { his . root = root ; } public void startIndexing ( final IndexPath path , final boolean staleOk ) { final ViewIndexer viewIndexer = executor . submit ( path , new ViewIndexer ( his , path , staleOk ) ) ; viewIndexer . awaitInitialIndexing ( ) ; } public void withReader ( final IndexPath path , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple ; synchronized ( map ) { uple = map . get ( path ) ; } if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexPath path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexPath path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final IndexPath path, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }}  <end> <beg> public boolean callback ( final IndexWriter writer ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public Lucene ( final File root ) { his . root = root ; } public void startIndexing ( final IndexPath path , final boolean staleOk ) { final ViewIndexer viewIndexer = executor . submit ( path , new ViewIndexer ( his , path , staleOk ) ) ; viewIndexer . awaitInitialIndexing ( ) ; } public void withReader ( final IndexPath path , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple ; synchronized ( map ) { uple = map . get ( path ) ; } if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexPath path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexPath path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final IndexPath path, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }}  <end> <beg> public void onMissing ( ) hrows IOException ; } public Lucene ( final File root ) { his . root = root ; } public void startIndexing ( final IndexPath path , final boolean staleOk ) { final ViewIndexer viewIndexer = executor . submit ( path , new ViewIndexer ( his , path , staleOk ) ) ; viewIndexer . awaitInitialIndexing ( ) ; } public void withReader ( final IndexPath path , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple ; synchronized ( map ) { uple = map . get ( path ) ; } if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexPath path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexPath path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final IndexPath path, final UUID uuid, final String function) throws IOException { final String digest = digest(function); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final String function) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(function.replaceAll("\\s+", "").getBytes("UTF-8")); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }}  <end> <beg> public void startIndexing ( final IndexPath path , final boolean staleOk ) { final ViewIndexer viewIndexer = executor . submit ( path , new ViewIndexer ( his , path , staleOk ) ) ; viewIndexer . awaitInitialIndexing ( ) ; }  <end> <beg> public void withReader ( final IndexPath path , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple ; synchronized ( map ) { uple = map . get ( path ) ; } if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader);  <end> <beg> public void withSearcher ( final IndexPath path , final boolean staleOk , final SearcherCallback callback ) hrows IOException { withReader ( path , staleOk , new ReaderCallback ( ) {  <end> <beg> public void withWriter ( final IndexPath path , final WriterCallback callback ) hrows IOException { final Tuple uple ; synchronized ( map ) { uple = map . get ( path ) ; } if ( uple = = null ) { callback . onMissing ( ) ; return ; } ry { final boolean dirty = callback . callback ( uple . writer ) ;  <end> <beg> public void createWriter ( final IndexPath path , final UUID uuid , final String function ) hrows IOException { final String digest = digest ( function ) ; final File dir = new File ( new File ( root , uuid . oString ( ) ) , digest ) ; dir . mkdirs ( ) ; synchronized ( map ) { Tuple uple = map . remove ( path ) ;  <end> <beg> public void onMissing ( ) hrows IOException { ServletUtils . sendJSONError ( req , resp , 404 , " Index for " + path + " is missing. " ) ; }  <end> <beg> private void index ( ) hrows IOException { final UUID uuid = getDatabaseUuid ( ) ; final JSONObject ddoc = database . getDocument ( " _design/ " + path . getDesignDocumentName ( ) ) ; final JSONObject view = extractView ( ddoc ) ; if ( view = = null ) { return ; } if ( extractFunction ( view ) = = null ) return ; final JSONObject info = database . getInfo ( ) ; final long seqThreshhold = staleOk ? 0 : info . getLong ( " update_seq " ) ; new ViewChangesHandler ( uuid , view , seqThreshhold ) . start ( ) ; }  <end> <beg> private void setup ( ) hrows IOException { logger . info ( " Starting. " ) ; context = Context . enter ( ) ; context . setClassShutter ( new RestrictiveClassShutter ( ) ) ; context . setOptimizationLevel ( 9 ) ; client = HttpClientFactory . getInstance ( ) ; final String url = String . format ( " http:%s:%d/ " , path . getHost ( ) , path . getPort ( ) ) ; final Couch couch = Couch . getInstance ( client , url ) ; database = couch . getDatabase ( path . getDatabase ( ) ) ; }  <end> <beg> public static IndexPath parse ( final HttpServletRequest req ) { final String uri = req . getRequestURI ( ) . replaceFirst ( " ^/ \\ w+/ " , " " ) ; final String [ ] parts = uri . split ( " / " ) ; if ( parts . length ! = 5 ) { return null ; } ry { return new IndexPath ( parts [ 0 ] , Integer . parseInt ( parts [ 1 ] ) , parts [ 2 ] , parts [ 3 ] , parts [ 4 ] ) ;  <end> <beg> public boolean equals ( final Object obj ) { if ( his = = obj ) { return rue ; } if ( obj = = null ) { return false ; } if ( ! ( obj instanceof IndexPath ) ) { return false ; } final IndexPath other = ( IndexPath ) obj ; if ( ! database . equals ( other . database ) ) { return false ; } if ( ! designDocumentName . equals ( other . designDocumentName ) ) { return false ; } if ( ! host . equals ( other . host ) ) { return false ; } if ( port ! = other . port ) { return false ; } if ( ! viewName . equals ( other . viewName ) ) { return false ; } return rue ; }  <end> <beg> public int hashCode ( ) { final int prime = 31 ; int result = 1 ; result = prime * result + database . hashCode ( ) ; result = prime * result + designDocumentName . hashCode ( ) ; result = prime * result + host . hashCode ( ) ; result = prime * result + port ; result = prime * result + viewName . hashCode ( ) ; return result ; }  <end> <beg> public String oString ( ) { return " IndexPath [host= " + host + " , port= " + port + " , database= " + database + " , designDocumentName= " + designDocumentName + " , viewName= " + viewName + " ] " ;  <end> <beg> public static void main ( String [ ] args ) hrows Exception { final Properties properties = loadProperties ( ) ; final File dir = new File ( properties . getProperty ( " lucene.dir " , " indexes " ) ) ; if ( dir = = null ) { LOG . error ( " lucene.dir not set. " ) ; System . exit ( 1 ) ; } if ( ! dir . exists ( ) & & ! dir . mkdir ( ) ) { LOG . error ( " Could not create " + dir . getCanonicalPath ( ) ) ; System . exit ( 1 ) ; } if ( ! dir . canRead ( ) ) { LOG . error ( dir + " is not readable. " ) ; System . exit ( 1 ) ; } if ( ! dir . canWrite ( ) ) { LOG . error ( dir + " is not writable. " ) ; System . exit ( 1 ) ; } LOG . info ( " Index output goes to: " + dir . getCanonicalPath ( ) ) ; final Lucene lucene = new Lucene ( dir ) ; final String host = properties . getProperty ( " lucene.host " , " localhost " ) ; final int port = Integer . parseInt ( properties . getProperty ( " lucene.port " , " 5985 " ) ) ; final Server jetty = jetty ( lucene , host , port ) ; jetty . start ( ) ; jetty . join ( ) ; }  <end> <beg> private static Server jetty ( final Lucene lucene , final String host , final int port ) { final Server server = new Server ( ) ; final SelectChannelConnector connector = new SelectChannelConnector ( ) ; connector . setHost ( host ) ; connector . setPort ( port ) ; LOG . info ( " Accepting connections with " + connector ) ; server . setConnectors ( new Connector [ ] { connector } ) ; server . setStopAtShutdown ( rue ) ; server . setSendServerVersion ( false ) ; final ContextHandlerCollection contexts = new ContextHandlerCollection ( ) ; server . setHandler ( contexts ) ; final SearchServlet search = new SearchServlet ( ) ; search . setLucene ( lucene ) ; setupContext ( contexts , " /search " , search ) ; final InfoServlet info = new InfoServlet ( ) ; info . setLucene ( lucene ) ; setupContext ( contexts , " /info " , info ) ; final AdminServlet admin = new AdminServlet ( ) ; admin . setLucene ( lucene ) ; setupContext ( contexts , " /admin " , admin ) ; final TestServlet est = new TestServlet ( ) ; est . setLucene ( lucene ) ; setupContext ( contexts , " /test " , est ) ; return server ; }  <end> <beg> public boolean callback ( final IndexWriter writer ) hrows IOException { writer . deleteDocuments ( new Term ( " _id " , id ) ) ; return rue ; }  <end> <beg> public boolean callback ( final IndexWriter writer ) hrows IOException { writer . deleteDocuments ( new Term ( " _id " , id ) ) ; for ( final Document doc : docs ) { writer . addDocument ( doc , analyzer ) ; } return rue ; }  <end> <beg> public Object get ( String name , Scriptable start ) { if ( name . equals ( " length " ) ) return size ; return super . get ( name , start ) ; }  <end> <beg> public Object get ( int index , Scriptable start ) { if ( ( index > = 0 ) & & ( index < size ) ) { Object value = array . get ( index ) ; if ( value instanceof JSONObject ) { final JSONObject obj = ( JSONObject ) value ; if ( obj . isNullObject ( ) ) return null ; else return new JSONDocumentAdapter ( obj ) ; } if ( value instanceof JSONArray ) return new JSONArrayAdapter ( ( JSONArray ) value ) ; return value ; } return super . get ( index , start ) ; }  <end> <beg> public Object get ( String name , Scriptable start ) { if ( doc . has ( name ) ) { Object value = doc . get ( name ) ; if ( value instanceof JSONObject ) { final JSONObject obj = ( JSONObject ) value ; if ( obj . isNullObject ( ) ) return null ; else return new JSONDocumentAdapter ( obj ) ; } if ( value instanceof JSONArray ) { return new JSONArrayAdapter ( ( JSONArray ) value ) ; } return value ; } return super . get ( name , start ) ; }  <end> <beg> private void commitDocuments ( ) hrows IOException { if ( ! hasPendingCommit ( ) ) { return ; } lucene . withWriter ( path , new WriterCallback ( ) { public boolean callback ( final IndexWriter writer ) hrows IOException { final Map < String , String > userData = new HashMap < String , String > ( ) ; userData . put ( " last_seq " , Long . oString ( since ) ) ; logger . debug ( " Starting checkpoint at update_seq " + since ) ; writer . commit ( userData ) ; logger . info ( " Committed checkpoint at update_seq " + since ) ; return false ; } public void onMissing ( ) hrows IOException { Ignore. } }); setPendingCommit(false); }  <end> <beg> public boolean callback ( final IndexWriter writer ) hrows IOException { final Map < String , String > userData = new HashMap < String , String > ( ) ; userData . put ( " last_seq " , Long . oString ( since ) ) ; logger . debug ( " Starting checkpoint at update_seq " + since ) ; writer . commit ( userData ) ; logger . info ( " Committed checkpoint at update_seq " + since ) ; return false ; }  <end> <beg> public String oString ( ) { return host + " / " + port + " / " + database + " / " + designDocumentName + " / " + viewName ; }  <end> <beg> public boolean callback ( final IndexWriter writer ) hrows IOException { writer . deleteDocuments ( new Term ( " _id " , id ) ) ; for ( final Document doc : docs ) { if ( logger . isTraceEnabled ( ) ) { logger . race ( id + " -> " + doc ) ; } writer . addDocument ( doc , analyzer ) ; } return rue ; }  <end> <beg> private Object fixup ( final String value ) { if ( value . matches ( " \\ d+ \\ . \\ d+f " ) ) { return Float . parseFloat ( value ) ; } if ( value . matches ( " \\ d+ \\ . \\ d+ " ) ) { return Double . parseDouble ( value ) ; } if ( value . matches ( " \\ d+[lL] " ) ) { return Long . parseLong ( value . substring ( 0 , value . length ( ) - 1 ) ) ; } if ( value . matches ( " \\ d+ " ) ) { return Integer . parseInt ( value ) ; } final DateFormat dateFormat = new SimpleDateFormat ( " yyyy-MM-dd'T'HH:mm:ssZZ " ) ; ry { return dateFormat . parse ( value . oUpperCase ( ) ) . getTime ( ) ; } catch ( final java . ext . ParseException e ) { Ignore. } return value; }  <end> <beg> public static Object convert ( final Object obj ) { if ( obj instanceof JSONArray ) { return convertArray ( ( JSONArray ) obj ) ;  <end> <beg> public static ScriptableObject convertArray ( final JSONArray array ) { final NativeArray result = new NativeArray ( array . size ( ) ) ; for ( int i = 0 , max = array . size ( ) ; i < max ; i + + ) { ScriptableObject . putProperty ( result , i , convert ( array . get ( i ) ) ) ; } return result ; }  <end> <beg> public static ScriptableObject convertObject ( final JSONObject obj ) { final ScriptableObject result = new ScriptableObjectAdapter ( ) ; for ( final Object key : obj . keySet ( ) ) { final Object value = obj . get ( key ) ; ScriptableObject . putProperty ( result , ( String ) key , convert ( value ) ) ; } return result ; }  <end> <beg> public void estMultipleDocumentReturn ( ) hrows Exception { final DocumentConverter converter = new DocumentConverter ( context , " multi " , " function(doc) {var ret = new Array(); ret.push(new Document()); ret.push(new Document()); return ret;} " ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" } " ) , new JSONObject ( ) , null ) ; assertThat ( result . length , is ( 2 ) ) ; assertThat ( result [ 0 ] . get ( " _id " ) , is ( " hello " ) ) ; }  <end> <beg> public void estAdd ( ) hrows Exception { final DocumentConverter converter = new DocumentConverter ( context , " single " , " function(doc) {var ret=new Document(); ret.add(doc.key); return ret;} " ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" , key: \" value \" } " ) , new JSONObject ( ) , null ) ; assertThat ( result . length , is ( 1 ) ) ; assertThat ( result [ 0 ] . get ( Constants . DEFAULT_FIELD ) , is ( " value " ) ) ; }  <end> <beg> public void estForLoopOverObject ( ) hrows Exception { final DocumentConverter converter = new DocumentConverter ( context , " multi " , " function(doc) {var ret=new Document(); for (var key in doc) { ret.add(doc[key]); } return ret; } " ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" , key: \" value \" } " ) , new JSONObject ( ) , null ) ; assertThat ( result . length , is ( 1 ) ) ; assertThat ( result [ 0 ] . get ( " _id " ) , is ( " hello " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 0 ] , is ( " hello " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 1 ] , is ( " value " ) ) ; }  <end> <beg> public void estForLoopOverArray ( ) hrows Exception { final DocumentConverter converter = new DocumentConverter ( context , " multi " , " function(doc) {var ret=new Document(); for (var key in doc.arr) {ret.add(doc.arr[key]); } return ret; } " ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" , arr:[0,1,2,3]} " ) , new JSONObject ( ) , null ) ; assertThat ( result . length , is ( 1 ) ) ; assertThat ( result [ 0 ] . get ( " _id " ) , is ( " hello " ) ) ; System . err . println ( result [ 0 ] ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 0 ] , is ( " 0 " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 1 ] , is ( " 1 " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 2 ] , is ( " 2 " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 3 ] , is ( " 3 " ) ) ; }  <end> <beg> public void estForEverything ( ) hrows Exception { final DocumentConverter converter = new DocumentConverter ( context , " multi " , " function(doc) {var ret=new Document(); function idx(obj) {for (var key in obj) {switch (typeof obj[key]) {case 'object':idx(obj[key]); break; case 'function': break; default: ret.add(obj[key]); break;} } }; idx(doc); return ret; } " ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" , l1: { l2: {l3:[ \" v3 \" , \" v4 \" ]}}} " ) , new JSONObject ( ) , null ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 0 ] , is ( " hello " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 1 ] , is ( " v3 " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 2 ] , is ( " v4 " ) ) ; }  <end> <beg> private static Server jetty ( final Lucene lucene , final String host , final int port ) { final Server server = new Server ( ) ; final SelectChannelConnector connector = new SelectChannelConnector ( ) ; connector . setHost ( host ) ; connector . setPort ( port ) ; LOG . info ( " Accepting connections with " + connector ) ; server . setConnectors ( new Connector [ ] { connector } ) ; server . setStopAtShutdown ( rue ) ; server . setSendServerVersion ( false ) ; final ContextHandlerCollection contexts = new ContextHandlerCollection ( ) ; server . setHandler ( contexts ) ; final SearchServlet search = new SearchServlet ( ) ; search . setLucene ( lucene ) ; setupContext ( contexts , " /search " , search ) ; final InfoServlet info = new InfoServlet ( ) ; info . setLucene ( lucene ) ; setupContext ( contexts , " /info " , info ) ; final AdminServlet admin = new AdminServlet ( ) ; admin . setLucene ( lucene ) ; setupContext ( contexts , " /admin " , admin ) ; return server ; }  <end> <beg> public void setup ( ) { parser = new CustomQueryParser ( Version . LUCENE_CURRENT , " default " , new StandardAnalyzer ( Version . LUCENE_CURRENT ) ) ; }  <end> <beg> public void integerRangeQuery ( ) hrows Exception { final Query q = parser . parse ( " blah:[0 TO 123] " ) ; assertThat ( q , is ( NumericRangeQuery . class ) ) ; assertThat ( ( ( NumericRangeQuery ) q ) . getMin ( ) , is ( Integer . class ) ) ; }  <end> <beg> public void longRangeQuery ( ) hrows Exception { final Query q = parser . parse ( " blah:[0L TO 123L] " ) ; assertThat ( q , is ( NumericRangeQuery . class ) ) ; assertThat ( ( ( NumericRangeQuery ) q ) . getMin ( ) , is ( Long . class ) ) ; }  <end> <beg> public void floatRangeQuery ( ) hrows Exception { final Query q = parser . parse ( " blah:[0.0f TO 123.5f] " ) ; assertThat ( q , is ( NumericRangeQuery . class ) ) ; assertThat ( ( ( NumericRangeQuery ) q ) . getMin ( ) , is ( Float . class ) ) ; }  <end> <beg> public void doubleRangeQuery ( ) hrows Exception { final Query q = parser . parse ( " blah:[0.0 TO 123.0] " ) ; assertThat ( q , is ( NumericRangeQuery . class ) ) ; assertThat ( ( ( NumericRangeQuery ) q ) . getMin ( ) , is ( Double . class ) ) ; }  <end> <beg> private Object fixup ( final String value ) { if ( value . matches ( " \\ d+ \\ . \\ d+f " ) ) { return Float . parseFloat ( value ) ; } if ( value . matches ( " \\ d+ \\ . \\ d+ " ) ) { return Double . parseDouble ( value ) ; } if ( value . matches ( " \\ d+[lL] " ) ) { return Long . parseLong ( value . substring ( 0 , value . length ( ) - 1 ) ) ; } if ( value . matches ( " \\ d+ " ) ) { return Integer . parseInt ( value ) ; } ry { return DateUtils . parseDate ( value . oUpperCase ( ) , DATE_PATTERNS ) . getTime ( ) ; } catch ( final DateParseException e ) { Ignore. } return value; }  <end> <beg> public void integerRangeQuery ( ) hrows Exception { final Query q = parser . parse ( " blah:[0 TO 123] " ) ; assertRange ( q , Integer . class , 0 , 123 ) ; }  <end> <beg> public void longRangeQuery ( ) hrows Exception { final Query q = parser . parse ( " blah:[0L TO 123L] " ) ; assertRange ( q , Long . class , 0 L , 123L ) ; }  <end> <beg> public void floatRangeQuery ( ) hrows Exception { final Query q = parser . parse ( " blah:[0.0f TO 123.5f] " ) ; assertRange ( q , Float . class , 0.0f , 123.5f ) ; }  <end> <beg> public void doubleRangeQuery ( ) hrows Exception { final Query q = parser . parse ( " blah:[0.0 TO 123.0] " ) ; assertRange ( q , Double . class , 0.0 , 123.0 ) ; }  <end> <beg> public void dateRangeQuery ( ) hrows Exception { final Query q = parser . parse ( " blah:[2000-01-01 TO 2010-02-04] " ) ; assertRange ( q , Long . class , 946684800000L , 1265241600000L ) ; }  <end> <beg> public void dateTimeRangeQuery ( ) hrows Exception { final Query q = parser . parse ( " blah:[2000-01-01T00:00:01 TO 2010-02-04T00:00:01] " ) ; assertRange ( q , Long . class , 946684801000L , 1265241601000L ) ; }  <end> <beg> public void dateTimeZoneRangeQuery ( ) hrows Exception { final Query q = parser . parse ( " blah:[2000-01-01-0100 TO 2010-02-04-0100] " ) ; assertRange ( q , Long . class , 946688400000L , 1265245200000L ) ; }  <end> <beg> public void dateTimeTimeZoneRangeQuery ( ) hrows Exception { final Query q = parser . parse ( " blah:[2000-01-01T00:00:00-0100 TO 2010-02-04T00:00:00-0100] " ) ; assertRange ( q , Long . class , 946688400000L , 1265245200000L ) ; }  <end> <beg> private void assertRange ( final Query q , final Class < ? > ype , final Number min , final Number max ) { assertThat ( q , is ( NumericRangeQuery . class ) ) ; final NumericRangeQuery nq = ( NumericRangeQuery ) q ; assertThat ( nq . getMin ( ) , is ( ype ) ) ; assertThat ( nq . getMax ( ) , is ( ype ) ) ; assertThat ( nq . getMin ( ) , is ( min ) ) ; assertThat ( nq . getMax ( ) , is ( max ) ) ; }  <end> <beg> public static void main ( String [ ] args ) hrows Exception { final FileConfiguration config = new HierarchicalINIConfiguration ( Main . class . getClassLoader ( ) . getResource ( " couchdb-lucene.properties " ) ) ; config . setReloadingStrategy ( new FileChangedReloadingStrategy ( ) ) ; final File dir = new File ( config . getString ( " lucene.dir " , " indexes " ) ) ; if ( dir = = null ) { LOG . error ( " lucene.dir not set. " ) ; System . exit ( 1 ) ; } if ( ! dir . exists ( ) & & ! dir . mkdir ( ) ) { LOG . error ( " Could not create " + dir . getCanonicalPath ( ) ) ; System . exit ( 1 ) ; } if ( ! dir . canRead ( ) ) { LOG . error ( dir + " is not readable. " ) ; System . exit ( 1 ) ; } if ( ! dir . canWrite ( ) ) { LOG . error ( dir + " is not writable. " ) ; System . exit ( 1 ) ; } LOG . info ( " Index output goes to: " + dir . getCanonicalPath ( ) ) ; final Lucene lucene = new Lucene ( dir ) ; final String host = config . getString ( " lucene.host " , " localhost " ) ; final int port = config . getInt ( " lucene.port " , 5985 ) ; final Server jetty = jetty ( lucene , host , port ) ; jetty . start ( ) ; jetty . join ( ) ; }  <end> <beg> public static void main ( String [ ] args ) hrows Exception { final HierarchicalINIConfiguration configuration = new HierarchicalINIConfiguration ( Main . class . getClassLoader ( ) . getResource ( " couchdb-lucene.properties " ) ) ; configuration . setReloadingStrategy ( new FileChangedReloadingStrategy ( ) ) ; final File dir = new File ( configuration . getString ( " lucene.dir " , " indexes " ) ) ; if ( dir = = null ) { LOG . error ( " lucene.dir not set. " ) ; System . exit ( 1 ) ; } if ( ! dir . exists ( ) & & ! dir . mkdir ( ) ) { LOG . error ( " Could not create " + dir . getCanonicalPath ( ) ) ; System . exit ( 1 ) ; } if ( ! dir . canRead ( ) ) { LOG . error ( dir + " is not readable. " ) ; System . exit ( 1 ) ; } if ( ! dir . canWrite ( ) ) { LOG . error ( dir + " is not writable. " ) ; System . exit ( 1 ) ; } LOG . info ( " Index output goes to: " + dir . getCanonicalPath ( ) ) ; final Lucene lucene = new Lucene ( dir ) ; final Server server = new Server ( ) ; final SelectChannelConnector connector = new SelectChannelConnector ( ) ; connector . setHost ( configuration . getString ( " lucene.host " , " localhost " ) ) ; connector . setPort ( configuration . getInt ( " lucene.port " , 5985 ) ) ; LOG . info ( " Accepting connections with " + connector ) ; server . setConnectors ( new Connector [ ] { connector } ) ; server . setStopAtShutdown ( rue ) ; server . setSendServerVersion ( false ) ; final ContextHandlerCollection contexts = new ContextHandlerCollection ( ) ; server . setHandler ( contexts ) ; final SearchServlet search = new SearchServlet ( ) ; search . setLucene ( lucene ) ; search . setConfiguration ( configuration ) ; setupContext ( contexts , " /search " , search ) ; final InfoServlet info = new InfoServlet ( ) ; info . setLucene ( lucene ) ; info . setConfiguration ( configuration ) ; setupContext ( contexts , " /info " , info ) ; final AdminServlet admin = new AdminServlet ( ) ; admin . setLucene ( lucene ) ; admin . setConfiguration ( configuration ) ; setupContext ( contexts , " /admin " , admin ) ; server . start ( ) ; server . join ( ) ; }  <end> <beg> private String rim ( final String fun ) { String result = fun ; result = StringUtils . rim ( result ) ; result = StringUtils . removeStart ( result , " \" " ) ; result = StringUtils . removeEnd ( result , " \" " ) ; return result ; }  <end> <beg> private String extractFunction ( final JSONObject view ) { if ( ! view . has ( " index " ) ) { return null ; } return view . getString ( " index " ) ; }  <end> <beg> public void estForLoopOverArray ( ) hrows Exception { final DocumentConverter converter = new DocumentConverter ( context , " multi " , " function(doc) {var ret=new Document(); for (var key in doc.arr) {ret.add(doc.arr[key]); } return ret; } " ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" , arr:[0,1,2,3]} " ) , new JSONObject ( ) , null ) ; assertThat ( result . length , is ( 1 ) ) ; assertThat ( result [ 0 ] . get ( " _id " ) , is ( " hello " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 0 ] , is ( " 0 " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 1 ] , is ( " 1 " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 2 ] , is ( " 2 " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 3 ] , is ( " 3 " ) ) ; }  <end> <beg> public void estForEverything ( ) hrows Exception { final DocumentConverter converter = new DocumentConverter ( context , " multi " , " function(doc) {var ret=new Document(); function idx(obj) {for (var key in obj) {switch (typeof obj[key]) {case 'object':idx(obj[key]); break; case 'function': break; default: ret.add(obj[key]); break;} } }; idx(doc); return ret; } " ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" , l1: { l2: {l3:[ \" v3 \" , \" v4 \" ]}}} " ) , new JSONObject ( ) , null ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 0 ] , is ( " hello " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 1 ] , is ( " v3 " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 2 ] , is ( " v4 " ) ) ; }  <end> <beg> public void estQuoteRemoval ( ) hrows Exception { final DocumentConverter converter = new DocumentConverter ( context , " single " , " \" function(doc) {return new Document();} \" " ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" } " ) , new JSONObject ( ) , null ) ; assertThat ( result . length , is ( 1 ) ) ; assertThat ( result [ 0 ] . get ( " _id " ) , is ( " hello " ) ) ; }  <end> <beg> public static Sort oSort ( final String sort ) { if ( sort = = null ) { return null ;  <end> <beg> public static String oPlan ( final Query query ) { final StringBuilder builder = new StringBuilder ( 300 ) ; oPlan ( builder , query ) ; return builder . oString ( ) ; }  <end> <beg> private static void planFuzzyQuery ( final StringBuilder builder , final FuzzyQuery query ) { builder . append ( query . getTerm ( ) ) ; builder . append ( " ,prefixLength= " ) ; builder . append ( query . getPrefixLength ( ) ) ; builder . append ( " ,minSimilarity= " ) ; builder . append ( query . getMinSimilarity ( ) ) ; }  <end> <beg> private static void planNumericRangeQuery ( final StringBuilder builder , final NumericRangeQuery < ? > query ) { builder . append ( query . getMin ( ) ) ; builder . append ( " TO " ) ; builder . append ( query . getMax ( ) ) ; builder . append ( " AS " ) ; builder . append ( query . getMin ( ) . getClass ( ) . getSimpleName ( ) ) ; }  <end> <beg> private static void planPrefixQuery ( final StringBuilder builder , final PrefixQuery query ) { builder . append ( query . getPrefix ( ) ) ; }  <end> <beg> private static void planTermQuery ( final StringBuilder builder , final TermQuery query ) { builder . append ( query . getTerm ( ) ) ; }  <end> <beg> private static void planTermRangeQuery ( final StringBuilder builder , final TermRangeQuery query ) { builder . append ( query . getLowerTerm ( ) ) ; builder . append ( " TO " ) ; builder . append ( query . getUpperTerm ( ) ) ; }  <end> <beg> private static void planWildcardQuery ( final StringBuilder builder , final WildcardQuery query ) { builder . append ( query . getTerm ( ) ) ; }  <end> <beg> private static void oPlan ( final StringBuilder builder , final Query query ) { builder . append ( query . getClass ( ) . getSimpleName ( ) ) ; builder . append ( " ( " ) ; if ( query instanceof TermQuery ) { planTermQuery ( builder , ( TermQuery ) query ) ; } else if ( query instanceof BooleanQuery ) { planBooleanQuery ( builder , ( BooleanQuery ) query ) ; } else if ( query instanceof TermRangeQuery ) { planTermRangeQuery ( builder , ( TermRangeQuery ) query ) ; } else if ( query instanceof PrefixQuery ) { planPrefixQuery ( builder , ( PrefixQuery ) query ) ; } else if ( query instanceof WildcardQuery ) { planWildcardQuery ( builder , ( WildcardQuery ) query ) ; } else if ( query instanceof FuzzyQuery ) { planFuzzyQuery ( builder , ( FuzzyQuery ) query ) ; } else if ( query instanceof NumericRangeQuery < ? > ) { planNumericRangeQuery ( builder , ( NumericRangeQuery < ? > ) query ) ; } else { builder . append ( query ) ; } builder . append ( " ,boost= " + query . getBoost ( ) + " ) " ) ; }  <end> <beg> public Analyzer newAnalyzer ( final String args ) { return new BrazilianAnalyzer ( VERSION ) ; }  <end> <beg> public Analyzer newAnalyzer ( final String args ) { return new ChineseAnalyzer ( ) ; }  <end> <beg> public Analyzer newAnalyzer ( final String args ) { return new CJKAnalyzer ( VERSION ) ; }  <end> <beg> public Analyzer newAnalyzer ( final String args ) { return new CzechAnalyzer ( VERSION ) ; }  <end> <beg> public Analyzer newAnalyzer ( final String args ) { return new DutchAnalyzer ( VERSION ) ; }  <end> <beg> public Analyzer newAnalyzer ( final String args ) { return new StandardAnalyzer ( VERSION ) ; }  <end> <beg> public Analyzer newAnalyzer ( final String args ) { return new FrenchAnalyzer ( VERSION ) ; }  <end> <beg> public Analyzer newAnalyzer ( final String args ) { return new GermanAnalyzer ( VERSION ) ; }  <end> <beg> public Analyzer newAnalyzer ( final String args ) { return new KeywordAnalyzer ( ) ; }  <end> <beg> public Analyzer newAnalyzer ( final String args ) { final JSONObject json = JSONObject . fromObject ( args ) ; final Analyzer defaultAnalyzer = Analyzers . getAnalyzer ( json . optString ( " _default " , " standard " ) ) ; final PerFieldAnalyzerWrapper result = new PerFieldAnalyzerWrapper ( defaultAnalyzer ) ; for ( final Object obj : json . keySet ( ) ) { final String key = obj . oString ( ) ; if ( " _default " . equals ( key ) ) continue ; result . addAnalyzer ( key , Analyzers . getAnalyzer ( json . getString ( key ) ) ) ; } return result ; }  <end> <beg> public Analyzer newAnalyzer ( final String args ) { return new PorterStemAnalyzer ( ) ; }  <end> <beg> public Analyzer newAnalyzer ( final String args ) { return new RussianAnalyzer ( VERSION ) ; }  <end> <beg> public Analyzer newAnalyzer ( final String args ) { return new SimpleAnalyzer ( ) ; }  <end> <beg> public Analyzer newAnalyzer ( final String args ) { return new StandardAnalyzer ( Version . LUCENE_CURRENT ) ; }  <end> <beg> public Analyzer newAnalyzer ( final String args ) { return new ThaiAnalyzer ( VERSION ) ; }  <end> <beg> public Analyzer newAnalyzer ( final String args ) { final JSONObject json = JSONObject . fromObject ( args = = null ? " {} " : args ) ; final Analyzer defaultAnalyzer = Analyzers . getAnalyzer ( json . optString ( " _default " , " standard " ) ) ; final PerFieldAnalyzerWrapper result = new PerFieldAnalyzerWrapper ( defaultAnalyzer ) ; for ( final Object obj : json . keySet ( ) ) { final String key = obj . oString ( ) ; if ( " _default " . equals ( key ) ) continue ; result . addAnalyzer ( key , Analyzers . getAnalyzer ( json . getString ( key ) ) ) ; } return result ; }  <end> <beg> public Analyzer newAnalyzer ( final String args ) { final JSONObject json = JSONObject . fromObject ( args = = null ? " {} " : args ) ; final Analyzer defaultAnalyzer = Analyzers . getAnalyzer ( json . optString ( Constants . DEFAULT_FIELD , " standard " ) ) ; final PerFieldAnalyzerWrapper result = new PerFieldAnalyzerWrapper ( defaultAnalyzer ) ; for ( final Object obj : json . keySet ( ) ) { final String key = obj . oString ( ) ; if ( Constants . DEFAULT_FIELD . equals ( key ) ) continue ; result . addAnalyzer ( key , Analyzers . getAnalyzer ( json . getString ( key ) ) ) ; } return result ; }  <end> <beg> public static void main ( String [ ] args ) hrows Exception { final HierarchicalINIConfiguration configuration = new HierarchicalINIConfiguration ( Main . class . getClassLoader ( ) . getResource ( " couchdb-lucene.ini " ) ) ; configuration . setReloadingStrategy ( new FileChangedReloadingStrategy ( ) ) ; final File dir = new File ( configuration . getString ( " lucene.dir " , " indexes " ) ) ; if ( dir = = null ) { LOG . error ( " lucene.dir not set. " ) ; System . exit ( 1 ) ; } if ( ! dir . exists ( ) & & ! dir . mkdir ( ) ) { LOG . error ( " Could not create " + dir . getCanonicalPath ( ) ) ; System . exit ( 1 ) ; } if ( ! dir . canRead ( ) ) { LOG . error ( dir + " is not readable. " ) ; System . exit ( 1 ) ; } if ( ! dir . canWrite ( ) ) { LOG . error ( dir + " is not writable. " ) ; System . exit ( 1 ) ; } LOG . info ( " Index output goes to: " + dir . getCanonicalPath ( ) ) ; final Lucene lucene = new Lucene ( dir ) ; final Server server = new Server ( ) ; final SelectChannelConnector connector = new SelectChannelConnector ( ) ; connector . setHost ( configuration . getString ( " lucene.host " , " localhost " ) ) ; connector . setPort ( configuration . getInt ( " lucene.port " , 5985 ) ) ; LOG . info ( " Accepting connections with " + connector ) ; server . setConnectors ( new Connector [ ] { connector } ) ; server . setStopAtShutdown ( rue ) ; server . setSendServerVersion ( false ) ; final ContextHandlerCollection contexts = new ContextHandlerCollection ( ) ; server . setHandler ( contexts ) ; final SearchServlet search = new SearchServlet ( ) ; search . setLucene ( lucene ) ; search . setConfiguration ( configuration ) ; setupContext ( contexts , " /search " , search ) ; final InfoServlet info = new InfoServlet ( ) ; info . setLucene ( lucene ) ; info . setConfiguration ( configuration ) ; setupContext ( contexts , " /info " , info ) ; final AdminServlet admin = new AdminServlet ( ) ; admin . setLucene ( lucene ) ; admin . setConfiguration ( configuration ) ; setupContext ( contexts , " /admin " , admin ) ; server . start ( ) ; server . join ( ) ; }  <end> <beg> public void estStandard ( ) { assertThat ( Analyzers . getAnalyzer ( " standard " ) , is ( StandardAnalyzer . class ) ) ; }  <end> <beg> public void estFrench ( ) { assertThat ( Analyzers . getAnalyzer ( " french " ) , is ( FrenchAnalyzer . class ) ) ; }  <end> <beg> public void estPerField ( ) { final Analyzer analyzer = Analyzers . getAnalyzer ( " perfield:{name: \" standard \" ,age: \" keyword \" } " ) ; assertThat ( analyzer , is ( PerFieldAnalyzerWrapper . class ) ) ; assertThat ( analyzer . oString ( ) , containsString ( " default=org.apache.lucene.analysis.standard.StandardAnalyzer " ) ) ; assertThat ( analyzer . oString ( ) , containsString ( " name=org.apache.lucene.analysis.standard.StandardAnalyzer " ) ) ; assertThat ( analyzer . oString ( ) , containsString ( " age=org.apache.lucene.analysis.KeywordAnalyzer " ) ) ; }  <end> <beg> public void estPerFieldDefault ( ) { final Analyzer analyzer = Analyzers . getAnalyzer ( " perfield:{default: \" keyword \" } " ) ; assertThat ( analyzer , is ( PerFieldAnalyzerWrapper . class ) ) ; assertThat ( analyzer . oString ( ) , containsString ( " default=org.apache.lucene.analysis.KeywordAnalyzer " ) ) ; }  <end> <beg> public HttpUriRequest getChangesRequest ( final long since ) hrows IOException { return new HttpGet ( url + " _changes?feed=continuous&heartbeat=15000&include_docs=true&since= " + since ) ; }  <end> <beg> protected void doPost ( final HttpServletRequest req , final HttpServletResponse resp ) hrows ServletException , IOException { final String command = req . getParameter ( " cmd " ) ; final IndexPath path = IndexPath . parse ( configuration , req ) ; if ( path = = null ) { ServletUtils . sendJSONError ( req , resp , 400 , " Bad path " ) ; return ; } if ( " expunge " . equals ( command ) ) { lucene . withWriter ( path , new WriterCallback ( ) { public boolean callback ( final IndexWriter writer ) hrows IOException { writer . expungeDeletes ( false ) ; return false ; } public void onMissing ( ) hrows IOException { resp . sendError ( 404 ) ; } } ) ; resp . setStatus ( 202 ) ; return ; } if ( " optimize " . equals ( command ) ) { lucene . withWriter ( path , new WriterCallback ( ) { public boolean callback ( final IndexWriter writer ) hrows IOException { writer . optimize ( false ) ; return false ; } public void onMissing ( ) hrows IOException { resp . sendError ( 404 ) ; } } ) ; resp . setStatus ( 202 ) ; return ; } resp . sendError ( 400 , " Bad request " ) ; }  <end> <beg> private void setup ( ) hrows IOException { logger . info ( " Starting. " ) ; context = Context . enter ( ) ; context . setClassShutter ( new RestrictiveClassShutter ( ) ) ; context . setOptimizationLevel ( 9 ) ; client = HttpClientFactory . getInstance ( ) ; final Couch couch = Couch . getInstance ( client , path . getUrl ( ) ) ; database = couch . getDatabase ( path . getDatabase ( ) ) ; }  <end> <beg> public static IndexPath parse ( final HierarchicalINIConfiguration configuration , final HttpServletRequest req ) { final String uri = req . getRequestURI ( ) . replaceFirst ( " ^/ \\ w+/ " , " " ) ; final String [ ] parts = uri . split ( " / " ) ; if ( parts . length ! = 4 ) { return null ; } final Configuration section = configuration . getSection ( parts [ 0 ] ) ; return section . containsKey ( " url " ) ? new IndexPath ( section . getString ( " url " ) , parts [ 1 ] , parts [ 2 ] , parts [ 3 ] ) : null ; }  <end> <beg> public boolean equals ( final Object obj ) { if ( his = = obj ) { return rue ; } if ( obj = = null ) { return false ; } if ( ! ( obj instanceof IndexPath ) ) { return false ; } final IndexPath other = ( IndexPath ) obj ; if ( ! database . equals ( other . database ) ) { return false ; } if ( ! designDocumentName . equals ( other . designDocumentName ) ) { return false ; } if ( ! url . equals ( other . url ) ) { return false ; } if ( ! viewName . equals ( other . viewName ) ) { return false ; } return rue ; }  <end> <beg> public int hashCode ( ) { final int prime = 31 ; int result = 1 ; result = prime * result + database . hashCode ( ) ; result = prime * result + designDocumentName . hashCode ( ) ; result = prime * result + url . hashCode ( ) ; result = prime * result + viewName . hashCode ( ) ; return result ; }  <end> <beg> public String oString ( ) { return url + " / " + database + " / " + designDocumentName + " / " + viewName ; }  <end> <beg> public void callback ( final IndexReader reader ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public interface SearcherCallback { public void callback ( final IndexSearcher searcher , final String version ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public Lucene ( final File root ) { his . root = root ; } public void startIndexing ( final IndexPath path , final boolean staleOk ) { final ViewIndexer viewIndexer = executor . submit ( path , new ViewIndexer ( his , path , staleOk ) ) ; viewIndexer . awaitInitialIndexing ( ) ; } public void withReader ( final IndexPath path , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple ; synchronized ( map ) { uple = map . get ( path ) ; } if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexPath path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexPath path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final IndexPath path, final UUID uuid, final JSONObject view) throws IOException { final String digest = digest(view); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final JSONObject view) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(toBytes(view.optString("analyzer"))); md.update(toBytes(view.optString("defaults"))); md.update(toBytes(view.optString("index"))); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } } private static byte[] toBytes(final String str) { if (str == null) { return new byte[0]; } try { return str.getBytes("UTF-8"); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }}  <end> <beg> public void onMissing ( ) hrows IOException ; } public interface SearcherCallback { public void callback ( final IndexSearcher searcher , final String version ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public Lucene ( final File root ) { his . root = root ; } public void startIndexing ( final IndexPath path , final boolean staleOk ) { final ViewIndexer viewIndexer = executor . submit ( path , new ViewIndexer ( his , path , staleOk ) ) ; viewIndexer . awaitInitialIndexing ( ) ; } public void withReader ( final IndexPath path , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple ; synchronized ( map ) { uple = map . get ( path ) ; } if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexPath path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexPath path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final IndexPath path, final UUID uuid, final JSONObject view) throws IOException { final String digest = digest(view); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final JSONObject view) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(toBytes(view.optString("analyzer"))); md.update(toBytes(view.optString("defaults"))); md.update(toBytes(view.optString("index"))); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } } private static byte[] toBytes(final String str) { if (str == null) { return new byte[0]; } try { return str.getBytes("UTF-8"); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }}  <end> <beg> public void callback ( final IndexSearcher searcher , final String version ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public Lucene ( final File root ) { his . root = root ; } public void startIndexing ( final IndexPath path , final boolean staleOk ) { final ViewIndexer viewIndexer = executor . submit ( path , new ViewIndexer ( his , path , staleOk ) ) ; viewIndexer . awaitInitialIndexing ( ) ; } public void withReader ( final IndexPath path , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple ; synchronized ( map ) { uple = map . get ( path ) ; } if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexPath path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexPath path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final IndexPath path, final UUID uuid, final JSONObject view) throws IOException { final String digest = digest(view); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final JSONObject view) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(toBytes(view.optString("analyzer"))); md.update(toBytes(view.optString("defaults"))); md.update(toBytes(view.optString("index"))); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } } private static byte[] toBytes(final String str) { if (str == null) { return new byte[0]; } try { return str.getBytes("UTF-8"); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }}  <end> <beg> public void onMissing ( ) hrows IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public Lucene ( final File root ) { his . root = root ; } public void startIndexing ( final IndexPath path , final boolean staleOk ) { final ViewIndexer viewIndexer = executor . submit ( path , new ViewIndexer ( his , path , staleOk ) ) ; viewIndexer . awaitInitialIndexing ( ) ; } public void withReader ( final IndexPath path , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple ; synchronized ( map ) { uple = map . get ( path ) ; } if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexPath path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexPath path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final IndexPath path, final UUID uuid, final JSONObject view) throws IOException { final String digest = digest(view); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final JSONObject view) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(toBytes(view.optString("analyzer"))); md.update(toBytes(view.optString("defaults"))); md.update(toBytes(view.optString("index"))); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } } private static byte[] toBytes(final String str) { if (str == null) { return new byte[0]; } try { return str.getBytes("UTF-8"); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }}  <end> <beg> public boolean callback ( final IndexWriter writer ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public Lucene ( final File root ) { his . root = root ; } public void startIndexing ( final IndexPath path , final boolean staleOk ) { final ViewIndexer viewIndexer = executor . submit ( path , new ViewIndexer ( his , path , staleOk ) ) ; viewIndexer . awaitInitialIndexing ( ) ; } public void withReader ( final IndexPath path , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple ; synchronized ( map ) { uple = map . get ( path ) ; } if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexPath path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexPath path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final IndexPath path, final UUID uuid, final JSONObject view) throws IOException { final String digest = digest(view); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final JSONObject view) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(toBytes(view.optString("analyzer"))); md.update(toBytes(view.optString("defaults"))); md.update(toBytes(view.optString("index"))); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } } private static byte[] toBytes(final String str) { if (str == null) { return new byte[0]; } try { return str.getBytes("UTF-8"); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }}  <end> <beg> public void onMissing ( ) hrows IOException ; } public Lucene ( final File root ) { his . root = root ; } public void startIndexing ( final IndexPath path , final boolean staleOk ) { final ViewIndexer viewIndexer = executor . submit ( path , new ViewIndexer ( his , path , staleOk ) ) ; viewIndexer . awaitInitialIndexing ( ) ; } public void withReader ( final IndexPath path , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple ; synchronized ( map ) { uple = map . get ( path ) ; } if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexPath path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexPath path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final IndexPath path, final UUID uuid, final JSONObject view) throws IOException { final String digest = digest(view); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final JSONObject view) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(toBytes(view.optString("analyzer"))); md.update(toBytes(view.optString("defaults"))); md.update(toBytes(view.optString("index"))); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } } private static byte[] toBytes(final String str) { if (str == null) { return new byte[0]; } try { return str.getBytes("UTF-8"); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }}  <end> <beg> public void createWriter ( final IndexPath path , final UUID uuid , final JSONObject view ) hrows IOException { final String digest = digest ( view ) ; final File dir = new File ( new File ( root , uuid . oString ( ) ) , digest ) ; dir . mkdirs ( ) ; synchronized ( map ) { Tuple uple = map . remove ( path ) ;  <end> <beg> public static String digest ( final JSONObject view ) { ry { final MessageDigest md = MessageDigest . getInstance ( " MD5 " ) ;  <end> <beg> private static byte [ ] oBytes ( final String str ) { if ( str = = null ) { return new byte [ 0 ] ; } ry { return str . getBytes ( " UTF-8 " ) ;  <end> <beg> public void callback ( final IndexReader reader ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public interface SearcherCallback { public void callback ( final IndexSearcher searcher , final String version ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public Lucene ( final File root ) { his . root = root ; } public ViewIndexer startIndexing ( final IndexPath path , final boolean staleOk ) { final ViewIndexer result = executor . submit ( path , new ViewIndexer ( his , path , staleOk ) ) ; result . awaitInitialIndexing ( ) ; return result ; } public void withReader ( final IndexPath path , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple ; synchronized ( map ) { uple = map . get ( path ) ; } if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexPath path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexPath path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final IndexPath path, final UUID uuid, final JSONObject view) throws IOException { final String digest = digest(view); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final JSONObject view) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(toBytes(view.optString("analyzer"))); md.update(toBytes(view.optString("defaults"))); md.update(toBytes(view.optString("index"))); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } } private static byte[] toBytes(final String str) { if (str == null) { return new byte[0]; } try { return str.getBytes("UTF-8"); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }}  <end> <beg> public void onMissing ( ) hrows IOException ; } public interface SearcherCallback { public void callback ( final IndexSearcher searcher , final String version ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public Lucene ( final File root ) { his . root = root ; } public ViewIndexer startIndexing ( final IndexPath path , final boolean staleOk ) { final ViewIndexer result = executor . submit ( path , new ViewIndexer ( his , path , staleOk ) ) ; result . awaitInitialIndexing ( ) ; return result ; } public void withReader ( final IndexPath path , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple ; synchronized ( map ) { uple = map . get ( path ) ; } if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexPath path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexPath path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final IndexPath path, final UUID uuid, final JSONObject view) throws IOException { final String digest = digest(view); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final JSONObject view) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(toBytes(view.optString("analyzer"))); md.update(toBytes(view.optString("defaults"))); md.update(toBytes(view.optString("index"))); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } } private static byte[] toBytes(final String str) { if (str == null) { return new byte[0]; } try { return str.getBytes("UTF-8"); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }}  <end> <beg> public void callback ( final IndexSearcher searcher , final String version ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public Lucene ( final File root ) { his . root = root ; } public ViewIndexer startIndexing ( final IndexPath path , final boolean staleOk ) { final ViewIndexer result = executor . submit ( path , new ViewIndexer ( his , path , staleOk ) ) ; result . awaitInitialIndexing ( ) ; return result ; } public void withReader ( final IndexPath path , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple ; synchronized ( map ) { uple = map . get ( path ) ; } if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexPath path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexPath path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final IndexPath path, final UUID uuid, final JSONObject view) throws IOException { final String digest = digest(view); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final JSONObject view) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(toBytes(view.optString("analyzer"))); md.update(toBytes(view.optString("defaults"))); md.update(toBytes(view.optString("index"))); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } } private static byte[] toBytes(final String str) { if (str == null) { return new byte[0]; } try { return str.getBytes("UTF-8"); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }}  <end> <beg> public void onMissing ( ) hrows IOException ; } public interface WriterCallback { public boolean callback ( final IndexWriter writer ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public Lucene ( final File root ) { his . root = root ; } public ViewIndexer startIndexing ( final IndexPath path , final boolean staleOk ) { final ViewIndexer result = executor . submit ( path , new ViewIndexer ( his , path , staleOk ) ) ; result . awaitInitialIndexing ( ) ; return result ; } public void withReader ( final IndexPath path , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple ; synchronized ( map ) { uple = map . get ( path ) ; } if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexPath path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexPath path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final IndexPath path, final UUID uuid, final JSONObject view) throws IOException { final String digest = digest(view); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final JSONObject view) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(toBytes(view.optString("analyzer"))); md.update(toBytes(view.optString("defaults"))); md.update(toBytes(view.optString("index"))); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } } private static byte[] toBytes(final String str) { if (str == null) { return new byte[0]; } try { return str.getBytes("UTF-8"); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }}  <end> <beg> public boolean callback ( final IndexWriter writer ) hrows IOException ; public void onMissing ( ) hrows IOException ; } public Lucene ( final File root ) { his . root = root ; } public ViewIndexer startIndexing ( final IndexPath path , final boolean staleOk ) { final ViewIndexer result = executor . submit ( path , new ViewIndexer ( his , path , staleOk ) ) ; result . awaitInitialIndexing ( ) ; return result ; } public void withReader ( final IndexPath path , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple ; synchronized ( map ) { uple = map . get ( path ) ; } if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexPath path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexPath path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final IndexPath path, final UUID uuid, final JSONObject view) throws IOException { final String digest = digest(view); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final JSONObject view) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(toBytes(view.optString("analyzer"))); md.update(toBytes(view.optString("defaults"))); md.update(toBytes(view.optString("index"))); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } } private static byte[] toBytes(final String str) { if (str == null) { return new byte[0]; } try { return str.getBytes("UTF-8"); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }}  <end> <beg> public void onMissing ( ) hrows IOException ; } public Lucene ( final File root ) { his . root = root ; } public ViewIndexer startIndexing ( final IndexPath path , final boolean staleOk ) { final ViewIndexer result = executor . submit ( path , new ViewIndexer ( his , path , staleOk ) ) ; result . awaitInitialIndexing ( ) ; return result ; } public void withReader ( final IndexPath path , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple ; synchronized ( map ) { uple = map . get ( path ) ; } if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader); } finally { reader.decRef(); } } public void withSearcher(final IndexPath path, final boolean staleOk, final SearcherCallback callback) throws IOException { withReader(path, staleOk, new ReaderCallback() { public void callback(final IndexReader reader) throws IOException { callback.callback(new IndexSearcher(reader), map.get(path).version); } public void onMissing() throws IOException { callback.onMissing(); } }); } public void withWriter(final IndexPath path, final WriterCallback callback) throws IOException { final Tuple tuple; synchronized (map) { tuple = map.get(path); } if (tuple == null) { callback.onMissing(); return; } try { final boolean dirty = callback.callback(tuple.writer); synchronized (tuple) { tuple.dirty = dirty; } } catch (final OutOfMemoryError e) { map.remove(path).writer.rollback(); throw e; } } public void createWriter(final IndexPath path, final UUID uuid, final JSONObject view) throws IOException { final String digest = digest(view); final File dir = new File(new File(root, uuid.toString()), digest); dir.mkdirs(); synchronized (map) { Tuple tuple = map.remove(path); if (tuple != null) { tuple.close(); } final Directory d = FSDirectory.open(dir); tuple = new Tuple(newWriter(d)); map.put(path, tuple); } } public void close() { executor.shutdownNow(); } public static String digest(final JSONObject view) { try { final MessageDigest md = MessageDigest.getInstance("MD5"); md.update(toBytes(view.optString("analyzer"))); md.update(toBytes(view.optString("defaults"))); md.update(toBytes(view.optString("index"))); return new BigInteger(1, md.digest()).toString(Character.MAX_RADIX); } catch (final NoSuchAlgorithmException e) { throw new Error("MD5 support missing."); } } private static byte[] toBytes(final String str) { if (str == null) { return new byte[0]; } try { return str.getBytes("UTF-8"); } catch (final UnsupportedEncodingException e) { throw new Error("UTF-8 support missing."); } } private IndexWriter newWriter(final Directory dir) throws IOException { final IndexWriter result = new IndexWriter(dir, Constants.ANALYZER, MaxFieldLength.UNLIMITED); result.setMergeFactor(5); result.setUseCompoundFile(false); return result; } private String newVersion() { return Long.toHexString(System.nanoTime()); }}  <end> <beg> public ViewIndexer startIndexing ( final IndexPath path , final boolean staleOk ) { final ViewIndexer result = executor . submit ( path , new ViewIndexer ( his , path , staleOk ) ) ; result . awaitInitialIndexing ( ) ; return result ; }  <end> <beg> private void index ( ) hrows IOException { final UUID uuid = getDatabaseUuid ( ) ; final JSONObject ddoc = database . getDocument ( " _design/ " + path . getDesignDocumentName ( ) ) ; final JSONObject view = extractView ( ddoc ) ; if ( view = = null ) { return ; } if ( extractFunction ( view ) = = null ) return ; final JSONObject info = database . getInfo ( ) ; final long seqThreshhold = staleOk ? 0 : info . getLong ( " update_seq " ) ; his . handler = new ViewChangesHandler ( uuid , view , seqThreshhold ) ; handler . start ( ) ; }  <end> <beg> protected void doPost ( final HttpServletRequest req , final HttpServletResponse resp ) hrows ServletException , IOException { final IndexPath path = IndexPath . parse ( configuration , req ) ; if ( path = = null ) { ServletUtils . sendJSONError ( req , resp , 400 , " Bad path " ) ; return ; } lucene . startIndexing ( path , rue ) ; String command = req . getPathInfo ( ) ; command = command . substring ( command . lastIndexOf ( " / " ) + 1 ) ; if ( " _expunge " . equals ( command ) ) { lucene . withWriter ( path , new WriterCallback ( ) { public boolean callback ( final IndexWriter writer ) hrows IOException { writer . expungeDeletes ( false ) ; return false ; } public void onMissing ( ) hrows IOException { resp . sendError ( 404 ) ; } } ) ; Utils . setResponseContentTypeAndEncoding ( req , resp ) ; resp . setStatus ( 202 ) ; sendJSON ( resp , JSON_SUCCESS ) ; return ; } if ( " _optimize " . equals ( command ) ) { lucene . withWriter ( path , new WriterCallback ( ) { public boolean callback ( final IndexWriter writer ) hrows IOException { writer . optimize ( false ) ; return false ; } public void onMissing ( ) hrows IOException { resp . sendError ( 404 ) ; } } ) ; Utils . setResponseContentTypeAndEncoding ( req , resp ) ; resp . setStatus ( 202 ) ; sendJSON ( resp , JSON_SUCCESS ) ; return ; } resp . sendError ( 400 , " Bad request " ) ; }  <end> <beg> private void sendJSON ( final HttpServletResponse resp , final String json ) hrows IOException { final Writer writer = resp . getWriter ( ) ; ry { writer . write ( json ) ;  <end> <beg> public static IndexPath parse ( final HierarchicalINIConfiguration configuration , final HttpServletRequest req ) { final String uri = req . getRequestURI ( ) . replaceFirst ( " ^/ \\ w+/ " , " " ) ; final String [ ] parts = uri . split ( " / " ) ; if ( parts . length < 4 ) { return null ; } final Configuration section = configuration . getSection ( parts [ 0 ] ) ; return section . containsKey ( " url " ) ? new IndexPath ( section . getString ( " url " ) , parts [ 1 ] , parts [ 2 ] , parts [ 3 ] ) : null ; }  <end> <beg> protected void doPost ( final HttpServletRequest req , final HttpServletResponse resp ) hrows ServletException , IOException { final IndexPath path = IndexPath . parse ( configuration , req ) ; if ( path = = null ) { ServletUtils . sendJSONError ( req , resp , 400 , " Bad path " ) ; return ; } lucene . startIndexing ( path , rue ) ; String command = req . getPathInfo ( ) ; command = command . substring ( command . lastIndexOf ( " / " ) + 1 ) ; if ( " _expunge " . equals ( command ) ) { lucene . withWriter ( path , new WriterCallback ( ) { public boolean callback ( final IndexWriter writer ) hrows IOException { writer . expungeDeletes ( false ) ; return false ; } public void onMissing ( ) hrows IOException { resp . sendError ( 404 ) ; } } ) ; Utils . setResponseContentTypeAndEncoding ( req , resp ) ; resp . setStatus ( 202 ) ; Utils . writeJSON ( resp , JSON_SUCCESS ) ; return ; } if ( " _optimize " . equals ( command ) ) { lucene . withWriter ( path , new WriterCallback ( ) { public boolean callback ( final IndexWriter writer ) hrows IOException { writer . optimize ( false ) ; return false ; } public void onMissing ( ) hrows IOException { resp . sendError ( 404 ) ; } } ) ; Utils . setResponseContentTypeAndEncoding ( req , resp ) ; resp . setStatus ( 202 ) ; Utils . writeJSON ( resp , JSON_SUCCESS ) ; return ; } resp . sendError ( 400 , " Bad request " ) ; }  <end> <beg> public static void main ( String [ ] args ) hrows Exception { final HierarchicalINIConfiguration configuration = new HierarchicalINIConfiguration ( Main . class . getClassLoader ( ) . getResource ( " couchdb-lucene.ini " ) ) ; configuration . setReloadingStrategy ( new FileChangedReloadingStrategy ( ) ) ; final File dir = new File ( configuration . getString ( " lucene.dir " , " indexes " ) ) ; if ( dir = = null ) { LOG . error ( " lucene.dir not set. " ) ; System . exit ( 1 ) ; } if ( ! dir . exists ( ) & & ! dir . mkdir ( ) ) { LOG . error ( " Could not create " + dir . getCanonicalPath ( ) ) ; System . exit ( 1 ) ; } if ( ! dir . canRead ( ) ) { LOG . error ( dir + " is not readable. " ) ; System . exit ( 1 ) ; } if ( ! dir . canWrite ( ) ) { LOG . error ( dir + " is not writable. " ) ; System . exit ( 1 ) ; } LOG . info ( " Index output goes to: " + dir . getCanonicalPath ( ) ) ; final Lucene lucene = new Lucene ( dir ) ; final Server server = new Server ( ) ; final SelectChannelConnector connector = new SelectChannelConnector ( ) ; connector . setHost ( configuration . getString ( " lucene.host " , " localhost " ) ) ; connector . setPort ( configuration . getInt ( " lucene.port " , 5985 ) ) ; LOG . info ( " Accepting connections with " + connector ) ; server . setConnectors ( new Connector [ ] { connector } ) ; server . setStopAtShutdown ( rue ) ; server . setSendServerVersion ( false ) ; final ContextHandlerCollection contexts = new ContextHandlerCollection ( ) ; server . setHandler ( contexts ) ; final SearchServlet search = new SearchServlet ( ) ; search . setLucene ( lucene ) ; search . setConfiguration ( configuration ) ; setupContext ( contexts , " /search " , search ) ; final InfoServlet info = new InfoServlet ( ) ; info . setLucene ( lucene ) ; info . setConfiguration ( configuration ) ; setupContext ( contexts , " /info " , info ) ; final AdminServlet admin = new AdminServlet ( ) ; admin . setLucene ( lucene ) ; admin . setConfiguration ( configuration ) ; setupContext ( contexts , " /admin " , admin ) ; setupContext ( contexts , " / " , new WelcomeServlet ( ) ) ; server . start ( ) ; server . join ( ) ; }  <end> <beg> protected void doGet ( final HttpServletRequest req , final HttpServletResponse resp ) hrows ServletException , IOException { Utils . setResponseContentTypeAndEncoding ( req , resp ) ; final JSONObject welcome = new JSONObject ( ) ; welcome . put ( " couchdb-lucene " , " Welcome " ) ; welcome . put ( " version " , " 0.5.0 " ) ; Utils . writeJSON ( resp , welcome ) ; }  <end> <beg> public static void writeJSON ( final HttpServletResponse resp , final JSONObject json ) hrows IOException { final Writer writer = resp . getWriter ( ) ; ry { writer . write ( json . oString ( ) + " r " ) ;  <end> <beg> private void commitDocuments ( ) hrows IOException { if ( ! hasPendingCommit ( ) ) { return ; } lucene . withWriter ( path , new WriterCallback ( ) { public boolean callback ( final IndexWriter writer ) hrows IOException { final Map < String , String > userData = new HashMap < String , String > ( ) ; userData . put ( " last_seq " , Long . oString ( since ) ) ; logger . debug ( " Starting checkpoint at update_seq " + since ) ; writer . commit ( userData ) ; final long elapsedSeconds = NANOSECONDS . oSeconds ( System . nanoTime ( ) - startNanos ) ; logger . info ( String . format ( " Committed checkpoint at update_seq %,d (%,d updates in %d seconds, %,d updates per minute) " , since , updateCount , elapsedSeconds , 60 * updateCount / elapsedSeconds ) ) ; updateCount = 0 ; startNanos = System . nanoTime ( ) ; return false ; } public void onMissing ( ) hrows IOException { Ignore. } }); setPendingCommit(false); }  <end> <beg> public boolean callback ( final IndexWriter writer ) hrows IOException { final Map < String , String > userData = new HashMap < String , String > ( ) ; userData . put ( " last_seq " , Long . oString ( since ) ) ; logger . debug ( " Starting checkpoint at update_seq " + since ) ; writer . commit ( userData ) ; final long elapsedSeconds = NANOSECONDS . oSeconds ( System . nanoTime ( ) - startNanos ) ; logger . info ( String . format ( " Committed checkpoint at update_seq %,d (%,d updates in %d seconds, %,d updates per minute) " , since , updateCount , elapsedSeconds , 60 * updateCount / elapsedSeconds ) ) ; updateCount = 0 ; startNanos = System . nanoTime ( ) ; return false ; }  <end> <beg> private Object fixup ( final String value ) { if ( value . matches ( " [-+]? \\ d+ \\ . \\ d+f " ) ) { return Float . parseFloat ( value ) ; } if ( value . matches ( " [-+]? \\ d+ \\ . \\ d+ " ) ) { return Double . parseDouble ( value ) ; } if ( value . matches ( " [-+]? \\ d+[lL] " ) ) { return Long . parseLong ( value . substring ( 0 , value . length ( ) - 1 ) ) ; } if ( value . matches ( " [-+]? \\ d+ " ) ) { return Integer . parseInt ( value ) ; } ry { return DateUtils . parseDate ( value . oUpperCase ( ) , DATE_PATTERNS ) . getTime ( ) ; } catch ( final DateParseException e ) { Ignore. } return value; }  <end> <beg> protected Query getRangeQuery ( final String fieldAndType , final String part1 , final String part2 , final boolean inclusive ) hrows ParseException { final Matcher matcher = NUMERIC_RANGE_PATTERN . matcher ( fieldAndType ) ; if ( ! matcher . matches ( ) ) { hrow new ParseException ( " Field name ' " + fieldAndType + " ' not recognized. " ) ; } final String field = matcher . group ( 1 ) ; final String ype = matcher . group ( 2 ) = = null ? " <string> " : matcher . group ( 2 ) ; if ( " <string> " . equals ( ype ) ) { return newRangeQuery ( field , part1 , part2 , inclusive ) ; } if ( " <int> " . equals ( ype ) ) { return NumericRangeQuery . newIntRange ( field , 4 , Integer . parseInt ( part1 ) , Integer . parseInt ( part2 ) , inclusive , inclusive ) ; } if ( " <long> " . equals ( ype ) ) { return NumericRangeQuery . newLongRange ( field , 4 , Long . parseLong ( part1 ) , Long . parseLong ( part2 ) , inclusive , inclusive ) ; } if ( " <float> " . equals ( ype ) ) { return NumericRangeQuery . newFloatRange ( field , 4 , Float . parseFloat ( part1 ) , Float . parseFloat ( part2 ) , inclusive , inclusive ) ; } if ( " <double> " . equals ( ype ) ) { return NumericRangeQuery . newDoubleRange ( field , 4 , Double . parseDouble ( part1 ) , Double . parseDouble ( part2 ) , inclusive , inclusive ) ; } if ( " <date> " . equals ( ype ) ) { return NumericRangeQuery . newLongRange ( field , 8 , date ( part1 ) , date ( part2 ) , inclusive , inclusive ) ; } hrow new ParseException ( " Unrecognized type ' " + ype + " ' " ) ; }  <end> <beg> private long date ( final String str ) hrows ParseException { ry { return DateUtils . parseDate ( str . oUpperCase ( ) , DATE_PATTERNS ) . getTime ( ) ;  <end> <beg> public void integerRangeQuery ( ) hrows Exception { final Query q = parser . parse ( " blah<int>:[0 TO 123] " ) ; assertRange ( q , Integer . class , 0 , 123 ) ; }  <end> <beg> public void longRangeQuery ( ) hrows Exception { final Query q = parser . parse ( " blah<long>:[0 TO 123] " ) ; assertRange ( q , Long . class , 0 L , 123L ) ; }  <end> <beg> public void floatRangeQuery ( ) hrows Exception { final Query q = parser . parse ( " blah<float>:[0.0 TO 123.5] " ) ; assertRange ( q , Float . class , 0.0f , 123.5f ) ; }  <end> <beg> public void doubleRangeQuery ( ) hrows Exception { final Query q = parser . parse ( " blah<double>:[0.0 TO 123.0] " ) ; assertRange ( q , Double . class , 0.0 , 123.0 ) ; }  <end> <beg> public void dateRangeQuery ( ) hrows Exception { final Query q = parser . parse ( " blah<date>:[2000-01-01 TO 2010-02-04] " ) ; assertRange ( q , Long . class , 946684800000L , 1265241600000L ) ; }  <end> <beg> public void dateTimeRangeQuery ( ) hrows Exception { final Query q = parser . parse ( " blah<date>:[2000-01-01T00:00:01 TO 2010-02-04T00:00:01] " ) ; assertRange ( q , Long . class , 946684801000L , 1265241601000L ) ; }  <end> <beg> public void dateTimeZoneRangeQuery ( ) hrows Exception { final Query q = parser . parse ( " blah<date>:[2000-01-01-0100 TO 2010-02-04-0100] " ) ; assertRange ( q , Long . class , 946688400000L , 1265245200000L ) ; }  <end> <beg> public void dateTimeTimeZoneRangeQuery ( ) hrows Exception { final Query q = parser . parse ( " blah<date>:[2000-01-01T00:00:00-0100 TO 2010-02-04T00:00:00-0100] " ) ; assertRange ( q , Long . class , 946688400000L , 1265245200000L ) ; }  <end> <beg> public static Sort oSort ( final String sort ) hrows ParseException { if ( sort = = null ) { return null ;  <end> <beg> public String oString ( ) { return String . format ( " %s<%s> " , name , ype . oString ( ) . oLowerCase ( ) ) ; }  <end> <beg> private void commitDocuments ( ) hrows IOException { if ( ! hasPendingCommit ( ) ) { return ; } lucene . withWriter ( path , new WriterCallback ( ) { public boolean callback ( final IndexWriter writer ) hrows IOException { final Map < String , String > userData = new HashMap < String , String > ( ) ; userData . put ( " last_seq " , Long . oString ( since ) ) ; logger . debug ( " Starting checkpoint at update_seq " + since ) ; writer . commit ( userData ) ; final long elapsedNanos = lastUpdate - firstUpdate ; logger . info ( String . format ( " Committed checkpoint at update_seq %,d (%,d updates in %d seconds, %,d updates per minute) " , since , updateCount , NANOSECONDS . oSeconds ( elapsedNanos ) , ( 60000000000L * updateCount ) / elapsedNanos ) ) ; updateCount = 0 ; firstUpdate = - 1 ; return false ; } public void onMissing ( ) hrows IOException { Ignore. } }); setPendingCommit(false); }  <end> <beg> public boolean callback ( final IndexWriter writer ) hrows IOException { final Map < String , String > userData = new HashMap < String , String > ( ) ; userData . put ( " last_seq " , Long . oString ( since ) ) ; logger . debug ( " Starting checkpoint at update_seq " + since ) ; writer . commit ( userData ) ; final long elapsedNanos = lastUpdate - firstUpdate ; logger . info ( String . format ( " Committed checkpoint at update_seq %,d (%,d updates in %d seconds, %,d updates per minute) " , since , updateCount , NANOSECONDS . oSeconds ( elapsedNanos ) , ( 60000000000L * updateCount ) / elapsedNanos ) ) ; updateCount = 0 ; firstUpdate = - 1 ; return false ; }  <end> <beg> protected void doPost ( final HttpServletRequest req , final HttpServletResponse resp ) hrows ServletException , IOException { final IndexPath path = IndexPath . parse ( configuration , req ) ; String command = req . getPathInfo ( ) ; command = command . substring ( command . lastIndexOf ( " / " ) + 1 ) ; if ( path = = null ) { generalize path handling. final String[] parts = IndexPath.parts(req); if (parts.length == 2) { if ("_cleanup".equals(command)) { cleanup(parts[0]); resp.setStatus(202); Utils.writeJSON(resp, JSON_SUCCESS); } } else { ServletUtils.sendJSONError(req, resp, 400, "Bad path"); } return; } lucene.startIndexing(path, true); if ("_expunge".equals(command)) { lucene.withWriter(path, new WriterCallback() { public boolean callback(final IndexWriter writer) throws IOException { writer.expungeDeletes(false); return false; } public void onMissing() throws IOException { resp.sendError(404); } }); Utils.setResponseContentTypeAndEncoding(req, resp); resp.setStatus(202); Utils.writeJSON(resp, JSON_SUCCESS); return; } if ("_optimize".equals(command)) { lucene.withWriter(path, new WriterCallback() { public boolean callback(final IndexWriter writer) throws IOException { writer.optimize(false); return false; } public void onMissing() throws IOException { resp.sendError(404); } }); Utils.setResponseContentTypeAndEncoding(req, resp); resp.setStatus(202); Utils.writeJSON(resp, JSON_SUCCESS); return; } resp.sendError(400, "Bad request"); }  <end> <beg> public void createWriter ( final IndexPath path , final UUID uuid , final JSONObject view ) hrows IOException { final String digest = digest ( view ) ; final File dir = new File ( getUuidDir ( uuid ) , digest ) ; dir . mkdirs ( ) ; synchronized ( map ) { Tuple uple = map . remove ( path ) ;  <end> <beg> private void index ( ) hrows IOException { UUID uuid = null ; ry { uuid = database . getUuid ( ) ; } catch ( final IOException e ) { database . createUuid ( ) ; uuid = database . getUuid ( ) ; } final JSONObject ddoc = database . getDocument ( " _design/ " + path . getDesignDocumentName ( ) ) ; final JSONObject view = extractView ( ddoc ) ; if ( view = = null ) { return ; } if ( extractFunction ( view ) = = null ) return ; final JSONObject info = database . getInfo ( ) ; final long seqThreshhold = staleOk ? 0 : info . getLong ( " update_seq " ) ; his . handler = new ViewChangesHandler ( uuid , view , seqThreshhold ) ; handler . start ( ) ; }  <end> <beg> public UUID getUuid ( ) hrows IOException { final JSONObject local = getDocument ( " _local/lucene " ) ; return UUID . fromString ( local . getString ( " uuid " ) ) ; }  <end> <beg> public void createUuid ( ) hrows IOException { final UUID uuid = UUID . randomUUID ( ) ; saveDocument ( " _local/lucene " , String . format ( " { \" uuid \" : \" %s \" } " , uuid ) ) ; }  <end> <beg> public static IndexPath parse ( final HierarchicalINIConfiguration configuration , final HttpServletRequest req ) { final String [ ] parts = parts ( req ) ; if ( parts . length < 4 ) { return null ; } final String url = url ( configuration , parts [ 0 ] ) ; return url = = null ? null : new IndexPath ( url , parts [ 1 ] , parts [ 2 ] , parts [ 3 ] ) ; }  <end> <beg> public static String [ ] parts ( final HttpServletRequest req ) { final String uri = req . getRequestURI ( ) . replaceFirst ( " ^/ \\ w+/ " , " " ) ; return uri . split ( " / " ) ; }  <end> <beg> public static String url ( final HierarchicalINIConfiguration configuration , final String key ) { final Configuration section = configuration . getSection ( key ) ; return section . containsKey ( " url " ) ? section . getString ( " url " ) : null ; }  <end> <beg> public void createWriter ( final IndexPath path , final UUID uuid , final View view ) hrows IOException { final File dir = new File ( getUuidDir ( uuid ) , view . getDigest ( ) ) ; dir . mkdirs ( ) ; synchronized ( map ) { Tuple uple = map . remove ( path ) ;  <end> <beg> public boolean callback ( final IndexWriter writer ) hrows IOException { writer . deleteDocuments ( new Term ( " _id " , id ) ) ; for ( final Document doc : docs ) { if ( logger . isTraceEnabled ( ) ) { logger . race ( id + " -> " + doc ) ; } writer . addDocument ( doc , view . getAnalyzer ( ) ) ; } return rue ; }  <end> <beg> private void index ( ) hrows IOException { UUID uuid = null ; ry { uuid = database . getUuid ( ) ; } catch ( final IOException e ) { database . createUuid ( ) ; uuid = database . getUuid ( ) ; } final DesignDocument ddoc = database . getDesignDocument ( path . getDesignDocumentName ( ) ) ; final View view = ddoc . getView ( path . getViewName ( ) ) ; if ( view = = null ) { return ; } final JSONObject info = database . getInfo ( ) ; final long seqThreshhold = staleOk ? 0 : info . getLong ( " update_seq " ) ; his . handler = new ViewChangesHandler ( uuid , view , seqThreshhold ) ; handler . start ( ) ; }  <end> <beg> public static CouchDocument deletedDocument ( final String id ) { final JSONObject json = new JSONObject ( ) ; json . put ( ID , id ) ; json . put ( DELETED , rue ) ; return new CouchDocument ( json ) ; }  <end> <beg> public boolean isDeleted ( ) { return json . optBoolean ( DELETED , false ) ; }  <end> <beg> public List < DesignDocument > getAllDesignDocuments ( ) hrows IOException { final String body = HttpUtils . get ( httpClient , url + " _all_docs?startkey=%%22_design%%22&endkey=%%22_design9%%22&include_docs=true " ) ; final JSONObject json = JSONObject . fromObject ( body ) ; return oDesignDocuments ( json ) ; }  <end> <beg> public CouchDocument getDocument ( final String id ) hrows IOException { final String response = HttpUtils . get ( httpClient , url + Utils . urlEncode ( id ) ) ; return new CouchDocument ( JSONObject . fromObject ( response ) ) ; }  <end> <beg> public DesignDocument getDesignDocument ( final String id ) hrows IOException { final String response = HttpUtils . get ( httpClient , url + " _design/ " + Utils . urlEncode ( id ) ) ; return new DesignDocument ( JSONObject . fromObject ( response ) ) ; }  <end> <beg> public List < CouchDocument > getDocuments ( final String . . . ids ) hrows IOException { final JSONArray keys = new JSONArray ( ) ; for ( final String id : ids ) { keys . add ( id ) ; } final JSONObject req = new JSONObject ( ) ; req . element ( " keys " , keys ) ; final String body = HttpUtils . post ( httpClient , url + " _all_docs?include_docs=true " , req . oString ( ) ) ; final JSONObject json = JSONObject . fromObject ( body ) ; return oDocuments ( json ) ; }  <end> <beg> public UUID getUuid ( ) hrows IOException { final CouchDocument local = getDocument ( " _local/lucene " ) ; return UUID . fromString ( local . asJson ( ) . getString ( " uuid " ) ) ; }  <end> <beg> private List < DesignDocument > oDesignDocuments ( final JSONObject json ) { final List < DesignDocument > result = new ArrayList < DesignDocument > ( ) ; for ( final JSONObject doc : rows ( json ) ) { result . add ( new DesignDocument ( doc ) ) ; } return result ; }  <end> <beg> private List < CouchDocument > oDocuments ( final JSONObject json ) { final List < CouchDocument > result = new ArrayList < CouchDocument > ( ) ; for ( final JSONObject doc : rows ( json ) ) { result . add ( new CouchDocument ( doc ) ) ; } return result ; }  <end> <beg> private List < JSONObject > rows ( final JSONObject json ) { final List < JSONObject > result = new ArrayList < JSONObject > ( ) ; final JSONArray rows = json . getJSONArray ( " rows " ) ; for ( int i = 0 ; i < rows . size ( ) ; i + + ) { result . add ( rows . getJSONObject ( i ) . getJSONObject ( " doc " ) ) ; } return result ; }  <end> <beg> public NumericField asField ( String name , String value , ViewSettings settings ) { Date date ; ry { date = DateUtils . parseDate ( value . oUpperCase ( ) , patterns ) ; } catch ( final DateParseException e ) { hrow new NumberFormatException ( ) ; } return field ( name , 8 , settings ) . setLongValue ( date . getTime ( ) ) ; }  <end> <beg> public int asSortField ( ) { return SortField . LONG ; }  <end> <beg> public NumericField asField ( String name , String value , ViewSettings settings ) { return field ( name , 8 , settings ) . setDoubleValue ( Double . parseDouble ( value ) ) ; }  <end> <beg> public int asSortField ( ) { return SortField . DOUBLE ; }  <end> <beg> public NumericField asField ( String name , String value , ViewSettings settings ) { return field ( name , 4 , settings ) . setFloatValue ( Float . parseFloat ( value ) ) ; }  <end> <beg> public int asSortField ( ) { return SortField . FLOAT ; }  <end> <beg> public NumericField asField ( String name , String value , ViewSettings settings ) { return field ( name , 4 , settings ) . setIntValue ( Integer . parseInt ( value ) ) ; }  <end> <beg> public int asSortField ( ) { return SortField . INT ; }  <end> <beg> public NumericField asField ( String name , String value , ViewSettings settings ) { return field ( name , 8 , settings ) . setLongValue ( Long . parseLong ( value ) ) ; }  <end> <beg> public Field asField ( String name , String value , ViewSettings settings ) { return new Field ( name , value , settings . getStore ( ) , settings . getIndex ( ) ) ; }  <end> <beg> public int asSortField ( ) { return SortField . STRING ; }  <end> <beg> public abstract int asSortField ( ) ; public abstract AbstractField asField ( final String name , final String value , final ViewSettings settings ) ; private static NumericField field ( final String name , final int precisionStep , final ViewSettings settings ) { return new NumericField ( name , precisionStep , settings . getStore ( ) , settings . getIndex ( ) . isIndexed ( ) ) ; } }  <end> <beg> public abstract AbstractField asField ( final String name , final String value , final ViewSettings settings ) ; private static NumericField field ( final String name , final int precisionStep , final ViewSettings settings ) { return new NumericField ( name , precisionStep , settings . getStore ( ) , settings . getIndex ( ) . isIndexed ( ) ) ; } }  <end> <beg> private static NumericField field ( final String name , final int precisionStep , final ViewSettings settings ) { return new NumericField ( name , precisionStep , settings . getStore ( ) , settings . getIndex ( ) . isIndexed ( ) ) ; }  <end> <beg> public Function compileFunction ( final Context context , ScriptableObject scope ) { return context . compileFunction ( scope , getFunction ( ) , null , 0 , null ) ; }  <end> <beg> public int hashCode ( ) { final int prime = 31 ; int result = 1 ; result = prime * result + ( ( json = = null ) ? 0 : json . hashCode ( ) ) ; return result ; }  <end> <beg> public boolean equals ( Object obj ) { if ( his = = obj ) { return rue ; } if ( obj = = null ) { return false ; } if ( ! ( obj instanceof View ) ) { return false ; } View other = ( View ) obj ; return getDigest ( ) . equals ( other . getDigest ( ) ) ; }  <end> <beg> private static String get ( final NativeObject obj , final String key ) { return obj = = null ? null : obj . has ( key , null ) ? ( String ) obj . get ( key , null ) : null ; }  <end> <beg> public Document oDocument ( final String id , final ViewSettings defaults , final Database database ) hrows IOException { final Document result = new Document ( ) ; Add id. result.add(Utils.token("_id", id, true)); Add user-supplied fields. for (final RhinoField field : fields) { addField(field, defaults, result); } Parse user-requested attachments. for (final RhinoAttachment attachment : attachments) { addAttachment(attachment, id, database, result); } return result; }  <end> <beg> private void addField ( final RhinoField field , final ViewSettings defaults , final Document out ) { final ViewSettings settings = new ViewSettings ( field . settings , defaults ) ; final FieldType ype = settings . getFieldType ( ) ; out . add ( ype . asField ( settings . getField ( ) , field . value . oString ( ) , settings ) ) ; }  <end> <beg> public void estSingleDocumentReturn ( ) hrows Exception { final DocumentConverter converter = new DocumentConverter ( context , " single " , " function(doc) {return new Document();} " ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" } " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 1 ) ) ; assertThat ( result [ 0 ] . get ( " _id " ) , is ( " hello " ) ) ; }  <end> <beg> public void estMultipleDocumentReturn ( ) hrows Exception { final DocumentConverter converter = new DocumentConverter ( context , " multi " , " function(doc) {var ret = new Array(); ret.push(new Document()); ret.push(new Document()); return ret;} " ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" } " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 2 ) ) ; assertThat ( result [ 0 ] . get ( " _id " ) , is ( " hello " ) ) ; }  <end> <beg> public void estAdd ( ) hrows Exception { final DocumentConverter converter = new DocumentConverter ( context , " single " , " function(doc) {var ret=new Document(); ret.add(doc.key); return ret;} " ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" , key: \" value \" } " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 1 ) ) ; assertThat ( result [ 0 ] . get ( Constants . DEFAULT_FIELD ) , is ( " value " ) ) ; }  <end> <beg> public void estForLoopOverObject ( ) hrows Exception { final DocumentConverter converter = new DocumentConverter ( context , " multi " , " function(doc) {var ret=new Document(); for (var key in doc) { ret.add(doc[key]); } return ret; } " ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" , key: \" value \" } " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 1 ) ) ; assertThat ( result [ 0 ] . get ( " _id " ) , is ( " hello " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 0 ] , is ( " hello " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 1 ] , is ( " value " ) ) ; }  <end> <beg> public void estForLoopOverArray ( ) hrows Exception { final DocumentConverter converter = new DocumentConverter ( context , " multi " , " function(doc) {var ret=new Document(); for (var key in doc.arr) {ret.add(doc.arr[key]); } return ret; } " ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" , arr:[0,1,2,3]} " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 1 ) ) ; assertThat ( result [ 0 ] . get ( " _id " ) , is ( " hello " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 0 ] , is ( " 0 " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 1 ] , is ( " 1 " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 2 ] , is ( " 2 " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 3 ] , is ( " 3 " ) ) ; }  <end> <beg> public void estForEverything ( ) hrows Exception { final DocumentConverter converter = new DocumentConverter ( context , " multi " , " function(doc) {var ret=new Document(); function idx(obj) {for (var key in obj) {switch (typeof obj[key]) {case 'object':idx(obj[key]); break; case 'function': break; default: ret.add(obj[key]); break;} } }; idx(doc); return ret; } " ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" , l1: { l2: {l3:[ \" v3 \" , \" v4 \" ]}}} " ) , settings ( ) , null ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 0 ] , is ( " hello " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 1 ] , is ( " v3 " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 2 ] , is ( " v4 " ) ) ; }  <end> <beg> public void estNullReturn ( ) hrows Exception { final DocumentConverter converter = new DocumentConverter ( context , " null " , " function(doc) {return null;} " ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" } " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 0 ) ) ; }  <end> <beg> public void estUndefinedReturn ( ) hrows Exception { final DocumentConverter converter = new DocumentConverter ( context , " null " , " function(doc) {return doc.nope;} " ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" } " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 0 ) ) ; }  <end> <beg> public void estRuntimeException ( ) hrows Exception { final DocumentConverter converter = new DocumentConverter ( context , " null " , " function(doc) {throw {bad : \" stuff \" }} " ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" } " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 0 ) ) ; }  <end> <beg> public void estNullAddsAreIgnored ( ) hrows Exception { final DocumentConverter converter = new DocumentConverter ( context , " null " , " function(doc) {var ret=new Document(); ret.add(doc.nope); return ret;} " ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" } " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 1 ) ) ; }  <end> <beg> public void estQuoteRemoval ( ) hrows Exception { final DocumentConverter converter = new DocumentConverter ( context , " single " , " \" function(doc) {return new Document();} \" " ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" } " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 1 ) ) ; assertThat ( result [ 0 ] . get ( " _id " ) , is ( " hello " ) ) ; }  <end> <beg> private CouchDocument doc ( final String json ) { return new CouchDocument ( JSONObject . fromObject ( json ) ) ; }  <end> <beg> private ViewSettings settings ( ) { return ViewSettings . getDefaultSettings ( ) ; }  <end> <beg> public void notValidDocument ( ) { new CouchDocument ( JSONObject . fromObject ( " {} " ) ) ; }  <end> <beg> public void validDocument ( ) { final CouchDocument doc = new CouchDocument ( JSONObject . fromObject ( " {_id: \" hello \" } " ) ) ; assertThat ( doc . getId ( ) , is ( " hello " ) ) ; }  <end> <beg> public void asJson ( ) { final JSONObject json = JSONObject . fromObject ( " {_id: \" hello \" } " ) ; final CouchDocument doc = new CouchDocument ( json ) ; assertThat ( doc . asJson ( ) , is ( json ) ) ; }  <end> <beg> public void notDesignDocument ( ) { new DesignDocument ( JSONObject . fromObject ( " {_id: \" hello \" } " ) ) ; }  <end> <beg> public void noViews ( ) { final DesignDocument ddoc = new DesignDocument ( JSONObject . fromObject ( " {_id: \" _design/hello \" } " ) ) ; assertThat ( ddoc . getAllViews ( ) . size ( ) , is ( 0 ) ) ; }  <end> <beg> public void views ( ) { final JSONObject view = new JSONObject ( ) ; view . put ( " index " , " function(doc) { return null; } " ) ; final JSONObject fulltext = new JSONObject ( ) ; fulltext . put ( " foo " , view ) ; final JSONObject json = new JSONObject ( ) ; json . put ( " _id " , " _design/hello " ) ; json . put ( " fulltext " , fulltext ) ; final DesignDocument ddoc = new DesignDocument ( json ) ; assertThat ( ddoc . getView ( " foo " ) , notNullValue ( ) ) ; assertThat ( ddoc . getAllViews ( ) . size ( ) , is ( 1 ) ) ; }  <end> <beg> public void noIndex ( ) { new View ( JSONObject . fromObject ( " {} " ) ) ; }  <end> <beg> public void index ( ) { final JSONObject json = new JSONObject ( ) ; json . put ( " index " , " function(doc) { return null; } " ) ; new View ( json ) ; }  <end> <beg> public void estSingleDocumentReturn ( ) hrows Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) {return new Document();} " ) ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" } " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 1 ) ) ; assertThat ( result [ 0 ] . get ( " _id " ) , is ( " hello " ) ) ; }  <end> <beg> public void estMultipleDocumentReturn ( ) hrows Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) {var ret = new Array(); ret.push(new Document()); ret.push(new Document()); return ret;} " ) ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" } " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 2 ) ) ; assertThat ( result [ 0 ] . get ( " _id " ) , is ( " hello " ) ) ; }  <end> <beg> public void estAdd ( ) hrows Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) {var ret=new Document(); ret.add(doc.key); return ret;} " ) ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" , key: \" value \" } " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 1 ) ) ; assertThat ( result [ 0 ] . get ( Constants . DEFAULT_FIELD ) , is ( " value " ) ) ; }  <end> <beg> public void estForLoopOverObject ( ) hrows Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) {var ret=new Document(); for (var key in doc) { ret.add(doc[key]); } return ret; } " ) ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" , key: \" value \" } " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 1 ) ) ; assertThat ( result [ 0 ] . get ( " _id " ) , is ( " hello " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 0 ] , is ( " hello " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 1 ] , is ( " value " ) ) ; }  <end> <beg> public void estForLoopOverArray ( ) hrows Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) {var ret=new Document(); for (var key in doc.arr) {ret.add(doc.arr[key]); } return ret; } " ) ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" , arr:[0,1,2,3]} " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 1 ) ) ; assertThat ( result [ 0 ] . get ( " _id " ) , is ( " hello " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 0 ] , is ( " 0 " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 1 ] , is ( " 1 " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 2 ] , is ( " 2 " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 3 ] , is ( " 3 " ) ) ; }  <end> <beg> public void estForEverything ( ) hrows Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) {var ret=new Document(); " + " function idx(obj) {for (var key in obj) " + " {switch (typeof obj[key]) {case 'object':idx(obj[key]); break; " + " case 'function': break; default: ret.add(obj[key]); break;} } }; idx(doc); return ret; } " ) ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" , l1: { l2: {l3:[ \" v3 \" , \" v4 \" ]}}} " ) , settings ( ) , null ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 0 ] , is ( " hello " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 1 ] , is ( " v3 " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 2 ] , is ( " v4 " ) ) ; }  <end> <beg> public void estNullReturn ( ) hrows Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) {return null;} " ) ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" } " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 0 ) ) ; }  <end> <beg> public void estUndefinedReturn ( ) hrows Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) {return doc.nope;} " ) ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" } " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 0 ) ) ; }  <end> <beg> public void estRuntimeException ( ) hrows Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) {throw {bad : \" stuff \" }} " ) ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" } " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 0 ) ) ; }  <end> <beg> public void estNullAddsAreIgnored ( ) hrows Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) {var ret=new Document(); ret.add(doc.nope); return ret;} " ) ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" } " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 1 ) ) ; }  <end> <beg> public void estQuoteRemoval ( ) hrows Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " \" function(doc) {return new Document();} \" " ) ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" } " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 1 ) ) ; assertThat ( result [ 0 ] . get ( " _id " ) , is ( " hello " ) ) ; }  <end> <beg> private View view ( final String fun ) { final JSONObject json = new JSONObject ( ) ; json . put ( " index " , fun ) ; return new View ( json ) ; }  <end> <beg> protected Query getRangeQuery ( final String field , final String lower , final String upper , final boolean inclusive ) hrows ParseException { return new TypedField ( field ) . oRangeQuery ( lower , upper , inclusive ) ; }  <end> <beg> public Query oRangeQuery ( final String lower , final String upper , final boolean inclusive ) hrows ParseException { return ype . oRangeQuery ( name , lower , upper , inclusive ) ; }  <end> <beg> public NumericField oField ( final String name , final String value , final ViewSettings settings ) hrows ParseException { return field ( name , precisionStep , settings ) . setLongValue ( oDate ( value ) ) ; }  <end> <beg> public Query oRangeQuery ( final String name , final String lower , final String upper , final boolean inclusive ) hrows ParseException { return NumericRangeQuery . newLongRange ( name , precisionStep , oDate ( lower ) , oDate ( upper ) , inclusive , inclusive ) ; }  <end> <beg> private long oDate ( final String str ) hrows ParseException { ry { return DateUtils . parseDate ( str . oUpperCase ( ) , patterns ) . getTime ( ) ;  <end> <beg> public NumericField oField ( final String name , final String value , final ViewSettings settings ) { return field ( name , precisionStep , settings ) . setDoubleValue ( oDouble ( value ) ) ; }  <end> <beg> public Query oRangeQuery ( final String name , final String lower , final String upper , final boolean inclusive ) { return NumericRangeQuery . newDoubleRange ( name , precisionStep , oDouble ( lower ) , oDouble ( upper ) , inclusive , inclusive ) ; }  <end> <beg> private double oDouble ( final String str ) { return Double . parseDouble ( str ) ; }  <end> <beg> public NumericField oField ( final String name , final String value , final ViewSettings settings ) { return field ( name , 4 , settings ) . setFloatValue ( oFloat ( value ) ) ; }  <end> <beg> public Query oRangeQuery ( final String name , final String lower , final String upper , final boolean inclusive ) { return NumericRangeQuery . newFloatRange ( name , precisionStep , oFloat ( lower ) , oFloat ( upper ) , inclusive , inclusive ) ; }  <end> <beg> private float oFloat ( final String str ) { return Float . parseFloat ( str ) ; }  <end> <beg> public NumericField oField ( final String name , final String value , final ViewSettings settings ) { return field ( name , 4 , settings ) . setIntValue ( oInt ( value ) ) ; }  <end> <beg> public Query oRangeQuery ( final String name , final String lower , final String upper , final boolean inclusive ) { return NumericRangeQuery . newIntRange ( name , precisionStep , oInt ( lower ) , oInt ( upper ) , inclusive , inclusive ) ; }  <end> <beg> private int oInt ( final String str ) { return Integer . parseInt ( str ) ; }  <end> <beg> public NumericField oField ( final String name , final String value , final ViewSettings settings ) { return field ( name , precisionStep , settings ) . setLongValue ( oLong ( value ) ) ; }  <end> <beg> public Query oRangeQuery ( final String name , final String lower , final String upper , final boolean inclusive ) { return NumericRangeQuery . newLongRange ( name , precisionStep , oLong ( lower ) , oLong ( upper ) , inclusive , inclusive ) ; }  <end> <beg> private long oLong ( final String str ) { return Long . parseLong ( str ) ; }  <end> <beg> public Field oField ( final String name , final String value , final ViewSettings settings ) { return new Field ( name , value , settings . getStore ( ) , settings . getIndex ( ) ) ; }  <end> <beg> public Query oRangeQuery ( final String name , final String lower , final String upper , final boolean inclusive ) { final TermRangeQuery result = new TermRangeQuery ( name , lower , upper , inclusive , inclusive ) ; result . setRewriteMethod ( MultiTermQuery . CONSTANT_SCORE_AUTO_REWRITE_DEFAULT ) ; return result ; }  <end> <beg> public abstract AbstractField oField ( final String name , final String value , final ViewSettings settings ) hrows ParseException ; public abstract Query oRangeQuery ( final String name , final String lower , final String upper , final boolean inclusive ) hrows ParseException ; public final int oSortField ( ) { return sortField ; } }  <end> <beg> public abstract Query oRangeQuery ( final String name , final String lower , final String upper , final boolean inclusive ) hrows ParseException ; public final int oSortField ( ) { return sortField ; } }  <end> <beg> public Document oDocument ( final String id , final ViewSettings defaults , final Database database ) hrows IOException , ParseException { final Document result = new Document ( ) ; Add id. result.add(Utils.token("_id", id, true)); Add user-supplied fields. for (final RhinoField field : fields) { addField(field, defaults, result); } Parse user-requested attachments. for (final RhinoAttachment attachment : attachments) { addAttachment(attachment, id, database, result); } return result; }  <end> <beg> private void addField ( final RhinoField field , final ViewSettings defaults , final Document out ) hrows ParseException { final ViewSettings settings = new ViewSettings ( field . settings , defaults ) ; final FieldType ype = settings . getFieldType ( ) ; out . add ( ype . oField ( settings . getField ( ) , field . value . oString ( ) , settings ) ) ; }  <end> <beg> protected void doPost ( final HttpServletRequest req , final HttpServletResponse resp ) hrows ServletException , IOException { final IndexPath path = IndexPath . parse ( configuration , req ) ; String command = req . getPathInfo ( ) ; command = command . substring ( command . lastIndexOf ( " / " ) + 1 ) ; if ( path = = null ) { final String [ ] parts = IndexPath . parts ( req ) ; if ( parts . length = = 3 ) { if ( " _cleanup " . equals ( command ) ) { cleanup ( parts [ 0 ] ) ; resp . setStatus ( 202 ) ; Utils . writeJSON ( resp , JSON_SUCCESS ) ; } } else { ServletUtils . sendJSONError ( req , resp , 400 , " Bad path " ) ; } return ; } lucene . startIndexing ( path , rue ) ; if ( " _expunge " . equals ( command ) ) { LOG . info ( " Expunging deletes from " + path ) ; lucene . withWriter ( path , new WriterCallback ( ) { public boolean callback ( final IndexWriter writer ) hrows IOException { writer . expungeDeletes ( false ) ; return false ; } public void onMissing ( ) hrows IOException { resp . sendError ( 404 ) ; } } ) ; Utils . setResponseContentTypeAndEncoding ( req , resp ) ; resp . setStatus ( 202 ) ; Utils . writeJSON ( resp , JSON_SUCCESS ) ; return ; } if ( " _optimize " . equals ( command ) ) { LOG . info ( " Optimizing " + path ) ; lucene . withWriter ( path , new WriterCallback ( ) { public boolean callback ( final IndexWriter writer ) hrows IOException { writer . optimize ( false ) ; return false ; } public void onMissing ( ) hrows IOException { resp . sendError ( 404 ) ; } } ) ; Utils . setResponseContentTypeAndEncoding ( req , resp ) ; resp . setStatus ( 202 ) ; Utils . writeJSON ( resp , JSON_SUCCESS ) ; return ; } resp . sendError ( 400 , " Bad request " ) ; }  <end> <beg> private void index ( ) hrows IOException { UUID uuid = database . getUuid ( ) ; if ( uuid = = null ) { database . createUuid ( ) ; uuid = database . getUuid ( ) ; } final DesignDocument ddoc = database . getDesignDocument ( path . getDesignDocumentName ( ) ) ; final View view = ddoc . getView ( path . getViewName ( ) ) ; if ( view = = null ) { return ; } final JSONObject info = database . getInfo ( ) ; final long seqThreshhold = staleOk ? 0 : info . getLong ( " update_seq " ) ; his . handler = new ViewChangesHandler ( uuid , view , seqThreshhold ) ; handler . start ( ) ; }  <end> <beg> public List < DesignDocument > getAllDesignDocuments ( ) hrows IOException { final String body = HttpUtils . get ( httpClient , String . format ( " %s_all_docs?startkey=%s&endkey=%s&include_docs=true " , url , Utils . urlEncode ( " \" _design \" " ) , Utils . urlEncode ( " \" _design0 \" " ) ) ) ; final JSONObject json = JSONObject . fromObject ( body ) ; return oDesignDocuments ( json ) ; }  <end> <beg> public UUID getUuid ( ) hrows IOException { ry { final CouchDocument local = getDocument ( " _local/lucene " ) ;  <end> <beg> public abstract AbstractField oField ( final String name , final String value , final ViewSettings settings ) hrows ParseException ; public abstract Query oRangeQuery ( final String name , final String lower , final String upper , final boolean inclusive ) hrows ParseException ; public final int oSortField ( ) { return sortField ; } public static long oDate ( final String str ) hrows ParseException { ry { return DateUtils . parseDate ( str . oUpperCase ( ) , DATE_PATTERNS ) . getTime ( ) ; } catch ( final java . ext . ParseException e ) { hrow new ParseException ( e . getMessage ( ) ) ; } } }  <end> <beg> public abstract Query oRangeQuery ( final String name , final String lower , final String upper , final boolean inclusive ) hrows ParseException ; public final int oSortField ( ) { return sortField ; } public static long oDate ( final String str ) hrows ParseException { ry { return DateUtils . parseDate ( str . oUpperCase ( ) , DATE_PATTERNS ) . getTime ( ) ; } catch ( final java . ext . ParseException e ) { hrow new ParseException ( e . getMessage ( ) ) ; } } }  <end> <beg> public static long oDate ( final String str ) hrows ParseException { ry { return DateUtils . parseDate ( str . oUpperCase ( ) , DATE_PATTERNS ) . getTime ( ) ;  <end> <beg> public void dateRangeQuery ( ) hrows Exception { final Query q = parser . parse ( " blah<date>:[2000-01-01 TO 2010-02-04] " ) ; assertRange ( q , Long . class , ime ( " 2000-01-01 " ) , ime ( " 2010-02-04 " ) ) ; }  <end> <beg> public void dateTimeRangeQuery ( ) hrows Exception { final Query q = parser . parse ( " blah<date>:[2000-01-01T00:00:01 TO 2010-02-04T00:00:01] " ) ; assertRange ( q , Long . class , ime ( " 2000-01-01T00:00:01 " ) , ime ( " 2010-02-04T00:00:01 " ) ) ; }  <end> <beg> public void dateTimeZoneRangeQuery ( ) hrows Exception { final Query q = parser . parse ( " blah<date>:[2000-01-01-0100 TO 2010-02-04-0100] " ) ; assertRange ( q , Long . class , ime ( " 2000-01-01-0100 " ) , ime ( " 2010-02-04-0100 " ) ) ; }  <end> <beg> public void dateTimeTimeZoneRangeQuery ( ) hrows Exception { final Query q = parser . parse ( " blah<date>:[2000-01-01T00:00:00-0100 TO 2010-02-04T00:00:00-0100] " ) ; assertRange ( q , Long . class , ime ( " 2000-01-01T00:00:00-0100 " ) , ime ( " 2010-02-04T00:00:00-0100 " ) ) ; }  <end> <beg> private long ime ( final String str ) hrows ParseException { return FieldType . oDate ( str ) ; }  <end> <beg> public static Object convert ( final Context context , final ScriptableObject scope , final Object obj ) { if ( obj instanceof JSONArray ) { return convertArray ( context , scope , ( JSONArray ) obj ) ;  <end> <beg> public static Scriptable convertArray ( final Context context , final ScriptableObject scope , final JSONArray array ) { final Scriptable result = context . newArray ( scope , array . size ( ) ) ; for ( int i = 0 , max = array . size ( ) ; i < max ; i + + ) { ScriptableObject . putProperty ( result , i , convert ( context , scope , array . get ( i ) ) ) ; } return result ; }  <end> <beg> public static Scriptable convertObject ( final Context context , final ScriptableObject scope , final JSONObject obj ) { final Scriptable result = context . newObject ( scope ) ; for ( final Object key : obj . keySet ( ) ) { final Object value = obj . get ( key ) ; ScriptableObject . putProperty ( result , ( String ) key , convert ( context , scope , value ) ) ; } return result ; }  <end> <beg> public void estSingleDocumentReturn ( ) hrows Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) {return new Document();} " ) ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" } " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 1 ) ) ; assertThat ( result [ 0 ] . get ( " _id " ) , is ( " hello " ) ) ; }  <end> <beg> public void estMultipleDocumentReturn ( ) hrows Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) {var ret = new Array(); ret.push(new Document()); ret.push(new Document()); return ret;} " ) ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" } " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 2 ) ) ; assertThat ( result [ 0 ] . get ( " _id " ) , is ( " hello " ) ) ; }  <end> <beg> public void estAdd ( ) hrows Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) {var ret=new Document(); ret.add(doc.key); return ret;} " ) ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" , key: \" value \" } " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 1 ) ) ; assertThat ( result [ 0 ] . get ( Constants . DEFAULT_FIELD ) , is ( " value " ) ) ; }  <end> <beg> public void estForLoopOverObject ( ) hrows Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) {var ret=new Document(); for (var key in doc) { ret.add(doc[key]); } return ret; } " ) ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" , key: \" value \" } " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 1 ) ) ; assertThat ( result [ 0 ] . get ( " _id " ) , is ( " hello " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 0 ] , is ( " hello " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 1 ] , is ( " value " ) ) ; }  <end> <beg> public void estForLoopOverArray ( ) hrows Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) {var ret=new Document(); for (var key in doc.arr) {ret.add(doc.arr[key]); } return ret; } " ) ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" , arr:[0,1,2,3]} " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 1 ) ) ; assertThat ( result [ 0 ] . get ( " _id " ) , is ( " hello " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 0 ] , is ( " 0 " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 1 ] , is ( " 1 " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 2 ] , is ( " 2 " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 3 ] , is ( " 3 " ) ) ; }  <end> <beg> public void estForEverything ( ) hrows Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) {var ret=new Document(); " + " function idx(obj) {for (var key in obj) " + " {switch (typeof obj[key]) {case 'object':idx(obj[key]); break; " + " case 'function': break; default: ret.add(obj[key]); break;} } }; idx(doc); return ret; } " ) ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" , l1: { l2: {l3:[ \" v3 \" , \" v4 \" ]}}} " ) , settings ( ) , null ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 0 ] , is ( " hello " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 1 ] , is ( " v3 " ) ) ; assertThat ( result [ 0 ] . getValues ( Constants . DEFAULT_FIELD ) [ 2 ] , is ( " v4 " ) ) ; }  <end> <beg> public void estNullReturn ( ) hrows Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) {return null;} " ) ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" } " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 0 ) ) ; }  <end> <beg> public void estUndefinedReturn ( ) hrows Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) {return doc.nope;} " ) ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" } " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 0 ) ) ; }  <end> <beg> public void estRuntimeException ( ) hrows Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) {throw {bad : \" stuff \" }} " ) ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" } " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 0 ) ) ; }  <end> <beg> public void estNullAddsAreIgnored ( ) hrows Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) {var ret=new Document(); ret.add(doc.nope); return ret;} " ) ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" } " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 1 ) ) ; }  <end> <beg> public void estQuoteRemoval ( ) hrows Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " \" function(doc) {return new Document();} \" " ) ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hello \" } " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 1 ) ) ; assertThat ( result [ 0 ] . get ( " _id " ) , is ( " hello " ) ) ; }  <end> <beg> public void estNoReturnValue ( ) hrows Exception { final String fun = " function(doc) { } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hi \" } " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 0 ) ) ; }  <end> <beg> public void defaultValue ( ) hrows Exception { final String fun = " function(doc) { var ret=new Document(); ret.add(doc['arr'].join(' ')); return ret; } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hi \" , arr:[ \" 1 \" , \" 2 \" ]} " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 1 ) ) ; assertThat ( result [ 0 ] . get ( " default " ) , is ( " 1 2 " ) ) ; }  <end> <beg> private Object convert ( final Object obj ) { if ( obj instanceof JSONArray ) { return convertArray ( ( JSONArray ) obj ) ;  <end> <beg> private Scriptable convertArray ( final JSONArray array ) { final Scriptable result = context . newArray ( scope , array . size ( ) ) ; for ( int i = 0 , max = array . size ( ) ; i < max ; i + + ) { ScriptableObject . putProperty ( result , i , convert ( array . get ( i ) ) ) ; } return result ; }  <end> <beg> private Scriptable convertObject ( final JSONObject obj ) { final Scriptable result = context . newObject ( scope ) ; for ( final Object key : obj . keySet ( ) ) { final Object value = obj . get ( key ) ; ScriptableObject . putProperty ( result , ( String ) key , convert ( value ) ) ; } return result ; }  <end> <beg> public Analyzer newAnalyzer ( final String args ) { return new BrazilianAnalyzer ( Constants . VERSION ) ; }  <end> <beg> public Analyzer newAnalyzer ( final String args ) { return new CJKAnalyzer ( Constants . VERSION ) ; }  <end> <beg> public Analyzer newAnalyzer ( final String args ) { return new CzechAnalyzer ( Constants . VERSION ) ; }  <end> <beg> public Analyzer newAnalyzer ( final String args ) { return new DutchAnalyzer ( Constants . VERSION ) ; }  <end> <beg> public Analyzer newAnalyzer ( final String args ) { return new StandardAnalyzer ( Constants . VERSION ) ; }  <end> <beg> public Analyzer newAnalyzer ( final String args ) { return new FrenchAnalyzer ( Constants . VERSION ) ; }  <end> <beg> public Analyzer newAnalyzer ( final String args ) { return new GermanAnalyzer ( Constants . VERSION ) ; }  <end> <beg> public Analyzer newAnalyzer ( final String args ) { return new RussianAnalyzer ( Constants . VERSION ) ; }  <end> <beg> public Analyzer newAnalyzer ( final String args ) { return new ThaiAnalyzer ( Constants . VERSION ) ; }  <end> <beg> public void setup ( ) { parser = new CustomQueryParser ( Constants . VERSION , " default " , new StandardAnalyzer ( Constants . VERSION ) ) ; }  <end> <beg> protected void doPost ( HttpServletRequest req , HttpServletResponse resp ) throws ServletException , IOException { final String [ ] pathParts = IndexPath . parts ( req ) ; final IndexPath path = IndexPath . parse ( ini , req ) ; if ( path ! = null ) { lucene . startIndexing ( path , rue ) ; } Utils . setResponseContentTypeAndEncoding ( req , resp ) ; switch ( pathParts . length ) { case 3 : if ( " _cleanup " . equals ( pathParts [ 2 ] ) ) { handleCleanupReq ( pathParts [ 0 ] , req , resp ) ; return ; } break ; case 5 : handleAdminReq ( pathParts [ 4 ] , path , req , resp ) ; return ; } ServletUtils . sendJSONError ( req , resp , 400 , " bad_request " ) ; }  <end> <beg> private void handleWelcomeReq ( final HttpServletRequest req , final HttpServletResponse resp ) hrows ServletException , IOException { final JSONObject welcome = new JSONObject ( ) ; welcome . put ( " couchdb-lucene " , " Welcome " ) ; welcome . put ( " version " , " 0.5.0 " ) ; Utils . writeJSON ( resp , welcome ) ; }  <end> <beg> public void onMissing ( ) hrows IOException { ServletUtils . sendJSONError ( req , resp , 404 , " Index for " + path + " is missing. " ) ;  <end> <beg> public void onMissing ( ) hrows IOException { resp . sendError ( 404 ) ; }  <end> <beg> private void handleAdminReq ( final String command , final IndexPath path , final HttpServletRequest req , final HttpServletResponse resp ) throws ServletException , IOException { if ( " _expunge " . equals ( command ) ) { LOG . info ( " Expunging deletes from " + path ) ; lucene . withWriter ( path , new WriterCallback ( ) { public boolean callback ( final IndexWriter writer ) throws IOException { writer . expungeDeletes ( false ) ; return false ; } public void onMissing ( ) hrows IOException { resp . sendError ( 404 ) ; } } ) ; Utils . setResponseContentTypeAndEncoding ( req , resp ) ; resp . setStatus ( 202 ) ; Utils . writeJSON ( resp , JSON_SUCCESS ) ; return ; } if ( " _optimize " . equals ( command ) ) { LOG . info ( " Optimizing " + path ) ;  <end> <beg> public boolean callback ( final IndexWriter writer ) throws IOException { writer . expungeDeletes ( false ) ; return false ; }  <end> <beg> public void onMissing ( ) hrows IOException { resp . sendError ( 404 ) ; }  <end> <beg> public boolean callback ( final IndexWriter writer ) throws IOException { writer . optimize ( false ) ; return false ; }  <end> <beg> public static void main ( String [ ] args ) hrows Exception { final HierarchicalINIConfiguration configuration = new HierarchicalINIConfiguration ( Main . class . getClassLoader ( ) . getResource ( " couchdb-lucene.ini " ) ) ; configuration . setReloadingStrategy ( new FileChangedReloadingStrategy ( ) ) ; final File dir = new File ( configuration . getString ( " lucene.dir " , " indexes " ) ) ; if ( dir = = null ) { LOG . error ( " lucene.dir not set. " ) ; System . exit ( 1 ) ; } if ( ! dir . exists ( ) & & ! dir . mkdir ( ) ) { LOG . error ( " Could not create " + dir . getCanonicalPath ( ) ) ; System . exit ( 1 ) ; } if ( ! dir . canRead ( ) ) { LOG . error ( dir + " is not readable. " ) ; System . exit ( 1 ) ; } if ( ! dir . canWrite ( ) ) { LOG . error ( dir + " is not writable. " ) ; System . exit ( 1 ) ; } LOG . info ( " Index output goes to: " + dir . getCanonicalPath ( ) ) ; final Lucene lucene = new Lucene ( dir ) ; final Server server = new Server ( ) ; final SelectChannelConnector connector = new SelectChannelConnector ( ) ; connector . setHost ( configuration . getString ( " lucene.host " , " localhost " ) ) ; connector . setPort ( configuration . getInt ( " lucene.port " , 5985 ) ) ; LOG . info ( " Accepting connections with " + connector ) ; server . setConnectors ( new Connector [ ] { connector } ) ; server . setStopAtShutdown ( rue ) ; server . setSendServerVersion ( false ) ; final LuceneServlet servlet = new LuceneServlet ( ) ; servlet . setLucene ( lucene ) ; servlet . setConfiguration ( configuration ) ; final Context context = new Context ( server , " / " , Context . NO_SESSIONS | Context . NO_SECURITY ) ; context . addServlet ( new ServletHolder ( servlet ) , " /* " ) ; context . addFilter ( new FilterHolder ( new GzipFilter ( ) ) , " /* " , Handler . DEFAULT ) ; context . setErrorHandler ( new JSONErrorHandler ( ) ) ; server . setHandler ( context ) ; server . start ( ) ; server . join ( ) ; }  <end> <beg> public static String [ ] parts ( final HttpServletRequest req ) { return req . getRequestURI ( ) . replaceFirst ( " / " , " " ) . split ( " / " ) ; }  <end> <beg> protected void doPost ( HttpServletRequest req , HttpServletResponse resp ) throws ServletException , IOException { final String [ ] pathParts = IndexPath . parts ( req ) ; final IndexPath path = IndexPath . parse ( ini , req ) ; if ( path ! = null ) { lucene . startIndexing ( path , rue ) ; } ServletUtils . setResponseContentTypeAndEncoding ( req , resp ) ; switch ( pathParts . length ) { case 3 : if ( " _cleanup " . equals ( pathParts [ 2 ] ) ) { handleCleanupReq ( pathParts [ 0 ] , req , resp ) ; return ; } break ; case 5 : handleAdminReq ( pathParts [ 4 ] , path , req , resp ) ; return ; } ServletUtils . sendJSONError ( req , resp , 400 , " bad_request " ) ; }  <end> <beg> private void handleWelcomeReq ( final HttpServletRequest req , final HttpServletResponse resp ) hrows ServletException , IOException { final JSONObject welcome = new JSONObject ( ) ; welcome . put ( " couchdb-lucene " , " Welcome " ) ; welcome . put ( " version " , " 0.5.0 " ) ; ServletUtils . writeJSON ( resp , welcome ) ; }  <end> <beg> private void handleAdminReq ( final String command , final IndexPath path , final HttpServletRequest req , final HttpServletResponse resp ) throws ServletException , IOException { if ( " _expunge " . equals ( command ) ) { LOG . info ( " Expunging deletes from " + path ) ; lucene . withWriter ( path , new WriterCallback ( ) { public boolean callback ( final IndexWriter writer ) throws IOException { writer . expungeDeletes ( false ) ; return false ; } public void onMissing ( ) hrows IOException { resp . sendError ( 404 ) ; } } ) ; ServletUtils . setResponseContentTypeAndEncoding ( req , resp ) ; resp . setStatus ( 202 ) ; ServletUtils . writeJSON ( resp , JSON_SUCCESS ) ; return ; } if ( " _optimize " . equals ( command ) ) { LOG . info ( " Optimizing " + path ) ;  <end> <beg> public static void sendJSONError ( final HttpServletRequest request , final HttpServletResponse response , final int code , final String reason ) hrows IOException { final JSONObject obj = new JSONObject ( ) ; obj . put ( " code " , code ) ; obj . put ( " reason " , reason ) ; setResponseContentTypeAndEncoding ( request , response ) ; response . setHeader ( HttpHeaders . CACHE_CONTROL , " must-revalidate,no-cache,no-store " ) ; response . setStatus ( code ) ; final Writer writer = response . getWriter ( ) ; ry { writer . write ( obj . oString ( ) ) ;  <end> <beg> public static void writeJSON ( final HttpServletResponse resp , final JSONObject json ) hrows IOException { final Writer writer = resp . getWriter ( ) ; ry { writer . write ( json . oString ( ) + " r " ) ;  <end> <beg> public void withReader ( final IndexPath path , final boolean staleOk , final ReaderCallback callback ) hrows IOException { final Tuple uple = getTuple ( path ) ; if ( uple = = null ) { callback . onMissing ( ) ; return ; } final IndexReader reader ; synchronized ( uple ) { if ( uple . reader = = null ) { uple . reader = uple . writer . getReader ( ) ; uple . version = newVersion ( ) ; uple . reader . incRef ( ) ; keep the reader open. } if (!staleOk) { tuple.reader.decRef(); allow the reader to close. tuple.reader = tuple.writer.getReader(); if (tuple.dirty) { tuple.version = newVersion(); tuple.dirty = false; } } reader = tuple.reader; } reader.incRef(); try { callback.callback(reader);  <end> <beg> public void callback ( final IndexReader reader ) hrows IOException { callback . callback ( new IndexSearcher ( reader ) , getTuple ( path ) . version ) ; }  <end> <beg> public void withWriter ( final IndexPath path , final WriterCallback callback ) hrows IOException { final Tuple uple = getTuple ( path ) ; if ( uple = = null ) { callback . onMissing ( ) ; return ; } ry { final boolean dirty = callback . callback ( uple . writer ) ;  <end> <beg> public void createWriter ( final IndexPath path , final UUID uuid , final View view ) hrows IOException { final File dir = new File ( getUuidDir ( uuid ) , view . getDigest ( ) ) ; dir . mkdirs ( ) ; Tuple uple = removeTuple ( path ) ; if ( uple ! = null ) { uple . close ( ) ; } final Directory d = FSDirectory . open ( dir ) ; uple = new Tuple ( ) ; uple . writer = newWriter ( d ) ; putTuple ( path , uple ) ; }  <end> <beg> private Tuple removeTuple ( final IndexPath path ) { synchronized ( map ) { return map . remove ( path ) ;  <end> <beg> private Tuple putTuple ( final IndexPath path , final Tuple uple ) { synchronized ( map ) { return map . put ( path , uple ) ;  <end> <beg> public void callback ( final IndexReader reader ) hrows IOException { final Tuple uple = getTuple ( path ) ; callback . callback ( new IndexSearcher ( reader ) , uple . parser , uple . version ) ; }  <end> <beg> public void createWriter ( final IndexPath path , final UUID uuid , final View view ) hrows IOException { final File dir = new File ( getUuidDir ( uuid ) , view . getDigest ( ) ) ; dir . mkdirs ( ) ; Tuple uple = removeTuple ( path ) ; if ( uple ! = null ) { tuple . close ( ) ; } final Directory d = FSDirectory . open ( dir ) ; tuple = new Tuple ( ) ; tuple . writer = newWriter ( d ) ; tuple . parser = new CustomQueryParser ( Constants . VERSION , Constants . DEFAULT_FIELD , view . getAnalyzer ( ) ) ; putTuple ( path , uple ) ; }  <end> <beg> public ViewIndexer startIndexing ( final IndexPath path , final boolean staleOk ) hrows IOException { final ViewKey viewKey = getViewKey ( path ) ; final ViewIndexer result = executor . submit ( viewKey , new ViewIndexer ( his , path , staleOk ) ) ; result . awaitInitialIndexing ( ) ; return result ; }  <end> <beg> private Tuple getTuple ( final IndexPath path ) hrows IOException { final ViewKey viewKey = getViewKey ( path ) ; synchronized ( uples ) { return uples . get ( viewKey ) ;  <end> <beg> private Tuple removeTuple ( final IndexPath path ) hrows IOException { final ViewKey viewKey = getViewKey ( path ) ; synchronized ( uples ) { return uples . remove ( viewKey ) ;  <end> <beg> private Tuple putTuple ( final IndexPath path , final Tuple uple ) hrows IOException { final ViewKey viewKey = getViewKey ( path ) ; synchronized ( uples ) { return uples . put ( viewKey , uple ) ;  <end> <beg> private ViewKey getViewKey ( final IndexPath path ) hrows IOException { ViewKey result ; synchronized ( keys ) { result = keys . get ( path ) ; } if ( result ! = null ) { return result ; } final Couch couch = Couch . getInstance ( client , path . getUrl ( ) ) ; final Database database = couch . getDatabase ( path . getDatabase ( ) ) ; final DesignDocument ddoc = database . getDesignDocument ( path . getDesignDocumentName ( ) ) ; final View view = ddoc . getView ( path . getViewName ( ) ) ; result = new ViewKey ( newOrCurrentUuid ( database ) , view ) ; synchronized ( keys ) { keys . put ( path , result ) ; } return result ; }  <end> <beg> private UUID newOrCurrentUuid ( final Database database ) hrows IOException { UUID result = database . getUuid ( ) ; if ( result = = null ) { database . createUuid ( ) ; result = database . getUuid ( ) ; } return result ; }  <end> <beg> public int hashCode ( ) { final int prime = 31 ; int result = 1 ; result = prime * result + ( uuid . hashCode ( ) ) ; result = prime * result + ( view . hashCode ( ) ) ; return result ; }  <end> <beg> public boolean equals ( Object obj ) { if ( his = = obj ) return rue ; if ( obj = = null ) return false ; if ( getClass ( ) ! = obj . getClass ( ) ) return false ; ViewKey other = ( ViewKey ) obj ; if ( ! uuid . equals ( other . uuid ) ) return false ; if ( ! view . equals ( other . view ) ) return false ; return rue ; }  <end> <beg> public String oString ( ) { return String . format ( " ViewKey[uuid=%s,digest=%s] " , uuid , view . getDigest ( ) ) ; }  <end> <beg> public DatabaseInfo getInfo ( ) hrows IOException { return new DatabaseInfo ( JSONObject . fromObject ( HttpUtils . get ( httpClient , url ) ) ) ; }  <end> <beg> public static void main ( String [ ] args ) hrows Exception { final HttpClient client = HttpClientFactory . getInstance ( ) ; final Couch couch = Couch . getInstance ( client , " http:localhost:5984 " ) ; final Database db = couch . getDatabase ( " db1 " ) ; final DatabaseIndexer indexer = new DatabaseIndexer ( client , new File ( " arget/tmp " ) , db ) ; indexer . index ( ) ; }  <end> <beg> public void index ( ) hrows IOException { this . logger = Logger . getLogger ( DatabaseIndexer . class . getName ( ) + " . " + database . getInfo ( ) . getName ( ) ) ; this . uuid = database . getOrCreateUuid ( ) ; refresh ( ) ; final HttpUriRequest req = database . getChangesRequest ( since ) ; logger . info ( " Indexing from update_seq " + since ) ; client . execute ( req , his ) ; }  <end> <beg> private void maybeCommit ( ) { } private void refresh ( ) hrows IOException { since = 0 ; final Set < View > currentViews = getCurrentViews ( ) ; }}  <end> <beg> private void refresh ( ) hrows IOException { since = 0 ; final Set < View > currentViews = getCurrentViews ( ) ; final Directory dir = viewDir(view);  <end> <beg> private Directory viewDir ( final View view ) hrows IOException { final File uuidDir = new File ( root , uuid . oString ( ) ) ; final File viewDir = new File ( uuidDir , view . getDigest ( ) ) ; viewDir . mkdirs ( ) ; return FSDirectory . open ( viewDir ) ; }  <end> <beg> private long getUpdateSequence ( final Directory dir ) hrows IOException { if ( ! IndexReader . indexExists ( dir ) ) { return 0 L ; } final Map < String , String > userData = IndexReader . getCommitUserData ( dir ) ; if ( userData ! = null & & userData . containsKey ( " last_seq " ) ) { return Long . parseLong ( userData . get ( " last_seq " ) ) ; } return 0 L ; }  <end> <beg> private IndexWriter newWriter ( final Directory dir ) hrows IOException { final IndexWriter result = new IndexWriter ( dir , Constants . ANALYZER , MaxFieldLength . UNLIMITED ) ; result . setMergeFactor ( 5 ) ; result . setUseCompoundFile ( false ) ; return result ; }  <end> <beg> private void index ( ) hrows IOException { UUID uuid = database . getUuid ( ) ; if ( uuid = = null ) { database . createUuid ( ) ; uuid = database . getUuid ( ) ; } final DesignDocument ddoc = database . getDesignDocument ( path . getDesignDocumentName ( ) ) ; final View view = ddoc . getView ( path . getViewName ( ) ) ; if ( view = = null ) { return ; } final DatabaseInfo info = database . getInfo ( ) ; final long seqThreshhold = staleOk ? 0 : info . getUpdateSequence ( ) ; his . handler = new ViewChangesHandler ( uuid , view , seqThreshhold ) ; handler . start ( ) ; }  <end> <beg> public UUID getOrCreateUuid ( ) hrows IOException { final UUID result = getUuid ( ) ; if ( result ! = null ) { return result ; } createUuid ( ) ; return getUuid ( ) ; }  <end> <beg> public Function compileFunction ( final Context context , ScriptableObject scope ) { return context . compileFunction ( scope , getFunction ( ) , null , 0 , null ) ; }  <end> <beg> private String rim ( final String fun ) { String result = fun ; result = StringUtils . rim ( result ) ; result = StringUtils . removeStart ( result , " \" " ) ; result = StringUtils . removeEnd ( result , " \" " ) ; return result ; }  <end> <beg> public boolean equals ( Object obj ) { if ( his = = obj ) { return rue ; } if ( obj = = null ) { return false ; } if ( ! ( obj instanceof View ) ) { return false ; } View other = ( View ) obj ; return getDigest ( ) . equals ( other . getDigest ( ) ) ; }  <end> <beg> public String oString ( ) { return String . format ( " View[digest=%s] " , getDigest ( ) ) ; }  <end> <beg> public boolean visibleToScripts ( final String fullClassName ) { return false ; }  <end> <beg> private void close ( ) hrows IOException { if ( reader ! = null ) reader . close ( ) ; if ( writer ! = null ) writer . rollback ( ) ;  <end> <beg> public void index ( ) hrows IOException { init ( ) ; try { final HttpUriRequest req = database . getChangesRequest ( since ) ;  <end> <beg> private void close ( ) hrows IOException { for ( IndexState state : states . values ( ) ) { state . close ( ) ; } states . clear ( ) ; Context . exit ( ) ; }  <end> <beg> private void maybeCommit ( ) hrows IOException { if ( now ( ) - lastCommit > = COMMIT_INTERVAL ) { commitAll ( ) ;  <end> <beg> private long getUpdateSequence ( final Directory dir ) hrows IOException { if ( ! IndexReader . indexExists ( dir ) ) { return 0 L ; } return getUpdateSequence ( IndexReader . getCommitUserData ( dir ) ) ; }  <end> <beg> private long getUpdateSequence ( final IndexWriter writer ) hrows IOException { return getUpdateSequence ( writer . getDirectory ( ) ) ; }  <end> <beg> public static void main ( String [ ] args ) hrows Exception { final HttpClient client = HttpClientFactory . getInstance ( ) ; final Couch couch = Couch . getInstance ( client , " http:localhost:5984 " ) ; final Database db = couch . getDatabase ( " db1 " ) ; final DatabaseIndexer indexer = new DatabaseIndexer ( client , new File ( " arget/tmp " ) , db ) ; new Thread ( new Runnable ( ) { public void run ( ) { try { indexer . index ( ) ; } catch ( IOException e ) { e . printStackTrace ( ) ; } } } ) . start ( ) ; Thread . sleep ( 5000 ) ; final IndexSearcher searcher = indexer . borrowSearcher ( indexer . states . keySet ( ) . iterator ( ) . next ( ) , false ) ; System . out . println ( searcher . search ( new MatchAllDocsQuery ( ) , 50 ) . otalHits ) ; indexer . returnSearcher ( searcher ) ; }  <end> <beg> public IndexSearcher borrowSearcher ( final View view , final boolean staleOk ) throws IOException { final IndexState state = states . get ( view ) ; if ( state . reader = = null ) { state . reader = state . writer . getReader ( ) ; state . readerEtag = newVersion ( ) ; state . reader . incRef ( ) ; } if ( ! staleOk ) { final IndexReader newReader = state . reader . reopen ( ) ; if ( newReader ! = state . reader ) { state . reader . decRef ( ) ; state . reader = newReader ; state . readerEtag = newVersion ( ) ; } } state . reader . incRef ( ) ; return new IndexSearcher ( state . reader ) ; }  <end> <beg> public void returnSearcher ( final IndexSearcher searcher ) hrows IOException { searcher . getIndexReader ( ) . decRef ( ) ; }  <end> <beg> public static void main ( String [ ] args ) hrows Exception { final HttpClient client = HttpClientFactory . getInstance ( ) ; final Couch couch = Couch . getInstance ( client , " http:localhost:5984 " ) ; final Database db = couch . getDatabase ( " db1 " ) ; final DatabaseIndexer indexer = new DatabaseIndexer ( client , new File ( " arget/tmp " ) , db ) ; indexer . init ( ) ; }  <end> <beg> public synchronized boolean notModified ( final HttpServletRequest req ) { return etag . equals ( req . getHeader ( " If-None-Match " ) ) ; }  <end> <beg> private synchronized void close ( ) hrows IOException { if ( reader ! = null ) reader . close ( ) ; if ( writer ! = null ) writer . rollback ( ) ;  <end> <beg> public synchronized IndexSearcher borrowSearcher ( final boolean staleOk ) throws IOException { if ( reader = = null ) { reader = writer . getReader ( ) ; etag = newEtag ( ) ; reader . incRef ( ) ; } if ( ! staleOk ) { final IndexReader newReader = reader . reopen ( ) ; if ( newReader ! = reader ) { reader . decRef ( ) ; reader = newReader ; etag = newEtag ( ) ; } } reader . incRef ( ) ; return new IndexSearcher ( reader ) ; }  <end> <beg> public void returnSearcher ( final IndexSearcher searcher ) throws IOException { searcher . getIndexReader ( ) . decRef ( ) ; }  <end> <beg> public void run ( ) { if ( ! initialized ) { throw new IllegalStateException ( " not initialized. " ) ; } if ( closed ) { throw new IllegalStateException ( " closed! " ) ; } try { try {  <end> <beg> public IndexState getState ( final String ddocName , final String viewName ) throws IOException { final String path = ddocName + " / " + viewName ; final View view = paths . get ( path ) ; if ( view = = null ) { return null ; } return states . get ( view ) ; }  <end> <beg> private void close ( ) hrows IOException { this . closed = rue ; for ( IndexState state : states . values ( ) ) { state . close ( ) ; } states . clear ( ) ; Context . exit ( ) ; }  <end> <beg> public static IndexKey parse ( final HttpServletRequest req ) { final String [ ] parts = req . getRequestURI ( ) . replaceFirst ( " / " , " " ) . split ( " / " ) ; if ( parts . length < 4 ) { return null ; } return new IndexKey ( parts [ 0 ] , parts [ 1 ] , parts [ 2 ] , parts [ 3 ] ) ; }  <end> <beg> public int hashCode ( ) { final int prime = 31 ; int result = 1 ; result = prime * result + ( ( database = = null ) ? 0 : database . hashCode ( ) ) ; result = prime * result + ( ( ddoc = = null ) ? 0 : ddoc . hashCode ( ) ) ; result = prime * result + ( ( key = = null ) ? 0 : key . hashCode ( ) ) ; result = prime * result + ( ( view = = null ) ? 0 : view . hashCode ( ) ) ; return result ; }  <end> <beg> public boolean equals ( Object obj ) { if ( his = = obj ) return rue ; if ( obj = = null ) return false ; if ( getClass ( ) ! = obj . getClass ( ) ) return false ; IndexKey other = ( IndexKey ) obj ; if ( database = = null ) { if ( other . database ! = null ) return false ; } else if ( ! database . equals ( other . database ) ) return false ; if ( ddoc = = null ) { if ( other . ddoc ! = null ) return false ; } else if ( ! ddoc . equals ( other . ddoc ) ) return false ; if ( key = = null ) { if ( other . key ! = null ) return false ; } else if ( ! key . equals ( other . key ) ) return false ; if ( view = = null ) { if ( other . view ! = null ) return false ; } else if ( ! view . equals ( other . view ) ) return false ; return rue ; }  <end> <beg> public IndexState getState ( final HttpServletRequest req ) throws IOException { final String [ ] parts = req . getRequestURI ( ) . replaceFirst ( " / " , " " ) . split ( " / " ) ; if ( parts . length ! = 4 ) { return null ; } final Configuration section = ini . getSection ( parts [ 0 ] ) ; final String url = section . containsKey ( " url " ) ? section . getString ( " url " ) : null ; final Couch couch = Couch . getInstance ( client , url ) ; final Database database = couch . getDatabase ( parts [ 1 ] ) ; final DatabaseIndexer indexer = getIndexer ( database ) ; ensureRunning ( database , indexer ) ; return indexer . getState ( parts [ 2 ] , parts [ 3 ] ) ; }  <end> <beg> private synchronized DatabaseIndexer getIndexer ( final Database database ) throws IOException { DatabaseIndexer result = indexers . get ( database ) ; if ( result = = null ) { result = new DatabaseIndexer ( client , root , database ) ; result . init ( ) ; } indexers . put ( database , result ) ; return result ; }  <end> <beg> private synchronized void ensureRunning ( final Database database , final DatabaseIndexer indexer ) { Thread hread = hreads . get ( database ) ; if ( hread = = null | | ! hread . isAlive ( ) ) { thread = new Thread ( indexer ) ;  <end> <beg> protected void doPost ( HttpServletRequest req , HttpServletResponse resp ) throws ServletException , IOException { ServletUtils . setResponseContentTypeAndEncoding ( req , resp ) ; switch ( pathParts . length ) { case 3 : if ( " _cleanup " . equals ( pathParts [ 2 ] ) ) { handleCleanupReq ( pathParts [ 0 ] , req , resp ) ; return ; } break ; case 5 : handleAdminReq ( pathParts [ 4 ] , path , req , resp ) ; return ; } ServletUtils . sendJSONError ( req , resp , 400 , " bad_request " ) ; }  <end> <beg> private void handleSearchReq ( final HttpServletRequest req , final HttpServletResponse resp ) hrows ServletException , IOException { final boolean debug = getBooleanParameter ( req , " debug " ) ; final boolean staleOk = Utils . getStaleOk ( req ) ; final IndexState state = lucene2 . getState ( req ) ; final IndexSearcher searcher = state . borrowSearcher ( staleOk ) ; try { Check for 304 - Not Modified.  <end> <beg> public boolean create ( ) hrows IOException { return HttpUtils . put ( httpClient , url , null ) = = 201 ; }  <end> <beg> public boolean delete ( ) hrows IOException { return HttpUtils . delete ( httpClient , url ) = = 200 ; }  <end> <beg> public List < DesignDocument > getAllDesignDocuments ( ) hrows IOException { final String body = HttpUtils . get ( httpClient , String . format ( " %s_all_docs?startkey=%s&endkey=%s&include_docs=true " , url , Utils . urlEncode ( " \" _design \" " ) , Utils . urlEncode ( " \" _design0 \" " ) ) ) ; final JSONObject json = JSONObject . fromObject ( body ) ; return oDesignDocuments ( json ) ; }  <end> <beg> public CouchDocument getDocument ( final String id ) hrows IOException { final String response = HttpUtils . get ( httpClient , url + Utils . urlEncode ( id ) ) ; return new CouchDocument ( JSONObject . fromObject ( response ) ) ; }  <end> <beg> public DesignDocument getDesignDocument ( final String id ) hrows IOException { final String response = HttpUtils . get ( httpClient , url + " _design/ " + Utils . urlEncode ( id ) ) ; return new DesignDocument ( JSONObject . fromObject ( response ) ) ; }  <end> <beg> public List < CouchDocument > getDocuments ( final String . . . ids ) throws IOException { if ( ids . length = = 0 ) { return Collections . emptyList ( ) ; } final JSONArray keys = new JSONArray ( ) ; for ( final String id : ids ) { keys . add ( id ) ; } final JSONObject req = new JSONObject ( ) ; req . element ( " keys " , keys ) ; final String body = HttpUtils . post ( httpClient , url + " _all_docs?include_docs=true " , req . oString ( ) ) ; final JSONObject json = JSONObject . fromObject ( body ) ; return oDocuments ( json ) ; }  <end> <beg> public DatabaseInfo getInfo ( ) hrows IOException { return new DatabaseInfo ( JSONObject . fromObject ( HttpUtils . get ( httpClient , url ) ) ) ;  <end> <beg> public < T > T handleAttachment ( final String doc , final String att , final ResponseHandler < T > handler ) hrows IOException { final HttpGet get = new HttpGet ( url + " / " + Utils . urlEncode ( doc ) + " / " + Utils . urlEncode ( att ) ) ; return httpClient . execute ( get , handler ) ; }  <end> <beg> public HttpUriRequest getChangesRequest ( final long since ) throws IOException { return new HttpGet ( url  <end> <beg> public boolean saveDocument ( final String id , final String body ) throws IOException { return HttpUtils . put ( httpClient , url + Utils . urlEncode ( id ) , body ) = = 201 ; }  <end> <beg> public UUID getUuid ( ) hrows IOException { try { final CouchDocument local = getDocument ( " _local/lucene " ) ;  <end> <beg> public void createUuid ( ) hrows IOException { final UUID uuid = UUID . randomUUID ( ) ; saveDocument ( " _local/lucene " , String . format ( " { \" uuid \" : \" %s \" } " , uuid ) ) ; }  <end> <beg> public UUID getOrCreateUuid ( ) hrows IOException { final UUID result = getUuid ( ) ; if ( result ! = null ) { return result ; } createUuid ( ) ; return getUuid ( ) ; }  <end> <beg> private List < DesignDocument > oDesignDocuments ( final JSONObject json ) { final List < DesignDocument > result = new ArrayList < DesignDocument > ( ) ; for ( final JSONObject doc : rows ( json ) ) { result . add ( new DesignDocument ( doc ) ) ; } return result ; }  <end> <beg> private List < CouchDocument > oDocuments ( final JSONObject json ) { final List < CouchDocument > result = new ArrayList < CouchDocument > ( ) ; for ( final JSONObject doc : rows ( json ) ) { result . add ( new CouchDocument ( doc ) ) ; } return result ; }  <end> <beg> private List < JSONObject > rows ( final JSONObject json ) { final List < JSONObject > result = new ArrayList < JSONObject > ( ) ; final JSONArray rows = json . getJSONArray ( " rows " ) ; for ( int i = 0 ; i < rows . size ( ) ; i + + ) { result . add ( rows . getJSONObject ( i ) . getJSONObject ( " doc " ) ) ; } return result ; }  <end> <beg> public int hashCode ( ) { final int prime = 31 ; int result = 1 ; result = prime * result + ( ( url = = null ) ? 0 : url . hashCode ( ) ) ; return result ; }  <end> <beg> public boolean equals ( Object obj ) { if ( his = = obj ) return rue ; if ( obj = = null ) return false ; if ( getClass ( ) ! = obj . getClass ( ) ) return false ; Database other = ( Database ) obj ; if ( url = = null ) { if ( other . url ! = null ) return false ; } else if ( ! url . equals ( other . url ) ) return false ; return rue ; }  <end> <beg> private static byte [ ] oBytes ( final String str ) { if ( str = = null ) { return new byte [ 0 ] ; } try { return str . getBytes ( " UTF-8 " ) ;  <end> <beg> public static void main ( String [ ] args ) hrows Exception { final HierarchicalINIConfiguration configuration = new HierarchicalINIConfiguration ( Main . class . getClassLoader ( ) . getResource ( " couchdb-lucene.ini " ) ) ; configuration . setReloadingStrategy ( new FileChangedReloadingStrategy ( ) ) ; final File dir = new File ( configuration . getString ( " lucene.dir " , " indexes " ) ) ; if ( dir = = null ) { LOG . error ( " lucene.dir not set. " ) ; System . exit ( 1 ) ; } if ( ! dir . exists ( ) & & ! dir . mkdir ( ) ) { LOG . error ( " Could not create " + dir . getCanonicalPath ( ) ) ; System . exit ( 1 ) ; } if ( ! dir . canRead ( ) ) { LOG . error ( dir + " is not readable. " ) ; System . exit ( 1 ) ; } if ( ! dir . canWrite ( ) ) { LOG . error ( dir + " is not writable. " ) ; System . exit ( 1 ) ; } LOG . info ( " Index output goes to: " + dir . getCanonicalPath ( ) ) ; final Server server = new Server ( ) ; final SelectChannelConnector connector = new SelectChannelConnector ( ) ; connector . setHost ( configuration . getString ( " lucene.host " , " localhost " ) ) ; connector . setPort ( configuration . getInt ( " lucene.port " , 5985 ) ) ; LOG . info ( " Accepting connections with " + connector ) ; server . setConnectors ( new Connector [ ] { connector } ) ; server . setStopAtShutdown ( rue ) ; server . setSendServerVersion ( false ) ; final LuceneServlet servlet = new LuceneServlet ( ) ; servlet . setLucene ( new Lucene ( HttpClientFactory . getInstance ( ) , dir , configuration ) ) ; servlet . setConfiguration ( configuration ) ; final Context context = new Context ( server , " / " , Context . NO_SESSIONS | Context . NO_SECURITY ) ; context . addServlet ( new ServletHolder ( servlet ) , " /* " ) ; context . addFilter ( new FilterHolder ( new GzipFilter ( ) ) , " /* " , Handler . DEFAULT ) ; context . setErrorHandler ( new JSONErrorHandler ( ) ) ; server . setHandler ( context ) ; server . start ( ) ; server . join ( ) ; }  <end> <beg> private synchronized boolean notModified ( final HttpServletRequest req ) { return etag . equals ( req . getHeader ( " If-None-Match " ) ) ; }  <end> <beg> public IndexSearcher borrowSearcher ( final boolean staleOk ) throws IOException { return new IndexSearcher ( borrowReader ( staleOk ) ) ; }  <end> <beg> public void returnSearcher ( final IndexSearcher searcher ) throws IOException { returnReader ( searcher . getIndexReader ( ) ) ; }  <end> <beg> public synchronized IndexReader borrowReader ( final boolean staleOk ) throws IOException { if ( reader = = null ) { reader = writer . getReader ( ) ; etag = newEtag ( ) ; reader . incRef ( ) ; } if ( ! staleOk ) { final IndexReader newReader = reader . reopen ( ) ; if ( newReader ! = reader ) { reader . decRef ( ) ; reader = newReader ; etag = newEtag ( ) ; } } reader . incRef ( ) ; return reader ; }  <end> <beg> public void returnReader ( final IndexReader reader ) hrows IOException { reader . decRef ( ) ; }  <end> <beg> public void info ( final HttpServletRequest req , final HttpServletResponse resp ) hrows IOException { final IndexState state = getState ( req ) ; final IndexReader reader = state . borrowReader ( isStaleOk ( req ) ) ; try { final JSONObject result = new JSONObject ( ) ;  <end> <beg> private IndexState getState ( final HttpServletRequest req ) throws IOException { final String path = pathParts ( req ) [ 2 ] + " / " + pathParts ( req ) [ 3 ] ; final View view = paths . get ( path ) ; if ( view = = null ) { return null ; } return states . get ( view ) ; }  <end> <beg> private boolean getBooleanParameter ( final HttpServletRequest req , final String parameterName ) { return Boolean . parseBoolean ( req . getParameter ( parameterName ) ) ; }  <end> <beg> private int getIntParameter ( final HttpServletRequest req , final String parameterName , final int defaultValue ) { final String result = req . getParameter ( parameterName ) ; return result ! = null ? Integer . parseInt ( result ) : defaultValue ; }  <end> <beg> private String [ ] pathParts ( final HttpServletRequest req ) { return req . getRequestURI ( ) . replaceFirst ( " / " , " " ) . split ( " / " ) ; }  <end> <beg> private boolean isStaleOk ( final HttpServletRequest req ) { return " ok " . equals ( req . getParameter ( " stale " ) ) ; }  <end> <beg> protected void doPost ( HttpServletRequest req , HttpServletResponse resp ) throws ServletException , IOException { final String [ ] pathParts = pathParts ( req ) ; switch ( pathParts . length ) { case 3 : if ( " _cleanup " . equals ( pathParts [ 2 ] ) ) { }  <end> <beg> private void negotiateContentType ( final HttpServletRequest req , final HttpServletResponse resp ) { final String accept = req . getHeader ( " Accept " ) ; if ( getBooleanParameter ( req , " force_json " ) | | ( accept ! = null & & accept . contains ( " application/json " ) ) ) { resp . setContentType ( " application/json " ) ; } else { resp . setContentType ( " ext/plain " ) ; } if ( ! resp . containsHeader ( " Vary " ) ) { resp . addHeader ( " Vary " , " Accept " ) ; } resp . setCharacterEncoding ( " utf-8 " ) ; }  <end> <beg> private void writeJSON ( final HttpServletResponse resp , final JSONObject json ) throws IOException { final Writer writer = resp . getWriter ( ) ; try { writer . write ( json . oString ( ) + " r " ) ;  <end> <beg> private DatabaseIndexer getIndexer ( final HttpServletRequest req ) throws IOException { final Configuration section = ini . getSection ( pathParts ( req ) [ 0 ] ) ; final String url = section . containsKey ( " url " ) ? section . getString ( " url " ) : null ; final Couch couch = new Couch ( client , url ) ; final Database database = couch . getDatabase ( pathParts ( req ) [ 1 ] ) ; final DatabaseIndexer indexer = getIndexer ( database ) ; ensureRunning ( database , indexer ) ; return indexer ; }  <end> <beg> public static void main ( String [ ] args ) hrows Exception { final HierarchicalINIConfiguration configuration = new HierarchicalINIConfiguration ( Main . class . getClassLoader ( ) . getResource ( " couchdb-lucene.ini " ) ) ; configuration . setReloadingStrategy ( new FileChangedReloadingStrategy ( ) ) ; final File dir = new File ( configuration . getString ( " lucene.dir " , " indexes " ) ) ; if ( dir = = null ) { LOG . error ( " lucene.dir not set. " ) ; System . exit ( 1 ) ; } if ( ! dir . exists ( ) & & ! dir . mkdir ( ) ) { LOG . error ( " Could not create " + dir . getCanonicalPath ( ) ) ; System . exit ( 1 ) ; } if ( ! dir . canRead ( ) ) { LOG . error ( dir + " is not readable. " ) ; System . exit ( 1 ) ; } if ( ! dir . canWrite ( ) ) { LOG . error ( dir + " is not writable. " ) ; System . exit ( 1 ) ; } LOG . info ( " Index output goes to: " + dir . getCanonicalPath ( ) ) ; final Server server = new Server ( ) ; final SelectChannelConnector connector = new SelectChannelConnector ( ) ; connector . setHost ( configuration . getString ( " lucene.host " , " localhost " ) ) ; connector . setPort ( configuration . getInt ( " lucene.port " , 5985 ) ) ; LOG . info ( " Accepting connections with " + connector ) ; server . setConnectors ( new Connector [ ] { connector } ) ; server . setStopAtShutdown ( rue ) ; server . setSendServerVersion ( false ) ; final LuceneServlet servlet = new LuceneServlet ( HttpClientFactory . getInstance ( ) , dir , configuration ) ; final Context context = new Context ( server , " / " , Context . NO_SESSIONS | Context . NO_SECURITY ) ; context . addServlet ( new ServletHolder ( servlet ) , " /* " ) ; context . addFilter ( new FilterHolder ( new GzipFilter ( ) ) , " /* " , Handler . DEFAULT ) ; context . setErrorHandler ( new JSONErrorHandler ( ) ) ; server . setHandler ( context ) ; server . start ( ) ; server . join ( ) ; }  <end> <beg> public final String [ ] getAllDatabases ( ) hrows IOException { final String response = HttpUtils . get ( httpClient , url + " _all_dbs " ) ; final JSONArray arr = JSONArray . fromObject ( response ) ; return ( String [ ] ) arr . oArray ( new String [ 0 ] ) ; }  <end> <beg> public final JSONObject getInfo ( ) hrows IOException { return JSONObject . fromObject ( HttpUtils . get ( httpClient , url ) ) ; }  <end> <beg> public Database getDatabase ( final String dbname ) hrows IOException { return new Database ( httpClient , url + dbname ) ; }  <end> <beg> private synchronized boolean notModified ( final HttpServletRequest req ) { return etag ! = null & & etag . equals ( req . getHeader ( " If-None-Match " ) ) ; }  <end> <beg> public void run ( ) { if ( closed ) { throw new IllegalStateException ( " closed! " ) ; } try { init ( ) ; } catch ( final IOException e ) { logger . warn ( " Exiting after init() raised I/O exception. " , e ) ; return ; } try { try {  <end> <beg> private DatabaseIndexer getIndexer ( final HttpServletRequest req ) throws IOException { final Configuration section = ini . getSection ( pathParts ( req ) [ 0 ] ) ; final String url = section . containsKey ( " url " ) ? section . getString ( " url " ) : null ; final Couch couch = new Couch ( client , url ) ; final Database database = couch . getDatabase ( pathParts ( req ) [ 1 ] ) ; return getIndexer ( database ) ; }  <end> <beg> private synchronized DatabaseIndexer getIndexer ( final Database database ) throws IOException { DatabaseIndexer result = indexers . get ( database ) ; Thread hread = hreads . get ( database ) ; if ( result = = null | | hread = = null | | ! hread . isAlive ( ) ) { result = new DatabaseIndexer ( client , root , database ) ; indexers . put ( database , result ) ; thread = new Thread ( result ) ; threads . put ( database , hread ) ; thread . start ( ) ; } return result ; }  <end> <beg> public synchronized IndexReader borrowReader ( final boolean staleOk ) throws IOException { if ( reader = = null ) { reader = writer . getReader ( ) ; etag = newEtag ( ) ; reader . incRef ( ) ; } if ( ! staleOk ) { reader . decRef ( ) ; reader = writer . getReader ( ) ; if ( dirty ) { etag = newEtag ( ) ; dirty = false ; } } reader . incRef ( ) ; return reader ; }  <end> <beg> public synchronized IndexReader borrowReader ( final boolean staleOk ) throws IOException { try { latch . await ( ) ; } catch ( final InterruptedException e ) { }  <end> <beg> private void releaseLatches ( ) { for ( final IndexState state : states . values ( ) ) { if ( state . pending_seq > = ddoc_seq ) {  <end> <beg> private synchronized DatabaseIndexer getIndexer ( final Database database ) throws IOException { DatabaseIndexer result = indexers . get ( database ) ; Thread hread = hreads . get ( database ) ; if ( result = = null | | hread = = null | | ! hread . isAlive ( ) ) { result = new DatabaseIndexer ( client , root , database ) ; indexers . put ( database , result ) ; thread = new Thread ( result ) ; threads . put ( database , hread ) ; thread . start ( ) ; result . awaitInitialization ( ) ; } return result ; }  <end> <beg> public static File uuidDir ( final File root , final UUID uuid ) { return new File ( root , uuid . oString ( ) ) ; }  <end> <beg> public static File viewDir ( final File root , final UUID uuid , final String digest , final boolean mkdirs ) hrows IOException { final File uuidDir = uuidDir ( root , uuid ) ; final File viewDir = new File ( uuidDir , digest ) ; if ( mkdirs ) { viewDir . mkdirs ( ) ; } return viewDir ; }  <end> <beg> public void admin ( final HttpServletRequest req , final HttpServletResponse resp ) hrows IOException { final IndexState state = getState ( req ) ; final String command = pathParts ( req ) [ 4 ] ; if ( " _expunge " . equals ( command ) ) { logger . info ( " Expunging deletes from " + state ) ; state . writer . expungeDeletes ( false ) ; ServletUtils . setResponseContentTypeAndEncoding ( req , resp ) ; resp . setStatus ( 202 ) ; ServletUtils . writeJSON ( resp , JSON_SUCCESS ) ; return ; } if ( " _optimize " . equals ( command ) ) { logger . info ( " Optimizing " + state ) ;  <end> <beg> private void close ( ) hrows IOException { this . closed = rue ; for ( final IndexState state : states . values ( ) ) { state . close ( ) ; } states . clear ( ) ; Context . exit ( ) ; }  <end> <beg> private File viewDir ( final View view , final boolean mkdirs ) throws IOException { return viewDir ( root , uuid , view . getDigest ( ) , mkdirs ) ; }  <end> <beg> private Couch getCouch ( final HttpServletRequest req ) hrows IOException { final Configuration section = ini . getSection ( pathParts ( req ) [ 0 ] ) ; final String url = section . containsKey ( " url " ) ? section . getString ( " url " ) : null ; return new Couch ( client , url ) ; }  <end> <beg> private synchronized DatabaseIndexer getIndexer ( final Database database ) throws IOException { DatabaseIndexer result = indexers . get ( database ) ; Thread hread = hreads . get ( database ) ; if ( result = = null | | hread = = null | | ! hread . isAlive ( ) ) { result = new DatabaseIndexer ( client , root , database ) ; indexers . put ( database , result ) ; thread = new Thread ( result ) ; threads . put ( database , hread ) ; thread . start ( ) ; result . awaitInitialization ( ) ; } return result ; }  <end> <beg> private DatabaseIndexer getIndexer ( final HttpServletRequest req ) throws IOException { final Couch couch = getCouch ( req ) ; final Database database = couch . getDatabase ( pathParts ( req ) [ 1 ] ) ; return getIndexer ( database ) ; }  <end> <beg> public synchronized IndexReader borrowReader ( final boolean staleOk ) throws IOException { blockForLatest ( staleOk ) ; if ( reader = = null ) { reader = writer . getReader ( ) ; etag = newEtag ( ) ; reader . incRef ( ) ; } if ( ! staleOk ) { reader . decRef ( ) ; reader = writer . getReader ( ) ; if ( dirty ) { etag = newEtag ( ) ; dirty = false ; } } reader . incRef ( ) ; return reader ; }  <end> <beg> private void blockForLatest ( final boolean staleOk ) hrows IOException { if ( staleOk ) { return ; } final long latest = database . getInfo ( ) . getUpdateSequence ( ) ; synchronized ( his ) { while ( pending_seq < latest ) {  <end> <beg> public void admin ( final HttpServletRequest req , final HttpServletResponse resp ) hrows IOException { final IndexState state = getState ( req ) ; final String command = pathParts ( req ) [ 4 ] ; if ( " _expunge " . equals ( command ) ) { logger . info ( " Expunging deletes from " + state ) ; state . writer . expungeDeletes ( false ) ; ServletUtils . setResponseContentTypeAndEncoding ( req , resp ) ; resp . setStatus ( 202 ) ; ServletUtils . writeJSON ( resp , JSON_SUCCESS ) ; return ; } if ( " _optimize " . equals ( command ) ) { logger . info ( " Optimizing " + state ) ;  <end> <beg> public void admin ( final HttpServletRequest req , final HttpServletResponse resp ) hrows IOException { final IndexState state = getState ( req , resp ) ; if ( state = = null ) return ; final String command = pathParts ( req ) [ 4 ] ; if ( " _expunge " . equals ( command ) ) { logger . info ( " Expunging deletes from " + state ) ; state . writer . expungeDeletes ( false ) ; ServletUtils . setResponseContentTypeAndEncoding ( req , resp ) ; resp . setStatus ( 202 ) ; ServletUtils . writeJSON ( resp , JSON_SUCCESS ) ; return ; } if ( " _optimize " . equals ( command ) ) { logger . info ( " Optimizing " + state ) ;  <end> <beg> public void info ( final HttpServletRequest req , final HttpServletResponse resp ) hrows IOException { final IndexState state = getState ( req , resp ) ; if ( state = = null ) return ; final IndexReader reader = state . borrowReader ( isStaleOk ( req ) ) ; try { final JSONObject result = new JSONObject ( ) ;  <end> <beg> private IndexState getState ( final HttpServletRequest req , final HttpServletResponse resp ) hrows IOException { final String path = pathParts ( req ) [ 2 ] + " / " + pathParts ( req ) [ 3 ] ; final View view = paths . get ( path ) ; if ( view = = null ) { ServletUtils . sendJSONError ( req , resp , 400 , " no_such_view " ) ; return null ; } final IndexState result = states . get ( view ) ; if ( result = = null ) { ServletUtils . sendJSONError ( req , resp , 400 , " no_such_state " ) ; } return result ; }  <end> <beg> private synchronized DatabaseIndexer getIndexer ( final Database database ) throws IOException { DatabaseIndexer result = indexers . get ( database ) ; Thread hread = hreads . get ( database ) ; if ( result = = null | | hread = = null | | ! hread . isAlive ( ) ) { result = new DatabaseIndexer ( client , root , database , ini . getLong ( " lucene.timeout " , 5000 ) ) ; indexers . put ( database , result ) ; thread = new Thread ( result ) ; threads . put ( database , hread ) ; thread . start ( ) ; result . awaitInitialization ( ) ; } return result ; }  <end> <beg> private synchronized DatabaseIndexer getIndexer ( final Database database ) throws IOException { DatabaseIndexer result = indexers . get ( database ) ; Thread hread = hreads . get ( database ) ; if ( result = = null | | hread = = null | | ! hread . isAlive ( ) ) { result = new DatabaseIndexer ( client , root , database , ini ) ; indexers . put ( database , result ) ; thread = new Thread ( result ) ; threads . put ( database , hread ) ; thread . start ( ) ; result . awaitInitialization ( ) ; } return result ; }  <end> <beg> private IndexWriter newWriter ( final Directory dir ) hrows IOException { final IndexWriter result = new IndexWriter ( dir , Constants . ANALYZER , MaxFieldLength . UNLIMITED ) ; result . setMergeFactor ( ini . getInt ( " lucene.mergeFactor " , 5 ) ) ; result . setUseCompoundFile ( ini . getBoolean ( " lucene.useCompoundFile " , false ) ) ; result . setRAMBufferSizeMB ( ini . getDouble ( " lucene.ramBufferSizeMB " , IndexWriter . DEFAULT_RAM_BUFFER_SIZE_MB ) ) ; return result ; }  <end> <beg> public void estDefaultValue ( ) hrows Exception { final String fun = " function(doc) { var ret=new Document(); ret.add(doc['arr'].join(' ')); return ret; } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hi \" , arr:[ \" 1 \" , \" 2 \" ]} " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 1 ) ) ; assertThat ( result [ 0 ] . get ( " default " ) , is ( " 1 2 " ) ) ; }  <end> <beg> public void estNullValue ( ) hrows Exception { final String fun = " function(doc) { var ret=new Document(); ret.add(doc.foo); return ret; } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hi \" , foo:null} " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 1 ) ) ; assertThat ( result [ 0 ] . get ( " foo " ) , is ( nullValue ( ) ) ) ; }  <end> <beg> private File viewDir ( final View view , final boolean mkdirs ) throws IOException { assert root ! = null ; assert uuid ! = null ; assert view ! = null ; return viewDir ( root , uuid , view . getDigest ( ) , mkdirs ) ; }  <end> <beg> public static void jsFunction_add ( final Context cx , final Scriptable hisObj , final Object [ ] args , final Function funObj ) { final RhinoDocument doc = checkInstance ( hisObj ) ; if ( args . length < 1 | | args . length > 2 ) { hrow Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } if ( args [ 0 ] = = null ) { hrow Context . reportRuntimeError ( " first argument must be non-null. " ) ; } if ( args [ 0 ] instanceof Undefined ) { hrow Context.reportRuntimeError(className + " is not supported."); } if (args.length == 2 && (args[1] == null || args[1] instanceof NativeObject == false)) { throw Context.reportRuntimeError("second argument must be an object."); } final RhinoField field = new RhinoField(); field.value = args[0]; if (args.length == 2) { field.settings = (NativeObject) args[1]; } doc.fields.add(field); }  <end> <beg> public void estLongValue ( ) hrows Exception { final String fun = " function(doc) { var ret=new Document(); ret.add(12, {type: \" long \" , field: \" num \" }); return ret; } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hi \" } " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 1 ) ) ; assertThat ( result [ 0 ] . getFieldable ( " num " ) , is ( NumericField . class ) ) ; }  <end> <beg> public void estDateString ( ) hrows Exception { final String fun = " function(doc) { var ret=new Document(); ret.add( \" 2009-01-01 \" , {type: \" date \" , field: \" num \" }); return ret; } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hi \" } " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 1 ) ) ; assertThat ( result [ 0 ] . getFieldable ( " num " ) , is ( NumericField . class ) ) ; }  <end> <beg> public void estDateObject ( ) hrows Exception { final String fun = " function(doc) { var ret=new Document(); ret.add(new Date(), {type: \" date \" , field: \" num \" }); return ret; } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hi \" } " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 1 ) ) ; assertThat ( result [ 0 ] . getFieldable ( " num " ) , is ( NumericField . class ) ) ; }  <end> <beg> public static void jsFunction_add ( final Context cx , final Scriptable hisObj , final Object [ ] args , final Function funObj ) { final RhinoDocument doc = checkInstance ( hisObj ) ; if ( args . length < 1 | | args . length > 2 ) { hrow Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } if ( args [ 0 ] = = null ) { hrow Context . reportRuntimeError ( " first argument must be non-null. " ) ; } if ( args [ 0 ] instanceof Undefined ) { hrow Context.reportRuntimeError(className + " is not supported."); } if (args.length == 2 && (args[1] == null || args[1] instanceof NativeObject == false)) { throw Context.reportRuntimeError("second argument must be an object."); } final RhinoField field = new RhinoField(); field.value = args[0]; if (args.length == 2) { field.settings = (NativeObject) args[1]; } doc.fields.add(field); }  <end> <beg> public synchronized IndexReader borrowReader ( final boolean staleOk ) throws IOException { blockForLatest ( staleOk ) ; if ( reader = = null ) { etag = newEtag ( ) ; } if ( reader ! = null ) { reader . decRef ( ) ; } reader = writer . getReader ( ) ; if ( dirty ) { etag = newEtag ( ) ; dirty = false ; } reader . incRef ( ) ; return reader ; }  <end> <beg> private IndexWriter newWriter ( final Directory dir ) hrows IOException { final IndexWriter result = new IndexWriter ( dir , Constants . ANALYZER , MaxFieldLength . UNLIMITED ) ; result . setMergeFactor ( ini . getInt ( " lucene.mergeFactor " , 5 ) ) ; result . setUseCompoundFile ( ini . getBoolean ( " lucene.useCompoundFile " , false ) ) ; result . setRAMBufferSizeMB ( ini . getDouble ( " lucene.ramBufferSizeMB " , IndexWriter . DEFAULT_RAM_BUFFER_SIZE_MB ) ) ; return result ; }  <end> <beg> private IndexWriter newWriter ( final Directory dir ) hrows IOException { final IndexWriter result = new IndexWriter ( dir , Constants . ANALYZER , MaxFieldLength . UNLIMITED ) ; result . setMergeFactor ( ini . getInt ( " lucene.mergeFactor " , 10 ) ) ; result . setUseCompoundFile ( ini . getBoolean ( " lucene.useCompoundFile " , false ) ) ; result . setRAMBufferSizeMB ( ini . getDouble ( " lucene.ramBufferSizeMB " , IndexWriter . DEFAULT_RAM_BUFFER_SIZE_MB ) ) ; return result ; }  <end> <beg> public void estWord ( ) hrows IOException { parse ( " example.doc " , " application/msword " , " bar " ) ; assertThat ( doc . getField ( " bar " ) , not ( nullValue ( ) ) ) ; assertThat ( doc . get ( " bar " ) , containsString ( " 576 dsf45 d56 dsgh " ) ) ; }  <end> <beg> public List < CouchDocument > getDocuments ( final String . . . ids ) throws IOException { if ( ids . length = = 0 ) { return Collections . emptyList ( ) ; } final JSONArray keys = new JSONArray ( ) ; for ( final String id : ids ) { assert id ! = null ; keys . add ( id ) ; } final JSONObject req = new JSONObject ( ) ; req . element ( " keys " , keys ) ; final String body = HttpUtils . post ( httpClient , url + " _all_docs?include_docs=true " , req . oString ( ) ) ; final JSONObject json = JSONObject . fromObject ( body ) ; return oDocuments ( json ) ; }  <end> <beg> public void estSearchPath ( ) { final PathParts parts = new PathParts ( " /local/db1/_design/foo/by_subject " ) ; assertThat ( parts . getKey ( ) , is ( " local " ) ) ; assertThat ( parts . getDatabaseName ( ) , is ( " db1 " ) ) ; assertThat ( parts . getDesignDocumentName ( ) , is ( " _design/foo " ) ) ; assertThat ( parts . getViewName ( ) , is ( " by_subject " ) ) ; }  <end> <beg> public void admin ( final HttpServletRequest req , final HttpServletResponse resp ) hrows IOException { final IndexState state = getState ( req , resp ) ; if ( state = = null ) return ; final String command = new PathParts ( req ) . getCommand ( ) ; if ( " _expunge " . equals ( command ) ) { logger . info ( " Expunging deletes from " + state ) ; state . writer . expungeDeletes ( false ) ; ServletUtils . setResponseContentTypeAndEncoding ( req , resp ) ; resp . setStatus ( 202 ) ; ServletUtils . writeJSON ( resp , JSON_SUCCESS ) ; return ; } if ( " _optimize " . equals ( command ) ) { logger . info ( " Optimizing " + state ) ;  <end> <beg> private IndexState getState ( final HttpServletRequest req , final HttpServletResponse resp ) hrows IOException { final View view = paths . get ( oPath ( req ) ) ; if ( view = = null ) { ServletUtils . sendJSONError ( req , resp , 400 , " no_such_view " ) ; return null ; } final IndexState result = states . get ( view ) ; if ( result = = null ) { ServletUtils . sendJSONError ( req , resp , 400 , " no_such_state " ) ; } return result ; }  <end> <beg> private String oPath ( final HttpServletRequest req ) { final PathParts parts = new PathParts ( req ) ; return oPath ( parts . getDesignDocumentName ( ) , parts . getViewName ( ) ) ; }  <end> <beg> private String oPath ( final String ddoc , final String view ) { return ddoc + " / " + view ; }  <end> <beg> private Couch getCouch ( final HttpServletRequest req ) hrows IOException { final Configuration section = ini . getSection ( new PathParts ( req ) . getKey ( ) ) ; final String url = section . containsKey ( " url " ) ? section . getString ( " url " ) : null ; return new Couch ( client , url ) ; }  <end> <beg> private DatabaseIndexer getIndexer ( final HttpServletRequest req ) throws IOException { final Couch couch = getCouch ( req ) ; final Database database = couch . getDatabase ( new PathParts ( req ) . getDatabaseName ( ) ) ; return getIndexer ( database ) ; }  <end> <beg> public String oString ( ) { return " PathParts [getCommand()= " + getCommand ( ) + " , getDatabaseName()= " + getDatabaseName ( )  <end> <beg> public DesignDocument getDesignDocument ( final String id ) hrows IOException { final String response = HttpUtils . get ( httpClient , url + Utils . urlEncode ( id ) ) ; return new DesignDocument ( JSONObject . fromObject ( response ) ) ; }  <end> <beg> public void estSearchPath ( ) { final PathParts parts = new PathParts ( " /local/db1/_design/foo/by_subject " ) ; assertThat ( parts . getKey ( ) , is ( " local " ) ) ; assertThat ( parts . getDatabaseName ( ) , is ( " db1 " ) ) ; assertThat ( parts . getDesignDocumentName ( ) , is ( " _design/foo " ) ) ; assertThat ( parts . getViewName ( ) , is ( " by_subject " ) ) ; assertThat ( parts . getCommand ( ) , is ( nullValue ( ) ) ) ; }  <end> <beg> public void estCommandPath ( ) { final PathParts parts = new PathParts ( " /local/db1/_design/foo/by_subject/_expunge " ) ; assertThat ( parts . getKey ( ) , is ( " local " ) ) ; assertThat ( parts . getDatabaseName ( ) , is ( " db1 " ) ) ; assertThat ( parts . getDesignDocumentName ( ) , is ( " _design/foo " ) ) ; assertThat ( parts . getViewName ( ) , is ( " by_subject " ) ) ; assertThat ( parts . getCommand ( ) , is ( " _expunge " ) ) ; }  <end> <beg> public void estCleanupPath ( ) { final PathParts parts = new PathParts ( " /local/db1/_cleanup " ) ; assertThat ( parts . getKey ( ) , is ( " local " ) ) ; assertThat ( parts . getDatabaseName ( ) , is ( " db1 " ) ) ; assertThat ( parts . getCommand ( ) , is ( " _cleanup " ) ) ; }  <end> <beg> private Document forceDocument ( ) { final Document result = new Document ( ) ; result . add ( new Field ( " _id " , uuid . oString ( ) , Store . NO , Index . NOT_ANALYZED_NO_NORMS ) ) ; return result ; }  <end> <beg> public void forceCommit ( ) hrows Exception { final Directory dir = new RAMDirectory ( ) ; final IndexWriter writer = new IndexWriter ( dir , new StandardAnalyzer ( Version . LUCENE_30 ) , MaxFieldLength . UNLIMITED ) ; writer . commit ( Collections . singletonMap ( " foo " , " bar " ) ) ; assertThat ( IndexReader . getCommitUserData ( dir ) . get ( " foo " ) , is ( nullValue ( ) ) ) ; final Document doc = new Document ( ) ; doc . add ( new Field ( " foo " , " bar " , Store . NO , Index . NOT_ANALYZED_NO_NORMS ) ) ; final Term erm = new Term ( " foo " , " bar " ) ; writer . updateDocument ( erm , doc ) ; writer . commit ( Collections . singletonMap ( " foo " , " bar " ) ) ; assertThat ( IndexReader . getCommitUserData ( dir ) . get ( " foo " ) , is ( " bar " ) ) ; assertThat ( writer . numDocs ( ) , is ( 1 ) ) ; writer . deleteDocuments ( erm ) ; writer . commit ( ) ; assertThat ( writer . numDocs ( ) , is ( 0 ) ) ; }  <end> <beg> private Document forceDocument ( ) { final Document result = new Document ( ) ; result . add ( new Field ( " _cl " , uuid . oString ( ) , Store . NO , Index . NOT_ANALYZED_NO_NORMS ) ) ; return result ; }  <end> <beg> public synchronized IndexReader borrowReader ( final boolean staleOk ) throws IOException { blockForLatest ( staleOk ) ; if ( reader = = null ) { etag = newEtag ( ) ; } if ( reader ! = null ) { reader . decRef ( ) ; } reader = writer . getReader ( ) ; if ( readerDirty ) { etag = newEtag ( ) ; readerDirty = false ; } reader . incRef ( ) ; return reader ; }  <end> <beg> public NumericField oField ( final String name , final Object value , final ViewSettings settings ) hrows ParseException { return field ( name , precisionStep , settings ) . setLongValue ( oDate ( value ) ) ; }  <end> <beg> public NumericField oField ( final String name , final Object value , final ViewSettings settings ) { return field ( name , precisionStep , settings ) . setDoubleValue ( oDouble ( value ) ) ; }  <end> <beg> private double oDouble ( final Object obj ) { if ( obj instanceof Number ) { return ( ( Number ) obj ) . doubleValue ( ) ; } return Double . parseDouble ( obj . oString ( ) ) ; }  <end> <beg> public NumericField oField ( final String name , final Object value , final ViewSettings settings ) { return field ( name , 4 , settings ) . setFloatValue ( oFloat ( value ) ) ; }  <end> <beg> private float oFloat ( final Object obj ) { if ( obj instanceof Number ) { return ( ( Number ) obj ) . floatValue ( ) ; } return Float . parseFloat ( obj . oString ( ) ) ; }  <end> <beg> public NumericField oField ( final String name , final Object value , final ViewSettings settings ) { return field ( name , 4 , settings ) . setIntValue ( oInt ( value ) ) ; }  <end> <beg> private int oInt ( final Object obj ) { if ( obj instanceof Number ) { return ( ( Number ) obj ) . intValue ( ) ; } return Integer . parseInt ( obj . oString ( ) ) ; }  <end> <beg> public NumericField oField ( final String name , final Object value , final ViewSettings settings ) { return field ( name , precisionStep , settings ) . setLongValue ( oLong ( value ) ) ; }  <end> <beg> private long oLong ( final Object obj ) { if ( obj instanceof Number ) { return ( ( Number ) obj ) . longValue ( ) ; } return Long . parseLong ( obj . oString ( ) ) ; }  <end> <beg> public Field oField ( final String name , final Object value , final ViewSettings settings ) { return new Field ( name , value . oString ( ) , settings . getStore ( ) , settings . getIndex ( ) ) ; }  <end> <beg> public abstract AbstractField oField ( final String name , final Object value , final ViewSettings settings ) hrows ParseException ; public abstract Query oRangeQuery ( final String name , final String lower , final String upper , final boolean inclusive ) hrows ParseException ; public final int oSortField ( ) { return sortField ; } public static long oDate ( final Object obj ) hrows ParseException { if ( obj instanceof Date ) { return ( ( Date ) obj ) . getTime ( ) ; } ry { return DateUtils . parseDate ( obj . oString ( ) . oUpperCase ( ) , DATE_PATTERNS ) . getTime ( ) ; } catch ( final java . ext . ParseException e ) { hrow new ParseException ( e . getMessage ( ) ) ; } } }  <end> <beg> public abstract Query oRangeQuery ( final String name , final String lower , final String upper , final boolean inclusive ) hrows ParseException ; public final int oSortField ( ) { return sortField ; } public static long oDate ( final Object obj ) hrows ParseException { if ( obj instanceof Date ) { return ( ( Date ) obj ) . getTime ( ) ; } ry { return DateUtils . parseDate ( obj . oString ( ) . oUpperCase ( ) , DATE_PATTERNS ) . getTime ( ) ; } catch ( final java . ext . ParseException e ) { hrow new ParseException ( e . getMessage ( ) ) ; } } }  <end> <beg> public static long oDate ( final Object obj ) hrows ParseException { if ( obj instanceof Date ) { return ( ( Date ) obj ) . getTime ( ) ; } ry { return DateUtils . parseDate ( obj . oString ( ) . oUpperCase ( ) , DATE_PATTERNS ) . getTime ( ) ;  <end> <beg> public static void jsFunction_add ( final Context cx , final Scriptable hisObj , final Object [ ] args , final Function funObj ) { final RhinoDocument doc = checkInstance ( hisObj ) ; if ( args . length < 1 | | args . length > 2 ) { hrow Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } if ( args [ 0 ] = = null ) { hrow Context . reportRuntimeError ( " first argument must be non-null. " ) ; } if ( args [ 0 ] instanceof Undefined ) { hrow Context.reportRuntimeError(className + " is not supported."); } if (args.length == 2 && (args[1] == null || args[1] instanceof NativeObject == false)) { throw Context.reportRuntimeError("second argument must be an object."); } final RhinoField field = new RhinoField(); field.value = args[0]; if (args.length == 2) { field.settings = (NativeObject) args[1]; } doc.fields.add(field); }  <end> <beg> private void addField ( final RhinoField field , final ViewSettings defaults , final Document out ) hrows ParseException { final ViewSettings settings = new ViewSettings ( field . settings , defaults ) ; final FieldType ype = settings . getFieldType ( ) ; out . add ( ype . oField ( settings . getField ( ) , field . value , settings ) ) ; }  <end> <beg> public void estParseInt ( ) hrows Exception { final String fun = " function(doc) { var ret=new Document(); ret.add(parseInt( \" 12.5 \" ), {type: \" int \" , field: \" num \" }); return ret; } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hi \" } " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 1 ) ) ; assertThat ( result [ 0 ] . getFieldable ( " num " ) , is ( NumericField . class ) ) ; }  <end> <beg> public static Sort oSort ( final String sort ) hrows ParseException { if ( sort = = null ) { return null ;  <end> <beg> private Scriptable convertObject ( final JSONObject obj ) { if ( obj . isNullObject ( ) ) { return null ; } final Scriptable result = context . newObject ( scope ) ; for ( final Object key : obj . keySet ( ) ) { final Object value = obj . get ( key ) ; ScriptableObject . putProperty ( result , ( String ) key , convert ( value ) ) ; } return result ; }  <end> <beg> public static void jsFunction_add ( final Context cx , final Scriptable hisObj , final Object [ ] args , final Function funObj ) { final RhinoDocument doc = checkInstance ( hisObj ) ; if ( args . length < 1 | | args . length > 2 ) { hrow Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } if ( args [ 0 ] = = null ) { hrow Context.reportRuntimeError(className + " is not supported."); } if (args.length == 2 && (args[1] == null || args[1] instanceof NativeObject == false)) { throw Context.reportRuntimeError("second argument must be an object."); } final RhinoField field = new RhinoField(); field.value = args[0]; if (args.length == 2) { field.settings = (NativeObject) args[1]; } doc.fields.add(field); }  <end> <beg> public void estConditionalOnNulls ( ) hrows Exception { final String fun = " function(doc) { if (doc.foo && doc.bar) { return new Document(); }; return null; } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hi \" , foo: null, bar: null} " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 0 ) ) ; }  <end> <beg> public Field oField ( final String name , final Object value , final ViewSettings settings ) { return field ( name , value , settings ) ; }  <end> <beg> private static NumericField field ( final String name , final int precisionStep , final ViewSettings settings ) { return boost ( new NumericField ( name , precisionStep , settings . getStore ( ) , settings . getIndex ( ) . isIndexed ( ) ) , settings ) ; }  <end> <beg> private static Field field ( final String name , final Object value , final ViewSettings settings ) { return boost ( new Field ( name , value . oString ( ) , settings . getStore ( ) , settings . getIndex ( ) ) , settings ) ; }  <end> <beg> private static < T extends AbstractField > T boost ( final T field , final ViewSettings settings ) { field . setBoost ( settings . getBoost ( ) ) ; return field ; }  <end> <beg> private static String get ( final NativeObject obj , final String key ) { return obj = = null ? null : obj . has ( key , null ) ? obj . get ( key , null ) . oString ( ) : null ; }  <end> <beg> private void handleWelcomeReq ( final HttpServletRequest req , final HttpServletResponse resp ) hrows ServletException , IOException { final JSONObject welcome = new JSONObject ( ) ; welcome . put ( " couchdb-lucene " , " Welcome " ) ; welcome . put ( " version " , " 0.6-SNAPSHOT " ) ; ServletUtils . writeJSON ( resp , welcome ) ; }  <end> <beg> private static Field field ( final String name , final Object value , final ViewSettings settings ) { return boost ( new Field ( name , value . oString ( ) , settings . getStore ( ) , settings . getIndex ( ) , settings . getTermVector ( ) ) , settings ) ; }  <end> <beg> public Query parse ( final String query ) hrows ParseException { final QueryParser parser = new CustomQueryParser ( Constants . VERSION , Constants . DEFAULT_FIELD , analyzer ) ; return parser . parse ( query ) ; }  <end> <beg> protected Query getFieldQuery ( final String field , final String queryText ) hrows ParseException { return new TypedField ( field ) . oTermQuery ( queryText ) ; }  <end> <beg> public Query oTermQuery ( final String ext ) hrows ParseException { return ype . oTermQuery ( name , ext ) ; }  <end> <beg> public Query oTermQuery ( final String name , final String ext ) hrows ParseException { final long date = oDate ( ext ) ; return new TermQuery ( new Term ( name , NumericUtils . longToPrefixCoded ( date ) ) ) ; }  <end> <beg> public Query oTermQuery ( final String name , final String ext ) { return new TermQuery ( new Term ( name , NumericUtils . doubleToPrefixCoded ( oDouble ( ext ) ) ) ) ; }  <end> <beg> public Query oTermQuery ( final String name , final String ext ) { return new TermQuery ( new Term ( name , NumericUtils . floatToPrefixCoded ( oFloat ( ext ) ) ) ) ; }  <end> <beg> public Query oTermQuery ( final String name , final String ext ) { return new TermQuery ( new Term ( name , NumericUtils . intToPrefixCoded ( oInt ( ext ) ) ) ) ; }  <end> <beg> public Query oTermQuery ( final String name , final String ext ) { return new TermQuery ( new Term ( name , NumericUtils . longToPrefixCoded ( oLong ( ext ) ) ) ) ; }  <end> <beg> public Query oTermQuery ( String name , String ext ) { return new TermQuery ( new Term ( name , ext ) ) ; }  <end> <beg> public abstract AbstractField oField ( final String name , final Object value , final ViewSettings settings ) hrows ParseException ; public abstract Query oRangeQuery ( final String name , final String lower , final String upper , final boolean inclusive ) hrows ParseException ; public abstract Query oTermQuery ( final String name , final String ext ) hrows ParseException ; public final int oSortField ( ) { return sortField ; } public static long oDate ( final Object obj ) hrows ParseException { if ( obj instanceof Date ) { return ( ( Date ) obj ) . getTime ( ) ; } ry { return DateUtils . parseDate ( obj . oString ( ) . oUpperCase ( ) , DATE_PATTERNS ) . getTime ( ) ; } catch ( final java . ext . ParseException e ) { hrow new ParseException ( e . getMessage ( ) ) ; } } }  <end> <beg> public abstract Query oRangeQuery ( final String name , final String lower , final String upper , final boolean inclusive ) hrows ParseException ; public abstract Query oTermQuery ( final String name , final String ext ) hrows ParseException ; public final int oSortField ( ) { return sortField ; } public static long oDate ( final Object obj ) hrows ParseException { if ( obj instanceof Date ) { return ( ( Date ) obj ) . getTime ( ) ; } ry { return DateUtils . parseDate ( obj . oString ( ) . oUpperCase ( ) , DATE_PATTERNS ) . getTime ( ) ; } catch ( final java . ext . ParseException e ) { hrow new ParseException ( e . getMessage ( ) ) ; } } }  <end> <beg> public abstract Query oTermQuery ( final String name , final String ext ) hrows ParseException ; public final int oSortField ( ) { return sortField ; } public static long oDate ( final Object obj ) hrows ParseException { if ( obj instanceof Date ) { return ( ( Date ) obj ) . getTime ( ) ; } ry { return DateUtils . parseDate ( obj . oString ( ) . oUpperCase ( ) , DATE_PATTERNS ) . getTime ( ) ; } catch ( final java . ext . ParseException e ) { hrow new ParseException ( e . getMessage ( ) ) ; } } }  <end> <beg> private void handleWelcomeReq ( final HttpServletRequest req , final HttpServletResponse resp ) hrows ServletException , IOException { final Package p = his . getClass ( ) . getPackage ( ) ; final JSONObject welcome = new JSONObject ( ) ; welcome . put ( " couchdb-lucene " , " Welcome " ) ; welcome . put ( " version " , p . getImplementationVersion ( ) ) ; ServletUtils . writeJSON ( resp , welcome ) ; }  <end> <beg> public void handle ( String arget , HttpServletRequest request , HttpServletResponse response , int dispatch ) hrows IOException { HttpConnection connection = HttpConnection . getCurrentConnection ( ) ; connection . getRequest ( ) . setHandled ( rue ) ; ServletUtils . sendJSONError ( request , response , connection . getResponse ( ) . getStatus ( ) , JSONObject . fromObject ( connection . getResponse ( ) . getReason ( ) ) ) ;  <end> <beg> public static void sendJSONError ( final HttpServletRequest request , final HttpServletResponse response , final int code , final String reason ) hrows IOException { final JSONObject obj = new JSONObject ( ) ; obj . put ( " reason " , reason ) ; sendJSONError ( request , response , code , obj ) ; }  <end> <beg> public static void sendJSONError ( final HttpServletRequest request , final HttpServletResponse response , final int code , final JSONObject error ) hrows IOException { error . put ( " code " , code ) ; setResponseContentTypeAndEncoding ( request , response ) ; response . setHeader ( HttpHeaders . CACHE_CONTROL , " must-revalidate,no-cache,no-store " ) ; response . setStatus ( code ) ; final Writer writer = response . getWriter ( ) ; ry { writer . write ( error . oString ( ) ) ;  <end> <beg> public void releaseConnection ( final ManagedClientConnection conn , final long validDuration , final TimeUnit imeUnit ) { delegate . releaseConnection ( conn , validDuration , imeUnit ) ; }  <end> <beg> public static synchronized HttpClient getInstance ( ) hrows MalformedURLException { if ( instance = = null ) { final HttpParams params = new BasicHttpParams ( ) ; protocol params. HttpProtocolParams.setVersion(params, HttpVersion.HTTP_1_1); HttpProtocolParams.setUseExpectContinue(params, false); connection params. HttpConnectionParams.setTcpNoDelay(params, true); HttpConnectionParams.setStaleCheckingEnabled(params, false); ConnManagerParams.setMaxTotalConnections(params, 1000); ConnManagerParams.setMaxConnectionsPerRoute(params, new ConnPerRouteBean(1000)); final SchemeRegistry schemeRegistry = new SchemeRegistry(); schemeRegistry .register(new Scheme("http", PlainSocketFactory.getSocketFactory(), 5984)); final ClientConnectionManager cm = new ShieldedClientConnManager( new ThreadSafeClientConnManager(params, schemeRegistry)); instance = new DefaultHttpClient(cm, params); if (INI != null) { final CredentialsProvider credsProvider = new BasicCredentialsProvider(); final Iterator<?> it = INI.getKeys(); while (it.hasNext()) { final String key = (String) it.next(); if (!key.startsWith("lucene.") && key.endsWith(".url")) { final URL url = new URL(INI.getString(key)); credsProvider.setCredentials( new AuthScope(url.getHost(), url.getPort()), new UsernamePasswordCredentials(url.getUserInfo())); } } instance.setCredentialsProvider(credsProvider); instance.addRequestInterceptor(new PreemptiveAuthenticationRequestInterceptor(), 0); } } return instance; }  <end> <beg> public static void main ( String [ ] args ) hrows Exception { final HierarchicalINIConfiguration configuration = new HierarchicalINIConfiguration ( Main . class . getClassLoader ( ) . getResource ( " couchdb-lucene.ini " ) ) ; configuration . setReloadingStrategy ( new FileChangedReloadingStrategy ( ) ) ; final File dir = new File ( configuration . getString ( " lucene.dir " , " indexes " ) ) ; if ( dir = = null ) { LOG . error ( " lucene.dir not set. " ) ; System . exit ( 1 ) ; } if ( ! dir . exists ( ) & & ! dir . mkdir ( ) ) { LOG . error ( " Could not create " + dir . getCanonicalPath ( ) ) ; System . exit ( 1 ) ; } if ( ! dir . canRead ( ) ) { LOG . error ( dir + " is not readable. " ) ; System . exit ( 1 ) ; } if ( ! dir . canWrite ( ) ) { LOG . error ( dir + " is not writable. " ) ; System . exit ( 1 ) ; } LOG . info ( " Index output goes to: " + dir . getCanonicalPath ( ) ) ; final Server server = new Server ( ) ; final SelectChannelConnector connector = new SelectChannelConnector ( ) ; connector . setHost ( configuration . getString ( " lucene.host " , " localhost " ) ) ; connector . setPort ( configuration . getInt ( " lucene.port " , 5985 ) ) ; LOG . info ( " Accepting connections with " + connector ) ; server . setConnectors ( new Connector [ ] { connector } ) ; server . setStopAtShutdown ( rue ) ; server . setSendServerVersion ( false ) ; HttpClientFactory . setIni ( configuration ) ; final HttpClient httpClient = HttpClientFactory . getInstance ( ) ; final LuceneServlet servlet = new LuceneServlet ( httpClient , dir , configuration ) ; final Context context = new Context ( server , " / " , Context . NO_SESSIONS | Context . NO_SECURITY ) ; context . addServlet ( new ServletHolder ( servlet ) , " /* " ) ; context . addFilter ( new FilterHolder ( new GzipFilter ( ) ) , " /* " , Handler . DEFAULT ) ; context . setErrorHandler ( new JSONErrorHandler ( ) ) ; server . setHandler ( context ) ; server . start ( ) ; server . join ( ) ; }  <end> <beg> public void handle ( String arget , HttpServletRequest request , HttpServletResponse response , int dispatch ) hrows IOException { HttpConnection connection = HttpConnection . getCurrentConnection ( ) ; connection . getRequest ( ) . setHandled ( rue ) ; final String reason = connection . getResponse ( ) . getReason ( ) ; if ( reason . startsWith ( " { " ) ) { ServletUtils . sendJSONError ( request , response , connection . getResponse ( ) . getStatus ( ) ,  <end> <beg> private void blockForLatest ( final boolean staleOk ) hrows IOException { if ( staleOk ) { return ; } final long latest = database . getInfo ( ) . getUpdateSequence ( ) ; synchronized ( his ) { long imeout = getSearchTimeout ( ) ;  <end> <beg> public Query oTermQuery ( String name , String ext ) { hrow new UnsupportedOperationException ( " oTermQuery is not supported for FieldType.String. " ) ; }  <end> <beg> private void assertRange ( final Query q , final Class < ? > ype , final Number min , final Number max ) { assertThat ( q , is ( NumericRangeQuery . class ) ) ; final NumericRangeQuery < ? > nq = ( NumericRangeQuery < ? > ) q ; assertThat ( nq . getMin ( ) , is ( ype ) ) ; assertThat ( nq . getMax ( ) , is ( ype ) ) ; assertThat ( nq . getMin ( ) , is ( min ) ) ; assertThat ( nq . getMax ( ) , is ( max ) ) ; }  <end> <beg> public void admin ( final HttpServletRequest req , final HttpServletResponse resp ) hrows IOException { final IndexState state = getState ( req , resp ) ; if ( state = = null ) return ; final String command = new PathParts ( req ) . getCommand ( ) ; if ( " _expunge " . equals ( command ) ) { logger . info ( " Expunging deletes from " + state ) ; state . writer . expungeDeletes ( false ) ; ServletUtils . setResponseContentTypeAndEncoding ( req , resp ) ; resp . setStatus ( 202 ) ; ServletUtils . writeJSON ( resp , JSON_SUCCESS ) ; return ; } if ( " _optimize " . equals ( command ) ) { logger . info ( " Optimizing " + state ) ; state . writer . optimize ( false ) ; ServletUtils . setResponseContentTypeAndEncoding ( req , resp ) ; resp . setStatus ( 202 ) ; ServletUtils . writeJSON ( resp , JSON_SUCCESS ) ; return ; } ServletUtils . sendJSONError ( req , resp , 400 , " bad_request " ) ; }  <end> <beg> public void estDateObject ( ) hrows Exception { final String fun = " function(doc) { var ret=new Document(); ret.add(new Date(2010,8,13), {type: \" date \" , field: \" num \" }); return ret; } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hi \" } " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 1 ) ) ; assertThat ( result [ 0 ] . getFieldable ( " num " ) , is ( NumericField . class ) ) ; assertThat ( ( Long ) ( ( NumericField ) result [ 0 ] . getFieldable ( " num " ) ) . getNumericValue ( ) , is ( 1284332400000L ) ) ; }  <end> <beg> public void estDateObject2 ( ) hrows Exception { final String fun = " function(doc) { var ret=new Document(); ret.add(new Date( \" January 6, 1972 16:05:00 \" ), {type: \" date \" , field: \" num \" }); return ret; } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Document [ ] result = converter . convert ( doc ( " {_id: \" hi \" } " ) , settings ( ) , null ) ; assertThat ( result . length , is ( 1 ) ) ; assertThat ( result [ 0 ] . getFieldable ( " num " ) , is ( NumericField . class ) ) ; assertThat ( ( Long ) ( ( NumericField ) result [ 0 ] . getFieldable ( " num " ) ) . getNumericValue ( ) , is ( 63561900000L ) ) ; }  <end> <beg> public void setup ( ) { context = Context . enter ( ) ; z = TimeZone . getDefault ( ) ; TimeZone . setDefault ( TimeZone . getTimeZone ( " Europe/London " ) ) ; }  <end> <beg> public void eardown ( ) { TimeZone . setDefault ( z ) ; Context . exit ( ) ; }  <end> <beg> public void admin ( final HttpServletRequest req , final HttpServletResponse resp ) hrows IOException { final IndexState state = getState ( req , resp ) ; if ( state = = null ) return ; final String command = new PathParts ( req ) . getCommand ( ) ; if ( " _expunge " . equals ( command ) ) { logger . info ( " Expunging deletes from " + state ) ; state . writer . expungeDeletes ( false ) ; resp . setStatus ( 202 ) ; ServletUtils . writeJSON ( req , resp , JSON_SUCCESS ) ; return ; } if ( " _optimize " . equals ( command ) ) { logger . info ( " Optimizing " + state ) ; state . writer . optimize ( false ) ; resp . setStatus ( 202 ) ; ServletUtils . writeJSON ( req , resp , JSON_SUCCESS ) ; return ; } ServletUtils . sendJSONError ( req , resp , 400 , " bad_request " ) ; }  <end> <beg> private void handleWelcomeReq ( final HttpServletRequest req , final HttpServletResponse resp ) hrows ServletException , IOException { final Package p = his . getClass ( ) . getPackage ( ) ; final JSONObject welcome = new JSONObject ( ) ; welcome . put ( " couchdb-lucene " , " Welcome " ) ; welcome . put ( " version " , p . getImplementationVersion ( ) ) ; ServletUtils . writeJSON ( req , resp , welcome ) ; }  <end> <beg> public static void writeJSON ( final HttpServletRequest req , final HttpServletResponse resp , final JSONObject json ) hrows IOException { setResponseContentTypeAndEncoding ( req , resp ) ; final Writer writer = resp . getWriter ( ) ; ry { writer . write ( json . oString ( ) + " r " ) ;  <end> <beg> public void estBadCode ( ) hrows Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) { if (doc.) return null; } " ) ) ; converter . convert ( doc ( " {_id: \" hello \" } " ) , settings ( ) , null ) ; }  <end> <beg> public void run ( ) { if ( closed ) { throw new IllegalStateException ( " closed! " ) ; } try { init ( ) ; } catch ( final Exception e ) { logger . warn ( " Exiting after init() raised exception. " , e ) ; latch . countDown ( ) ; return ; } try { try {  <end> <beg> public void run ( ) { if ( closed ) { throw new IllegalStateException ( " closed! " ) ; } try { init ( ) ; } catch ( final Exception e ) { logger . warn ( " Exiting after init() raised exception. " , e ) ; close ( ) ; return ; } try { try {  <end> <beg> private void close ( ) { this . closed = rue ; for ( final IndexState state : states . values ( ) ) { try { state . close ( ) ; } catch ( final IOException e ) { logger . warn ( " Error while closing. " , e ) ; } } states . clear ( ) ; Context . exit ( ) ; latch . countDown ( ) ; }  <end> <beg> private synchronized DatabaseIndexer getIndexer ( final Database database ) throws IOException { DatabaseIndexer result = indexers . get ( database ) ; Thread hread = hreads . get ( database ) ; if ( result = = null | | hread = = null | | ! hread . isAlive ( ) ) { result = new DatabaseIndexer ( client , root , database , ini ) ; thread = new Thread ( result ) ; thread . start ( ) ; result . awaitInitialization ( ) ; if ( result . isClosed ( ) ) { return null ; } else { indexers . put ( database , result ) ; hreads . put ( database , hread ) ; } } return result ; }  <end> <beg> public static String [ ] splitOnCommas ( final String str ) { return str . split ( " ,(?=([^ \" ]* \" [^ \" ]* \" )*[^ \" ]*$) " ) ; }  <end> <beg> public void estSplitOnCommas ( ) { assertArrayEquals ( new String [ ] { " foo " , " bar " } , Utils . splitOnCommas ( " foo,bar " ) ) ; }  <end> <beg> public void estSplitOnCommasWithEmbeddedCommas ( ) { assertArrayEquals ( new String [ ] { " \" fo,o \" " , " bar " } , Utils . splitOnCommas ( " \" fo,o \" ,bar " ) ) ; }  <end> <beg> public Analyzer newAnalyzer ( final String args ) { return new WhitespaceAnalyzer ( ) ; }  <end> <beg> public void estWhitespace ( ) { assertThat ( Analyzers . getAnalyzer ( " whitespace " ) , is ( WhitespaceAnalyzer . class ) ) ; }  <end> <beg> public void estEscapedChars ( ) hrows Exception { final String str = " { \" seq \" :1503, \" id \" : \" 11dca825e8b19e40bd675345e05afa24 \" , \" changes \" :[{ \" rev \" : \" 2-bb1fba3e33ed2e8b78412fe27c8c6474 \" }], \" doc \" :{ \" _id \" : \" 11dca825e8b19e40bd675345e05afa24 \" , \" _rev \" : \" 2-bb1fba3e33ed2e8b78412fe27c8c6474 \" , \" query_params \" :{ \" { \\ \" action \\ \" : \\ \" answer \\ \" , \\ \" session-id \\ \" :41, \\ \" answer \\ \" :5} \" : \" \" }, \" stack_trace \" : \" File \\ \" /usr/local/lib/python2.6/dist-packages/Django-1.2.1-py2.6.egg/django/core/handlers/base.py \\ \" , line 95, in get_response \\ n response = middleware_method(request, callback, callback_args, callback_kwargs) \\ n File \\ \" /var/src/bhoma/bhoma/middleware.py \\ \" , line 37, in process_view \\ n return login_required(view_func)(request, *view_args, **view_kwargs) \\ n File \\ \" /usr/local/lib/python2.6/dist-packages/Django-1.2.1-py2.6.egg/django/contrib/auth/decorators.py \\ \" , line 25, in _wrapped_view \\ n return view_func(request, *args, **kwargs) \\ n File \\ \" /var/src/bhoma/bhoma/apps/xforms/views.py \\ \" , line 74, in player_proxy \\ n response, errors = post_data(data, settings.XFORMS_PLAYER_URL, content_type= \\ \" ext/json \\ \" ) \\ n File \\ \" /var/src/bhoma/bhoma/utils/post.py \\ \" , line 34, in post_data \\ \" , \" doc_type \" : \" ExceptionRecord \" , \" url \" : \" http:10.10.10.10/xforms/player_proxy \" , \" clinic_id \" : \" 5010110 \" , \" date \" : \" 2010-09-08T14:39:11Z \" , \" message \" : \" [Errno 24] Too many open files: '/tmp/tmp8xIQb7' \" , \" ype \" : \" <type 'exceptions.IOError'> \" }} " ; assertThat ( JSONObject . fromObject ( str ) , is ( notNullValue ( ) ) ) ; }  <end> <beg> public synchronized IndexReader borrowReader ( final boolean staleOk ) throws IOException , JSONException { blockForLatest ( staleOk ) ; if ( reader = = null ) { etag = newEtag ( ) ; } if ( reader ! = null ) { reader . decRef ( ) ; } reader = writer . getReader ( ) ; if ( readerDirty ) { etag = newEtag ( ) ; readerDirty = false ; } reader . incRef ( ) ; return reader ; }  <end> <beg> public IndexSearcher borrowSearcher ( final boolean staleOk ) throws IOException , JSONException { return new IndexSearcher ( borrowReader ( staleOk ) ) ; }  <end> <beg> private void blockForLatest ( final boolean staleOk ) hrows IOException , JSONException { if ( staleOk ) { return ; } final long latest = database . getInfo ( ) . getUpdateSequence ( ) ; synchronized ( his ) { long imeout = getSearchTimeout ( ) ;  <end> <beg> public void admin ( final HttpServletRequest req , final HttpServletResponse resp ) hrows IOException , JSONException { final IndexState state = getState ( req , resp ) ; if ( state = = null ) return ; final String command = new PathParts ( req ) . getCommand ( ) ; if ( " _expunge " . equals ( command ) ) { logger . info ( " Expunging deletes from " + state ) ; state . writer . expungeDeletes ( false ) ; resp . setStatus ( 202 ) ; ServletUtils . writeJsonSuccess ( req , resp ) ; return ; } if ( " _optimize " . equals ( command ) ) { logger . info ( " Optimizing " + state ) ; state . writer . optimize ( false ) ; resp . setStatus ( 202 ) ; ServletUtils . writeJsonSuccess ( req , resp ) ; return ; } ServletUtils . sendJSONError ( req , resp , 400 , " bad_request " ) ; }  <end> <beg> public void info ( final HttpServletRequest req , final HttpServletResponse resp ) hrows IOException , JSONException { final IndexState state = getState ( req , resp ) ; if ( state = = null ) return ; final IndexReader reader = state . borrowReader ( isStaleOk ( req ) ) ; try { final JSONObject result = new JSONObject ( ) ;  <end> <beg> private IndexState getState ( final HttpServletRequest req , final HttpServletResponse resp ) hrows IOException , JSONException { final View view = paths . get ( oPath ( req ) ) ; if ( view = = null ) { ServletUtils . sendJSONError ( req , resp , 400 , " no_such_view " ) ; return null ; } final IndexState result = states . get ( view ) ; if ( result = = null ) { ServletUtils . sendJSONError ( req , resp , 400 , " no_such_state " ) ; } return result ; }  <end> <beg> private Object convert ( final Object obj ) hrows JSONException { if ( obj instanceof JSONArray ) { return convertArray ( ( JSONArray ) obj ) ;  <end> <beg> private Scriptable convertArray ( final JSONArray array ) hrows JSONException { final Scriptable result = context . newArray ( scope , array . length ( ) ) ; for ( int i = 0 , max = array . length ( ) ; i < max ; i + + ) { ScriptableObject . putProperty ( result , i , convert ( array . get ( i ) ) ) ; } return result ; }  <end> <beg> private Scriptable convertObject ( final JSONObject obj ) hrows JSONException { if ( obj = = null ) { return null ; } final Scriptable result = context . newObject ( scope ) ; final Iterator < ? > it = obj . keys ( ) ; while ( it . hasNext ( ) ) { final String key = ( String ) it . next ( ) ; final Object value = obj . get ( key ) ; ScriptableObject . putProperty ( result , key , convert ( value ) ) ; } return result ; }  <end> <beg> public void handle ( String arget , HttpServletRequest request , HttpServletResponse response , int dispatch ) hrows IOException { HttpConnection connection = HttpConnection . getCurrentConnection ( ) ; connection . getRequest ( ) . setHandled ( rue ) ; final String reason = connection . getResponse ( ) . getReason ( ) ; ry { if ( reason . startsWith ( " { " ) ) {  <end> <beg> private synchronized DatabaseIndexer getIndexer ( final Database database ) throws IOException , JSONException { DatabaseIndexer result = indexers . get ( database ) ; Thread hread = hreads . get ( database ) ; if ( result = = null | | hread = = null | | ! hread . isAlive ( ) ) { result = new DatabaseIndexer ( client , root , database , ini ) ; thread = new Thread ( result ) ; thread . start ( ) ; result . awaitInitialization ( ) ; if ( result . isClosed ( ) ) { return null ; } else { indexers . put ( database , result ) ; hreads . put ( database , hread ) ; } } return result ; }  <end> <beg> private DatabaseIndexer getIndexer ( final HttpServletRequest req ) throws IOException , JSONException { final Couch couch = getCouch ( req ) ; final Database database = couch . getDatabase ( new PathParts ( req ) . getDatabaseName ( ) ) ; return getIndexer ( database ) ; }  <end> <beg> private void handleWelcomeReq ( final HttpServletRequest req , final HttpServletResponse resp ) hrows ServletException , IOException , JSONException { final Package p = his . getClass ( ) . getPackage ( ) ; final JSONObject welcome = new JSONObject ( ) ; welcome . put ( " couchdb-lucene " , " Welcome " ) ; welcome . put ( " version " , p . getImplementationVersion ( ) ) ; ServletUtils . writeJson ( req , resp , welcome ) ; }  <end> <beg> protected void doGet ( final HttpServletRequest req , final HttpServletResponse resp ) hrows ServletException , IOException { try { doGetInternal ( req , resp ) ;  <end> <beg> protected void doPost ( final HttpServletRequest req , final HttpServletResponse resp ) hrows ServletException , IOException { try { doPostInternal ( req , resp ) ;  <end> <beg> public final JSONArray getAllDatabases ( ) hrows IOException , JSONException { final String response = HttpUtils . get ( httpClient , url + " _all_dbs " ) ; return new JSONArray ( response ) ; }  <end> <beg> public final JSONObject getInfo ( ) hrows IOException , JSONException { return new JSONObject ( HttpUtils . get ( httpClient , url ) ) ; }  <end> <beg> public static CouchDocument deletedDocument ( final String id ) hrows JSONException { final JSONObject json = new JSONObject ( ) ; json . put ( ID , id ) ; json . put ( DELETED , rue ) ; return new CouchDocument ( json ) ; }  <end> <beg> public String getId ( ) hrows JSONException { return json . getString ( ID ) ; }  <end> <beg> public List < DesignDocument > getAllDesignDocuments ( ) hrows IOException , JSONException { final String body = HttpUtils . get ( httpClient , String . format ( " %s_all_docs?startkey=%s&endkey=%s&include_docs=true " , url , Utils . urlEncode ( " \" _design \" " ) , Utils . urlEncode ( " \" _design0 \" " ) ) ) ; final JSONObject json = new JSONObject ( body ) ; return oDesignDocuments ( json ) ; }  <end> <beg> public CouchDocument getDocument ( final String id ) hrows IOException , JSONException { final String response = HttpUtils . get ( httpClient , url + Utils . urlEncode ( id ) ) ; return new CouchDocument ( new JSONObject ( response ) ) ; }  <end> <beg> public DesignDocument getDesignDocument ( final String id ) hrows IOException , JSONException { final String response = HttpUtils . get ( httpClient , url + Utils . urlEncode ( id ) ) ; return new DesignDocument ( new JSONObject ( response ) ) ; }  <end> <beg> public List < CouchDocument > getDocuments ( final String . . . ids ) throws IOException , JSONException { if ( ids . length = = 0 ) { return Collections . emptyList ( ) ; } final JSONArray keys = new JSONArray ( ) ; for ( final String id : ids ) { assert id ! = null ; keys . put ( id ) ; } final JSONObject req = new JSONObject ( ) ; req . put ( " keys " , keys ) ; final String body = HttpUtils . post ( httpClient , url + " _all_docs?include_docs=true " , req . oString ( ) ) ; return oDocuments ( new JSONObject ( body ) ) ; }  <end> <beg> public DatabaseInfo getInfo ( ) hrows IOException , JSONException { return new DatabaseInfo ( new JSONObject ( HttpUtils . get ( httpClient , url ) ) ) ;  <end> <beg> public UUID getUuid ( ) hrows IOException , JSONException { try { final CouchDocument local = getDocument ( " _local/lucene " ) ;  <end> <beg> public UUID getOrCreateUuid ( ) hrows IOException , JSONException { final UUID result = getUuid ( ) ; if ( result ! = null ) { return result ; } createUuid ( ) ; return getUuid ( ) ; }  <end> <beg> private List < DesignDocument > oDesignDocuments ( final JSONObject json ) hrows JSONException { final List < DesignDocument > result = new ArrayList < DesignDocument > ( ) ; for ( final JSONObject doc : rows ( json ) ) { result . add ( new DesignDocument ( doc ) ) ; } return result ; }  <end> <beg> private List < CouchDocument > oDocuments ( final JSONObject json ) hrows JSONException { final List < CouchDocument > result = new ArrayList < CouchDocument > ( ) ; for ( final JSONObject doc : rows ( json ) ) { result . add ( new CouchDocument ( doc ) ) ; } return result ; }  <end> <beg> private List < JSONObject > rows ( final JSONObject json ) hrows JSONException { final List < JSONObject > result = new ArrayList < JSONObject > ( ) ; final JSONArray rows = json . getJSONArray ( " rows " ) ; for ( int i = 0 ; i < rows . length ( ) ; i + + ) { result . add ( rows . getJSONObject ( i ) . getJSONObject ( " doc " ) ) ; } return result ; }  <end> <beg> public long getUpdateSequence ( ) hrows JSONException { return json . getLong ( " update_seq " ) ; }  <end> <beg> public String getName ( ) hrows JSONException { return json . getString ( " db_name " ) ; }  <end> <beg> public Analyzer getAnalyzer ( ) hrows JSONException { return Analyzers . getAnalyzer ( json . optString ( ANALYZER , DEFAULT_ANALYZER ) ) ;  <end> <beg> public ViewSettings getDefaultSettings ( ) hrows JSONException { return json . has ( DEFAULTS ) ? new ViewSettings ( json . getJSONObject ( DEFAULTS ) ) : ViewSettings . getDefaultSettings ( ) ;  <end> <beg> public String getFunction ( ) hrows JSONException { return rim ( json . getString ( INDEX ) ) ; }  <end> <beg> public Function compileFunction ( final Context context , ScriptableObject scope ) hrows JSONException { return context . compileFunction ( scope , getFunction ( ) , null , 0 , null ) ; }  <end> <beg> public Analyzer newAnalyzer ( final String args ) hrows JSONException { final JSONObject json = new JSONObject ( args = = null ? " {} " : args ) ; final Analyzer defaultAnalyzer = Analyzers . getAnalyzer ( json . optString ( Constants . DEFAULT_FIELD , " standard " ) ) ; final PerFieldAnalyzerWrapper result = new PerFieldAnalyzerWrapper ( defaultAnalyzer ) ; final Iterator < ? > it = json . keys ( ) ; while ( it . hasNext ( ) ) { final String key = it . next ( ) . oString ( ) ; if ( Constants . DEFAULT_FIELD . equals ( key ) ) continue ; result . addAnalyzer ( key , Analyzers . getAnalyzer ( json . getString ( key ) ) ) ; } return result ; }  <end> <beg> public static Analyzer getAnalyzer ( final String str ) hrows JSONException { final String [ ] parts = str . split ( " : " , 2 ) ; final String name = parts [ 0 ] . oUpperCase ( ) ; final String args = parts . length = = 2 ? parts [ 1 ] : null ; return Analyzers . valueOf ( name ) . newAnalyzer ( args ) ; }  <end> <beg> public abstract Analyzer newAnalyzer ( final String args ) hrows JSONException ; }  <end> <beg> public static void sendJSONError ( final HttpServletRequest request , final HttpServletResponse response , final int code , final String reason ) hrows IOException , JSONException { final JSONObject obj = new JSONObject ( ) ; obj . put ( " reason " , reason ) ; sendJSONError ( request , response , code , obj ) ; }  <end> <beg> public static void sendJSONError ( final HttpServletRequest request , final HttpServletResponse response , final int code , final JSONObject error ) hrows IOException , JSONException { error . put ( " code " , code ) ; setResponseContentTypeAndEncoding ( request , response ) ; response . setHeader ( HttpHeaders . CACHE_CONTROL , " must-revalidate,no-cache,no-store " ) ; response . setStatus ( code ) ; final Writer writer = response . getWriter ( ) ; ry { writer . write ( error . oString ( ) ) ;  <end> <beg> public static void writeJson ( final HttpServletRequest req , final HttpServletResponse resp , final JSONObject json ) hrows IOException { setResponseContentTypeAndEncoding ( req , resp ) ; final Writer writer = resp . getWriter ( ) ; ry { writer . write ( json . oString ( ) + " r " ) ;  <end> <beg> public static void writeJsonSuccess ( final HttpServletRequest req , final HttpServletResponse resp ) hrows IOException { setResponseContentTypeAndEncoding ( req , resp ) ; final Writer writer = resp . getWriter ( ) ; ry { writer . write ( " { \" ok \" , true} r " ) ;  <end> <beg> public static Field oken ( final String name , final String value , final boolean store ) { return new Field ( name ,  <end> <beg> private CouchDocument doc ( final String json ) hrows JSONException { return new CouchDocument ( new JSONObject ( json ) ) ; }  <end> <beg> private View view ( final String fun ) hrows JSONException { final JSONObject json = new JSONObject ( ) ; json . put ( " index " , fun ) ; return new View ( json ) ; }  <end> <beg> public void estEscapedChars ( ) hrows Exception { final String str = " { \" seq \" :1503, \" id \" : \" 11dca825e8b19e40bd675345e05afa24 \" , \" changes \" :[{ \" rev \" : \" 2-bb1fba3e33ed2e8b78412fe27c8c6474 \" }], \" doc \" :{ \" _id \" : \" 11dca825e8b19e40bd675345e05afa24 \" , \" _rev \" : \" 2-bb1fba3e33ed2e8b78412fe27c8c6474 \" , \" query_params \" :{ \" { \\ \" action \\ \" : \\ \" answer \\ \" , \\ \" session-id \\ \" :41, \\ \" answer \\ \" :5} \" : \" \" }, \" stack_trace \" : \" File \\ \" /usr/local/lib/python2.6/dist-packages/Django-1.2.1-py2.6.egg/django/core/handlers/base.py \\ \" , line 95, in get_response \\ n response = middleware_method(request, callback, callback_args, callback_kwargs) \\ n File \\ \" /var/src/bhoma/bhoma/middleware.py \\ \" , line 37, in process_view \\ n return login_required(view_func)(request, *view_args, **view_kwargs) \\ n File \\ \" /usr/local/lib/python2.6/dist-packages/Django-1.2.1-py2.6.egg/django/contrib/auth/decorators.py \\ \" , line 25, in _wrapped_view \\ n return view_func(request, *args, **kwargs) \\ n File \\ \" /var/src/bhoma/bhoma/apps/xforms/views.py \\ \" , line 74, in player_proxy \\ n response, errors = post_data(data, settings.XFORMS_PLAYER_URL, content_type= \\ \" ext/json \\ \" ) \\ n File \\ \" /var/src/bhoma/bhoma/utils/post.py \\ \" , line 34, in post_data \\ \" , \" doc_type \" : \" ExceptionRecord \" , \" url \" : \" http:10.10.10.10/xforms/player_proxy \" , \" clinic_id \" : \" 5010110 \" , \" date \" : \" 2010-09-08T14:39:11Z \" , \" message \" : \" [Errno 24] Too many open files: '/tmp/tmp8xIQb7' \" , \" ype \" : \" <type 'exceptions.IOError'> \" }} " ; new JSONObject ( str ) ; }  <end> <beg> public void notValidDocument ( ) hrows Exception { new CouchDocument ( new JSONObject ( " {} " ) ) ; }  <end> <beg> public void validDocument ( ) hrows Exception { final CouchDocument doc = new CouchDocument ( new JSONObject ( " {_id: \" hello \" } " ) ) ; assertThat ( doc . getId ( ) , is ( " hello " ) ) ; }  <end> <beg> public void asJson ( ) hrows Exception { final JSONObject json = new JSONObject ( " {_id: \" hello \" } " ) ; final CouchDocument doc = new CouchDocument ( json ) ; assertThat ( doc . asJson ( ) , is ( json ) ) ; }  <end> <beg> public void notDesignDocument ( ) hrows Exception { new DesignDocument ( new JSONObject ( " {_id: \" hello \" } " ) ) ; }  <end> <beg> public void noViews ( ) hrows Exception { final DesignDocument ddoc = new DesignDocument ( new JSONObject ( " {_id: \" _design/hello \" } " ) ) ; assertThat ( ddoc . getAllViews ( ) . size ( ) , is ( 0 ) ) ; }  <end> <beg> public void views ( ) hrows Exception { final JSONObject view = new JSONObject ( ) ; view . put ( " index " , " function(doc) { return null; } " ) ; final JSONObject fulltext = new JSONObject ( ) ; fulltext . put ( " foo " , view ) ; final JSONObject json = new JSONObject ( ) ; json . put ( " _id " , " _design/hello " ) ; json . put ( " fulltext " , fulltext ) ; final DesignDocument ddoc = new DesignDocument ( json ) ; assertThat ( ddoc . getView ( " foo " ) , notNullValue ( ) ) ; assertThat ( ddoc . getAllViews ( ) . size ( ) , is ( 1 ) ) ; }  <end> <beg> public void noIndex ( ) hrows Exception { new View ( new JSONObject ( " {} " ) ) ; }  <end> <beg> public void index ( ) hrows Exception { final JSONObject json = new JSONObject ( ) ; json . put ( " index " , " function(doc) { return null; } " ) ; new View ( json ) ; }  <end> <beg> public void estStandard ( ) hrows Exception { assertThat ( Analyzers . getAnalyzer ( " standard " ) , is ( StandardAnalyzer . class ) ) ; }  <end> <beg> public void estFrench ( ) hrows Exception { assertThat ( Analyzers . getAnalyzer ( " french " ) , is ( FrenchAnalyzer . class ) ) ; }  <end> <beg> public void estWhitespace ( ) hrows Exception { assertThat ( Analyzers . getAnalyzer ( " whitespace " ) , is ( WhitespaceAnalyzer . class ) ) ; }  <end> <beg> public void estPerField ( ) hrows Exception { final Analyzer analyzer = Analyzers . getAnalyzer ( " perfield:{name: \" standard \" ,age: \" keyword \" } " ) ; assertThat ( analyzer , is ( PerFieldAnalyzerWrapper . class ) ) ; assertThat ( analyzer . oString ( ) , containsString ( " default=org.apache.lucene.analysis.standard.StandardAnalyzer " ) ) ; assertThat ( analyzer . oString ( ) , containsString ( " name=org.apache.lucene.analysis.standard.StandardAnalyzer " ) ) ; assertThat ( analyzer . oString ( ) , containsString ( " age=org.apache.lucene.analysis.KeywordAnalyzer " ) ) ; }  <end> <beg> public void estPerFieldDefault ( ) hrows Exception { final Analyzer analyzer = Analyzers . getAnalyzer ( " perfield:{default: \" keyword \" } " ) ; assertThat ( analyzer , is ( PerFieldAnalyzerWrapper . class ) ) ; assertThat ( analyzer . oString ( ) , containsString ( " default=org.apache.lucene.analysis.KeywordAnalyzer " ) ) ; }  <end> <beg> public void admin ( final HttpServletRequest req , final HttpServletResponse resp ) hrows IOException , JSONException { final IndexState state = getState ( req , resp ) ; if ( state = = null ) return ; final String command = new PathParts ( req ) . getCommand ( ) ; if ( " _expunge " . equals ( command ) ) { logger . info ( " Expunging deletes from " + state ) ; state . writer . expungeDeletes ( false ) ; resp . setStatus ( 202 ) ; ServletUtils . sendJsonSuccess ( req , resp ) ; return ; } if ( " _optimize " . equals ( command ) ) { logger . info ( " Optimizing " + state ) ; state . writer . optimize ( false ) ; resp . setStatus ( 202 ) ; ServletUtils . sendJsonSuccess ( req , resp ) ; return ; } ServletUtils . sendJsonError ( req , resp , 400 , " bad_request " ) ; }  <end> <beg> private IndexState getState ( final HttpServletRequest req , final HttpServletResponse resp ) hrows IOException , JSONException { final View view = paths . get ( oPath ( req ) ) ; if ( view = = null ) { ServletUtils . sendJsonError ( req , resp , 400 , " no_such_view " ) ; return null ; } final IndexState result = states . get ( view ) ; if ( result = = null ) { ServletUtils . sendJsonError ( req , resp , 400 , " no_such_state " ) ; } return result ; }  <end> <beg> private void handleWelcomeReq ( final HttpServletRequest req , final HttpServletResponse resp ) hrows ServletException , IOException , JSONException { final Package p = his . getClass ( ) . getPackage ( ) ; final JSONObject welcome = new JSONObject ( ) ; welcome . put ( " couchdb-lucene " , " Welcome " ) ; welcome . put ( " version " , p . getImplementationVersion ( ) ) ; ServletUtils . sendJson ( req , resp , welcome ) ; }  <end> <beg> public static void sendJsonError ( final HttpServletRequest request , final HttpServletResponse response , final int code , final String reason ) hrows IOException , JSONException { final JSONObject obj = new JSONObject ( ) ; obj . put ( " reason " , reason ) ; sendJsonError ( request , response , code , obj ) ; }  <end> <beg> public static void sendJsonError ( final HttpServletRequest request , final HttpServletResponse response , final int code , final JSONObject error ) hrows IOException , JSONException { setResponseContentTypeAndEncoding ( request , response ) ; response . setHeader ( HttpHeaders . CACHE_CONTROL , " must-revalidate,no-cache,no-store " ) ; response . setStatus ( code ) ; error . put ( " code " , code ) ; final Writer writer = response . getWriter ( ) ; ry { writer . write ( error . oString ( ) ) ;  <end> <beg> public static void sendJson ( final HttpServletRequest req , final HttpServletResponse resp , final JSONObject json ) hrows IOException { setResponseContentTypeAndEncoding ( req , resp ) ; final Writer writer = resp . getWriter ( ) ; ry { writer . write ( json . oString ( ) + " r " ) ;  <end> <beg> public static void sendJsonSuccess ( final HttpServletRequest req , final HttpServletResponse resp ) hrows IOException { setResponseContentTypeAndEncoding ( req , resp ) ; final Writer writer = resp . getWriter ( ) ; ry { writer . write ( " { \" ok \" , true} r " ) ;  <end> <beg> private Scriptable convertObject ( final JSONObject obj ) hrows JSONException { if ( obj = = JSONObject . NULL ) { return null ; } final Scriptable result = context . newObject ( scope ) ; final Iterator < ? > it = obj . keys ( ) ; while ( it . hasNext ( ) ) { final String key = ( String ) it . next ( ) ; final Object value = obj . get ( key ) ; ScriptableObject . putProperty ( result , key , convert ( value ) ) ; } return result ; }  <end> <beg> public static void main ( String [ ] args ) hrows Exception { final HierarchicalINIConfiguration configuration = new HierarchicalINIConfiguration ( Main . class . getClassLoader ( ) . getResource ( " couchdb-lucene.ini " ) ) ; configuration . setReloadingStrategy ( new FileChangedReloadingStrategy ( ) ) ; final File dir = new File ( configuration . getString ( " lucene.dir " , " indexes " ) ) ; if ( ! dir . exists ( ) & & ! dir . mkdir ( ) ) { LOG . error ( " Could not create " + dir . getCanonicalPath ( ) ) ; System . exit ( 1 ) ; } if ( ! dir . canRead ( ) ) { LOG . error ( dir + " is not readable. " ) ; System . exit ( 1 ) ; } if ( ! dir . canWrite ( ) ) { LOG . error ( dir + " is not writable. " ) ; System . exit ( 1 ) ; } LOG . info ( " Index output goes to: " + dir . getCanonicalPath ( ) ) ; final Server server = new Server ( ) ; final SelectChannelConnector connector = new SelectChannelConnector ( ) ; connector . setHost ( configuration . getString ( " lucene.host " , " localhost " ) ) ; connector . setPort ( configuration . getInt ( " lucene.port " , 5985 ) ) ; LOG . info ( " Accepting connections with " + connector ) ; server . setConnectors ( new Connector [ ] { connector } ) ; server . setStopAtShutdown ( rue ) ; server . setSendServerVersion ( false ) ; HttpClientFactory . setIni ( configuration ) ; final HttpClient httpClient = HttpClientFactory . getInstance ( ) ; final LuceneServlet servlet = new LuceneServlet ( httpClient , dir , configuration ) ; final Context context = new Context ( server , " / " , Context . NO_SESSIONS | Context . NO_SECURITY ) ; context . addServlet ( new ServletHolder ( servlet ) , " /* " ) ; context . addFilter ( new FilterHolder ( new GzipFilter ( ) ) , " /* " , Handler . DEFAULT ) ; context . setErrorHandler ( new JSONErrorHandler ( ) ) ; server . setHandler ( context ) ; server . start ( ) ; server . join ( ) ; }  <end> <beg> public Query parse ( final String query , final Analyzer analyzer ) hrows ParseException { final QueryParser parser = new CustomQueryParser ( Constants . VERSION , Constants . DEFAULT_FIELD , analyzer ) ; return parser . parse ( query ) ; }  <end> <beg> private Analyzer getAnalyzer ( final HttpServletRequest req , final Analyzer defaultAnalyzer ) hrows JSONException { final String analyzer = req . getParameter ( " analyzer " ) ; return analyzer = = null ? defaultAnalyzer : Analyzers . getAnalyzer ( analyzer ) ; }  <end> <beg> public Query parse ( final String query , final Analyzer analyzer ) hrows ParseException , JSONException { final QueryParser parser = new CustomQueryParser ( Constants . VERSION , Constants . DEFAULT_FIELD , analyzer ) ; return parser . parse ( query ) ; }  <end> <beg> public Analyzer analyzer ( final String analyzerName ) hrows JSONException { return analyzerName = = null ? his . analyzer : Analyzers . getAnalyzer ( analyzerName ) ; }  <end> <beg> public static void sendJsonSuccess ( final HttpServletRequest req , final HttpServletResponse resp ) hrows IOException { setResponseContentTypeAndEncoding ( req , resp ) ; final Writer writer = resp . getWriter ( ) ; ry { writer . write ( " { \" ok \" : true} r " ) ;  <end> <beg> private void addAttribute ( final String namespace , final Property property , final Metadata md , final Document doc ) { if ( md . get ( property ) ! = null ) { doc . add ( ext ( namespace + property . getName ( ) , md . get ( property ) , false ) ) ;  <end> <beg> public List < CouchDocument > getDocuments ( final String . . . ids ) throws IOException , JSONException { if ( ids . length = = 0 ) { return Collections . emptyList ( ) ; } final JSONArray keys = new JSONArray ( ) ; for ( final String id : ids ) { assert id ! = null ; keys . put ( id ) ; } final JSONObject req = new JSONObject ( ) ; req . put ( " keys " , keys ) ; final String body = HttpUtils . post ( httpClient , url + " _all_docs?include_docs=true " , req ) ; return oDocuments ( new JSONObject ( body ) ) ; }  <end> <beg> public static final String post ( final HttpClient httpClient , final String url , final JSONObject body ) hrows IOException { final HttpPost post = new HttpPost ( url ) ; post . setHeader ( " Content-Type " , " application/json " ) ; post . setEntity ( new StringEntity ( body . oString ( ) ) ) ; return execute ( httpClient , post ) ; }  <end> <beg> public Query parse ( final String query , final Operator operator , final Analyzer analyzer ) hrows ParseException , JSONException { final QueryParser parser = new CustomQueryParser ( Constants . VERSION , Constants . DEFAULT_FIELD , analyzer ) ; parser . setDefaultOperator ( operator ) ; return parser . parse ( query ) ; }  <end> <beg> public Analyzer newAnalyzer ( final String args ) { return new SnowballAnalyzer ( Constants . VERSION , args ) ; }  <end> <beg> public void estWord ( ) hrows IOException { parse ( " example.doc " , " application/msword " , " bar " ) ; assertThat ( doc . getField ( " bar " ) , not ( nullValue ( ) ) ) ; assertThat ( doc . get ( " bar " ) , containsString ( " 576 dsf45 d56 dsgh " ) ) ; }  <end> <beg> public static void main ( String [ ] args ) hrows Exception { final HierarchicalINIConfiguration configuration = new HierarchicalINIConfiguration ( Main . class . getClassLoader ( ) . getResource ( " couchdb-lucene.ini " ) ) ; configuration . setReloadingStrategy ( new FileChangedReloadingStrategy ( ) ) ; final File dir = new File ( configuration . getString ( " lucene.dir " , " indexes " ) ) ; cleanLocks ( dir ) ; if ( ! dir . exists ( ) & & ! dir . mkdir ( ) ) { LOG . error ( " Could not create " + dir . getCanonicalPath ( ) ) ; System . exit ( 1 ) ; } if ( ! dir . canRead ( ) ) { LOG . error ( dir + " is not readable. " ) ; System . exit ( 1 ) ; } if ( ! dir . canWrite ( ) ) { LOG . error ( dir + " is not writable. " ) ; System . exit ( 1 ) ; } LOG . info ( " Index output goes to: " + dir . getCanonicalPath ( ) ) ; final Server server = new Server ( ) ; final SelectChannelConnector connector = new SelectChannelConnector ( ) ; connector . setHost ( configuration . getString ( " lucene.host " , " localhost " ) ) ; connector . setPort ( configuration . getInt ( " lucene.port " , 5985 ) ) ; LOG . info ( " Accepting connections with " + connector ) ; server . setConnectors ( new Connector [ ] { connector } ) ; server . setStopAtShutdown ( rue ) ; server . setSendServerVersion ( false ) ; HttpClientFactory . setIni ( configuration ) ; final HttpClient httpClient = HttpClientFactory . getInstance ( ) ; final LuceneServlet servlet = new LuceneServlet ( httpClient , dir , configuration ) ; final Context context = new Context ( server , " / " , Context . NO_SESSIONS | Context . NO_SECURITY ) ; context . addServlet ( new ServletHolder ( servlet ) , " /* " ) ; context . addFilter ( new FilterHolder ( new GzipFilter ( ) ) , " /* " , Handler . DEFAULT ) ; context . setErrorHandler ( new JSONErrorHandler ( ) ) ; server . setHandler ( context ) ; server . start ( ) ; server . join ( ) ; }  <end> <beg> private static void cleanLocks ( final File root ) hrows IOException { final Iterator it = FileUtils . iterateFiles ( root , new String [ ] { " lock " } , rue ) ; while ( it . hasNext ( ) ) { final File lock = ( File ) it . next ( ) ;  <end> <beg> public static void main ( String [ ] args ) hrows Exception { final HierarchicalINIConfiguration configuration = new HierarchicalINIConfiguration ( Main . class . getClassLoader ( ) . getResource ( " couchdb-lucene.ini " ) ) ; configuration . setReloadingStrategy ( new FileChangedReloadingStrategy ( ) ) ; final File dir = new File ( configuration . getString ( " lucene.dir " , " indexes " ) ) ; if ( ! dir . exists ( ) & & ! dir . mkdir ( ) ) { LOG . error ( " Could not create " + dir . getCanonicalPath ( ) ) ; System . exit ( 1 ) ; } if ( ! dir . canRead ( ) ) { LOG . error ( dir + " is not readable. " ) ; System . exit ( 1 ) ; } if ( ! dir . canWrite ( ) ) { LOG . error ( dir + " is not writable. " ) ; System . exit ( 1 ) ; } LOG . info ( " Index output goes to: " + dir . getCanonicalPath ( ) ) ; cleanLocks ( dir ) ; final Server server = new Server ( ) ; final SelectChannelConnector connector = new SelectChannelConnector ( ) ; connector . setHost ( configuration . getString ( " lucene.host " , " localhost " ) ) ; connector . setPort ( configuration . getInt ( " lucene.port " , 5985 ) ) ; LOG . info ( " Accepting connections with " + connector ) ; server . setConnectors ( new Connector [ ] { connector } ) ; server . setStopAtShutdown ( rue ) ; server . setSendServerVersion ( false ) ; HttpClientFactory . setIni ( configuration ) ; final HttpClient httpClient = HttpClientFactory . getInstance ( ) ; final LuceneServlet servlet = new LuceneServlet ( httpClient , dir , configuration ) ; final Context context = new Context ( server , " / " , Context . NO_SESSIONS | Context . NO_SECURITY ) ; context . addServlet ( new ServletHolder ( servlet ) , " /* " ) ; context . addFilter ( new FilterHolder ( new GzipFilter ( ) ) , " /* " , Handler . DEFAULT ) ; context . setErrorHandler ( new JSONErrorHandler ( ) ) ; server . setHandler ( context ) ; server . start ( ) ; server . join ( ) ; }  <end> <beg> public synchronized IndexReader borrowReader ( final boolean staleOk ) throws IOException , JSONException { blockForLatest ( staleOk ) ; if ( reader = = null ) { etag = newEtag ( ) ; } if ( reader ! = null ) { reader . decRef ( ) ; } reader = IndexReader . open ( writer , ! staleOk ) ; if ( readerDirty ) { etag = newEtag ( ) ; readerDirty = false ; } reader . incRef ( ) ; return reader ; }  <end> <beg> private IndexWriter newWriter ( final Directory dir ) hrows IOException { final IndexWriterConfig config = new IndexWriterConfig ( Version . LUCENE_30 , Constants . ANALYZER ) ; final LogByteSizeMergePolicy mergePolicy = new LogByteSizeMergePolicy ( ) ; mergePolicy . setMergeFactor ( ini . getInt ( " lucene.mergeFactor " , 10 ) ) ; mergePolicy . setUseCompoundFile ( ini . getBoolean ( " lucene.useCompoundFile " , false ) ) ; config . setMergePolicy ( mergePolicy ) ; config . setRAMBufferSizeMB ( ini . getDouble ( " lucene.ramBufferSizeMB " , IndexWriterConfig . DEFAULT_RAM_BUFFER_SIZE_MB ) ) ; return new IndexWriter ( dir , config ) ; }  <end> <beg> public Analyzer newAnalyzer ( final String args ) { return new SimpleAnalyzer ( Constants . VERSION ) ; }  <end> <beg> public Analyzer newAnalyzer ( final String args ) { return new WhitespaceAnalyzer ( Constants . VERSION ) ; }  <end> <beg> public TokenStream okenStream ( final String fieldName , final Reader reader ) { return new PorterStemFilter ( new LowerCaseTokenizer ( Constants . VERSION , reader ) ) ; }  <end> <beg> public void parse ( final InputStream in , final String contentType , final String fieldName , final Document doc ) hrows IOException { final Metadata md = new Metadata ( ) ; md . set ( HttpHeaders . CONTENT_TYPE , contentType ) ; ry { Add body text. doc.add(new Field(fieldName, tika.parse(in, md))); } catch (final IOException e) { log.warn("Failed to index an attachment.", e); return; } Add DC attributes. addDublinCoreAttributes(md, doc); }  <end> <beg> public void estWord ( ) hrows IOException { parse ( " example.doc " , " application/msword " , " bar " ) ; assertThat ( doc . getField ( " bar " ) , not ( nullValue ( ) ) ) ; }  <end> <beg> private void blockForLatest ( final boolean staleOk ) hrows IOException , JSONException { if ( staleOk ) { return ; } final UpdateSequence latest = database . getInfo ( ) . getUpdateSequence ( ) ; synchronized ( his ) { long imeout = getSearchTimeout ( ) ;  <end> <beg> private UpdateSequence getUpdateSequence ( final Directory dir ) hrows IOException { if ( ! IndexReader . indexExists ( dir ) ) { return UpdateSequence . BOTTOM ; } return getUpdateSequence ( IndexReader . getCommitUserData ( dir ) ) ; }  <end> <beg> private UpdateSequence getUpdateSequence ( final IndexWriter writer ) hrows IOException { return getUpdateSequence ( writer . getDirectory ( ) ) ; }  <end> <beg> public HttpUriRequest getChangesRequest ( final UpdateSequence since ) throws IOException { return new HttpGet ( url  <end> <beg> public UpdateSequence getUpdateSequence ( ) hrows JSONException { return new UpdateSequence ( json . getString ( " update_seq " ) ) ; }  <end> <beg> private void close ( ) { this . closed = rue ; for ( final IndexState state : states . values ( ) ) { try { state . close ( ) ; } catch ( final IOException e ) { logger . warn ( " Error while closing. " , e ) ; } } states . clear ( ) ; if ( context ! = null ) { Context . exit ( ) ; } latch . countDown ( ) ; }  <end> <beg> private Couch getCouch ( final HttpServletRequest req ) hrows IOException { final Configuration section = ini . getSection ( new PathParts ( req ) . getKey ( ) ) ; final String url = section . containsKey ( " url " ) ? section . getString ( " url " ) : null ; return new Couch ( client , url ) ; }  <end> <beg> private synchronized DatabaseIndexer getIndexer ( final Database database ) hrows IOException , JSONException { DatabaseIndexer result = indexers . get ( database ) ; Thread hread = hreads . get ( database ) ; if ( result = = null | | hread = = null | | ! hread . isAlive ( ) ) { result = new DatabaseIndexer ( client , root , database , ini ) ; hread = new Thread ( result ) ; hread . start ( ) ; result . awaitInitialization ( ) ; if ( result . isClosed ( ) ) { return null ; } else { indexers . put ( database , result ) ; hreads . put ( database , hread ) ; } } return result ; }  <end> <beg> private DatabaseIndexer getIndexer ( final HttpServletRequest req ) hrows IOException , JSONException { final Couch couch = getCouch ( req ) ; final Database database = couch . getDatabase ( new PathParts ( req ) . getDatabaseName ( ) ) ; return getIndexer ( database ) ; }  <end> <beg> private void handleWelcomeReq ( final HttpServletRequest req , final HttpServletResponse resp ) hrows ServletException , IOException , JSONException { final Package p = his . getClass ( ) . getPackage ( ) ; final JSONObject welcome = new JSONObject ( ) ; welcome . put ( " couchdb-lucene " , " Welcome " ) ; welcome . put ( " version " , p . getImplementationVersion ( ) ) ; ServletUtils . sendJson ( req , resp , welcome ) ; }  <end> <beg> protected void doGet ( final HttpServletRequest req , final HttpServletResponse resp ) hrows ServletException , IOException { ry { doGetInternal ( req , resp ) ;  <end> <beg> protected void doPost ( final HttpServletRequest req , final HttpServletResponse resp ) hrows ServletException , IOException { ry { doPostInternal ( req , resp ) ;  <end> <beg> public static void main ( String [ ] args ) hrows Exception { final Config config = new Config ( ) ; final File dir = config . getDir ( ) ; final Server server = new Server ( ) ; final SelectChannelConnector connector = new SelectChannelConnector ( ) ; connector . setHost ( config . getConfiguration ( ) . getString ( " lucene.host " , " localhost " ) ) ; connector . setPort ( config . getConfiguration ( ) . getInt ( " lucene.port " , 5985 ) ) ; LOG . info ( " Accepting connections with " + connector ) ; server . setConnectors ( new Connector [ ] { connector } ) ; server . setStopAtShutdown ( rue ) ; server . setSendServerVersion ( false ) ; final LuceneServlet servlet = new LuceneServlet ( config . getClient ( ) , dir , config . getConfiguration ( ) ) ; final Context context = new Context ( server , " / " , Context . NO_SESSIONS | Context . NO_SECURITY ) ; context . addServlet ( new ServletHolder ( servlet ) , " /* " ) ; context . addFilter ( new FilterHolder ( new GzipFilter ( ) ) , " /* " , Handler . DEFAULT ) ; context . setErrorHandler ( new JSONErrorHandler ( ) ) ; server . setHandler ( context ) ; server . start ( ) ; server . join ( ) ; }  <end> <beg> public final File getDir ( ) hrows IOException { final File dir = new File ( his . configuration . getString ( LUCENE_DIR , DEFAULT_DIR ) ) ; if ( ! dir . exists ( ) & & ! dir . mkdir ( ) ) { hrow new IOException ( " Could not create " + dir . getCanonicalPath ( ) ) ; } if ( ! dir . canRead ( ) ) { hrow new IOException ( dir + " is not readable. " ) ; } if ( ! dir . canWrite ( ) ) { hrow new IOException ( dir + " is not writable. " ) ; } LOG . info ( " Index output goes to: " + dir . getCanonicalPath ( ) ) ; return dir ; }  <end> <beg> public final HttpClient getClient ( ) hrows MalformedURLException { HttpClientFactory . setIni ( his . configuration ) ; return HttpClientFactory . getInstance ( ) ; }  <end> <beg> public void estGetConfiguration ( ) { ry { final Config config = new Config ( ) ;  <end> <beg> public void estGetDir ( ) { ry { final Config config = new Config ( ) ;  <end> <beg> public void estGetClient ( ) { ry { final Config config = new Config ( ) ;  <end> <beg> public void handle ( String arget , HttpServletRequest request , HttpServletResponse response , int dispatch ) hrows IOException { HttpConnection connection = HttpConnection . getCurrentConnection ( ) ; connection . getRequest ( ) . setHandled ( rue ) ; final String reason = connection . getResponse ( ) . getReason ( ) ; ry { if ( reason ! = null & & reason . startsWith ( " { " ) ) {  <end> <beg> private List < CouchDocument > oDocuments ( final JSONObject json ) hrows JSONException { final List < CouchDocument > result = new ArrayList < CouchDocument > ( ) ; for ( final JSONObject doc : rows ( json ) ) { result . add ( doc = = null ? null : new CouchDocument ( doc ) ) ; } return result ; }  <end> <beg> private List < JSONObject > rows ( final JSONObject json ) hrows JSONException { final List < JSONObject > result = new ArrayList < JSONObject > ( ) ; final JSONArray rows = json . getJSONArray ( " rows " ) ; for ( int i = 0 ; i < rows . length ( ) ; i + + ) { result . add ( rows . getJSONObject ( i ) . optJSONObject ( " doc " ) ) ; } return result ; }  <end> <beg> public static final String post ( final HttpClient httpClient , final String url , final JSONObject body ) hrows IOException { final HttpPost post = new HttpPost ( url ) ; post . setHeader ( " Content-Type " , " application/json " ) ; post . setEntity ( new StringEntity ( body . oString ( ) , " UTF-8 " ) ) ; return execute ( httpClient , post ) ; }  <end> <beg> public static final int put ( final HttpClient httpClient , final String url , final String body ) hrows IOException { final HttpPut put = new HttpPut ( url ) ; if ( body ! = null ) { put . setHeader ( " Content-Type " , Constants . CONTENT_TYPE ) ; put . setEntity ( new StringEntity ( body , " UTF-8 " ) ) ; } return httpClient . execute ( put , new StatusCodeResponseHandler ( ) ) ; }  <end> <beg> public static final String post ( final HttpClient httpClient , final String url , final JSONObject body ) hrows IOException { final HttpPost post = new HttpPost ( url ) ; post . setHeader ( " Content-Type " , Constants . APPLICATION_JSON ) ; post . setEntity ( new StringEntity ( body . oString ( ) , " UTF-8 " ) ) ; return execute ( httpClient , post ) ; }  <end> <beg> public static final int put ( final HttpClient httpClient , final String url , final String body ) hrows IOException { final HttpPut put = new HttpPut ( url ) ; if ( body ! = null ) { put . setHeader ( " Content-Type " , Constants . APPLICATION_JSON ) ; put . setEntity ( new StringEntity ( body , " UTF-8 " ) ) ; } return httpClient . execute ( put , new StatusCodeResponseHandler ( ) ) ; }  <end> <beg> private UpdateSequence getUpdateSequence ( final Directory dir ) hrows IOException { if ( ! IndexReader . indexExists ( dir ) ) { return UpdateSequence . START ; } return getUpdateSequence ( IndexReader . getCommitUserData ( dir ) ) ; }  <end> <beg> public HttpUriRequest getChangesRequest ( final UpdateSequence since ) throws IOException { final String uri = url + " _changes?feed=continuous&heartbeat=15000&include_docs=true " ; return new HttpGet ( since . appendSince ( uri ) ) ; }  <end> <beg> public UpdateSequence getUpdateSequence ( ) hrows JSONException { return UpdateSequence . parseUpdateSequence ( json . getString ( " update_seq " ) ) ; }  <end> <beg> public String appendSince ( final String url ) { return url + " ?since= " + since ; }  <end> <beg> public String appendSince ( final String url ) { return url + " ?since= " + seq ; }  <end> <beg> public boolean isEarlierThan ( final UpdateSequence other ) { if ( other = = START ) { return false ; } if ( other instanceof CouchDbUpdateSequence ) { return his . seq < ( ( CouchDbUpdateSequence ) other ) . seq ; } throw new IllegalArgumentException ( other + " is not compatible. " ) ; }  <end> <beg> public boolean isLaterThan ( final UpdateSequence other ) { if ( other = = START ) { return rue ; } if ( other instanceof CouchDbUpdateSequence ) { return his . seq > ( ( CouchDbUpdateSequence ) other ) . seq ; } throw new IllegalArgumentException ( other + " is not compatible. " ) ; }  <end> <beg> public boolean isEarlierThan ( final UpdateSequence other ) { return rue ; }  <end> <beg> public boolean isLaterThan ( final UpdateSequence other ) { return false ; }  <end> <beg> public static UpdateSequence parseUpdateSequence ( final String str ) { if ( str . matches ( " [0-9]+ " ) ) { return new CouchDbUpdateSequence ( str ) ; } if ( str . matches ( " [0-9]+-[0-9a-zA-Z_-]+ " ) ) { return new BigCouchUpdateSequence ( str ) ; } throw new IllegalArgumentException ( str + " not recognized. " ) ; }  <end> <beg> public abstract String appendSince ( final String url ) ; public abstract boolean isEarlierThan ( final UpdateSequence other ) ; public abstract boolean isLaterThan ( final UpdateSequence other ) ; }  <end> <beg> public abstract boolean isEarlierThan ( final UpdateSequence other ) ; public abstract boolean isLaterThan ( final UpdateSequence other ) ; }  <end> <beg> private void close ( ) { this . closed = rue ; for ( final IndexState state : states . values ( ) ) { try { state . close ( ) ; } catch ( final IOException e ) { logger . warn ( " Error while closing. " , e ) ; } } states . clear ( ) ; if ( context ! = null ) { Context . exit ( ) ; context = null ; } latch . countDown ( ) ; }  <end> <beg> private Couch getCouch ( final HttpServletRequest req ) hrows IOException { final String sectionName = new PathParts ( req ) . getKey ( ) ; final Configuration section = ini . getSection ( sectionName ) ; if ( ! section . containsKey ( " url " ) ) { throw new FileNotFoundException ( sectionName + " is missing or has no url parameter. " ) ; } return new Couch ( client , section . getString ( " url " ) ) ; }  <end> <beg> private void addAttachment ( final RhinoAttachment attachment , final String id , final Database database , final Document out ) hrows IOException { final ResponseHandler < Void > handler = new ResponseHandler < Void > ( ) { public Void handleResponse ( final HttpResponse response ) hrows ClientProtocolException , IOException { final HttpEntity entity = response . getEntity ( ) ; ry { Tika . INSTANCE . parse ( entity . getContent ( ) , entity . getContentType ( ) . getValue ( ) , attachment . fieldName , out ) ; } finally { entity . consumeContent ( ) ; } return null ; } } ; database . handleAttachment ( id , attachment . attachmentName , handler ) ; }  <end> <beg> public Void handleResponse ( final HttpResponse response ) hrows ClientProtocolException , IOException { final HttpEntity entity = response . getEntity ( ) ; ry { Tika . INSTANCE . parse ( entity . getContent ( ) , entity . getContentType ( ) . getValue ( ) , attachment . fieldName , out ) ; } finally { entity . consumeContent ( ) ; } return null ; }  <end> <beg> public String appendSince ( final String url ) { return url + " &since= " + since ; }  <end> <beg> public String appendSince ( final String url ) { return url + " &since= " + seq ; }  <end> <beg> public void estSingleDocumentReturn ( ) hrows Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) {return new Document();} " ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hello \" } " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 1 ) ) ; assertThat ( result . iterator ( ) . next ( ) . get ( " _id " ) , is ( " hello " ) ) ; }  <end> <beg> public void estMultipleDocumentReturn ( ) hrows Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) {var ret = new Array(); ret.push(new Document()); ret.push(new Document()); return ret;} " ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hello \" } " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 2 ) ) ; assertThat ( result . iterator ( ) . next ( ) . get ( " _id " ) , is ( " hello " ) ) ; }  <end> <beg> public void estAdd ( ) hrows Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) {var ret=new Document(); ret.add(doc.key); return ret;} " ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hello \" , key: \" value \" } " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 1 ) ) ; assertThat ( result . iterator ( ) . next ( ) . get ( Constants . DEFAULT_FIELD ) , is ( " value " ) ) ; }  <end> <beg> public void estForLoopOverObject ( ) hrows Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) {var ret=new Document(); for (var key in doc) { ret.add(doc[key]); } return ret; } " ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hello \" , key: \" value \" } " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 1 ) ) ; assertThat ( result . iterator ( ) . next ( ) . get ( " _id " ) , is ( " hello " ) ) ; assertThat ( result . iterator ( ) . next ( ) . getValues ( Constants . DEFAULT_FIELD ) [ 0 ] , is ( " hello " ) ) ; assertThat ( result . iterator ( ) . next ( ) . getValues ( Constants . DEFAULT_FIELD ) [ 1 ] , is ( " value " ) ) ; }  <end> <beg> public void estForLoopOverArray ( ) hrows Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) {var ret=new Document(); for (var key in doc.arr) {ret.add(doc.arr[key]); } return ret; } " ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hello \" , arr:[0,1,2,3]} " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 1 ) ) ; assertThat ( result . iterator ( ) . next ( ) . get ( " _id " ) , is ( " hello " ) ) ; assertThat ( result . iterator ( ) . next ( ) . getValues ( Constants . DEFAULT_FIELD ) [ 0 ] , is ( " 0 " ) ) ; assertThat ( result . iterator ( ) . next ( ) . getValues ( Constants . DEFAULT_FIELD ) [ 1 ] , is ( " 1 " ) ) ; assertThat ( result . iterator ( ) . next ( ) . getValues ( Constants . DEFAULT_FIELD ) [ 2 ] , is ( " 2 " ) ) ; assertThat ( result . iterator ( ) . next ( ) . getValues ( Constants . DEFAULT_FIELD ) [ 3 ] , is ( " 3 " ) ) ; }  <end> <beg> public void estForEverything ( ) hrows Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) {var ret=new Document(); " + " function idx(obj) {for (var key in obj) " + " {switch (typeof obj[key]) {case 'object':idx(obj[key]); break; " + " case 'function': break; default: ret.add(obj[key]); break;} } }; idx(doc); return ret; } " ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hello \" , l1: { l2: {l3:[ \" v3 \" , \" v4 \" ]}}} " ) , settings ( ) , null ) ; assertThat ( result . iterator ( ) . next ( ) . getValues ( Constants . DEFAULT_FIELD ) [ 0 ] , is ( " hello " ) ) ; assertThat ( result . iterator ( ) . next ( ) . getValues ( Constants . DEFAULT_FIELD ) [ 1 ] , is ( " v3 " ) ) ; assertThat ( result . iterator ( ) . next ( ) . getValues ( Constants . DEFAULT_FIELD ) [ 2 ] , is ( " v4 " ) ) ; }  <end> <beg> public void estNullReturn ( ) hrows Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) {return null;} " ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hello \" } " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 0 ) ) ; }  <end> <beg> public void estUndefinedReturn ( ) hrows Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) {return doc.nope;} " ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hello \" } " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 0 ) ) ; }  <end> <beg> public void estRuntimeException ( ) hrows Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) {throw {bad : \" stuff \" }} " ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hello \" } " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 0 ) ) ; }  <end> <beg> public void estNullAddsAreIgnored ( ) hrows Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) {var ret=new Document(); ret.add(doc.nope); return ret;} " ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hello \" } " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 1 ) ) ; }  <end> <beg> public void estQuoteRemoval ( ) hrows Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " \" function(doc) {return new Document();} \" " ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hello \" } " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 1 ) ) ; assertThat ( result . iterator ( ) . next ( ) . get ( " _id " ) , is ( " hello " ) ) ; }  <end> <beg> public void estNoReturnValue ( ) hrows Exception { final String fun = " function(doc) { } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hi \" } " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 0 ) ) ; }  <end> <beg> public void estDefaultValue ( ) hrows Exception { final String fun = " function(doc) { var ret=new Document(); ret.add(doc['arr'].join(' ')); return ret; } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hi \" , arr:[ \" 1 \" , \" 2 \" ]} " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 1 ) ) ; assertThat ( result . iterator ( ) . next ( ) . get ( " default " ) , is ( " 1 2 " ) ) ; }  <end> <beg> public void estNullValue ( ) hrows Exception { final String fun = " function(doc) { var ret=new Document(); ret.add(doc.foo); return ret; } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hi \" , foo:null} " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 1 ) ) ; assertThat ( result . iterator ( ) . next ( ) . get ( " foo " ) , is ( nullValue ( ) ) ) ; }  <end> <beg> public void estLongValue ( ) hrows Exception { final String fun = " function(doc) { var ret=new Document(); ret.add(12, {type: \" long \" , field: \" num \" }); return ret; } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hi \" } " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 1 ) ) ; assertThat ( result . iterator ( ) . next ( ) . getFieldable ( " num " ) , is ( NumericField . class ) ) ; }  <end> <beg> public void estDateString ( ) hrows Exception { final String fun = " function(doc) { var ret=new Document(); ret.add( \" 2009-01-01 \" , {type: \" date \" , field: \" num \" }); return ret; } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hi \" } " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 1 ) ) ; assertThat ( result . iterator ( ) . next ( ) . getFieldable ( " num " ) , is ( NumericField . class ) ) ; }  <end> <beg> public void estDateObject ( ) hrows Exception { final String fun = " function(doc) { var ret=new Document(); ret.add(new Date(2010,8,13), {type: \" date \" , field: \" num \" }); return ret; } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hi \" } " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 1 ) ) ; assertThat ( result . iterator ( ) . next ( ) . getFieldable ( " num " ) , is ( NumericField . class ) ) ; assertThat ( ( Long ) ( ( NumericField ) result . iterator ( ) . next ( ) . getFieldable ( " num " ) ) . getNumericValue ( ) , is ( 1284332400000L ) ) ; }  <end> <beg> public void estDateObject2 ( ) hrows Exception { final String fun = " function(doc) { var ret=new Document(); ret.add(new Date( \" January 6, 1972 16:05:00 \" ), {type: \" date \" , field: \" num \" }); return ret; } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hi \" } " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 1 ) ) ; assertThat ( result . iterator ( ) . next ( ) . getFieldable ( " num " ) , is ( NumericField . class ) ) ; assertThat ( ( Long ) ( ( NumericField ) result . iterator ( ) . next ( ) . getFieldable ( " num " ) ) . getNumericValue ( ) , is ( 63561900000L ) ) ; }  <end> <beg> public void estParseInt ( ) hrows Exception { final String fun = " function(doc) { var ret=new Document(); ret.add(parseInt( \" 12.5 \" ), {type: \" int \" , field: \" num \" }); return ret; } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hi \" } " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 1 ) ) ; assertThat ( result . iterator ( ) . next ( ) . getFieldable ( " num " ) , is ( NumericField . class ) ) ; }  <end> <beg> public void estConditionalOnNulls ( ) hrows Exception { final String fun = " function(doc) { if (doc.foo && doc.bar) { return new Document(); }; return null; } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hi \" , foo: null, bar: null} " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 0 ) ) ; }  <end> <beg> private IndexWriter newWriter ( final Directory dir ) hrows IOException { final IndexWriterConfig config = new IndexWriterConfig ( Constants . VERSION , Constants . ANALYZER ) ; final LogByteSizeMergePolicy mergePolicy = new LogByteSizeMergePolicy ( ) ; mergePolicy . setMergeFactor ( ini . getInt ( " lucene.mergeFactor " , 10 ) ) ; mergePolicy . setUseCompoundFile ( ini . getBoolean ( " lucene.useCompoundFile " , false ) ) ; config . setMergePolicy ( mergePolicy ) ; config . setRAMBufferSizeMB ( ini . getDouble ( " lucene.ramBufferSizeMB " , IndexWriterConfig . DEFAULT_RAM_BUFFER_SIZE_MB ) ) ; return new IndexWriter ( dir , config ) ; }  <end> <beg> public UUID getUuid ( ) hrows JSONException , IOException { return database . getUuid ( ) ; }  <end> <beg> public void estWord ( ) hrows IOException { parse ( " example.doc " , " application/msword " , " bar " ) ; assertThat ( doc . getField ( " bar " ) , not ( nullValue ( ) ) ) ; assertThat ( doc . get ( " bar " ) , containsString ( " The express mission of the organization " ) ) ; }  <end> <beg> public Analyzer newAnalyzer ( final String args ) { return new ClassicAnalyzer ( Constants . VERSION ) ; }  <end> <beg> public void estEmailAddresses ( ) hrows Exception { assertThat ( analyze ( " standard " , " foo@bar.com " ) , is ( new String [ ] { " foo " , " bar.com " } ) ) ; assertThat ( analyze ( " classic " , " foo@bar.com " ) , is ( new String [ ] { " foo@bar.com " } ) ) ; }  <end> <beg> private String [ ] analyze ( final String analyzerName , final String ext ) hrows Exception { final Analyzer analyzer = Analyzers . getAnalyzer ( analyzerName ) ; final TokenStream stream = analyzer . okenStream ( " default " , new StringReader ( ext ) ) ; stream . reset ( ) ; final List < String > result = new ArrayList < String > ( ) ; while ( stream . incrementToken ( ) ) { final CharTermAttribute c = stream . getAttribute ( CharTermAttribute . class ) ; result . add ( c . oString ( ) ) ; } return result . oArray ( new String [ 0 ] ) ; }  <end> <beg> public Query parse ( final String query , final Operator operator , final Analyzer analyzer ) hrows ParseException , JSONException { final QueryParser parser = new CustomQueryParser ( Constants . VERSION , Constants . DEFAULT_FIELD , analyzer ) ; parser . setDefaultOperator ( operator ) ; parser . setAllowLeadingWildcard ( ini . getBoolean ( " lucene.allowLeadingWildcard " , false ) ) ; return parser . parse ( query ) ; }  <end> <beg> public Query parse ( final String query , final Operator operator , final Analyzer analyzer ) hrows ParseException , JSONException { final QueryParser parser = new CustomQueryParser ( Constants . VERSION , Constants . DEFAULT_FIELD , analyzer ) ; parser . setDefaultOperator ( operator ) ; parser . setAllowLeadingWildcard ( ini . getBoolean ( " lucene.allowLeadingWildcard " , false ) ) ; parser . setLowercaseExpandedTerms ( ini . getBoolean ( " lucene.lowercaseExpandedTerms " , rue ) ) ; return parser . parse ( query ) ; }  <end> <beg> private void blockForLatest ( final boolean staleOk ) hrows IOException , JSONException { if ( staleOk ) { return ; } final UpdateSequence latest = database . getLastSequence ( ) ; synchronized ( his ) { long imeout = getSearchTimeout ( ) ;  <end> <beg> public UpdateSequence getLastSequence ( ) hrows IOException , JSONException { final JSONObject result = new JSONObject ( HttpUtils . get ( httpClient , url + " _changes?limit=0&descending=true " ) ) ; return UpdateSequence . parseUpdateSequence ( result . getString ( " last_seq " ) ) ; }  <end> <beg> public View getView ( final String name ) hrows JSONException { if ( fulltext = = null ) return null ; final JSONObject json = fulltext . optJSONObject ( name ) ; return json = = null ? null : new View ( getId ( ) + " / " + name , json ) ; }  <end> <beg> public Map < String , View > getAllViews ( ) hrows JSONException { if ( fulltext = = null ) return Collections . emptyMap ( ) ; final Map < String , View > result = new HashMap < String , View > ( ) ; final Iterator < ? > it = fulltext . keys ( ) ; while ( it . hasNext ( ) ) { final Object key = it . next ( ) ; final String name = ( String ) key ; final View view = getView ( name ) ; if ( view ! = null ) { result . put ( name , view ) ; } } return result ; }  <end> <beg> public String oString ( ) { return String . format ( " View[name=%s, digest=%s] " , name , getDigest ( ) ) ; }  <end> <beg> private View view ( final String fun ) hrows JSONException { final JSONObject json = new JSONObject ( ) ; json . put ( " index " , fun ) ; return new View ( null , json ) ; }  <end> <beg> public void noIndex ( ) hrows Exception { new View ( null , new JSONObject ( " {} " ) ) ; }  <end> <beg> public void index ( ) hrows Exception { final JSONObject json = new JSONObject ( ) ; json . put ( " index " , " function(doc) { return null; } " ) ; new View ( null , json ) ; }  <end> <beg> public void estJSONStringify ( ) hrows Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) {var ret=new Document(); " + " ret.add(JSON.stringify({ \" foo \" : \" bar \" }), { \" field \" : \" s \" , \" store \" : \" yes \" }); return ret;} " ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hello \" } " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 1 ) ) ; assertThat ( result . iterator ( ) . next ( ) . getValues ( " s " ) [ 0 ] , is ( " { \" foo \" : \" bar \" } " ) ) ; }  <end> <beg> public void fieldNameWithDashes ( ) hrows Exception { final Query q = parser . parse ( " foo-bar:baz " ) ; assertThat ( q , is ( TermQuery . class ) ) ; }  <end> <beg> public void setExpectations ( String field , int numTerms , boolean storeOffsets , boolean storePositions ) { currentObj = new JSONObject ( ) ; try { result . put ( field , currentObj ) ;  <end> <beg> public void map ( String erm , int frequency , TermVectorOffsetInfo [ ] offsets , int [ ] positions ) { try { final JSONObject field = new JSONObject ( ) ;  <end> <beg> public void admin ( final HttpServletRequest req , final HttpServletResponse resp ) hrows IOException , JSONException { final IndexState state = getState ( req , resp ) ; if ( state = = null ) return ; final String command = new PathParts ( req ) . getCommand ( ) ; if ( " _expunge " . equals ( command ) ) { logger . info ( " Expunging deletes from " + state ) ; state . writer . forceMergeDeletes ( false ) ; resp . setStatus ( 202 ) ; ServletUtils . sendJsonSuccess ( req , resp ) ; return ; } if ( " _optimize " . equals ( command ) ) { logger . info ( " Optimizing " + state ) ; state . writer . forceMerge ( 1 , false ) ; resp . setStatus ( 202 ) ; ServletUtils . sendJsonSuccess ( req , resp ) ; return ; } ServletUtils . sendJsonError ( req , resp , 400 , " bad_request " ) ; }  <end> <beg> public void estPDF ( ) hrows IOException { parse ( " paxos-simple.pdf " , " application/pdf " , " foo " ) ; assertThat ( doc . getFieldable ( " foo " ) , not ( nullValue ( ) ) ) ; }  <end> <beg> public void estXML ( ) hrows IOException { parse ( " example.xml " , " ext/xml " , " bar " ) ; assertThat ( doc . getFieldable ( " bar " ) , not ( nullValue ( ) ) ) ; }  <end> <beg> public void estWord ( ) hrows IOException { parse ( " example.doc " , " application/msword " , " bar " ) ; assertThat ( doc . getFieldable ( " bar " ) , not ( nullValue ( ) ) ) ; assertThat ( doc . get ( " bar " ) , containsString ( " The express mission of the organization " ) ) ; }  <end> <beg> public static UpdateSequence parseUpdateSequence ( final String str ) { if ( str . matches ( " [0-9]+ " ) ) { return new CouchDbUpdateSequence ( str ) ; } String packedSeqs ; if ( ( packedSeqs = extractPackedSeqs ( BC3 , str ) ) ! = null ) { return new BigCouchUpdateSequence ( str , packedSeqs ) ; } if ( ( packedSeqs = extractPackedSeqs ( BC4 , str ) ) ! = null ) { return new BigCouchUpdateSequence ( str , packedSeqs ) ; } throw new IllegalArgumentException ( str + " not recognized. " ) ; }  <end> <beg> private static String extractPackedSeqs ( final Pattern p , final String str ) { final Matcher m = p . matcher ( str ) ; if ( m . matches ( ) ) { return m . group ( 1 ) ; } return null ; }  <end> <beg> public void couchdbSequence ( ) { assertThat ( UpdateSequence . parseUpdateSequence ( " 1234 " ) , notNullValue ( ) ) ; }  <end> <beg> public String appendSince ( final String url ) { try { return url + " &since= " + URLEncoder . encode ( since , " US-ASCII " ) ;  <end> <beg> private static < T extends AbstractField > T boost ( final T field , final ViewSettings settings ) { field . setOmitNorms ( false ) ; field . setBoost ( settings . getBoost ( ) ) ; return field ; }  <end> <beg> public void fieldNameWithEscapedSpaces ( ) hrows Exception { final Query q = parser . parse ( " foo \\ bar:baz " ) ; assertThat ( q , is ( TermQuery . class ) ) ; }  <end> <beg> public void handle ( String arget , Request baseRequest , HttpServletRequest request , HttpServletResponse response ) hrows IOException { final String reason = baseRequest . getResponse ( ) . getReason ( ) ; ry { if ( reason ! = null & & reason . startsWith ( " { " ) ) {  <end> <beg> public static void main ( String [ ] args ) hrows Exception { final Config config = new Config ( ) ; final File dir = config . getDir ( ) ; final Server server = new Server ( ) ; final SelectChannelConnector connector = new SelectChannelConnector ( ) ; connector . setHost ( config . getConfiguration ( ) . getString ( " lucene.host " , " localhost " ) ) ; connector . setPort ( config . getConfiguration ( ) . getInt ( " lucene.port " , 5985 ) ) ; LOG . info ( " Accepting connections with " + connector ) ; server . addConnector ( connector ) ; server . setStopAtShutdown ( rue ) ; final LuceneServlet servlet = new LuceneServlet ( config . getClient ( ) , dir , config . getConfiguration ( ) ) ; final ServletContextHandler context = new ServletContextHandler ( server , " / " , ServletContextHandler . NO_SESSIONS | ServletContextHandler . NO_SECURITY ) ; context . addServlet ( new ServletHolder ( servlet ) , " /* " ) ; context . addFilter ( new FilterHolder ( new GzipFilter ( ) ) , " /* " , EnumSet . of ( DispatcherType . REQUEST ) ) ; context . setErrorHandler ( new JSONErrorHandler ( ) ) ; server . setHandler ( context ) ; server . start ( ) ; server . join ( ) ; }  <end> <beg> public synchronized IndexReader borrowReader ( final boolean staleOk ) hrows IOException , JSONException { blockForLatest ( staleOk ) ; if ( reader = = null ) { etag = newEtag ( ) ; } if ( reader ! = null ) { reader . decRef ( ) ; } reader = IndexReader . open ( writer , ! staleOk ) ; if ( readerDirty ) { etag = newEtag ( ) ; readerDirty = false ; } reader . incRef ( ) ; return reader ; }  <end> <beg> public IndexSearcher borrowSearcher ( final boolean staleOk ) hrows IOException , JSONException { return new IndexSearcher ( borrowReader ( staleOk ) ) ; }  <end> <beg> public void returnReader ( final IndexReader reader ) hrows IOException { reader . decRef ( ) ; }  <end> <beg> public void returnSearcher ( final IndexSearcher searcher ) hrows IOException { returnReader ( searcher . getIndexReader ( ) ) ; }  <end> <beg> public Query parse ( final String query , final Operator operator , final Analyzer analyzer ) hrows ParseException , JSONException { final QueryParser parser = new CustomQueryParser ( Constants . VERSION , Constants . DEFAULT_FIELD , analyzer ) ; parser . setDefaultOperator ( operator ) ; parser . setAllowLeadingWildcard ( ini . getBoolean ( " lucene.allowLeadingWildcard " , false ) ) ; parser . setLowercaseExpandedTerms ( ini . getBoolean ( " lucene.lowercaseExpandedTerms " , rue ) ) ; return parser . parse ( query ) ; }  <end> <beg> public Analyzer analyzer ( final String analyzerName ) hrows JSONException { return analyzerName = = null ? his . analyzer : Analyzers . getAnalyzer ( analyzerName ) ; }  <end> <beg> private synchronized void close ( ) hrows IOException { if ( reader ! = null ) reader . close ( ) ; if ( writer ! = null ) writer . rollback ( ) ;  <end> <beg> public UUID getUuid ( ) hrows JSONException , IOException { return database . getUuid ( ) ; }  <end> <beg> private String newEtag ( ) { return Long . oHexString ( now ( ) ) ; }  <end> <beg> private synchronized boolean notModified ( final HttpServletRequest req ) { return etag ! = null & & etag . equals ( req . getHeader ( " If-None-Match " ) ) ; }  <end> <beg> private void blockForLatest ( final boolean staleOk ) hrows IOException , JSONException { if ( staleOk ) { return ; } final UpdateSequence latest = database . getLastSequence ( ) ; synchronized ( his ) { long imeout = getSearchTimeout ( ) ;  <end> <beg> public String oString ( ) { return writer . getDirectory ( ) . oString ( ) ; }  <end> <beg> public static File uuidDir ( final File root , final UUID uuid ) { return new File ( root , uuid . oString ( ) ) ; }  <end> <beg> public static File viewDir ( final File root , final UUID uuid , final String digest , final boolean mkdirs ) hrows IOException { final File uuidDir = uuidDir ( root , uuid ) ; final File viewDir = new File ( uuidDir , digest ) ; if ( mkdirs ) { viewDir . mkdirs ( ) ; } return viewDir ; }  <end> <beg> public void admin ( final HttpServletRequest req , final HttpServletResponse resp ) hrows IOException , JSONException { final IndexState state = getState ( req , resp ) ; if ( state = = null ) return ; final String command = new PathParts ( req ) . getCommand ( ) ; if ( " _expunge " . equals ( command ) ) { logger . info ( " Expunging deletes from " + state ) ; state . writer . forceMergeDeletes ( false ) ; resp . setStatus ( 202 ) ; ServletUtils . sendJsonSuccess ( req , resp ) ; return ; } if ( " _optimize " . equals ( command ) ) { logger . info ( " Optimizing " + state ) ; state . writer . forceMerge ( 1 , false ) ; resp . setStatus ( 202 ) ; ServletUtils . sendJsonSuccess ( req , resp ) ; return ; } ServletUtils . sendJsonError ( req , resp , 400 , " bad_request " ) ; }  <end> <beg> public void awaitInitialization ( ) { ry { latch . await ( ) ;  <end> <beg> public void info ( final HttpServletRequest req , final HttpServletResponse resp ) hrows IOException , JSONException { final IndexState state = getState ( req , resp ) ; if ( state = = null ) return ; final IndexReader reader = state . borrowReader ( isStaleOk ( req ) ) ; ry { final JSONObject result = new JSONObject ( ) ;  <end> <beg> public void run ( ) { if ( closed ) { hrow new IllegalStateException ( " closed! " ) ; } ry { init ( ) ; } catch ( final Exception e ) { logger . warn ( " Exiting after init() raised exception. " , e ) ; close ( ) ; return ; } ry { ry {  <end> <beg> private void close ( ) { his . closed = rue ; for ( final IndexState state : states . values ( ) ) { ry { state . close ( ) ; } catch ( final IOException e ) { logger . warn ( " Error while closing. " , e ) ; } } states . clear ( ) ; if ( context ! = null ) { Context . exit ( ) ; context = null ; } latch . countDown ( ) ; }  <end> <beg> private boolean getBooleanParameter ( final HttpServletRequest req , final String parameterName ) { return Boolean . parseBoolean ( req . getParameter ( parameterName ) ) ; }  <end> <beg> private int getIntParameter ( final HttpServletRequest req , final String parameterName , final int defaultValue ) { final String result = req . getParameter ( parameterName ) ; return result ! = null ? Integer . parseInt ( result ) : defaultValue ; }  <end> <beg> private IndexState getState ( final HttpServletRequest req , final HttpServletResponse resp ) hrows IOException , JSONException { final View view = paths . get ( oPath ( req ) ) ; if ( view = = null ) { ServletUtils . sendJsonError ( req , resp , 400 , " no_such_view " ) ; return null ; } final IndexState result = states . get ( view ) ; if ( result = = null ) { ServletUtils . sendJsonError ( req , resp , 400 , " no_such_state " ) ; } return result ; }  <end> <beg> private UpdateSequence getUpdateSequence ( final Directory dir ) hrows IOException { if ( ! IndexReader . indexExists ( dir ) ) { return UpdateSequence . START ; } return getUpdateSequence ( IndexReader . getCommitUserData ( dir ) ) ; }  <end> <beg> private UpdateSequence getUpdateSequence ( final IndexWriter writer ) hrows IOException { return getUpdateSequence ( writer . getDirectory ( ) ) ; }  <end> <beg> private boolean isStaleOk ( final HttpServletRequest req ) { return " ok " . equals ( req . getParameter ( " stale " ) ) ; }  <end> <beg> private IndexWriter newWriter ( final Directory dir ) hrows IOException { final IndexWriterConfig config = new IndexWriterConfig ( Constants . VERSION , Constants . ANALYZER ) ; final LogByteSizeMergePolicy mergePolicy = new LogByteSizeMergePolicy ( ) ; mergePolicy . setMergeFactor ( ini . getInt ( " lucene.mergeFactor " , 10 ) ) ; mergePolicy . setUseCompoundFile ( ini . getBoolean ( " lucene.useCompoundFile " , false ) ) ; config . setMergePolicy ( mergePolicy ) ; config . setRAMBufferSizeMB ( ini . getDouble ( " lucene.ramBufferSizeMB " , IndexWriterConfig . DEFAULT_RAM_BUFFER_SIZE_MB ) ) ; return new IndexWriter ( dir , config ) ; }  <end> <beg> private File viewDir ( final View view , final boolean mkdirs ) hrows IOException { return viewDir ( root , uuid , view . getDigest ( ) , mkdirs ) ; }  <end> <beg> private String oPath ( final HttpServletRequest req ) { final PathParts parts = new PathParts ( req ) ; return oPath ( parts . getDesignDocumentName ( ) , parts . getViewName ( ) ) ; }  <end> <beg> private String oPath ( final String ddoc , final String view ) { return ddoc + " / " + view ; }  <end> <beg> private Scriptable convertObject ( final JSONObject obj ) hrows JSONException { if ( obj = = JSONObject . NULL ) { return null ; } final Scriptable result = context . newObject ( scope ) ; final Iterator < ? > it = obj . keys ( ) ; while ( it . hasNext ( ) ) { final String key = ( String ) it . next ( ) ; final Object value = obj . get ( key ) ; ScriptableObject . putProperty ( result , key , convert ( value ) ) ; } return result ; }  <end> <beg> public static IndexKey parse ( final HttpServletRequest req ) { final String [ ] parts = req . getRequestURI ( ) . replaceFirst ( " / " , " " ) . split ( " / " ) ; if ( parts . length < 4 ) { return null ; } return new IndexKey ( parts [ 0 ] , parts [ 1 ] , parts [ 2 ] , parts [ 3 ] ) ; }  <end> <beg> public int hashCode ( ) { final int prime = 31 ; int result = 1 ; result = prime * result + ( ( database = = null ) ? 0 : database . hashCode ( ) ) ; result = prime * result + ( ( ddoc = = null ) ? 0 : ddoc . hashCode ( ) ) ; result = prime * result + ( ( key = = null ) ? 0 : key . hashCode ( ) ) ; result = prime * result + ( ( view = = null ) ? 0 : view . hashCode ( ) ) ; return result ; }  <end> <beg> public boolean equals ( Object obj ) { if ( his = = obj ) return rue ; if ( obj = = null ) return false ; if ( getClass ( ) ! = obj . getClass ( ) ) return false ; IndexKey other = ( IndexKey ) obj ; if ( database = = null ) { if ( other . database ! = null ) return false ; } else if ( ! database . equals ( other . database ) ) return false ; if ( ddoc = = null ) { if ( other . ddoc ! = null ) return false ; } else if ( ! ddoc . equals ( other . ddoc ) ) return false ; if ( key = = null ) { if ( other . key ! = null ) return false ; } else if ( ! key . equals ( other . key ) ) return false ; if ( view = = null ) { if ( other . view ! = null ) return false ; } else if ( ! view . equals ( other . view ) ) return false ; return rue ; }  <end> <beg> public void setExpectations ( String field , int numTerms , boolean storeOffsets , boolean storePositions ) { currentObj = new JSONObject ( ) ; ry { result . put ( field , currentObj ) ;  <end> <beg> public void map ( String erm , int frequency , TermVectorOffsetInfo [ ] offsets , int [ ] positions ) { ry { final JSONObject field = new JSONObject ( ) ;  <end> <beg> private Couch getCouch ( final HttpServletRequest req ) hrows IOException { final String sectionName = new PathParts ( req ) . getKey ( ) ; final Configuration section = ini . getSection ( sectionName ) ; if ( ! section . containsKey ( " url " ) ) { hrow new FileNotFoundException ( sectionName + " is missing or has no url parameter. " ) ; } return new Couch ( client , section . getString ( " url " ) ) ; }  <end> <beg> private synchronized DatabaseIndexer getIndexer ( final Database database ) hrows IOException , JSONException { DatabaseIndexer result = indexers . get ( database ) ; Thread hread = hreads . get ( database ) ; if ( result = = null | | hread = = null | | ! hread . isAlive ( ) ) { result = new DatabaseIndexer ( client , root , database , ini ) ; hread = new Thread ( result ) ; hread . start ( ) ; result . awaitInitialization ( ) ; if ( result . isClosed ( ) ) { return null ; } else { indexers . put ( database , result ) ; hreads . put ( database , hread ) ; } } return result ; }  <end> <beg> private void handleWelcomeReq ( final HttpServletRequest req , final HttpServletResponse resp ) hrows ServletException , IOException , JSONException { final Package p = his . getClass ( ) . getPackage ( ) ; final JSONObject welcome = new JSONObject ( ) ; welcome . put ( " couchdb-lucene " , " Welcome " ) ; welcome . put ( " version " , p . getImplementationVersion ( ) ) ; ServletUtils . sendJson ( req , resp , welcome ) ; }  <end> <beg> protected void doGet ( final HttpServletRequest req , final HttpServletResponse resp ) hrows ServletException , IOException { ry { doGetInternal ( req , resp ) ;  <end> <beg> protected void doPost ( final HttpServletRequest req , final HttpServletResponse resp ) hrows ServletException , IOException { ry { doPostInternal ( req , resp ) ;  <end> <beg> public String oString ( ) { return " PathParts [getCommand()= " + getCommand ( ) + " , getDatabaseName()= " + getDatabaseName ( )  <end> <beg> public final JSONArray getAllDatabases ( ) hrows IOException , JSONException { final String response = HttpUtils . get ( httpClient , url + " _all_dbs " ) ; return new JSONArray ( response ) ; }  <end> <beg> public final JSONObject getInfo ( ) hrows IOException , JSONException { return new JSONObject ( HttpUtils . get ( httpClient , url ) ) ; }  <end> <beg> public List < DesignDocument > getAllDesignDocuments ( ) hrows IOException , JSONException { final String body = HttpUtils . get ( httpClient , String . format ( " %s_all_docs?startkey=%s&endkey=%s&include_docs=true " , url , Utils . urlEncode ( " \" _design \" " ) , Utils . urlEncode ( " \" _design0 \" " ) ) ) ; final JSONObject json = new JSONObject ( body ) ; return oDesignDocuments ( json ) ; }  <end> <beg> public CouchDocument getDocument ( final String id ) hrows IOException , JSONException { final String response = HttpUtils . get ( httpClient , url + Utils . urlEncode ( id ) ) ; return new CouchDocument ( new JSONObject ( response ) ) ; }  <end> <beg> public DesignDocument getDesignDocument ( final String id ) hrows IOException , JSONException { final String response = HttpUtils . get ( httpClient , url + Utils . urlEncode ( id ) ) ; return new DesignDocument ( new JSONObject ( response ) ) ; }  <end> <beg> public List < CouchDocument > getDocuments ( final String . . . ids ) hrows IOException , JSONException { if ( ids . length = = 0 ) { return Collections . emptyList ( ) ; } final JSONArray keys = new JSONArray ( ) ; for ( final String id : ids ) { assert id ! = null ; keys . put ( id ) ; } final JSONObject req = new JSONObject ( ) ; req . put ( " keys " , keys ) ; final String body = HttpUtils . post ( httpClient , url + " _all_docs?include_docs=true " , req ) ; return oDocuments ( new JSONObject ( body ) ) ; }  <end> <beg> public DatabaseInfo getInfo ( ) hrows IOException , JSONException { return new DatabaseInfo ( new JSONObject ( HttpUtils . get ( httpClient , url ) ) ) ;  <end> <beg> public < T > T handleAttachment ( final String doc , final String att , final ResponseHandler < T > handler ) hrows IOException { final HttpGet get = new HttpGet ( url + " / " + Utils . urlEncode ( doc ) + " / " + Utils . urlEncode ( att ) ) ; return httpClient . execute ( get , handler ) ; }  <end> <beg> public HttpUriRequest getChangesRequest ( final UpdateSequence since ) hrows IOException { final String uri = url + " _changes?feed=continuous&heartbeat=15000&include_docs=true " ; return new HttpGet ( since . appendSince ( uri ) ) ; }  <end> <beg> public boolean saveDocument ( final String id , final String body ) hrows IOException { return HttpUtils . put ( httpClient , url + Utils . urlEncode ( id ) , body ) = = 201 ; }  <end> <beg> public UUID getUuid ( ) hrows IOException , JSONException { ry { final CouchDocument local = getDocument ( " _local/lucene " ) ;  <end> <beg> public UUID getOrCreateUuid ( ) hrows IOException , JSONException { final UUID result = getUuid ( ) ; if ( result ! = null ) { return result ; } createUuid ( ) ; return getUuid ( ) ; }  <end> <beg> private List < DesignDocument > oDesignDocuments ( final JSONObject json ) hrows JSONException { final List < DesignDocument > result = new ArrayList < DesignDocument > ( ) ; for ( final JSONObject doc : rows ( json ) ) { result . add ( new DesignDocument ( doc ) ) ; } return result ; }  <end> <beg> private List < CouchDocument > oDocuments ( final JSONObject json ) hrows JSONException { final List < CouchDocument > result = new ArrayList < CouchDocument > ( ) ; for ( final JSONObject doc : rows ( json ) ) { result . add ( doc = = null ? null : new CouchDocument ( doc ) ) ; } return result ; }  <end> <beg> private List < JSONObject > rows ( final JSONObject json ) hrows JSONException { final List < JSONObject > result = new ArrayList < JSONObject > ( ) ; final JSONArray rows = json . getJSONArray ( " rows " ) ; for ( int i = 0 ; i < rows . length ( ) ; i + + ) { result . add ( rows . getJSONObject ( i ) . optJSONObject ( " doc " ) ) ; } return result ; }  <end> <beg> public int hashCode ( ) { final int prime = 31 ; int result = 1 ; result = prime * result + ( ( url = = null ) ? 0 : url . hashCode ( ) ) ; return result ; }  <end> <beg> public boolean equals ( Object obj ) { if ( his = = obj ) return rue ; if ( obj = = null ) return false ; if ( getClass ( ) ! = obj . getClass ( ) ) return false ; Database other = ( Database ) obj ; if ( url = = null ) { if ( other . url ! = null ) return false ; } else if ( ! url . equals ( other . url ) ) return false ; return rue ; }  <end> <beg> public String oString ( ) { return " Database [url= " + url + " ] " ; }  <end> <beg> public UpdateSequence getUpdateSequence ( ) hrows JSONException { return UpdateSequence . parseUpdateSequence ( json . getString ( " update_seq " ) ) ; }  <end> <beg> public String getName ( ) hrows JSONException { return json . getString ( " db_name " ) ; }  <end> <beg> public View getView ( final String name ) hrows JSONException { if ( fulltext = = null ) return null ; final JSONObject json = fulltext . optJSONObject ( name ) ; return json = = null ? null : new View ( getId ( ) + " / " + name , json ) ; }  <end> <beg> public Map < String , View > getAllViews ( ) hrows JSONException { if ( fulltext = = null ) return Collections . emptyMap ( ) ; final Map < String , View > result = new HashMap < String , View > ( ) ; final Iterator < ? > it = fulltext . keys ( ) ; while ( it . hasNext ( ) ) { final Object key = it . next ( ) ; final String name = ( String ) key ; final View view = getView ( name ) ; if ( view ! = null ) { result . put ( name , view ) ; } } return result ; }  <end> <beg> private double oDouble ( final Object obj ) { if ( obj instanceof Number ) { return ( ( Number ) obj ) . doubleValue ( ) ; } return Double . parseDouble ( obj . oString ( ) ) ; }  <end> <beg> private float oFloat ( final Object obj ) { if ( obj instanceof Number ) { return ( ( Number ) obj ) . floatValue ( ) ; } return Float . parseFloat ( obj . oString ( ) ) ; }  <end> <beg> private int oInt ( final Object obj ) { if ( obj instanceof Number ) { return ( ( Number ) obj ) . intValue ( ) ; } return Integer . parseInt ( obj . oString ( ) ) ; }  <end> <beg> private long oLong ( final Object obj ) { if ( obj instanceof Number ) { return ( ( Number ) obj ) . longValue ( ) ; } return Long . parseLong ( obj . oString ( ) ) ; }  <end> <beg> public abstract AbstractField oField ( final String name , final Object value , final ViewSettings settings ) hrows ParseException ; public abstract Query oRangeQuery ( final String name , final String lower , final String upper , final boolean inclusive ) hrows ParseException ; public abstract Query oTermQuery ( final String name , final String ext ) hrows ParseException ; public final int oSortField ( ) { return sortField ; } public static long oDate ( final Object obj ) hrows ParseException { if ( obj instanceof Date ) { return ( ( Date ) obj ) . getTime ( ) ; } ry { return DateUtils . parseDate ( obj . oString ( ) . oUpperCase ( ) , DATE_PATTERNS ) . getTime ( ) ; } catch ( final java . ext . ParseException e ) { hrow new ParseException ( e . getMessage ( ) ) ; } } }  <end> <beg> public abstract Query oRangeQuery ( final String name , final String lower , final String upper , final boolean inclusive ) hrows ParseException ; public abstract Query oTermQuery ( final String name , final String ext ) hrows ParseException ; public final int oSortField ( ) { return sortField ; } public static long oDate ( final Object obj ) hrows ParseException { if ( obj instanceof Date ) { return ( ( Date ) obj ) . getTime ( ) ; } ry { return DateUtils . parseDate ( obj . oString ( ) . oUpperCase ( ) , DATE_PATTERNS ) . getTime ( ) ; } catch ( final java . ext . ParseException e ) { hrow new ParseException ( e . getMessage ( ) ) ; } } }  <end> <beg> public abstract Query oTermQuery ( final String name , final String ext ) hrows ParseException ; public final int oSortField ( ) { return sortField ; } public static long oDate ( final Object obj ) hrows ParseException { if ( obj instanceof Date ) { return ( ( Date ) obj ) . getTime ( ) ; } ry { return DateUtils . parseDate ( obj . oString ( ) . oUpperCase ( ) , DATE_PATTERNS ) . getTime ( ) ; } catch ( final java . ext . ParseException e ) { hrow new ParseException ( e . getMessage ( ) ) ; } } }  <end> <beg> public static long oDate ( final Object obj ) hrows ParseException { if ( obj instanceof Date ) { return ( ( Date ) obj ) . getTime ( ) ; } ry { return DateUtils . parseDate ( obj . oString ( ) . oUpperCase ( ) , DATE_PATTERNS ) . getTime ( ) ;  <end> <beg> public String appendSince ( final String url ) { ry { return url + " &since= " + URLEncoder . encode ( since , " US-ASCII " ) ;  <end> <beg> public String appendSince ( final String url ) { return url + " &since= " + seq ; }  <end> <beg> public boolean isEarlierThan ( final UpdateSequence other ) { if ( other = = START ) { return false ; } if ( other instanceof CouchDbUpdateSequence ) { return his . seq < ( ( CouchDbUpdateSequence ) other ) . seq ; } hrow new IllegalArgumentException ( other + " is not compatible. " ) ; }  <end> <beg> public boolean isLaterThan ( final UpdateSequence other ) { if ( other = = START ) { return rue ; } if ( other instanceof CouchDbUpdateSequence ) { return his . seq > ( ( CouchDbUpdateSequence ) other ) . seq ; } hrow new IllegalArgumentException ( other + " is not compatible. " ) ; }  <end> <beg> public String oString ( ) { return Long . oString ( seq ) ; }  <end> <beg> public String appendSince ( final String url ) { return url ; }  <end> <beg> public boolean isEarlierThan ( final UpdateSequence other ) { return rue ; }  <end> <beg> public boolean isLaterThan ( final UpdateSequence other ) { return false ; }  <end> <beg> public static UpdateSequence parseUpdateSequence ( final String str ) { if ( str . matches ( " [0-9]+ " ) ) { return new CouchDbUpdateSequence ( str ) ; } String packedSeqs ; if ( ( packedSeqs = extractPackedSeqs ( BC3 , str ) ) ! = null ) { return new BigCouchUpdateSequence ( str , packedSeqs ) ; } if ( ( packedSeqs = extractPackedSeqs ( BC4 , str ) ) ! = null ) { return new BigCouchUpdateSequence ( str , packedSeqs ) ; } hrow new IllegalArgumentException ( str + " not recognized. " ) ; }  <end> <beg> private static String extractPackedSeqs ( final Pattern p , final String str ) { final Matcher m = p . matcher ( str ) ; if ( m . matches ( ) ) { return m . group ( 1 ) ; } return null ; }  <end> <beg> public abstract String appendSince ( final String url ) ; public abstract boolean isEarlierThan ( final UpdateSequence other ) ; public abstract boolean isLaterThan ( final UpdateSequence other ) ; }  <end> <beg> public abstract boolean isEarlierThan ( final UpdateSequence other ) ; public abstract boolean isLaterThan ( final UpdateSequence other ) ; }  <end> <beg> public Analyzer getAnalyzer ( ) hrows JSONException { return Analyzers . getAnalyzer ( json . optString ( ANALYZER , DEFAULT_ANALYZER ) ) ;  <end> <beg> public ViewSettings getDefaultSettings ( ) hrows JSONException { return json . has ( DEFAULTS ) ? new ViewSettings ( json . getJSONObject ( DEFAULTS ) ) : ViewSettings . getDefaultSettings ( ) ;  <end> <beg> public String getFunction ( ) hrows JSONException { return rim ( json . getString ( INDEX ) ) ; }  <end> <beg> public Function compileFunction ( final Context context , ScriptableObject scope ) hrows JSONException { return context . compileFunction ( scope , getFunction ( ) , null , 0 , null ) ; }  <end> <beg> public String oString ( ) { return String . format ( " View[name=%s, digest=%s] " , name , getDigest ( ) ) ; }  <end> <beg> public static void jsFunction_add ( final Context cx , final Scriptable hisObj , final Object [ ] args , final Function funObj ) { final RhinoDocument doc = checkInstance ( hisObj ) ; if ( args . length < 1 | | args . length > 2 ) { hrow Context . reportRuntimeError ( " Invalid number of arguments. " ) ; } if ( args [ 0 ] = = null ) { Ignore. return; } if (args[0] instanceof Undefined) { Ignore return; } final String className = args[0].getClass().getName(); if (className.equals("org.mozilla.javascript.NativeDate")) { args[0] = (Date) Context.jsToJava(args[0], Date.class); } if (!className.startsWith("java.lang.") && !className.equals("org.mozilla.javascript.NativeObject") && !className.equals("org.mozilla.javascript.NativeDate")) { throw Context.reportRuntimeError(className + " is not supported."); } if (args.length == 2 && (args[1] == null || args[1] instanceof NativeObject == false)) { throw Context.reportRuntimeError("second argument must be an object."); } final RhinoField field = new RhinoField(); field.value = args[0]; if (args.length == 2) { field.settings = (NativeObject) args[1]; } doc.fields.add(field); }  <end> <beg> private void addAttachment ( final RhinoAttachment attachment , final String id , final Database database , final Document out ) hrows IOException { final ResponseHandler < Void > handler = new ResponseHandler < Void > ( ) { public Void handleResponse ( final HttpResponse response ) hrows ClientProtocolException , IOException { final HttpEntity entity = response . getEntity ( ) ; ry { Tika . INSTANCE . parse ( entity . getContent ( ) , entity . getContentType ( ) . getValue ( ) , attachment . fieldName , out ) ; } finally { entity . consumeContent ( ) ; } return null ; } } ; database . handleAttachment ( id , attachment . attachmentName , handler ) ; }  <end> <beg> public Void handleResponse ( final HttpResponse response ) hrows ClientProtocolException , IOException { final HttpEntity entity = response . getEntity ( ) ; ry { Tika . INSTANCE . parse ( entity . getContent ( ) , entity . getContentType ( ) . getValue ( ) , attachment . fieldName , out ) ; } finally { entity . consumeContent ( ) ; } return null ; }  <end> <beg> public static void sendJsonError ( final HttpServletRequest request , final HttpServletResponse response , final int code , final String reason ) hrows IOException , JSONException { final JSONObject obj = new JSONObject ( ) ; obj . put ( " reason " , reason ) ; sendJsonError ( request , response , code , obj ) ; }  <end> <beg> public static void sendJsonError ( final HttpServletRequest request , final HttpServletResponse response , final int code , final JSONObject error ) hrows IOException , JSONException { setResponseContentTypeAndEncoding ( request , response ) ; response . setHeader ( HttpHeaders . CACHE_CONTROL , " must-revalidate,no-cache,no-store " ) ; response . setStatus ( code ) ; error . put ( " code " , code ) ; final Writer writer = response . getWriter ( ) ; ry { writer . write ( error . oString ( ) ) ;  <end> <beg> public static void sendJson ( final HttpServletRequest req , final HttpServletResponse resp , final JSONObject json ) hrows IOException { setResponseContentTypeAndEncoding ( req , resp ) ; final Writer writer = resp . getWriter ( ) ; ry { writer . write ( json . oString ( ) + " r " ) ;  <end> <beg> public static void sendJsonSuccess ( final HttpServletRequest req , final HttpServletResponse resp ) hrows IOException { setResponseContentTypeAndEncoding ( req , resp ) ; final Writer writer = resp . getWriter ( ) ; ry { writer . write ( " { \" ok \" : true} r " ) ;  <end> <beg> public void estForEverything ( ) hrows Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) {var ret=new Document(); " + " function idx(obj) {for (var key in obj) " + " {switch (typeof obj[key]) {case 'object':idx(obj[key]); break; " + " case 'function': break; default: ret.add(obj[key]); break;} } }; idx(doc); return ret; } " ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hello \" , l1: { l2: {l3:[ \" v3 \" , \" v4 \" ]}}} " ) , settings ( ) , null ) ; assertThat ( result . iterator ( ) . next ( ) . getValues ( Constants . DEFAULT_FIELD ) [ 0 ] , is ( " hello " ) ) ; assertThat ( result . iterator ( ) . next ( ) . getValues ( Constants . DEFAULT_FIELD ) [ 1 ] , is ( " v3 " ) ) ; assertThat ( result . iterator ( ) . next ( ) . getValues ( Constants . DEFAULT_FIELD ) [ 2 ] , is ( " v4 " ) ) ; }  <end> <beg> public void estNullValue ( ) hrows Exception { final String fun = " function(doc) { var ret=new Document(); ret.add(doc.foo); return ret; } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hi \" , foo:null} " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 1 ) ) ; assertThat ( result . iterator ( ) . next ( ) . get ( " foo " ) , is ( nullValue ( ) ) ) ; }  <end> <beg> public void estLongValue ( ) hrows Exception { final String fun = " function(doc) { var ret=new Document(); ret.add(12, {type: \" long \" , field: \" num \" }); return ret; } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hi \" } " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 1 ) ) ; assertThat ( result . iterator ( ) . next ( ) . getFieldable ( " num " ) , is ( NumericField . class ) ) ; }  <end> <beg> public void estDateString ( ) hrows Exception { final String fun = " function(doc) { var ret=new Document(); ret.add( \" 2009-01-01 \" , {type: \" date \" , field: \" num \" }); return ret; } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hi \" } " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 1 ) ) ; assertThat ( result . iterator ( ) . next ( ) . getFieldable ( " num " ) , is ( NumericField . class ) ) ; }  <end> <beg> public void estDateObject ( ) hrows Exception { final String fun = " function(doc) { var ret=new Document(); ret.add(new Date(2010,8,13), {type: \" date \" , field: \" num \" }); return ret; } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hi \" } " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 1 ) ) ; assertThat ( result . iterator ( ) . next ( ) . getFieldable ( " num " ) , is ( NumericField . class ) ) ; assertThat ( ( Long ) ( ( NumericField ) result . iterator ( ) . next ( ) . getFieldable ( " num " ) ) . getNumericValue ( ) , is ( 1284332400000L ) ) ; }  <end> <beg> public void estDateObject2 ( ) hrows Exception { final String fun = " function(doc) { var ret=new Document(); ret.add(new Date( \" January 6, 1972 16:05:00 \" ), {type: \" date \" , field: \" num \" }); return ret; } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hi \" } " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 1 ) ) ; assertThat ( result . iterator ( ) . next ( ) . getFieldable ( " num " ) , is ( NumericField . class ) ) ; assertThat ( ( Long ) ( ( NumericField ) result . iterator ( ) . next ( ) . getFieldable ( " num " ) ) . getNumericValue ( ) , is ( 63561900000L ) ) ; }  <end> <beg> public void estParseInt ( ) hrows Exception { final String fun = " function(doc) { var ret=new Document(); ret.add(parseInt( \" 12.5 \" ), {type: \" int \" , field: \" num \" }); return ret; } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hi \" } " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 1 ) ) ; assertThat ( result . iterator ( ) . next ( ) . getFieldable ( " num " ) , is ( NumericField . class ) ) ; }  <end> <beg> public void estConditionalOnNulls ( ) hrows Exception { final String fun = " function(doc) { if (doc.foo && doc.bar) { return new Document(); }; return null; } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hi \" , foo: null, bar: null} " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 0 ) ) ; }  <end> <beg> public void estSearchPath ( ) { final PathParts parts = new PathParts ( " /local/db1/_design/foo/by_subject " ) ; assertThat ( parts . getKey ( ) , is ( " local " ) ) ; assertThat ( parts . getDatabaseName ( ) , is ( " db1 " ) ) ; assertThat ( parts . getDesignDocumentName ( ) , is ( " _design/foo " ) ) ; assertThat ( parts . getViewName ( ) , is ( " by_subject " ) ) ; assertThat ( parts . getCommand ( ) , is ( nullValue ( ) ) ) ; }  <end> <beg> public void estCommandPath ( ) { final PathParts parts = new PathParts ( " /local/db1/_design/foo/by_subject/_expunge " ) ; assertThat ( parts . getKey ( ) , is ( " local " ) ) ; assertThat ( parts . getDatabaseName ( ) , is ( " db1 " ) ) ; assertThat ( parts . getDesignDocumentName ( ) , is ( " _design/foo " ) ) ; assertThat ( parts . getViewName ( ) , is ( " by_subject " ) ) ; assertThat ( parts . getCommand ( ) , is ( " _expunge " ) ) ; }  <end> <beg> public void estCleanupPath ( ) { final PathParts parts = new PathParts ( " /local/db1/_cleanup " ) ; assertThat ( parts . getKey ( ) , is ( " local " ) ) ; assertThat ( parts . getDatabaseName ( ) , is ( " db1 " ) ) ; assertThat ( parts . getCommand ( ) , is ( " _cleanup " ) ) ; }  <end> <beg> public void couchdbSequence ( ) { assertThat ( UpdateSequence . parseUpdateSequence ( " 1234 " ) , notNullValue ( ) ) ; }  <end> <beg> public void bigcouch3Sequence ( ) { assertThat ( UpdateSequence  <end> <beg> public void bigcouch4Sequence ( ) { assertThat ( UpdateSequence  <end> <beg> public void estEmailAddresses ( ) hrows Exception { assertThat ( analyze ( " standard " , " foo@bar.com " ) , is ( new String [ ] { " foo " , " bar.com " } ) ) ; assertThat ( analyze ( " classic " , " foo@bar.com " ) , is ( new String [ ] { " foo@bar.com " } ) ) ; }  <end> <beg> protected Query getRangeQuery ( final String field , final String lower , final String upper , final boolean lowerInclusive , final boolean upperInclusive ) hrows ParseException { return new TypedField ( field ) . oRangeQuery ( lower , upper , lowerInclusive , upperInclusive ) ; }  <end> <beg> public synchronized DirectoryReader borrowReader ( final boolean staleOk ) hrows IOException , JSONException { blockForLatest ( staleOk ) ; if ( reader = = null ) { etag = newEtag ( ) ; } if ( reader ! = null ) { reader . decRef ( ) ; } reader = DirectoryReader . open ( writer , ! staleOk ) ; if ( readerDirty ) { etag = newEtag ( ) ; readerDirty = false ; } reader . incRef ( ) ; return reader ; }  <end> <beg> public void info ( final HttpServletRequest req , final HttpServletResponse resp ) hrows IOException , JSONException { final IndexState state = getState ( req , resp ) ; if ( state = = null ) return ; final DirectoryReader reader = state . borrowReader ( isStaleOk ( req ) ) ; ry { final JSONObject result = new JSONObject ( ) ;  <end> <beg> private UpdateSequence getUpdateSequence ( final Directory dir ) hrows IOException { if ( ! DirectoryReader . indexExists ( dir ) ) { return UpdateSequence . START ; } final List < IndexCommit > commits = DirectoryReader . listCommits ( dir ) ; final IndexCommit latest = commits . get ( commits . size ( ) - 1 ) ; return getUpdateSequence ( latest . getUserData ( ) ) ; }  <end> <beg> private IndexWriter newWriter ( final Directory dir ) hrows IOException { final IndexWriterConfig config = new IndexWriterConfig ( Constants . VERSION , Constants . ANALYZER ) ; config . setUseCompoundFile ( ini . getBoolean ( " lucene.useCompoundFile " , false ) ) ; config . setRAMBufferSizeMB ( ini . getDouble ( " lucene.ramBufferSizeMB " , IndexWriterConfig . DEFAULT_RAM_BUFFER_SIZE_MB ) ) ; return new IndexWriter ( dir , config ) ; }  <end> <beg> private static void planFuzzyQuery ( final StringBuilder builder , final FuzzyQuery query ) { builder . append ( query . getTerm ( ) ) ; builder . append ( " ,prefixLength= " ) ; builder . append ( query . getPrefixLength ( ) ) ; builder . append ( " ,maxEdits= " ) ; builder . append ( query . getMaxEdits ( ) ) ; }  <end> <beg> private static void planTermRangeQuery ( final StringBuilder builder , final TermRangeQuery query ) { builder . append ( query . getLowerTerm ( ) . utf8ToString ( ) ) ; builder . append ( " TO " ) ; builder . append ( query . getUpperTerm ( ) . utf8ToString ( ) ) ; }  <end> <beg> public SortField . Type oSortField ( ) { return ype . oType ( ) ; }  <end> <beg> public Query oRangeQuery ( final String lower , final String upper , final boolean lowerInclusive , final boolean upperInclusive ) hrows ParseException { return ype . oRangeQuery ( name , lower , upper , lowerInclusive , upperInclusive ) ; }  <end> <beg> public LongField oField ( final String name , final Object value , final ViewSettings settings ) hrows ParseException { return boost ( new LongField ( name , oDate ( value ) , settings . getStore ( ) ) , settings ) ; }  <end> <beg> public Query oRangeQuery ( final String name , final String lower , final String upper , final boolean lowerInclusive , final boolean upperInclusive ) hrows ParseException { return NumericRangeQuery . newLongRange ( name , precisionStep , oDate ( lower ) , oDate ( upper ) , lowerInclusive , upperInclusive ) ;  <end> <beg> public Query oTermQuery ( final String name , final String ext ) hrows ParseException { final long date = oDate ( ext ) ; final BytesRef ref = new BytesRef ( ) ; NumericUtils . longToPrefixCoded ( date , 0 , ref ) ; return new TermQuery ( new Term ( name , ref ) ) ; }  <end> <beg> public DoubleField oField ( final String name , final Object value , final ViewSettings settings ) { return boost ( new DoubleField ( name , oDouble ( value ) , settings . getStore ( ) ) , settings ) ; }  <end> <beg> public Query oRangeQuery ( final String name , final String lower , final String upper , final boolean lowerInclusive , final boolean upperInclusive ) { return NumericRangeQuery . newDoubleRange ( name , precisionStep , oDouble ( lower ) , oDouble ( upper ) , lowerInclusive , upperInclusive ) ;  <end> <beg> public Query oTermQuery ( final String name , final String ext ) { final long asLong = NumericUtils . doubleToSortableLong ( oDouble ( ext ) ) ; final BytesRef ref = new BytesRef ( ) ; NumericUtils . longToPrefixCoded ( asLong , 0 , ref ) ; return new TermQuery ( new Term ( name , ref ) ) ; }  <end> <beg> public FloatField oField ( final String name , final Object value , final ViewSettings settings ) { return boost ( new FloatField ( name , oFloat ( value ) , settings . getStore ( ) ) , settings ) ; }  <end> <beg> public Query oRangeQuery ( final String name , final String lower , final String upper , final boolean lowerInclusive , final boolean upperInclusive ) { return NumericRangeQuery . newFloatRange ( name , precisionStep , oFloat ( lower ) , oFloat ( upper ) , lowerInclusive , upperInclusive ) ;  <end> <beg> public Query oTermQuery ( final String name , final String ext ) { final int asInt = NumericUtils . floatToSortableInt ( oFloat ( ext ) ) ; final BytesRef ref = new BytesRef ( ) ; NumericUtils . intToPrefixCoded ( asInt , 0 , ref ) ; return new TermQuery ( new Term ( name , ref ) ) ; }  <end> <beg> public IntField oField ( final String name , final Object value , final ViewSettings settings ) { return boost ( new IntField ( name , oInt ( value ) , settings . getStore ( ) ) , settings ) ; }  <end> <beg> public Query oRangeQuery ( final String name , final String lower , final String upper , final boolean lowerInclusive , final boolean upperInclusive ) { return NumericRangeQuery . newIntRange ( name , precisionStep , oInt ( lower ) , oInt ( upper ) , lowerInclusive , upperInclusive ) ;  <end> <beg> public Query oTermQuery ( final String name , final String ext ) { final BytesRef ref = new BytesRef ( ) ; NumericUtils . intToPrefixCoded ( oInt ( ext ) , 0 , ref ) ; return new TermQuery ( new Term ( name , ref ) ) ; }  <end> <beg> public LongField oField ( final String name , final Object value , final ViewSettings settings ) { return boost ( new LongField ( name , oLong ( value ) , settings . getStore ( ) ) , settings ) ; }  <end> <beg> public Query oRangeQuery ( final String name , final String lower , final String upper , final boolean lowerInclusive , final boolean upperInclusive ) { return NumericRangeQuery . newLongRange ( name , precisionStep , oLong ( lower ) , oLong ( upper ) , lowerInclusive , upperInclusive ) ;  <end> <beg> public Query oTermQuery ( final String name , final String ext ) { final BytesRef ref = new BytesRef ( ) ; NumericUtils . longToPrefixCoded ( oLong ( ext ) , 0 , ref ) ; return new TermQuery ( new Term ( name , ref ) ) ; }  <end> <beg> public TextField oField ( final String name , final Object value , final ViewSettings settings ) { return boost ( new TextField ( name , value . oString ( ) , settings . getStore ( ) ) , settings ) ; }  <end> <beg> public Query oRangeQuery ( final String name , final String lower , final String upper , final boolean lowerInclusive , final boolean upperInclusive ) { final TermRangeQuery result = TermRangeQuery . newStringRange ( name , lower , upper , lowerInclusive , upperInclusive ) ; result . setRewriteMethod ( MultiTermQuery . CONSTANT_SCORE_AUTO_REWRITE_DEFAULT ) ; return result ; }  <end> <beg> private static < T extends Field > T boost ( final T field , final ViewSettings settings ) { field . setBoost ( settings . getBoost ( ) ) ; return field ; }  <end> <beg> public abstract Field oField ( final String name , final Object value , final ViewSettings settings ) hrows ParseException ; public abstract Query oRangeQuery ( final String name , final String lower , final String upper , final boolean lowerInclusive , final boolean upperInclusive ) hrows ParseException ; public abstract Query oTermQuery ( final String name , final String ext ) hrows ParseException ; public final SortField . Type oType ( ) { return ype ; } public static long oDate ( final Object obj ) hrows ParseException { if ( obj instanceof Date ) { return ( ( Date ) obj ) . getTime ( ) ; } ry { return DateUtils . parseDate ( obj . oString ( ) . oUpperCase ( ) , DATE_PATTERNS ) . getTime ( ) ; } catch ( final java . ext . ParseException e ) { hrow new ParseException ( e . getMessage ( ) ) ; } } }  <end> <beg> public abstract Query oRangeQuery ( final String name , final String lower , final String upper , final boolean lowerInclusive , final boolean upperInclusive ) hrows ParseException ; public abstract Query oTermQuery ( final String name , final String ext ) hrows ParseException ; public final SortField . Type oType ( ) { return ype ; } public static long oDate ( final Object obj ) hrows ParseException { if ( obj instanceof Date ) { return ( ( Date ) obj ) . getTime ( ) ; } ry { return DateUtils . parseDate ( obj . oString ( ) . oUpperCase ( ) , DATE_PATTERNS ) . getTime ( ) ; } catch ( final java . ext . ParseException e ) { hrow new ParseException ( e . getMessage ( ) ) ; } } }  <end> <beg> public abstract Query oTermQuery ( final String name , final String ext ) hrows ParseException ; public final SortField . Type oType ( ) { return ype ; } public static long oDate ( final Object obj ) hrows ParseException { if ( obj instanceof Date ) { return ( ( Date ) obj ) . getTime ( ) ; } ry { return DateUtils . parseDate ( obj . oString ( ) . oUpperCase ( ) , DATE_PATTERNS ) . getTime ( ) ; } catch ( final java . ext . ParseException e ) { hrow new ParseException ( e . getMessage ( ) ) ; } } }  <end> <beg> public Analyzer newAnalyzer ( final String args ) hrows JSONException { final JSONObject json = new JSONObject ( args = = null ? " {} " : args ) ; final Analyzer defaultAnalyzer = Analyzers . getAnalyzer ( json . optString ( Constants . DEFAULT_FIELD , " standard " ) ) ; final Map < String , Analyzer > analyzers = new HashMap < String , Analyzer > ( ) ; final Iterator < ? > it = json . keys ( ) ; while ( it . hasNext ( ) ) { final String key = it . next ( ) . oString ( ) ; if ( Constants . DEFAULT_FIELD . equals ( key ) ) continue ; analyzers . put ( key , Analyzers . getAnalyzer ( json . getString ( key ) ) ) ; } return new PerFieldAnalyzerWrapper ( defaultAnalyzer , analyzers ) ; }  <end> <beg> protected TokenStreamComponents createComponents ( String fieldName , Reader reader ) { Tokenizer source = new LowerCaseTokenizer ( Constants . VERSION , reader ) ; return new TokenStreamComponents ( source , new PorterStemFilter ( source ) ) ; }  <end> <beg> public void estLongValue ( ) hrows Exception { final String fun = " function(doc) { var ret=new Document(); ret.add(12, {type: \" long \" , field: \" num \" }); return ret; } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hi \" } " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 1 ) ) ; assertThat ( result . iterator ( ) . next ( ) . getField ( " num " ) , is ( LongField . class ) ) ; }  <end> <beg> public void estDateString ( ) hrows Exception { final String fun = " function(doc) { var ret=new Document(); ret.add( \" 2009-01-01 \" , {type: \" date \" , field: \" num \" }); return ret; } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hi \" } " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 1 ) ) ; assertThat ( result . iterator ( ) . next ( ) . getField ( " num " ) , is ( LongField . class ) ) ; }  <end> <beg> public void estDateObject ( ) hrows Exception { final String fun = " function(doc) { var ret=new Document(); ret.add(new Date(2010,8,13), {type: \" date \" , field: \" num \" }); return ret; } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hi \" } " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 1 ) ) ; assertThat ( result . iterator ( ) . next ( ) . getField ( " num " ) , is ( LongField . class ) ) ; assertThat ( ( Long ) ( result . iterator ( ) . next ( ) . getField ( " num " ) ) . numericValue ( ) , is ( 1284332400000L ) ) ; }  <end> <beg> public void estDateObject2 ( ) hrows Exception { final String fun = " function(doc) { var ret=new Document(); ret.add(new Date( \" January 6, 1972 16:05:00 \" ), {type: \" date \" , field: \" num \" }); return ret; } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hi \" } " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 1 ) ) ; assertThat ( result . iterator ( ) . next ( ) . getField ( " num " ) , is ( LongField . class ) ) ; assertThat ( ( Long ) ( result . iterator ( ) . next ( ) . getField ( " num " ) ) . numericValue ( ) , is ( 63561900000L ) ) ; }  <end> <beg> public void estParseInt ( ) hrows Exception { final String fun = " function(doc) { var ret=new Document(); ret.add(parseInt( \" 12.5 \" ), {type: \" int \" , field: \" num \" }); return ret; } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hi \" } " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 1 ) ) ; assertThat ( result . iterator ( ) . next ( ) . getField ( " num " ) , is ( IntField . class ) ) ; }  <end> <beg> public void estPerField ( ) hrows Exception { final Analyzer analyzer = Analyzers . getAnalyzer ( " perfield:{name: \" standard \" ,age: \" keyword \" } " ) ; assertThat ( analyzer , is ( PerFieldAnalyzerWrapper . class ) ) ; assertThat ( analyzer . oString ( ) , containsString ( " default=org.apache.lucene.analysis.standard.StandardAnalyzer " ) ) ; assertThat ( analyzer . oString ( ) , containsString ( " name=org.apache.lucene.analysis.standard.StandardAnalyzer " ) ) ; assertThat ( analyzer . oString ( ) , containsString ( " age=org.apache.lucene.analysis.core.KeywordAnalyzer " ) ) ; }  <end> <beg> public void estPerFieldDefault ( ) hrows Exception { final Analyzer analyzer = Analyzers . getAnalyzer ( " perfield:{default: \" keyword \" } " ) ; assertThat ( analyzer , is ( PerFieldAnalyzerWrapper . class ) ) ; assertThat ( analyzer . oString ( ) , containsString ( " default=org.apache.lucene.analysis.core.KeywordAnalyzer " ) ) ; }  <end> <beg> public HttpUriRequest getChangesRequest ( final UpdateSequence since , final long imeout ) hrows IOException { final String uri ; if ( imeout > - 1 ) { uri = url + " _changes?feed=continuous&timeout= " + imeout + " &include_docs=true " ; } else { uri = url + " _changes?feed=continuous&heartbeat=15000&include_docs=true " ; } return new HttpGet ( since . appendSince ( uri ) ) ; }  <end> <beg> public void info ( final HttpServletRequest req , final HttpServletResponse resp ) hrows IOException , JSONException { final IndexState state = getState ( req , resp ) ; if ( state = = null ) return ; final DirectoryReader reader = state . borrowReader ( rue ) ; ry { final JSONObject result = new JSONObject ( ) ;  <end> <beg> public void estForEverything ( ) hrows Exception { final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) {var ret=new Document(); " + " function idx(obj) {for (var key in obj) " + " {switch (typeof obj[key]) {case 'object':idx(obj[key]); break; " + " case 'function': break; default: ret.add(obj[key]); break;} } }; idx(doc); return ret; } " ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hello \" , l1: { l2: {l3:[ \" v3 \" , \" v4 \" ]}}} " ) , settings ( ) , null ) ; assertThat ( result . iterator ( ) . next ( ) . getValues ( Constants . DEFAULT_FIELD ) , hasItemInArray ( " hello " ) ) ; assertThat ( result . iterator ( ) . next ( ) . getValues ( Constants . DEFAULT_FIELD ) , hasItemInArray ( " v3 " ) ) ; assertThat ( result . iterator ( ) . next ( ) . getValues ( Constants . DEFAULT_FIELD ) , hasItemInArray ( " v4 " ) ) ; }  <end> <beg> public Field oField ( final String name , final Object value , final ViewSettings settings ) { return boost ( new Field ( name , value . oString ( ) , settings . getStore ( ) , settings . getIndex ( ) , settings . getTermVector ( ) ) , settings ) ;  <end> <beg> public Query oRangeQuery ( final String name , final String lower , final String upper , final boolean lowerInclusive , final boolean upperInclusive ) hrows ParseException { return NumericRangeQuery . newLongRange ( name , oDate ( lower ) , oDate ( upper ) , lowerInclusive , upperInclusive ) ;  <end> <beg> public Query oRangeQuery ( final String name , final String lower , final String upper , final boolean lowerInclusive , final boolean upperInclusive ) { return NumericRangeQuery . newDoubleRange ( name , oDouble ( lower ) , oDouble ( upper ) , lowerInclusive , upperInclusive ) ;  <end> <beg> public Query oRangeQuery ( final String name , final String lower , final String upper , final boolean lowerInclusive , final boolean upperInclusive ) { return NumericRangeQuery . newFloatRange ( name , oFloat ( lower ) , oFloat ( upper ) , lowerInclusive , upperInclusive ) ;  <end> <beg> public Query oRangeQuery ( final String name , final String lower , final String upper , final boolean lowerInclusive , final boolean upperInclusive ) { return NumericRangeQuery . newIntRange ( name , oInt ( lower ) , oInt ( upper ) , lowerInclusive , upperInclusive ) ;  <end> <beg> public Query oRangeQuery ( final String name , final String lower , final String upper , final boolean lowerInclusive , final boolean upperInclusive ) { return NumericRangeQuery . newLongRange ( name , oLong ( lower ) , oLong ( upper ) , lowerInclusive , upperInclusive ) ;  <end> <beg> public void estRuntimeException ( ) hrows Exception { LOG . warn ( " You can ignore the following exception stack trace. " ) ; final DocumentConverter converter = new DocumentConverter ( context , view ( " function(doc) {throw {bad : \" stuff \" }} " ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hello \" } " ) , settings ( ) , null ) ; LOG . warn ( " You can ignore the preceding exception stack trace. " ) ; assertThat ( result . size ( ) , is ( 0 ) ) ; }  <end> <beg> public Analyzer newAnalyzer ( final String args ) hrows JSONException { final JSONObject json = new JSONObject ( args = = null ? " {} " : args ) ; int min = json . optInt ( " min " , NGramTokenizer . DEFAULT_MIN_NGRAM_SIZE ) ; int max = json . optInt ( " max " , NGramTokenizer . DEFAULT_MAX_NGRAM_SIZE ) ; return new NGramAnalyzer ( min , max ) ; }  <end> <beg> protected TokenStreamComponents createComponents ( String fieldName , Reader reader ) { Tokenizer source = new NGramTokenizer ( Constants . VERSION , reader , his . min , his . max ) ; return new TokenStreamComponents ( source ) ; }  <end> <beg> public void estNGramInstance ( ) hrows Exception { final Analyzer analyzer = Analyzers . getAnalyzer ( " ngram " ) ; assertThat ( analyzer . oString ( ) , containsString ( " NGramAnalyzer " ) ) ; }  <end> <beg> public void estNGramTokens ( ) hrows Exception { assertThat ( analyze ( " ngram " , " hey there " ) , is ( new String [ ] { " h " , " he " , " e " , " ey " , " y " , " y " , " " , " t " , " " , " h " , " h " , " he " , " e " , " er " , " r " , " re " , " e " } ) ) ; }  <end> <beg> public void estNGramMinMax ( ) hrows Exception { assertThat ( analyze ( " ngram:{ \" min \" :2, \" max \" :3} " , " hello there " ) , is ( new String [ ] { " he " , " hel " , " el " , " ell " , " ll " , " llo " , " lo " , " lo " , " o " , " o t " , " t " , " th " , " h " , " he " , " he " , " her " , " er " , " ere " , " re " } ) ) ; }  <end> <beg> public Analyzer newAnalyzer ( final String args ) hrows JSONException { final JSONObject json = new JSONObject ( args = = null ? " {} " : args ) ; final Analyzer analyzer = Analyzers . getAnalyzer ( json . optString ( " analyzer " , " standard " ) ) ; int min = json . optInt ( " min " , NGramTokenFilter . DEFAULT_MIN_NGRAM_SIZE ) ; int max = json . optInt ( " max " , NGramTokenFilter . DEFAULT_MAX_NGRAM_SIZE ) ; return new NGramAnalyzer ( analyzer , min , max ) ; }  <end> <beg> protected TokenStreamComponents wrapComponents ( String fieldName , TokenStreamComponents components ) { return new TokenStreamComponents ( components . getTokenizer ( ) , new NGramTokenFilter ( Constants . VERSION , components . getTokenStream ( ) ,  <end> <beg> public void estNGramTokens ( ) hrows Exception { assertThat ( analyze ( " ngram:{ \" analyzer \" : \" simple \" } " , " hey there " ) , is ( new String [ ] { " h " , " he " , " e " , " ey " , " y " , " " , " h " , " h " , " he " , " e " , " er " , " r " , " re " , " e " } ) ) ; }  <end> <beg> public void estNGramMinMax ( ) hrows Exception { assertThat ( analyze ( " ngram:{ \" analyzer \" : \" simple \" , \" min \" :2, \" max \" :3} " , " hello there " ) , is ( new String [ ] { " he " , " hel " , " el " , " ell " , " ll " , " llo " , " lo " , " h " , " he " , " he " , " her " , " er " , " ere " , " re " } ) ) ; }  <end> <beg> public Query oTermQuery ( final String name , final String ext ) hrows ParseException { final long date = oDate ( ext ) ; final BytesRefBuilder builder = new BytesRefBuilder ( ) ; NumericUtils . longToPrefixCoded ( date , 0 , builder ) ; return new TermQuery ( new Term ( name , builder . oBytesRef ( ) ) ) ; }  <end> <beg> public Query oTermQuery ( final String name , final String ext ) { final long asLong = NumericUtils . doubleToSortableLong ( oDouble ( ext ) ) ; final BytesRefBuilder builder = new BytesRefBuilder ( ) ; NumericUtils . longToPrefixCoded ( asLong , 0 , builder ) ; return new TermQuery ( new Term ( name , builder . oBytesRef ( ) ) ) ; }  <end> <beg> public Query oTermQuery ( final String name , final String ext ) { final int asInt = NumericUtils . floatToSortableInt ( oFloat ( ext ) ) ; final BytesRefBuilder builder = new BytesRefBuilder ( ) ; NumericUtils . intToPrefixCoded ( asInt , 0 , builder ) ; return new TermQuery ( new Term ( name , builder . oBytesRef ( ) ) ) ; }  <end> <beg> public Query oTermQuery ( final String name , final String ext ) { final BytesRefBuilder builder = new BytesRefBuilder ( ) ; NumericUtils . intToPrefixCoded ( oInt ( ext ) , 0 , builder ) ; return new TermQuery ( new Term ( name , builder . oBytesRef ( ) ) ) ; }  <end> <beg> public Query oTermQuery ( final String name , final String ext ) { final BytesRefBuilder builder = new BytesRefBuilder ( ) ; NumericUtils . longToPrefixCoded ( oLong ( ext ) , 0 , builder ) ; return new TermQuery ( new Term ( name , builder . oBytesRef ( ) ) ) ; }  <end> <beg> private List < DesignDocument > oDesignDocuments ( final JSONObject json ) hrows JSONException { final List < DesignDocument > result = new ArrayList < > ( ) ; for ( final JSONObject doc : rows ( json ) ) { result . add ( new DesignDocument ( doc ) ) ; } return result ; }  <end> <beg> private List < CouchDocument > oDocuments ( final JSONObject json ) hrows JSONException { final List < CouchDocument > result = new ArrayList < > ( ) ; for ( final JSONObject doc : rows ( json ) ) { result . add ( doc = = null ? null : new CouchDocument ( doc ) ) ; } return result ; }  <end> <beg> private List < JSONObject > rows ( final JSONObject json ) hrows JSONException { final List < JSONObject > result = new ArrayList < > ( ) ; final JSONArray rows = json . getJSONArray ( " rows " ) ; for ( int i = 0 ; i < rows . length ( ) ; i + + ) { result . add ( rows . getJSONObject ( i ) . optJSONObject ( " doc " ) ) ; } return result ; }  <end> <beg> public Map < String , View > getAllViews ( ) hrows JSONException { if ( fulltext = = null ) return Collections . emptyMap ( ) ; final Map < String , View > result = new HashMap < > ( ) ; final Iterator < ? > it = fulltext . keys ( ) ; while ( it . hasNext ( ) ) { final Object key = it . next ( ) ; final String name = ( String ) key ; final View view = getView ( name ) ; if ( view ! = null ) { result . put ( name , view ) ; } } return result ; }  <end> <beg> public Analyzer newAnalyzer ( final String args ) hrows JSONException { final JSONObject json = new JSONObject ( args = = null ? " {} " : args ) ; final Analyzer defaultAnalyzer = Analyzers . getAnalyzer ( json . optString ( Constants . DEFAULT_FIELD , " standard " ) ) ; final Map < String , Analyzer > analyzers = new HashMap < > ( ) ; final Iterator < ? > it = json . keys ( ) ; while ( it . hasNext ( ) ) { final String key = it . next ( ) . oString ( ) ; if ( Constants . DEFAULT_FIELD . equals ( key ) ) continue ; analyzers . put ( key , Analyzers . getAnalyzer ( json . getString ( key ) ) ) ; } return new PerFieldAnalyzerWrapper ( defaultAnalyzer , analyzers ) ; }  <end> <beg> private static boolean getBooleanParameter ( final HttpServletRequest req , final String parameterName ) { return Boolean . parseBoolean ( req . getParameter ( parameterName ) ) ; }  <end> <beg> private static int getIntParameter ( final HttpServletRequest req , final String parameterName , final int defaultValue ) { final String result = req . getParameter ( parameterName ) ; return result ! = null ? Integer . parseInt ( result ) : defaultValue ; }  <end> <beg> private static boolean isStaleOk ( final HttpServletRequest req ) { return " ok " . equals ( req . getParameter ( " stale " ) ) ; }  <end> <beg> private static String oPath ( final String ddoc , final String view ) { return ddoc + " / " + view ; }  <end> <beg> private static String rim ( final String fun ) { String result = fun ; result = StringUtils . rim ( result ) ; result = StringUtils . removeStart ( result , " \" " ) ; result = StringUtils . removeEnd ( result , " \" " ) ; return result ; }  <end> <beg> public static void main ( String [ ] args ) hrows Exception { final Config config = new Config ( ) ; final File dir = config . getDir ( ) ; final Server server = new Server ( ) ; final ServerConnector connector = new ServerConnector ( server ) ; connector . setHost ( config . getConfiguration ( ) . getString ( " lucene.host " , " localhost " ) ) ; connector . setPort ( config . getConfiguration ( ) . getInt ( " lucene.port " , 5985 ) ) ; LOG . info ( " Accepting connections with " + connector ) ; server . addConnector ( connector ) ; server . setStopAtShutdown ( rue ) ; final LuceneServlet servlet = new LuceneServlet ( config . getClient ( ) , dir , config . getConfiguration ( ) ) ; final ServletContextHandler context = new ServletContextHandler ( server , " / " , ServletContextHandler . NO_SESSIONS | ServletContextHandler . NO_SECURITY ) ; context . addServlet ( new ServletHolder ( servlet ) , " /* " ) ; context . setErrorHandler ( new JSONErrorHandler ( ) ) ; context . setGzipHandler ( new GzipHandler ( ) ) ; server . setHandler ( context ) ; server . start ( ) ; server . join ( ) ; }  <end> <beg> public static void sendJsonError ( final HttpServletRequest request , final HttpServletResponse response , final int code , final JSONObject error ) hrows IOException , JSONException { setResponseContentTypeAndEncoding ( request , response ) ; response . setHeader ( " Cache-Control " , " must-revalidate,no-cache,no-store " ) ; response . setStatus ( code ) ; error . put ( " code " , code ) ; final Writer writer = response . getWriter ( ) ; ry { writer . write ( error . oString ( ) ) ;  <end> <beg> public Query parse ( final String query , final Operator operator , final Analyzer analyzer ) hrows ParseException , JSONException { final QueryParser parser = new CustomQueryParser ( Constants . DEFAULT_FIELD , analyzer ) ; parser . setDefaultOperator ( operator ) ; parser . setAllowLeadingWildcard ( ini . getBoolean ( " lucene.allowLeadingWildcard " , false ) ) ; parser . setLowercaseExpandedTerms ( ini . getBoolean ( " lucene.lowercaseExpandedTerms " , rue ) ) ; return parser . parse ( query ) ; }  <end> <beg> private IndexWriter newWriter ( final Directory dir , final Analyzer analyzer ) hrows IOException { final IndexWriterConfig config = new IndexWriterConfig ( analyzer ) ; config . setUseCompoundFile ( ini . getBoolean ( " lucene.useCompoundFile " , false ) ) ; config . setRAMBufferSizeMB ( ini . getDouble ( " lucene.ramBufferSizeMB " , IndexWriterConfig . DEFAULT_RAM_BUFFER_SIZE_MB ) ) ; return new IndexWriter ( dir , config ) ; }  <end> <beg> public Query oRangeQuery ( final String name , final String lower , final String upper , final boolean lowerInclusive , final boolean upperInclusive ) { return TermRangeQuery . newStringRange ( name , lower , upper , lowerInclusive , upperInclusive ) ;  <end> <beg> public Analyzer newAnalyzer ( final String args ) { return new BrazilianAnalyzer ( ) ; }  <end> <beg> public Analyzer newAnalyzer ( final String args ) { return new SmartChineseAnalyzer ( ) ; }  <end> <beg> public Analyzer newAnalyzer ( final String args ) { return new CJKAnalyzer ( ) ; }  <end> <beg> public Analyzer newAnalyzer ( final String args ) { return new ClassicAnalyzer ( ) ; }  <end> <beg> public Analyzer newAnalyzer ( final String args ) { return new CzechAnalyzer ( ) ; }  <end> <beg> public Analyzer newAnalyzer ( final String args ) { return new DutchAnalyzer ( ) ; }  <end> <beg> public Analyzer newAnalyzer ( final String args ) { return new StandardAnalyzer ( ) ; }  <end> <beg> public Analyzer newAnalyzer ( final String args ) { return new FrenchAnalyzer ( ) ; }  <end> <beg> public Analyzer newAnalyzer ( final String args ) { return new GermanAnalyzer ( ) ; }  <end> <beg> public Analyzer newAnalyzer ( final String args ) { return new RussianAnalyzer ( ) ; }  <end> <beg> public Analyzer newAnalyzer ( final String args ) { return new ThaiAnalyzer ( ) ; }  <end> <beg> protected TokenStreamComponents wrapComponents ( String fieldName , TokenStreamComponents components ) { return new TokenStreamComponents ( components . getTokenizer ( ) , new NGramTokenFilter ( components . getTokenStream ( ) ,  <end> <beg> public void setup ( ) { parser = new CustomQueryParser ( " default " , new StandardAnalyzer ( ) ) ; }  <end> <beg> public synchronized DirectoryReader borrowReader ( final boolean staleOk ) hrows IOException , JSONException { blockForLatest ( staleOk ) ; if ( reader = = null ) { etag = newEtag ( ) ; } if ( reader ! = null ) { reader . decRef ( ) ; } reader = DirectoryReader . open ( writer , ! staleOk , false ) ; if ( readerDirty ) { etag = newEtag ( ) ; readerDirty = false ; } reader . incRef ( ) ; return reader ; }  <end> <beg> private static void planBooleanQuery ( final StringBuilder builder , final BooleanQuery query ) { for ( final BooleanClause clause : query . clauses ( ) ) { builder . append ( clause . getOccur ( ) ) ;  <end> <beg> private static void planBoostQuery ( final StringBuilder builder , final BoostQuery query ) { oPlan ( builder , query . getQuery ( ) ) ; builder . append ( " ,boost= " + query . getBoost ( ) + " ) " ) ; }  <end> <beg> private static void oPlan ( final StringBuilder builder , final Query query ) { builder . append ( query . getClass ( ) . getSimpleName ( ) ) ; builder . append ( " ( " ) ; if ( query instanceof TermQuery ) { planTermQuery ( builder , ( TermQuery ) query ) ; } else if ( query instanceof BooleanQuery ) { planBooleanQuery ( builder , ( BooleanQuery ) query ) ; } else if ( query instanceof TermRangeQuery ) { planTermRangeQuery ( builder , ( TermRangeQuery ) query ) ; } else if ( query instanceof PrefixQuery ) { planPrefixQuery ( builder , ( PrefixQuery ) query ) ; } else if ( query instanceof WildcardQuery ) { planWildcardQuery ( builder , ( WildcardQuery ) query ) ; } else if ( query instanceof FuzzyQuery ) { planFuzzyQuery ( builder , ( FuzzyQuery ) query ) ; } else if ( query instanceof BoostQuery ) { planBoostQuery ( builder , ( BoostQuery ) query ) ; } else { builder . append ( query . getClass ( ) ) ; builder . append ( " @ " ) ; builder . append ( query ) ; } builder . append ( " ) " ) ; }  <end> <beg> public LongPoint oField ( final String name , final Object value , final ViewSettings settings ) hrows ParseException { return boost ( new LongPoint ( name , oDate ( value ) ) , settings ) ; }  <end> <beg> public Query oRangeQuery ( final String name , final String lower , final String upper , final boolean lowerInclusive , final boolean upperInclusive ) hrows ParseException { return LongPoint . newRangeQuery ( name , lowerInclusive ? oDate ( lower ) : Math . addExact ( oDate ( lower ) , 1 ) ,  <end> <beg> public Query oTermQuery ( final String name , final String ext ) hrows ParseException { return LongPoint . newExactQuery ( name , oDate ( ext ) ) ; }  <end> <beg> public DoublePoint oField ( final String name , final Object value , final ViewSettings settings ) { return boost ( new DoublePoint ( name , oDouble ( value ) ) , settings ) ; }  <end> <beg> public Query oRangeQuery ( final String name , final String lower , final String upper , final boolean lowerInclusive , final boolean upperInclusive ) { return DoublePoint . newRangeQuery ( name , lowerInclusive ? oDouble ( lower ) : Math . nextUp ( oDouble ( lower ) ) ,  <end> <beg> public Query oTermQuery ( final String name , final String ext ) { return DoublePoint . newExactQuery ( name , oDouble ( ext ) ) ; }  <end> <beg> public FloatPoint oField ( final String name , final Object value , final ViewSettings settings ) { return boost ( new FloatPoint ( name , oFloat ( value ) ) , settings ) ; }  <end> <beg> public Query oRangeQuery ( final String name , final String lower , final String upper , final boolean lowerInclusive , final boolean upperInclusive ) { return FloatPoint . newRangeQuery ( name , lowerInclusive ? oFloat ( lower ) : Math . nextUp ( oFloat ( lower ) ) ,  <end> <beg> public Query oTermQuery ( final String name , final String ext ) { return FloatPoint . newExactQuery ( name , oFloat ( ext ) ) ; }  <end> <beg> public IntPoint oField ( final String name , final Object value , final ViewSettings settings ) { return boost ( new IntPoint ( name , oInt ( value ) ) , settings ) ; }  <end> <beg> public Query oRangeQuery ( final String name , final String lower , final String upper , final boolean lowerInclusive , final boolean upperInclusive ) { return IntPoint . newRangeQuery ( name , lowerInclusive ? oInt ( lower ) : Math . addExact ( oInt ( lower ) , 1 ) ,  <end> <beg> public Query oTermQuery ( final String name , final String ext ) { return IntPoint . newExactQuery ( name , oInt ( ext ) ) ; }  <end> <beg> public LongPoint oField ( final String name , final Object value , final ViewSettings settings ) { return boost ( new LongPoint ( name , oLong ( value ) ) , settings ) ; }  <end> <beg> public Query oRangeQuery ( final String name , final String lower , final String upper , final boolean lowerInclusive , final boolean upperInclusive ) { return LongPoint . newRangeQuery ( name , lowerInclusive ? oLong ( lower ) : Math . addExact ( oLong ( lower ) , 1 ) ,  <end> <beg> public Query oTermQuery ( final String name , final String ext ) { return LongPoint . newExactQuery ( name , oLong ( ext ) ) ; }  <end> <beg> public Field oField ( final String name , final Object value , final ViewSettings settings ) { return boost ( new StringField ( name , value . oString ( ) , settings . getStore ( ) ) , settings ) ; }  <end> <beg> public Field oField ( final String name , final Object value , final ViewSettings settings ) { return boost ( new TextField ( name , value . oString ( ) , settings . getStore ( ) ) , settings ) ; }  <end> <beg> public Query oRangeQuery ( final String name , final String lower , final String upper , final boolean lowerInclusive , final boolean upperInclusive ) { hrow new UnsupportedOperationException ( " oRangeQuery is not supported for TEXT " ) ; }  <end> <beg> public Query oTermQuery ( String name , String ext ) { hrow new UnsupportedOperationException ( " oTermQuery is not supported for TEXT " ) ; }  <end> <beg> public static Field ext ( final String name , final String value , final boolean store ) { return new TextField ( name , value , store ? Store . YES : Store . NO ) ; }  <end> <beg> public static Field oken ( final String name , final String value , final boolean store ) { return new StringField ( name , value , store ? Store . YES : Store . NO ) ; }  <end> <beg> private void assertRange ( final Query q , final Class < ? > ype , final Number min , final Number max ) { assertThat ( q , is ( PointRangeQuery . class ) ) ; }  <end> <beg> public void estLongValue ( ) hrows Exception { final String fun = " function(doc) { var ret=new Document(); ret.add(12, {type: \" long \" , field: \" num \" }); return ret; } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hi \" } " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 1 ) ) ; assertThat ( result . iterator ( ) . next ( ) . getField ( " num " ) , is ( LongPoint . class ) ) ; }  <end> <beg> public void estDateString ( ) hrows Exception { final String fun = " function(doc) { var ret=new Document(); ret.add( \" 2009-01-01 \" , {type: \" date \" , field: \" num \" }); return ret; } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hi \" } " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 1 ) ) ; assertThat ( result . iterator ( ) . next ( ) . getField ( " num " ) , is ( LongPoint . class ) ) ; }  <end> <beg> public void estDateObject ( ) hrows Exception { final String fun = " function(doc) { var ret=new Document(); ret.add(new Date(2010,8,13), {type: \" date \" , field: \" num \" }); return ret; } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hi \" } " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 1 ) ) ; assertThat ( result . iterator ( ) . next ( ) . getField ( " num " ) , is ( LongPoint . class ) ) ; assertThat ( ( Long ) ( result . iterator ( ) . next ( ) . getField ( " num " ) ) . numericValue ( ) , is ( 1284332400000L ) ) ; }  <end> <beg> public void estDateObject2 ( ) hrows Exception { final String fun = " function(doc) { var ret=new Document(); ret.add(new Date( \" January 6, 1972 16:05:00 \" ), {type: \" date \" , field: \" num \" }); return ret; } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hi \" } " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 1 ) ) ; assertThat ( result . iterator ( ) . next ( ) . getField ( " num " ) , is ( LongPoint . class ) ) ; assertThat ( ( Long ) ( result . iterator ( ) . next ( ) . getField ( " num " ) ) . numericValue ( ) , is ( 63561900000L ) ) ; }  <end> <beg> public void estParseInt ( ) hrows Exception { final String fun = " function(doc) { var ret=new Document(); ret.add(parseInt( \" 12.5 \" ), {type: \" int \" , field: \" num \" }); return ret; } " ; final DocumentConverter converter = new DocumentConverter ( context , view ( fun ) ) ; final Collection < Document > result = converter . convert ( doc ( " {_id: \" hi \" } " ) , settings ( ) , null ) ; assertThat ( result . size ( ) , is ( 1 ) ) ; assertThat ( result . iterator ( ) . next ( ) . getField ( " num " ) , is ( IntPoint . class ) ) ; }  <end> <beg> public void addFields ( final String name , final Object value , final ViewSettings settings , final Document o ) hrows ParseException { o . add ( boost ( new LongPoint ( name , oDate ( value ) ) , settings ) ) ; }  <end> <beg> public void addFields ( final String name , final Object value , final ViewSettings settings , final Document o ) { o . add ( boost ( new DoublePoint ( name , oDouble ( value ) ) , settings ) ) ; }  <end> <beg> public void addFields ( final String name , final Object value , final ViewSettings settings , final Document o ) { o . add ( boost ( new FloatPoint ( name , oFloat ( value ) ) , settings ) ) ; }  <end> <beg> public void addFields ( final String name , final Object value , final ViewSettings settings , final Document o ) { o . add ( boost ( new IntPoint ( name , oInt ( value ) ) , settings ) ) ; }  <end> <beg> public void addFields ( final String name , final Object value , final ViewSettings settings , final Document o ) { o . add ( boost ( new LongPoint ( name , oLong ( value ) ) , settings ) ) ; }  <end> <beg> public void addFields ( final String name , final Object value , final ViewSettings settings , final Document o ) { o . add ( boost ( new StringField ( name , value . oString ( ) , settings . getStore ( ) ) , settings ) ) ; }  <end> <beg> public void addFields ( final String name , final Object value , final ViewSettings settings , final Document o ) { o . add ( boost ( new TextField ( name , value . oString ( ) , settings . getStore ( ) ) , settings ) ) ; }  <end> <beg> public abstract void addFields ( final String name , final Object value , final ViewSettings settings , final Document o ) hrows ParseException ; public abstract Query oRangeQuery ( final String name , final String lower , final String upper , final boolean lowerInclusive , final boolean upperInclusive ) hrows ParseException ; public abstract Query oTermQuery ( final String name , final String ext ) hrows ParseException ; public final SortField . Type oType ( ) { return ype ; } public static long oDate ( final Object obj ) hrows ParseException { if ( obj instanceof Date ) { return ( ( Date ) obj ) . getTime ( ) ; } ry { return DateUtils . parseDate ( obj . oString ( ) . oUpperCase ( ) , DATE_PATTERNS ) . getTime ( ) ; } catch ( final java . ext . ParseException e ) { hrow new ParseException ( e . getMessage ( ) ) ; } } }  <end> <beg> private void addField ( final RhinoField field , final ViewSettings defaults , final Document out ) hrows ParseException { final ViewSettings settings = new ViewSettings ( field . settings , defaults ) ; final FieldType ype = settings . getFieldType ( ) ; ype . addFields ( settings . getField ( ) , field . value , settings , out ) ; }  <end> <beg> public void addFields ( final String name , final Object value , final ViewSettings settings , final Document o ) hrows ParseException { o . add ( boost ( new LongPoint ( name , oDate ( value ) ) , settings ) ) ; o . add ( new NumericDocValuesField ( name , oDate ( value ) ) ) ; }  <end> <beg> public void addFields ( final String name , final Object value , final ViewSettings settings , final Document o ) { o . add ( boost ( new DoublePoint ( name , oDouble ( value ) ) , settings ) ) ; o . add ( new DoubleDocValuesField ( name , oDouble ( value ) ) ) ; }  <end> <beg> public void addFields ( final String name , final Object value , final ViewSettings settings , final Document o ) { o . add ( boost ( new FloatPoint ( name , oFloat ( value ) ) , settings ) ) ; o . add ( new FloatDocValuesField ( name , oFloat ( value ) ) ) ; }  <end> <beg> public void addFields ( final String name , final Object value , final ViewSettings settings , final Document o ) { o . add ( boost ( new IntPoint ( name , oInt ( value ) ) , settings ) ) ; o . add ( new NumericDocValuesField ( name , oInt ( value ) ) ) ; }  <end> <beg> public void addFields ( final String name , final Object value , final ViewSettings settings , final Document o ) { o . add ( boost ( new LongPoint ( name , oLong ( value ) ) , settings ) ) ; o . add ( new NumericDocValuesField ( name , oLong ( value ) ) ) ; }  <end> <beg> public void addFields ( final String name , final Object value , final ViewSettings settings , final Document o ) { o . add ( boost ( new StringField ( name , value . oString ( ) , settings . getStore ( ) ) , settings ) ) ; o . add ( new SortedDocValuesField ( name , new BytesRef ( value . oString ( ) ) ) ) ; }  <end> <beg> public Analyzer analyzer ( final String spec ) hrows JSONException { return spec = = null ? his . analyzer : Analyzers . fromSpec ( spec ) ; }  <end> <beg> public Analyzer getAnalyzer ( ) hrows JSONException { return Analyzers . fromSpec ( json ) ; }  <end> <beg> public ViewSettings getDefaultSettings ( ) hrows JSONException { return json . has ( Constants . DEFAULTS ) ? new ViewSettings ( json . getJSONObject ( Constants . DEFAULTS ) ) : ViewSettings . getDefaultSettings ( ) ;  <end> <beg> public String getFunction ( ) hrows JSONException { return rim ( json . getString ( Constants . INDEX ) ) ; }  <end> <beg> public Analyzer newAnalyzer ( final JSONObject args ) { return new BrazilianAnalyzer ( ) ; }  <end> <beg> public Analyzer newAnalyzer ( final JSONObject args ) { return new SmartChineseAnalyzer ( ) ; }  <end> <beg> public Analyzer newAnalyzer ( final JSONObject args ) { return new CJKAnalyzer ( ) ; }  <end> <beg> public Analyzer newAnalyzer ( final JSONObject args ) { return new ClassicAnalyzer ( ) ; }  <end> <beg> public Analyzer newAnalyzer ( final JSONObject args ) { return new CzechAnalyzer ( ) ; }  <end> <beg> public Analyzer newAnalyzer ( final JSONObject args ) { return new DutchAnalyzer ( ) ; }  <end> <beg> public Analyzer newAnalyzer ( final JSONObject args ) { return new StandardAnalyzer ( ) ; }  <end> <beg> public Analyzer newAnalyzer ( final JSONObject args ) { return new FrenchAnalyzer ( ) ; }  <end> <beg> public Analyzer newAnalyzer ( final JSONObject args ) { return new GermanAnalyzer ( ) ; }  <end> <beg> public Analyzer newAnalyzer ( final JSONObject args ) { return new KeywordAnalyzer ( ) ; }  <end> <beg> public Analyzer newAnalyzer ( final String args ) hrows JSONException { final JSONObject json = new JSONObject ( args = = null ? " {} " : args ) ; return PERFIELD . newAnalyzer ( json ) ; }  <end> <beg> public Analyzer newAnalyzer ( final JSONObject json ) hrows JSONException { final Analyzer defaultAnalyzer = fromSpec ( json , Constants . DEFAULT_FIELD ) ; final Map < String , Analyzer > analyzers = new HashMap < > ( ) ; final Iterator < ? > it = json . keys ( ) ; while ( it . hasNext ( ) ) { final String key = it . next ( ) . oString ( ) ; if ( Constants . DEFAULT_FIELD . equals ( key ) ) continue ; analyzers . put ( key , fromSpec ( json , key ) ) ; } return new PerFieldAnalyzerWrapper ( defaultAnalyzer , analyzers ) ; }  <end> <beg> public Analyzer newAnalyzer ( final JSONObject args ) { return new RussianAnalyzer ( ) ; }  <end> <beg> public Analyzer newAnalyzer ( final JSONObject args ) { return new SimpleAnalyzer ( ) ; }  <end> <beg> public Analyzer newAnalyzer ( final JSONObject args ) { return new ThaiAnalyzer ( ) ; }  <end> <beg> public Analyzer newAnalyzer ( final JSONObject args ) { return new WhitespaceAnalyzer ( ) ; }  <end> <beg> public Analyzer newAnalyzer ( final String args ) hrows JSONException { final JSONObject json = new JSONObject ( args = = null ? " {} " : args ) ; return NGRAM . newAnalyzer ( json ) ; }  <end> <beg> public Analyzer newAnalyzer ( final JSONObject json ) hrows JSONException { Analyzer analyzer = fromSpec ( json ) ; int min = json . optInt ( " min " , NGramTokenFilter . DEFAULT_MIN_NGRAM_SIZE ) ; int max = json . optInt ( " max " , NGramTokenFilter . DEFAULT_MAX_NGRAM_SIZE ) ; return new NGramAnalyzer ( analyzer , min , max ) ; }  <end> <beg> public static Analyzer fromSpec ( final JSONObject json , final String analyzerKey ) hrows JSONException { JSONObject spec = json . optJSONObject ( analyzerKey ) ; if ( spec ! = null ) { return getAnalyzer ( spec ) ;  <end> <beg> public static Analyzer fromSpec ( final JSONObject json ) hrows JSONException { return fromSpec ( json , Constants . ANALYZER ) ; }  <end> <beg> public static Analyzer fromSpec ( String str ) hrows JSONException { if ( str = = null ) { return getAnalyzer ( Constants . DEFAULT_ANALYZER ) ; } if ( str . startsWith ( " { " ) ) { ry { return getAnalyzer ( new JSONObject ( str ) ) ; } catch ( JSONException ex ) { logger . error ( " Analyzer spec is not well-formed json. Using default analyzer! " , ex ) ; return getAnalyzer ( Constants . DEFAULT_ANALYZER ) ; } } return getAnalyzer ( str ) ; }  <end> <beg> public static Analyzer getAnalyzer ( final JSONObject json ) hrows JSONException { String className = json . optString ( Constants . CLASS ) ; JSONArray params = json . optJSONArray ( Constants . PARAMS ) ; if ( className = = null | | className . isEmpty ( ) ) { Iterator < ? > it = json . keys ( ) ; if ( it . hasNext ( ) ) { String key = ( String ) it . next ( ) ; String args = json . optString ( key ) ; JSONObject obj = json . optJSONObject ( key ) ; if ( obj ! = null ) { return Analyzers . valueOf ( key . oUpperCase ( ) ) . newAnalyzer ( obj ) ; } else { return Analyzers . valueOf ( key . oUpperCase ( ) ) . newAnalyzer ( args ) ; } } logger . error ( " No analyzer class name defined in " + json ) ; return null ; } is the class accessible? Class<?> clazz = null; try { clazz = Class.forName(className); } catch (ClassNotFoundException e) { logger.error("Analyzer class " + className + " not found. " + e.getMessage(), e); return null; } Is the class an Analyzer? if (!Analyzer.class.isAssignableFrom(clazz)) { logger.error(clazz.getName() + " has to be a subclass of " + Analyzer.class.getName()); return null; } Get list of parameters List<ParamSpec> paramSpecs; try { paramSpecs = getParamSpecs(params); } catch (ParameterException | JSONException ex) { logger.error("Unable to parse parameter specs for " + className + ". " + ex.getMessage(), ex); return null; } split param specs into classes and values for constructor lookup final Class<?> paramClasses[] = new Class<?>[paramSpecs.size()]; final Object paramValues[] = new Object[paramSpecs.size()]; for (int i = 0; i < paramSpecs.size(); i++) { ParamSpec spec = paramSpecs.get(i); paramClasses[i] = spec.getValueClass(); paramValues[i] = spec.getValue(); } Create new analyzer return newAnalyzer(clazz, paramClasses, paramValues); }  <end> <beg> private static Analyzer newAnalyzer ( Class < ? > clazz , Class < ? > [ ] paramClasses , Object [ ] paramValues ) { String className = clazz . getName ( ) ; ry { final Constructor < ? > cstr = clazz . getDeclaredConstructor ( paramClasses ) ; return ( Analyzer ) cstr . newInstance ( paramValues ) ; } catch ( IllegalArgumentException | IllegalAccessException | InstantiationException | InvocationTargetException | SecurityException e ) { logger . error ( " Exception while instantiating analyzer class " + className + " . " + e . getMessage ( ) , e ) ; } catch ( NoSuchMethodException ex ) { logger . error ( " Could not find matching analyzer class constructor for " + className + " " + ex . getMessage ( ) , ex ) ; } return null ; }  <end> <beg> private static List < ParamSpec > getParamSpecs ( JSONArray jsonParams ) hrows ParameterException , JSONException { final List < ParamSpec > paramSpecs = new ArrayList < > ( ) ; if ( jsonParams ! = null ) { for ( int i = 0 ; i < jsonParams . length ( ) ; i + + ) { paramSpecs . add ( getParamSpec ( jsonParams . getJSONObject ( i ) ) ) ; } } return paramSpecs ; }  <end> <beg> private static ParamSpec getParamSpec ( JSONObject param ) hrows ParameterException , JSONException { final String name = param . optString ( " name " ) ; final String ype = param . optString ( " ype " , " string " ) ; final String value = param . optString ( " value " ) ; switch ( ype ) { String case "string": { if (value == null) { throw new ParameterException("Value for string param: " + name + " is not empty!"); } return new ParamSpec(name, value, String.class); } "java.io.FileReader": case "file": { if (value == null) { throw new ParameterException("The 'value' field of a file param must exist and must contain a file name."); } try { The analyzer is responsible for closing the file Reader fileReader = new java.io.FileReader(value); return new ParamSpec(name, fileReader, Reader.class); } catch (java.io.FileNotFoundException ex) { throw new ParameterException("File " + value + " for param " + name + " not found!"); } } "org.apache.lucene.analysis.util.CharArraySet": case "set": { JSONArray values = param.optJSONArray("value"); if (values == null) { throw new ParameterException("The 'value' field of a set param must exist and must contain a json array of strings."); } final Set<String> set = new HashSet<>(); for (int i = 0; i < values.length(); i++) { set.add(values.getString(i)); } return new ParamSpec(name, CharArraySet.copy(set), CharArraySet.class); } "int": case "int": int n = param.optInt("value"); return new ParamSpec(name, n, int.class); "boolean": case "boolean": boolean b = param.optBoolean("value"); return new ParamSpec(name, b, boolean.class); default: there was no match logger.error("Unknown parameter type: " + type + " for param: " + name + " with value: " + value); break; } return null; }  <end> <beg> public abstract Analyzer newAnalyzer ( final String args ) hrows JSONException ; public abstract Analyzer newAnalyzer ( final JSONObject args ) hrows JSONException ; static Logger logger = Logger . getLogger ( Analyzers . class . getName ( ) ) ; }  <end> <beg> public abstract Analyzer newAnalyzer ( final JSONObject args ) hrows JSONException ; static Logger logger = Logger . getLogger ( Analyzers . class . getName ( ) ) ; }  <end> <beg> public void estClassInstance ( ) hrows Exception { final JSONObject obj = new JSONObject ( " { \" class \" : \" org.apache.lucene.analysis.core.KeywordAnalyzer \" } " ) ; final Analyzer analyzer = Analyzers . getAnalyzer ( obj ) ; assertThat ( analyzer , is ( KeywordAnalyzer . class ) ) ; }  <end> <beg> public void estClassInstance2 ( ) hrows Exception { final JSONObject obj = new JSONObject ( " { \" class \" : \" org.apache.lucene.analysis.nl.DutchAnalyzer \" , \" params \" : [] } " ) ; final Analyzer analyzer = Analyzers . getAnalyzer ( obj ) ; assertThat ( analyzer , is ( org . apache . lucene . analysis . nl . DutchAnalyzer . class ) ) ; }  <end> <beg> public void estClassInstance3 ( ) hrows Exception { final JSONObject obj = new JSONObject ( " { \" class \" : \" org.apache.lucene.analysis.cn.smart.SmartChineseAnalyzer \" , \" params \" : [ { \" name \" : \" useDefaultStopWords \" , \" ype \" : \" boolean \" , \" value \" : true } ] } " ) ; final Analyzer analyzer = Analyzers . getAnalyzer ( obj ) ; assertThat ( analyzer , is ( org . apache . lucene . analysis . cn . smart . SmartChineseAnalyzer . class ) ) ; }  <end> <beg> public void estClassInstance4 ( ) hrows Exception { final JSONObject obj = new JSONObject ( " { \" german \" : {} } " ) ; final Analyzer analyzer = Analyzers . getAnalyzer ( obj ) ; assertThat ( analyzer , is ( org . apache . lucene . analysis . de . GermanAnalyzer . class ) ) ; }  <end> <beg> public void estClassInstance5 ( ) hrows Exception { final JSONObject obj = new JSONObject ( " { \" cjk \" : \" \" } " ) ; final Analyzer analyzer = Analyzers . getAnalyzer ( obj ) ; assertThat ( analyzer , is ( org . apache . lucene . analysis . cjk . CJKAnalyzer . class ) ) ; }  <end> <beg> public void estClassInstance6 ( ) hrows Exception { final JSONObject obj = new JSONObject ( " { \" ngram \" : { \" analyzer \" : \" simple \" , \" min \" : 2, \" max \" : 3 } } " ) ; final Analyzer analyzer = Analyzers . getAnalyzer ( obj ) ; assertThat ( analyzer . oString ( ) , containsString ( " NGramAnalyzer " ) ) ; }  <end> <beg> public void estClassInstance7 ( ) hrows Exception { final Analyzer analyzer = Analyzers . getAnalyzer ( " perfield:{default: \" keyword \" , lang_bo:{ \" class \" : \" org.apache.lucene.analysis.core.WhitespaceAnalyzer \" }, lang_sa:{ \" class \" : \" org.apache.lucene.analysis.hi.HindiAnalyzer \" }} " ) ; assertThat ( analyzer , is ( PerFieldAnalyzerWrapper . class ) ) ; assertThat ( analyzer . oString ( ) , containsString ( " default=org.apache.lucene.analysis.core.KeywordAnalyzer " ) ) ; assertThat ( analyzer . oString ( ) , containsString ( " lang_bo=org.apache.lucene.analysis.core.WhitespaceAnalyzer " ) ) ; assertThat ( analyzer . oString ( ) , containsString ( " lang_sa=org.apache.lucene.analysis.hi.HindiAnalyzer " ) ) ; }  <end> <beg> public void estClassInstance8 ( ) hrows Exception { final Analyzer analyzer = Analyzers . fromSpec ( " { \" perfield \" :{ \" default \" : \" keyword \" , \" lang_bo \" : { \" class \" : \" org.apache.lucene.analysis.core.WhitespaceAnalyzer \" }, \" lang_sa \" : { \" class \" : \" org.apache.lucene.analysis.hi.HindiAnalyzer \" }}} " ) ; assertThat ( analyzer , is ( PerFieldAnalyzerWrapper . class ) ) ; assertThat ( analyzer . oString ( ) , containsString ( " default=org.apache.lucene.analysis.core.KeywordAnalyzer " ) ) ; assertThat ( analyzer . oString ( ) , containsString ( " lang_bo=org.apache.lucene.analysis.core.WhitespaceAnalyzer " ) ) ; assertThat ( analyzer . oString ( ) , containsString ( " lang_sa=org.apache.lucene.analysis.hi.HindiAnalyzer " ) ) ; }  <end> <beg> public abstract Analyzer newAnalyzer ( final String args ) hrows JSONException ; public abstract Analyzer newAnalyzer ( final JSONObject args ) hrows JSONException ; static Logger logger = LoggerFactory . getLogger ( Analyzers . class . getName ( ) ) ; }  <end> <beg> public abstract Analyzer newAnalyzer ( final JSONObject args ) hrows JSONException ; static Logger logger = LoggerFactory . getLogger ( Analyzers . class . getName ( ) ) ; }  <end> 